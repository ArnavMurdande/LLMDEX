[
  {
    "model_id": null,
    "model_slug": "gemini-31-pro-preview",
    "canonical_name": "Gemini 3.1 Pro Preview",
    "model_name": "Gemini 3.1 Pro Preview",
    "aliases": [
      "Gemini 3.1 Pro Preview",
      "gemini-3.1-pro-preview"
    ],
    "provider": "Google",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": 4052,
    "license_type": "Proprietary",
    "creator": "Google",
    "intelligence_score": 57.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1500.36,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 4.5,
    "latency_seconds": 34.07,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 93.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.400191+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 3.1 Pro Preview",
        "raw_scores": {
          "intelligence_score": 57.0,
          "blended_cost_per_1m": 4.5,
          "latency_seconds": 34.07,
          "tokens_per_second": 93.0,
          "context_window": 1000000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.827609+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-3.1-pro-preview",
        "raw_scores": {
          "arena_elo": 1500.36,
          "arena_votes": 4052
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 57.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1500.36
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gpt-53-codex",
    "canonical_name": "GPT-5.3 Codex (xhigh)",
    "model_name": "GPT-5.3 Codex (xhigh)",
    "aliases": [
      "GPT-5.3 Codex (xhigh)"
    ],
    "provider": "OpenAI",
    "context_window": 400000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "OpenAI",
    "intelligence_score": 54.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 4.81,
    "latency_seconds": 62.7,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 98.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.400291+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5.3 Codex (xhigh)",
        "raw_scores": {
          "intelligence_score": 54.0,
          "blended_cost_per_1m": 4.81,
          "latency_seconds": 62.7,
          "tokens_per_second": 98.0,
          "context_window": 400000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 54.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "claude-opus-46",
    "canonical_name": "Claude Opus 4.6 (max)",
    "model_name": "Claude Opus 4.6 (max)",
    "aliases": [
      "Claude Opus 4.6",
      "Claude Opus 4.6 (max)",
      "claude-opus-4.6",
      "claude-opus-4.6-thinking"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 7454,
    "license_type": "Proprietary",
    "creator": "Anthropic",
    "intelligence_score": 49.5,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1503.18,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 10.0,
    "latency_seconds": 1.735,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 70.5,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.400322+00:00",
        "confidence": 0.65,
        "raw_name": "Claude Opus 4.6 (max)",
        "raw_scores": {
          "intelligence_score": 53.0,
          "blended_cost_per_1m": 10.0,
          "latency_seconds": 1.77,
          "tokens_per_second": 72.0,
          "context_window": 200000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.400567+00:00",
        "confidence": 0.65,
        "raw_name": "Claude Opus 4.6",
        "raw_scores": {
          "intelligence_score": 46.0,
          "blended_cost_per_1m": 10.0,
          "latency_seconds": 1.7,
          "tokens_per_second": 69.0,
          "context_window": 200000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.827539+00:00",
        "confidence": 1.0,
        "raw_name": "claude-opus-4.6-thinking",
        "raw_scores": {
          "arena_elo": 1503.45,
          "arena_votes": 6583
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.827587+00:00",
        "confidence": 1.0,
        "raw_name": "claude-opus-4.6",
        "raw_scores": {
          "arena_elo": 1502.91,
          "arena_votes": 7454
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 53.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1503.45
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "claude-sonnet-46",
    "canonical_name": "Claude Sonnet 4.6 (max)",
    "model_name": "Claude Sonnet 4.6 (max)",
    "aliases": [
      "Claude Sonnet 4.6",
      "Claude Sonnet 4.6 (Non-reasoning, Low Effort)",
      "Claude Sonnet 4.6 (max)",
      "claude-sonnet-4.6"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 3470,
    "license_type": "Proprietary",
    "creator": "Anthropic",
    "intelligence_score": 46.3333,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1458.05,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 6.0,
    "latency_seconds": 0.8233,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 58.6667,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.400346+00:00",
        "confidence": 0.65,
        "raw_name": "Claude Sonnet 4.6 (max)",
        "raw_scores": {
          "intelligence_score": 52.0,
          "blended_cost_per_1m": 6.0,
          "latency_seconds": 0.85,
          "tokens_per_second": 59.0,
          "context_window": 200000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.400665+00:00",
        "confidence": 0.65,
        "raw_name": "Claude Sonnet 4.6",
        "raw_scores": {
          "intelligence_score": 44.0,
          "blended_cost_per_1m": 6.0,
          "latency_seconds": 0.69,
          "tokens_per_second": 56.0,
          "context_window": 200000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.400747+00:00",
        "confidence": 0.65,
        "raw_name": "Claude Sonnet 4.6 (Non-reasoning, Low Effort)",
        "raw_scores": {
          "intelligence_score": 43.0,
          "blended_cost_per_1m": 6.0,
          "latency_seconds": 0.93,
          "tokens_per_second": 61.0,
          "context_window": 200000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.827776+00:00",
        "confidence": 1.0,
        "raw_name": "claude-sonnet-4.6",
        "raw_scores": {
          "arena_elo": 1458.05,
          "arena_votes": 3470
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 52.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1458.05
      }
    },
    "confidence_score": 0.7375,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gpt-52",
    "canonical_name": "GPT-5.2 (xhigh)",
    "model_name": "GPT-5.2 (xhigh)",
    "aliases": [
      "GPT-5.2",
      "GPT-5.2 (medium)",
      "GPT-5.2 (xhigh)",
      "gpt-5.2",
      "gpt-5.2-chat-latest-20260210",
      "gpt-5.2-high"
    ],
    "provider": "OpenAI",
    "context_window": 400000,
    "open_source": null,
    "arena_votes": 19253,
    "license_type": "Proprietary",
    "creator": "OpenAI",
    "intelligence_score": 44.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1452.9067,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 4.81,
    "latency_seconds": 12.8567,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 59.3333,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.400370+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5.2 (xhigh)",
        "raw_scores": {
          "intelligence_score": 51.0,
          "blended_cost_per_1m": 4.81,
          "latency_seconds": 37.97,
          "tokens_per_second": 98.0,
          "context_window": 400000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.400545+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5.2 (medium)",
        "raw_scores": {
          "intelligence_score": 47.0,
          "blended_cost_per_1m": 4.81,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 400000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.401528+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5.2",
        "raw_scores": {
          "intelligence_score": 34.0,
          "blended_cost_per_1m": 4.81,
          "latency_seconds": 0.6,
          "tokens_per_second": 80.0,
          "context_window": 400000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.827653+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-5.2-chat-latest-20260210",
        "raw_scores": {
          "arena_elo": 1481.31,
          "arena_votes": 3605
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.827966+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-5.2-high",
        "raw_scores": {
          "arena_elo": 1440.87,
          "arena_votes": 19253
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828003+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-5.2",
        "raw_scores": {
          "arena_elo": 1436.54,
          "arena_votes": 16113
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 51.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1481.31
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "glm-5",
    "canonical_name": "GLM-5",
    "model_name": "GLM-5",
    "aliases": [
      "GLM-5",
      "glm-5"
    ],
    "provider": "Z.ai",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 6466,
    "license_type": "MIT",
    "creator": "Z AI",
    "intelligence_score": 50.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1455.43,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.55,
    "latency_seconds": 1.29,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 68.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.400393+00:00",
        "confidence": 0.65,
        "raw_name": "GLM-5",
        "raw_scores": {
          "intelligence_score": 50.0,
          "blended_cost_per_1m": 1.55,
          "latency_seconds": 1.29,
          "tokens_per_second": 68.0,
          "context_window": 200000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.827802+00:00",
        "confidence": 1.0,
        "raw_name": "glm-5",
        "raw_scores": {
          "arena_elo": 1455.43,
          "arena_votes": 6466
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 50.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1455.43
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "claude-opus-45",
    "canonical_name": "Claude Opus 4.5",
    "model_name": "Claude Opus 4.5",
    "aliases": [
      "Claude Opus 4.5",
      "claude-opus-4.5-20251101",
      "claude-opus-4.5-20251101-thinking-32k"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 35476,
    "license_type": "Proprietary",
    "creator": "Anthropic",
    "intelligence_score": 50.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1469.045,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 10.0,
    "latency_seconds": 1.37,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 78.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.400414+00:00",
        "confidence": 0.65,
        "raw_name": "Claude Opus 4.5",
        "raw_scores": {
          "intelligence_score": 50.0,
          "blended_cost_per_1m": 10.0,
          "latency_seconds": 1.37,
          "tokens_per_second": 78.0,
          "context_window": 200000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.827702+00:00",
        "confidence": 1.0,
        "raw_name": "claude-opus-4.5-20251101-thinking-32k",
        "raw_scores": {
          "arena_elo": 1470.96,
          "arena_votes": 30541
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.827734+00:00",
        "confidence": 1.0,
        "raw_name": "claude-opus-4.5-20251101",
        "raw_scores": {
          "arena_elo": 1467.13,
          "arena_votes": 35476
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 50.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1470.96
      }
    },
    "confidence_score": 0.8833,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gpt-52-codex",
    "canonical_name": "GPT-5.2 Codex (xhigh)",
    "model_name": "GPT-5.2 Codex (xhigh)",
    "aliases": [
      "GPT-5.2 Codex (xhigh)"
    ],
    "provider": "OpenAI",
    "context_window": 400000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "OpenAI",
    "intelligence_score": 49.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 4.81,
    "latency_seconds": 19.21,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 89.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.400447+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5.2 Codex (xhigh)",
        "raw_scores": {
          "intelligence_score": 49.0,
          "blended_cost_per_1m": 4.81,
          "latency_seconds": 19.21,
          "tokens_per_second": 89.0,
          "context_window": 400000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 49.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemini-3-pro",
    "canonical_name": "Gemini 3 Pro Preview (high)",
    "model_name": "Gemini 3 Pro Preview (high)",
    "aliases": [
      "Gemini 3 Pro Preview (high)",
      "Gemini 3 Pro Preview (low)",
      "gemini-3-pro"
    ],
    "provider": "Google",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": 38248,
    "license_type": "Proprietary",
    "creator": "Google",
    "intelligence_score": 44.5,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1486.23,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 4.5,
    "latency_seconds": 16.395,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 134.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.400474+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 3 Pro Preview (high)",
        "raw_scores": {
          "intelligence_score": 48.0,
          "blended_cost_per_1m": 4.5,
          "latency_seconds": 28.65,
          "tokens_per_second": 140.0,
          "context_window": 1000000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.400923+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 3 Pro Preview (low)",
        "raw_scores": {
          "intelligence_score": 41.0,
          "blended_cost_per_1m": 4.5,
          "latency_seconds": 4.14,
          "tokens_per_second": 128.0,
          "context_window": 1000000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.827639+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-3-pro",
        "raw_scores": {
          "arena_elo": 1486.23,
          "arena_votes": 38248
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 48.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1486.23
      }
    },
    "confidence_score": 0.7667,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gpt-51",
    "canonical_name": "GPT-5.1 (high)",
    "model_name": "GPT-5.1 (high)",
    "aliases": [
      "GPT-5.1",
      "GPT-5.1 (high)",
      "gpt-5.1",
      "gpt-5.1-high"
    ],
    "provider": "OpenAI",
    "context_window": 400000,
    "open_source": null,
    "arena_votes": 36738,
    "license_type": "Proprietary",
    "creator": "OpenAI",
    "intelligence_score": 37.5,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1446.86,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.44,
    "latency_seconds": 17.35,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 99.5,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.400498+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5.1 (high)",
        "raw_scores": {
          "intelligence_score": 48.0,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 34.03,
          "tokens_per_second": 108.0,
          "context_window": 400000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402273+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5.1",
        "raw_scores": {
          "intelligence_score": 27.0,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 0.67,
          "tokens_per_second": 91.0,
          "context_window": 400000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.827789+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-5.1-high",
        "raw_scores": {
          "arena_elo": 1456.77,
          "arena_votes": 34379
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.827991+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-5.1",
        "raw_scores": {
          "arena_elo": 1436.95,
          "arena_votes": 36738
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 48.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1456.77
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "kimi-k25",
    "canonical_name": "Kimi K2.5",
    "model_name": "Kimi K2.5",
    "aliases": [
      "Kimi K2.5",
      "kimi-k2.5-thinking"
    ],
    "provider": "Moonshot",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": 11075,
    "license_type": "Modified MIT",
    "creator": "Kimi",
    "intelligence_score": 47.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1451.66,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.2,
    "latency_seconds": 1.28,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 42.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.400519+00:00",
        "confidence": 0.65,
        "raw_name": "Kimi K2.5",
        "raw_scores": {
          "intelligence_score": 47.0,
          "blended_cost_per_1m": 1.2,
          "latency_seconds": 1.28,
          "tokens_per_second": 42.0,
          "context_window": 256000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.827840+00:00",
        "confidence": 1.0,
        "raw_name": "kimi-k2.5-thinking",
        "raw_scores": {
          "arena_elo": 1451.66,
          "arena_votes": 11075
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 47.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1451.66
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemini-3-flash",
    "canonical_name": "Gemini 3 Flash",
    "model_name": "Gemini 3 Flash",
    "aliases": [
      "Gemini 3 Flash",
      "gemini-3-flash",
      "gemini-3-flash (thinking-minimal)"
    ],
    "provider": "Google",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": 29334,
    "license_type": "Proprietary",
    "creator": "Google",
    "intelligence_score": 46.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1467.19,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.13,
    "latency_seconds": 11.59,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 217.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.400587+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 3 Flash",
        "raw_scores": {
          "intelligence_score": 46.0,
          "blended_cost_per_1m": 1.13,
          "latency_seconds": 11.59,
          "tokens_per_second": 217.0,
          "context_window": 1000000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.827666+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-3-flash",
        "raw_scores": {
          "arena_elo": 1473.23,
          "arena_votes": 29334
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.827760+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-3-flash (thinking-minimal)",
        "raw_scores": {
          "arena_elo": 1461.15,
          "arena_votes": 20672
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 46.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1473.23
      }
    },
    "confidence_score": 0.8833,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen35-397b",
    "canonical_name": "Qwen3.5 397B A17B",
    "model_name": "Qwen3.5 397B A17B",
    "aliases": [
      "Qwen3.5 397B A17B",
      "qwen3.5-397b-a17b"
    ],
    "provider": "Alibaba",
    "context_window": 262000,
    "open_source": null,
    "arena_votes": 4958,
    "license_type": "Apache 2.0",
    "creator": "Alibaba",
    "intelligence_score": 45.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1453.57,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.35,
    "latency_seconds": 1.44,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 87.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.400606+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3.5 397B A17B",
        "raw_scores": {
          "intelligence_score": 45.0,
          "blended_cost_per_1m": 1.35,
          "latency_seconds": 1.44,
          "tokens_per_second": 87.0,
          "context_window": 262000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.827814+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3.5-397b-a17b",
        "raw_scores": {
          "arena_elo": 1453.57,
          "arena_votes": 4958
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 45.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1453.57
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gpt-5",
    "canonical_name": "GPT-5 (high)",
    "model_name": "GPT-5 (high)",
    "aliases": [
      "GPT-5 (ChatGPT)",
      "GPT-5 (high)",
      "GPT-5 (low)",
      "GPT-5 (medium)",
      "GPT-5 (minimal)",
      "gpt-5-chat",
      "gpt-5-high"
    ],
    "provider": "OpenAI",
    "context_window": 400000,
    "open_source": null,
    "arena_votes": 32346,
    "license_type": "Proprietary",
    "creator": "OpenAI",
    "intelligence_score": 34.4,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1430.08,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.44,
    "latency_seconds": 36.86,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 105.4,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.400626+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5 (high)",
        "raw_scores": {
          "intelligence_score": 45.0,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 102.36,
          "tokens_per_second": 91.0,
          "context_window": 400000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.400805+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5 (medium)",
        "raw_scores": {
          "intelligence_score": 42.0,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 54.32,
          "tokens_per_second": 92.0,
          "context_window": 400000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.401103+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5 (low)",
        "raw_scores": {
          "intelligence_score": 39.0,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 26.17,
          "tokens_per_second": 93.0,
          "context_window": 400000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402823+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5 (minimal)",
        "raw_scores": {
          "intelligence_score": 24.0,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 0.95,
          "tokens_per_second": 71.0,
          "context_window": 400000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403245+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5 (ChatGPT)",
        "raw_scores": {
          "intelligence_score": 22.0,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 0.5,
          "tokens_per_second": 180.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828041+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-5-high",
        "raw_scores": {
          "arena_elo": 1434.12,
          "arena_votes": 32346
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828114+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-5-chat",
        "raw_scores": {
          "arena_elo": 1426.04,
          "arena_votes": 31603
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 45.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1434.12
      }
    },
    "confidence_score": 0.75,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gpt-5-codex",
    "canonical_name": "GPT-5 Codex (high)",
    "model_name": "GPT-5 Codex (high)",
    "aliases": [
      "GPT-5 Codex (high)"
    ],
    "provider": "OpenAI",
    "context_window": 400000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "OpenAI",
    "intelligence_score": 45.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.44,
    "latency_seconds": 12.87,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 350.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.400646+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5 Codex (high)",
        "raw_scores": {
          "intelligence_score": 45.0,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 12.87,
          "tokens_per_second": 350.0,
          "context_window": 400000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 45.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gpt-51-codex",
    "canonical_name": "GPT-5.1 Codex (high)",
    "model_name": "GPT-5.1 Codex (high)",
    "aliases": [
      "GPT-5.1 Codex (high)"
    ],
    "provider": "OpenAI",
    "context_window": 400000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "OpenAI",
    "intelligence_score": 43.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.44,
    "latency_seconds": 15.96,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 235.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.400685+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5.1 Codex (high)",
        "raw_scores": {
          "intelligence_score": 43.0,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 15.96,
          "tokens_per_second": 235.0,
          "context_window": 400000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 43.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "claude-45-sonnet",
    "canonical_name": "Claude 4.5 Sonnet",
    "model_name": "Claude 4.5 Sonnet",
    "aliases": [
      "Claude 4.5 Sonnet"
    ],
    "provider": "Anthropic",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Anthropic",
    "intelligence_score": 43.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 6.0,
    "latency_seconds": 1.06,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 75.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.400727+00:00",
        "confidence": 0.65,
        "raw_name": "Claude 4.5 Sonnet",
        "raw_scores": {
          "intelligence_score": 43.0,
          "blended_cost_per_1m": 6.0,
          "latency_seconds": 1.06,
          "tokens_per_second": 75.0,
          "context_window": 1000000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 43.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "glm-47",
    "canonical_name": "GLM-4.7",
    "model_name": "GLM-4.7",
    "aliases": [
      "GLM-4.7",
      "glm-4.7"
    ],
    "provider": "Z.ai",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 11937,
    "license_type": "MIT",
    "creator": "Z AI",
    "intelligence_score": 42.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1440.77,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.94,
    "latency_seconds": 0.67,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 106.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.400767+00:00",
        "confidence": 0.65,
        "raw_name": "GLM-4.7",
        "raw_scores": {
          "intelligence_score": 42.0,
          "blended_cost_per_1m": 0.94,
          "latency_seconds": 0.67,
          "tokens_per_second": 106.0,
          "context_window": 200000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.827979+00:00",
        "confidence": 1.0,
        "raw_name": "glm-4.7",
        "raw_scores": {
          "arena_elo": 1440.77,
          "arena_votes": 11937
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 42.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1440.77
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen35-27b",
    "canonical_name": "Qwen3.5 27B",
    "model_name": "Qwen3.5 27B",
    "aliases": [
      "Qwen3.5 27B"
    ],
    "provider": "Alibaba",
    "context_window": 262000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 42.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.82,
    "latency_seconds": 1.4,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 100.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.400786+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3.5 27B",
        "raw_scores": {
          "intelligence_score": 42.0,
          "blended_cost_per_1m": 0.82,
          "latency_seconds": 1.4,
          "tokens_per_second": 100.0,
          "context_window": 262000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 42.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "minimax-m25",
    "canonical_name": "MiniMax-M2.5",
    "model_name": "MiniMax-M2.5",
    "aliases": [
      "MiniMax-M2.5",
      "minimax-m2.5"
    ],
    "provider": "MiniMax",
    "context_window": 205000,
    "open_source": null,
    "arena_votes": 6065,
    "license_type": "Modified MIT",
    "creator": "MiniMax",
    "intelligence_score": 42.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1401.47,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.53,
    "latency_seconds": 3.35,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 55.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.400825+00:00",
        "confidence": 0.65,
        "raw_name": "MiniMax-M2.5",
        "raw_scores": {
          "intelligence_score": 42.0,
          "blended_cost_per_1m": 0.53,
          "latency_seconds": 3.35,
          "tokens_per_second": 55.0,
          "context_window": 205000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828597+00:00",
        "confidence": 1.0,
        "raw_name": "minimax-m2.5",
        "raw_scores": {
          "arena_elo": 1401.47,
          "arena_votes": 6065
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 42.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1401.47
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-v32",
    "canonical_name": "DeepSeek V3.2",
    "model_name": "DeepSeek V3.2",
    "aliases": [
      "DeepSeek V3.2",
      "deepseek-v3.2",
      "deepseek-v3.2-thinking"
    ],
    "provider": "DeepSeek",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 30709,
    "license_type": "MIT",
    "creator": "DeepSeek",
    "intelligence_score": 42.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1419.975,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.32,
    "latency_seconds": 1.33,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 39.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.400844+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek V3.2",
        "raw_scores": {
          "intelligence_score": 42.0,
          "blended_cost_per_1m": 0.32,
          "latency_seconds": 1.33,
          "tokens_per_second": 39.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828263+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-v3.2-thinking",
        "raw_scores": {
          "arena_elo": 1420.12,
          "arena_votes": 25692
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828277+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-v3.2",
        "raw_scores": {
          "arena_elo": 1419.83,
          "arena_votes": 30709
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 42.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1420.12
      }
    },
    "confidence_score": 0.8833,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen35-122b-a10b",
    "canonical_name": "Qwen3.5 122B A10B",
    "model_name": "Qwen3.5 122B A10B",
    "aliases": [
      "Qwen3.5 122B A10B"
    ],
    "provider": "Alibaba",
    "context_window": 262000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 42.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.1,
    "latency_seconds": 1.13,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 170.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.400864+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3.5 122B A10B",
        "raw_scores": {
          "intelligence_score": 42.0,
          "blended_cost_per_1m": 1.1,
          "latency_seconds": 1.13,
          "tokens_per_second": 170.0,
          "context_window": 262000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 42.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "grok-4",
    "canonical_name": "Grok 4",
    "model_name": "Grok 4",
    "aliases": [
      "Grok 4",
      "grok-4-0709"
    ],
    "provider": "xAI",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": 41753,
    "license_type": "Proprietary",
    "creator": "xAI",
    "intelligence_score": 42.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1409.41,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 6.0,
    "latency_seconds": 15.13,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 43.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.400884+00:00",
        "confidence": 0.65,
        "raw_name": "Grok 4",
        "raw_scores": {
          "intelligence_score": 42.0,
          "blended_cost_per_1m": 6.0,
          "latency_seconds": 15.13,
          "tokens_per_second": 43.0,
          "context_window": 256000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828503+00:00",
        "confidence": 1.0,
        "raw_name": "grok-4-0709",
        "raw_scores": {
          "arena_elo": 1409.41,
          "arena_votes": 41753
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 42.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1409.41
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "mimo-v2-flash",
    "canonical_name": "MiMo-V2-Flash (Feb 2026)",
    "model_name": "MiMo-V2-Flash (Feb 2026)",
    "aliases": [
      "MiMo-V2-Flash",
      "MiMo-V2-Flash (Feb 2026)",
      "mimo-v2-flash (non-thinking)",
      "mimo-v2-flash (thinking)"
    ],
    "provider": "Xiaomi",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": 19661,
    "license_type": "MIT",
    "creator": "Xiaomi",
    "intelligence_score": 40.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1388.7,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.15,
    "latency_seconds": 1.24,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 166.5,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.400904+00:00",
        "confidence": 0.65,
        "raw_name": "MiMo-V2-Flash (Feb 2026)",
        "raw_scores": {
          "intelligence_score": 41.0,
          "blended_cost_per_1m": 0.15,
          "latency_seconds": 1.2,
          "tokens_per_second": 166.0,
          "context_window": 256000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.401083+00:00",
        "confidence": 0.65,
        "raw_name": "MiMo-V2-Flash",
        "raw_scores": {
          "intelligence_score": 39.0,
          "blended_cost_per_1m": 0.15,
          "latency_seconds": 1.28,
          "tokens_per_second": 167.0,
          "context_window": 256000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828736+00:00",
        "confidence": 1.0,
        "raw_name": "mimo-v2-flash (non-thinking)",
        "raw_scores": {
          "arena_elo": 1390.49,
          "arena_votes": 19661
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828832+00:00",
        "confidence": 1.0,
        "raw_name": "mimo-v2-flash (thinking)",
        "raw_scores": {
          "arena_elo": 1386.91,
          "arena_votes": 10870
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 41.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1390.49
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gpt-5-mini",
    "canonical_name": "GPT-5 mini (high)",
    "model_name": "GPT-5 mini (high)",
    "aliases": [
      "GPT-5 mini (high)",
      "GPT-5 mini (medium)",
      "GPT-5 mini (minimal)",
      "gpt-5-mini-high"
    ],
    "provider": "OpenAI",
    "context_window": 400000,
    "open_source": null,
    "arena_votes": 26941,
    "license_type": "Proprietary",
    "creator": "OpenAI",
    "intelligence_score": 33.6667,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1390.38,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.69,
    "latency_seconds": 47.4167,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 72.3333,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.400943+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5 mini (high)",
        "raw_scores": {
          "intelligence_score": 41.0,
          "blended_cost_per_1m": 0.69,
          "latency_seconds": 108.5,
          "tokens_per_second": 75.0,
          "context_window": 400000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.401123+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5 mini (medium)",
        "raw_scores": {
          "intelligence_score": 39.0,
          "blended_cost_per_1m": 0.69,
          "latency_seconds": 32.93,
          "tokens_per_second": 67.0,
          "context_window": 400000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403415+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5 mini (minimal)",
        "raw_scores": {
          "intelligence_score": 21.0,
          "blended_cost_per_1m": 0.69,
          "latency_seconds": 0.82,
          "tokens_per_second": 75.0,
          "context_window": 400000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828748+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-5-mini-high",
        "raw_scores": {
          "arena_elo": 1390.38,
          "arena_votes": 26941
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 41.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1390.38
      }
    },
    "confidence_score": 0.7375,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "kimi-k2-thinking",
    "canonical_name": "Kimi K2 Thinking",
    "model_name": "Kimi K2 Thinking",
    "aliases": [
      "Kimi K2 Thinking"
    ],
    "provider": "Moonshot",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Kimi",
    "intelligence_score": 41.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.07,
    "latency_seconds": 0.64,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 66.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.400963+00:00",
        "confidence": 0.65,
        "raw_name": "Kimi K2 Thinking",
        "raw_scores": {
          "intelligence_score": 41.0,
          "blended_cost_per_1m": 1.07,
          "latency_seconds": 0.64,
          "tokens_per_second": 66.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 41.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "o3-pro",
    "canonical_name": "o3-pro",
    "model_name": "o3-pro",
    "aliases": [
      "o3-pro"
    ],
    "provider": "OpenAI",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "OpenAI",
    "intelligence_score": 41.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 35.0,
    "latency_seconds": 141.25,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 21.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.400982+00:00",
        "confidence": 0.65,
        "raw_name": "o3-pro",
        "raw_scores": {
          "intelligence_score": 41.0,
          "blended_cost_per_1m": 35.0,
          "latency_seconds": 141.25,
          "tokens_per_second": 21.0,
          "context_window": 200000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 41.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-max",
    "canonical_name": "Qwen3 Max Thinking",
    "model_name": "Qwen3 Max Thinking",
    "aliases": [
      "Qwen3 Max",
      "Qwen3 Max (Preview)",
      "Qwen3 Max Thinking",
      "Qwen3 Max Thinking (Preview)",
      "qwen3-max-2025-09-23",
      "qwen3-max-preview"
    ],
    "provider": "Alibaba",
    "context_window": 262000,
    "open_source": null,
    "arena_votes": 27642,
    "license_type": "Proprietary",
    "creator": "Alibaba",
    "intelligence_score": 32.25,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1429.365,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 2.4,
    "latency_seconds": 1.905,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 37.75,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.401043+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 Max Thinking",
        "raw_scores": {
          "intelligence_score": 40.0,
          "blended_cost_per_1m": 2.4,
          "latency_seconds": 1.8,
          "tokens_per_second": 38.0,
          "context_window": 256000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.401683+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 Max Thinking (Preview)",
        "raw_scores": {
          "intelligence_score": 32.0,
          "blended_cost_per_1m": 2.4,
          "latency_seconds": 1.78,
          "tokens_per_second": 51.0,
          "context_window": 262000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.401797+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 Max",
        "raw_scores": {
          "intelligence_score": 31.0,
          "blended_cost_per_1m": 2.4,
          "latency_seconds": 2.21,
          "tokens_per_second": 27.0,
          "context_window": 262000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402465+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 Max (Preview)",
        "raw_scores": {
          "intelligence_score": 26.0,
          "blended_cost_per_1m": 2.4,
          "latency_seconds": 1.83,
          "tokens_per_second": 35.0,
          "context_window": 262000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828016+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-max-preview",
        "raw_scores": {
          "arena_elo": 1434.2,
          "arena_votes": 27642
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828139+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-max-2025-09-23",
        "raw_scores": {
          "arena_elo": 1424.53,
          "arena_votes": 9170
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 40.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1434.2
      }
    },
    "confidence_score": 0.7667,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "minimax-m21",
    "canonical_name": "MiniMax-M2.1",
    "model_name": "MiniMax-M2.1",
    "aliases": [
      "MiniMax-M2.1"
    ],
    "provider": "MiniMax",
    "context_window": 205000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "MiniMax",
    "intelligence_score": 39.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.53,
    "latency_seconds": 3.2,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 51.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.401063+00:00",
        "confidence": 0.65,
        "raw_name": "MiniMax-M2.1",
        "raw_scores": {
          "intelligence_score": 39.0,
          "blended_cost_per_1m": 0.53,
          "latency_seconds": 3.2,
          "tokens_per_second": 51.0,
          "context_window": 205000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 39.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "claude-4-sonnet",
    "canonical_name": "Claude 4 Sonnet",
    "model_name": "Claude 4 Sonnet",
    "aliases": [
      "Claude 4 Sonnet"
    ],
    "provider": "Anthropic",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Anthropic",
    "intelligence_score": 39.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 6.0,
    "latency_seconds": 1.08,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 77.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.401142+00:00",
        "confidence": 0.65,
        "raw_name": "Claude 4 Sonnet",
        "raw_scores": {
          "intelligence_score": 39.0,
          "blended_cost_per_1m": 6.0,
          "latency_seconds": 1.08,
          "tokens_per_second": 77.0,
          "context_window": 1000000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 39.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gpt-51-codex-mini",
    "canonical_name": "GPT-5.1 Codex mini (high)",
    "model_name": "GPT-5.1 Codex mini (high)",
    "aliases": [
      "GPT-5.1 Codex mini (high)"
    ],
    "provider": "OpenAI",
    "context_window": 400000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "OpenAI",
    "intelligence_score": 39.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.69,
    "latency_seconds": 12.99,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 133.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.401161+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5.1 Codex mini (high)",
        "raw_scores": {
          "intelligence_score": 39.0,
          "blended_cost_per_1m": 0.69,
          "latency_seconds": 12.99,
          "tokens_per_second": 133.0,
          "context_window": 400000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 39.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "grok-41-fast",
    "canonical_name": "Grok 4.1 Fast",
    "model_name": "Grok 4.1 Fast",
    "aliases": [
      "Grok 4.1 Fast",
      "grok-4.1-fast-reasoning"
    ],
    "provider": "xAI",
    "context_window": 2000000,
    "open_source": null,
    "arena_votes": 31128,
    "license_type": "Proprietary",
    "creator": "xAI",
    "intelligence_score": 39.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1430.79,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.28,
    "latency_seconds": 8.27,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 182.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.401180+00:00",
        "confidence": 0.65,
        "raw_name": "Grok 4.1 Fast",
        "raw_scores": {
          "intelligence_score": 39.0,
          "blended_cost_per_1m": 0.28,
          "latency_seconds": 8.27,
          "tokens_per_second": 182.0,
          "context_window": 2000000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828086+00:00",
        "confidence": 1.0,
        "raw_name": "grok-4.1-fast-reasoning",
        "raw_scores": {
          "arena_elo": 1430.79,
          "arena_votes": 31128
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 39.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1430.79
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "o3",
    "canonical_name": "o3",
    "model_name": "o3",
    "aliases": [
      "o3",
      "o3-2025-04-16"
    ],
    "provider": "OpenAI",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 60957,
    "license_type": "Proprietary",
    "creator": "OpenAI",
    "intelligence_score": 38.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1432.45,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.5,
    "latency_seconds": 22.83,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 108.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.401223+00:00",
        "confidence": 0.65,
        "raw_name": "o3",
        "raw_scores": {
          "intelligence_score": 38.0,
          "blended_cost_per_1m": 3.5,
          "latency_seconds": 22.83,
          "tokens_per_second": 108.0,
          "context_window": 200000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828054+00:00",
        "confidence": 1.0,
        "raw_name": "o3-2025-04-16",
        "raw_scores": {
          "arena_elo": 1432.45,
          "arena_votes": 60957
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 38.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1432.45
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen35-35b-a3b",
    "canonical_name": "Qwen3.5 35B A3B",
    "model_name": "Qwen3.5 35B A3B",
    "aliases": [
      "Qwen3.5 35B A3B"
    ],
    "provider": "Alibaba",
    "context_window": 262000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 37.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.69,
    "latency_seconds": 0.98,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 168.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.401295+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3.5 35B A3B",
        "raw_scores": {
          "intelligence_score": 37.0,
          "blended_cost_per_1m": 0.69,
          "latency_seconds": 0.98,
          "tokens_per_second": 168.0,
          "context_window": 262000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 37.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "claude-45-haiku",
    "canonical_name": "Claude 4.5 Haiku",
    "model_name": "Claude 4.5 Haiku",
    "aliases": [
      "Claude 4.5 Haiku",
      "claude-haiku-4.5-20251001"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 47369,
    "license_type": "Proprietary",
    "creator": "Anthropic",
    "intelligence_score": 37.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1405.56,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 2.0,
    "latency_seconds": 0.46,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 117.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.401315+00:00",
        "confidence": 0.65,
        "raw_name": "Claude 4.5 Haiku",
        "raw_scores": {
          "intelligence_score": 37.0,
          "blended_cost_per_1m": 2.0,
          "latency_seconds": 0.46,
          "tokens_per_second": 117.0,
          "context_window": 200000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828521+00:00",
        "confidence": 1.0,
        "raw_name": "claude-haiku-4.5-20251001",
        "raw_scores": {
          "arena_elo": 1405.56,
          "arena_votes": 47369
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 37.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1405.56
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "minimax-m2",
    "canonical_name": "MiniMax-M2",
    "model_name": "MiniMax-M2",
    "aliases": [
      "MiniMax-M2",
      "minimax-m2"
    ],
    "provider": "MiniMax",
    "context_window": 205000,
    "open_source": null,
    "arena_votes": 6688,
    "license_type": "Apache 2.0",
    "creator": "MiniMax",
    "intelligence_score": 36.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1346.97,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.53,
    "latency_seconds": 2.44,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 52.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.401335+00:00",
        "confidence": 0.65,
        "raw_name": "MiniMax-M2",
        "raw_scores": {
          "intelligence_score": 36.0,
          "blended_cost_per_1m": 0.53,
          "latency_seconds": 2.44,
          "tokens_per_second": 52.0,
          "context_window": 205000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829470+00:00",
        "confidence": 1.0,
        "raw_name": "minimax-m2",
        "raw_scores": {
          "arena_elo": 1346.97,
          "arena_votes": 6688
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 36.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1346.97
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "kat-coder-pro-v1",
    "canonical_name": "KAT-Coder-Pro V1",
    "model_name": "KAT-Coder-Pro V1",
    "aliases": [
      "KAT-Coder-Pro V1"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "KwaiKAT",
    "intelligence_score": 36.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.53,
    "latency_seconds": 1.82,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 54.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.401354+00:00",
        "confidence": 0.65,
        "raw_name": "KAT-Coder-Pro V1",
        "raw_scores": {
          "intelligence_score": 36.0,
          "blended_cost_per_1m": 0.53,
          "latency_seconds": 1.82,
          "tokens_per_second": 54.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 36.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "nova-20-pro-preview",
    "canonical_name": "Nova 2.0 Pro Preview (medium)",
    "model_name": "Nova 2.0 Pro Preview (medium)",
    "aliases": [
      "Nova 2.0 Pro Preview",
      "Nova 2.0 Pro Preview (low)",
      "Nova 2.0 Pro Preview (medium)"
    ],
    "provider": "Amazon",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Amazon",
    "intelligence_score": 30.3333,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.44,
    "latency_seconds": 10.9867,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 141.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.401373+00:00",
        "confidence": 0.65,
        "raw_name": "Nova 2.0 Pro Preview (medium)",
        "raw_scores": {
          "intelligence_score": 36.0,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 20.55,
          "tokens_per_second": 132.0,
          "context_window": 256000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.401760+00:00",
        "confidence": 0.65,
        "raw_name": "Nova 2.0 Pro Preview (low)",
        "raw_scores": {
          "intelligence_score": 32.0,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 11.95,
          "tokens_per_second": 139.0,
          "context_window": 256000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403017+00:00",
        "confidence": 0.65,
        "raw_name": "Nova 2.0 Pro Preview",
        "raw_scores": {
          "intelligence_score": 23.0,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 0.46,
          "tokens_per_second": 152.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 36.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "grok-4-fast",
    "canonical_name": "Grok 4 Fast",
    "model_name": "Grok 4 Fast",
    "aliases": [
      "Grok 4 Fast",
      "grok-4-fast-chat",
      "grok-4-fast-reasoning"
    ],
    "provider": "xAI",
    "context_window": 2000000,
    "open_source": null,
    "arena_votes": 18440,
    "license_type": "Proprietary",
    "creator": "xAI",
    "intelligence_score": 35.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1412.7,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.28,
    "latency_seconds": 5.37,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 170.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.401393+00:00",
        "confidence": 0.65,
        "raw_name": "Grok 4 Fast",
        "raw_scores": {
          "intelligence_score": 35.0,
          "blended_cost_per_1m": 0.28,
          "latency_seconds": 5.37,
          "tokens_per_second": 170.0,
          "context_window": 2000000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828246+00:00",
        "confidence": 1.0,
        "raw_name": "grok-4-fast-chat",
        "raw_scores": {
          "arena_elo": 1421.81,
          "arena_votes": 6962
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828547+00:00",
        "confidence": 1.0,
        "raw_name": "grok-4-fast-reasoning",
        "raw_scores": {
          "arena_elo": 1403.59,
          "arena_votes": 18440
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 35.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1421.81
      }
    },
    "confidence_score": 0.8833,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "claude-37-sonnet",
    "canonical_name": "Claude 3.7 Sonnet",
    "model_name": "Claude 3.7 Sonnet",
    "aliases": [
      "Claude 3.7 Sonnet",
      "claude-3.7-sonnet-20250219"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 44275,
    "license_type": "Proprietary",
    "creator": "Anthropic",
    "intelligence_score": 35.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1371.24,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 6.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.401431+00:00",
        "confidence": 0.65,
        "raw_name": "Claude 3.7 Sonnet",
        "raw_scores": {
          "intelligence_score": 35.0,
          "blended_cost_per_1m": 6.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 200000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829039+00:00",
        "confidence": 1.0,
        "raw_name": "claude-3.7-sonnet-20250219",
        "raw_scores": {
          "arena_elo": 1371.24,
          "arena_votes": 44275
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 35.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1371.24
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemini-25-pro",
    "canonical_name": "Gemini 2.5 Pro",
    "model_name": "Gemini 2.5 Pro",
    "aliases": [
      "Gemini 2.5 Pro",
      "Gemini 2.5 Pro (Mar)",
      "Gemini 2.5 Pro (May)",
      "gemini-2.5-pro"
    ],
    "provider": "Google",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": 97296,
    "license_type": "Proprietary",
    "creator": "Google",
    "intelligence_score": 31.6667,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1449.24,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 2.2933,
    "latency_seconds": 11.9767,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 50.6667,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.401451+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 2.5 Pro",
        "raw_scores": {
          "intelligence_score": 35.0,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 35.93,
          "tokens_per_second": 152.0,
          "context_window": 1000000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.401929+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 2.5 Pro (Mar)",
        "raw_scores": {
          "intelligence_score": 30.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402004+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 2.5 Pro (May)",
        "raw_scores": {
          "intelligence_score": 30.0,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.827884+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-2.5-pro",
        "raw_scores": {
          "arena_elo": 1449.24,
          "arena_votes": 97296
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 35.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1449.24
      }
    },
    "confidence_score": 0.7375,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-v32-speciale",
    "canonical_name": "DeepSeek V3.2 Speciale",
    "model_name": "DeepSeek V3.2 Speciale",
    "aliases": [
      "DeepSeek V3.2 Exp",
      "DeepSeek V3.2 Speciale",
      "deepseek-v3.2-exp",
      "deepseek-v3.2-exp-thinking"
    ],
    "provider": "DeepSeek",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 11680,
    "license_type": "MIT",
    "creator": "DeepSeek",
    "intelligence_score": 33.5,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1423.49,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.16,
    "latency_seconds": 0.645,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 20.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.401489+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek V3.2 Speciale",
        "raw_scores": {
          "intelligence_score": 34.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.401624+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek V3.2 Exp",
        "raw_scores": {
          "intelligence_score": 33.0,
          "blended_cost_per_1m": 0.32,
          "latency_seconds": 1.29,
          "tokens_per_second": 40.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828168+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-v3.2-exp",
        "raw_scores": {
          "arena_elo": 1423.66,
          "arena_votes": 11680
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828181+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-v3.2-exp-thinking",
        "raw_scores": {
          "arena_elo": 1423.32,
          "arena_votes": 8944
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 34.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1423.66
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-v31",
    "canonical_name": "DeepSeek V3.1 Terminus",
    "model_name": "DeepSeek V3.1 Terminus",
    "aliases": [
      "DeepSeek V3.1",
      "DeepSeek V3.1 Terminus",
      "deepseek-v3.1",
      "deepseek-v3.1-terminus",
      "deepseek-v3.1-terminus-thinking",
      "deepseek-v3.1-thinking"
    ],
    "provider": "DeepSeek",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 15194,
    "license_type": "MIT",
    "creator": "DeepSeek",
    "intelligence_score": 31.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1416.835,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.82,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.401508+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek V3.1 Terminus",
        "raw_scores": {
          "intelligence_score": 34.0,
          "blended_cost_per_1m": 0.8,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402157+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek V3.1",
        "raw_scores": {
          "intelligence_score": 28.0,
          "blended_cost_per_1m": 0.84,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828315+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-v3.1",
        "raw_scores": {
          "arena_elo": 1418.24,
          "arena_votes": 15194
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828327+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-v3.1-thinking",
        "raw_scores": {
          "arena_elo": 1417.23,
          "arena_votes": 11918
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828365+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-v3.1-terminus",
        "raw_scores": {
          "arena_elo": 1416.1,
          "arena_votes": 3743
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828377+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-v3.1-terminus-thinking",
        "raw_scores": {
          "arena_elo": 1415.77,
          "arena_votes": 3536
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 34.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1418.24
      }
    },
    "confidence_score": 0.8833,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "doubao-seed-code",
    "canonical_name": "Doubao Seed Code",
    "model_name": "Doubao Seed Code",
    "aliases": [
      "Doubao Seed Code"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "ByteDance Seed",
    "intelligence_score": 34.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.401547+00:00",
        "confidence": 0.65,
        "raw_name": "Doubao Seed Code",
        "raw_scores": {
          "intelligence_score": 34.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 34.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gpt-oss-120b",
    "canonical_name": "gpt-oss-120B (high)",
    "model_name": "gpt-oss-120B (high)",
    "aliases": [
      "gpt-oss-120B (high)",
      "gpt-oss-120B (low)",
      "gpt-oss-120b"
    ],
    "provider": "OpenAI",
    "context_window": 131000,
    "open_source": null,
    "arena_votes": 30756,
    "license_type": "Apache 2.0",
    "creator": "OpenAI",
    "intelligence_score": 28.5,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1353.9,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.26,
    "latency_seconds": 0.475,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 300.5,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.401567+00:00",
        "confidence": 0.65,
        "raw_name": "gpt-oss-120B (high)",
        "raw_scores": {
          "intelligence_score": 33.0,
          "blended_cost_per_1m": 0.26,
          "latency_seconds": 0.51,
          "tokens_per_second": 305.0,
          "context_window": 131000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402710+00:00",
        "confidence": 0.65,
        "raw_name": "gpt-oss-120B (low)",
        "raw_scores": {
          "intelligence_score": 24.0,
          "blended_cost_per_1m": 0.26,
          "latency_seconds": 0.44,
          "tokens_per_second": 296.0,
          "context_window": 131000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829331+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-oss-120b",
        "raw_scores": {
          "arena_elo": 1353.9,
          "arena_votes": 30756
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 33.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1353.9
      }
    },
    "confidence_score": 0.7667,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "o4-mini",
    "canonical_name": "o4-mini (high)",
    "model_name": "o4-mini (high)",
    "aliases": [
      "o4-mini (high)",
      "o4-mini-2025-04-16"
    ],
    "provider": "OpenAI",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 46375,
    "license_type": "Proprietary",
    "creator": "OpenAI",
    "intelligence_score": 33.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1390.98,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.93,
    "latency_seconds": 58.66,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 121.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.401586+00:00",
        "confidence": 0.65,
        "raw_name": "o4-mini (high)",
        "raw_scores": {
          "intelligence_score": 33.0,
          "blended_cost_per_1m": 1.93,
          "latency_seconds": 58.66,
          "tokens_per_second": 121.0,
          "context_window": 200000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828724+00:00",
        "confidence": 1.0,
        "raw_name": "o4-mini-2025-04-16",
        "raw_scores": {
          "arena_elo": 1390.98,
          "arena_votes": 46375
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 33.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1390.98
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "mercury-2",
    "canonical_name": "Mercury 2",
    "model_name": "Mercury 2",
    "aliases": [
      "Mercury 2"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Inception",
    "intelligence_score": 33.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.38,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.401645+00:00",
        "confidence": 0.65,
        "raw_name": "Mercury 2",
        "raw_scores": {
          "intelligence_score": 33.0,
          "blended_cost_per_1m": 0.38,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 33.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "glm-46",
    "canonical_name": "GLM-4.6",
    "model_name": "GLM-4.6",
    "aliases": [
      "GLM-4.6",
      "glm-4.6"
    ],
    "provider": "Z.ai",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 35128,
    "license_type": "MIT",
    "creator": "Z AI",
    "intelligence_score": 33.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1425.04,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.98,
    "latency_seconds": 0.62,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 91.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.401664+00:00",
        "confidence": 0.65,
        "raw_name": "GLM-4.6",
        "raw_scores": {
          "intelligence_score": 33.0,
          "blended_cost_per_1m": 0.98,
          "latency_seconds": 0.62,
          "tokens_per_second": 91.0,
          "context_window": 200000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828126+00:00",
        "confidence": 1.0,
        "raw_name": "glm-4.6",
        "raw_scores": {
          "arena_elo": 1425.04,
          "arena_votes": 35128
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 33.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1425.04
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "k-exaone",
    "canonical_name": "K-EXAONE",
    "model_name": "K-EXAONE",
    "aliases": [
      "K-EXAONE"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "LG AI Research",
    "intelligence_score": 32.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.401702+00:00",
        "confidence": 0.65,
        "raw_name": "K-EXAONE",
        "raw_scores": {
          "intelligence_score": 32.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 32.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "grok-3-mini",
    "canonical_name": "Grok 3 mini Reasoning (high)",
    "model_name": "Grok 3 mini Reasoning (high)",
    "aliases": [
      "Grok 3 mini Reasoning (high)",
      "grok-3-mini-high"
    ],
    "provider": "xAI",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": 17413,
    "license_type": "Proprietary",
    "creator": "xAI",
    "intelligence_score": 32.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1362.9,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.35,
    "latency_seconds": 0.71,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 177.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.401740+00:00",
        "confidence": 0.65,
        "raw_name": "Grok 3 mini Reasoning (high)",
        "raw_scores": {
          "intelligence_score": 32.0,
          "blended_cost_per_1m": 0.35,
          "latency_seconds": 0.71,
          "tokens_per_second": 177.0,
          "context_window": 1000000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829256+00:00",
        "confidence": 1.0,
        "raw_name": "grok-3-mini-high",
        "raw_scores": {
          "arena_elo": 1362.9,
          "arena_votes": 17413
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 32.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1362.9
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "claude-opus-41",
    "canonical_name": "Claude 4.1 Opus",
    "model_name": "Claude 4.1 Opus",
    "aliases": [
      "Claude 4.1 Opus",
      "claude-opus-4.1-20250805",
      "claude-opus-4.1-20250805-thinking-16k"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 77218,
    "license_type": "Proprietary",
    "creator": "Anthropic",
    "intelligence_score": 32.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1447.44,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 30.0,
    "latency_seconds": 1.26,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 49.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.401779+00:00",
        "confidence": 0.65,
        "raw_name": "Claude 4.1 Opus",
        "raw_scores": {
          "intelligence_score": 32.0,
          "blended_cost_per_1m": 30.0,
          "latency_seconds": 1.26,
          "tokens_per_second": 49.0,
          "context_window": 200000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.827912+00:00",
        "confidence": 1.0,
        "raw_name": "claude-opus-4.1-20250805-thinking-16k",
        "raw_scores": {
          "arena_elo": 1448.65,
          "arena_votes": 49597
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.827927+00:00",
        "confidence": 1.0,
        "raw_name": "claude-opus-4.1-20250805",
        "raw_scores": {
          "arena_elo": 1446.23,
          "arena_votes": 77218
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 32.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1448.65
      }
    },
    "confidence_score": 0.8833,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemini-25-flash",
    "canonical_name": "Gemini 2.5 Flash (Sep)",
    "model_name": "Gemini 2.5 Flash (Sep)",
    "aliases": [
      "Gemini 2.5 Flash",
      "Gemini 2.5 Flash (Sep)",
      "gemini-2.5-flash",
      "gemini-2.5-flash-preview-09-2025"
    ],
    "provider": "Google",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": 96569,
    "license_type": "Proprietary",
    "creator": "Google",
    "intelligence_score": 29.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1407.56,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.85,
    "latency_seconds": 7.125,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 142.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.401816+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 2.5 Flash (Sep)",
        "raw_scores": {
          "intelligence_score": 31.0,
          "blended_cost_per_1m": 0.85,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402349+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 2.5 Flash",
        "raw_scores": {
          "intelligence_score": 27.0,
          "blended_cost_per_1m": 0.85,
          "latency_seconds": 14.25,
          "tokens_per_second": 284.0,
          "context_window": 1000000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828477+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-2.5-flash",
        "raw_scores": {
          "arena_elo": 1410.86,
          "arena_votes": 96569
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828534+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-2.5-flash-preview-09-2025",
        "raw_scores": {
          "arena_elo": 1404.26,
          "arena_votes": 32541
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 31.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1410.86
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "kimi-k2-0905",
    "canonical_name": "Kimi K2 0905",
    "model_name": "Kimi K2 0905",
    "aliases": [
      "Kimi K2 0905"
    ],
    "provider": "Moonshot",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Kimi",
    "intelligence_score": 31.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.2,
    "latency_seconds": 0.43,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 64.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.401854+00:00",
        "confidence": 0.65,
        "raw_name": "Kimi K2 0905",
        "raw_scores": {
          "intelligence_score": 31.0,
          "blended_cost_per_1m": 1.2,
          "latency_seconds": 0.43,
          "tokens_per_second": 64.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 31.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "o1",
    "canonical_name": "o1",
    "model_name": "o1",
    "aliases": [
      "o1",
      "o1-2024-12-17"
    ],
    "provider": "OpenAI",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 27822,
    "license_type": "Proprietary",
    "creator": "OpenAI",
    "intelligence_score": 31.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1401.92,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 26.25,
    "latency_seconds": 17.58,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 177.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.401892+00:00",
        "confidence": 0.65,
        "raw_name": "o1",
        "raw_scores": {
          "intelligence_score": 31.0,
          "blended_cost_per_1m": 26.25,
          "latency_seconds": 17.58,
          "tokens_per_second": 177.0,
          "context_window": 200000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828572+00:00",
        "confidence": 1.0,
        "raw_name": "o1-2024-12-17",
        "raw_scores": {
          "arena_elo": 1401.92,
          "arena_votes": 27822
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 31.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1401.92
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "glm-47-flash",
    "canonical_name": "GLM-4.7-Flash",
    "model_name": "GLM-4.7-Flash",
    "aliases": [
      "GLM-4.7-Flash",
      "glm-4.7-flash"
    ],
    "provider": "Z.ai",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 10660,
    "license_type": "MIT",
    "creator": "Z AI",
    "intelligence_score": 30.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1365.72,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.15,
    "latency_seconds": 0.7,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 59.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.401967+00:00",
        "confidence": 0.65,
        "raw_name": "GLM-4.7-Flash",
        "raw_scores": {
          "intelligence_score": 30.0,
          "blended_cost_per_1m": 0.15,
          "latency_seconds": 0.7,
          "tokens_per_second": 59.0,
          "context_window": 200000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829175+00:00",
        "confidence": 1.0,
        "raw_name": "glm-4.7-flash",
        "raw_scores": {
          "arena_elo": 1365.72,
          "arena_votes": 10660
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 30.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1365.72
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "nova-20-lite",
    "canonical_name": "Nova 2.0 Lite (medium)",
    "model_name": "Nova 2.0 Lite (medium)",
    "aliases": [
      "Nova 2.0 Lite",
      "Nova 2.0 Lite (low)",
      "Nova 2.0 Lite (medium)"
    ],
    "provider": "Amazon",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Amazon",
    "intelligence_score": 24.3333,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.85,
    "latency_seconds": 7.5567,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 216.6667,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.401986+00:00",
        "confidence": 0.65,
        "raw_name": "Nova 2.0 Lite (medium)",
        "raw_scores": {
          "intelligence_score": 30.0,
          "blended_cost_per_1m": 0.85,
          "latency_seconds": 13.73,
          "tokens_per_second": 241.0,
          "context_window": 1000000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402691+00:00",
        "confidence": 0.65,
        "raw_name": "Nova 2.0 Lite (low)",
        "raw_scores": {
          "intelligence_score": 25.0,
          "blended_cost_per_1m": 0.85,
          "latency_seconds": 8.41,
          "tokens_per_second": 230.0,
          "context_window": 1000000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404150+00:00",
        "confidence": 0.65,
        "raw_name": "Nova 2.0 Lite",
        "raw_scores": {
          "intelligence_score": 18.0,
          "blended_cost_per_1m": 0.85,
          "latency_seconds": 0.53,
          "tokens_per_second": 179.0,
          "context_window": 1000000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 30.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-235b-a22b-2507",
    "canonical_name": "Qwen3 235B A22B 2507",
    "model_name": "Qwen3 235B A22B 2507",
    "aliases": [
      "Qwen3 235B A22B 2507"
    ],
    "provider": "Alibaba",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 30.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 2.63,
    "latency_seconds": 1.51,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 40.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402023+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 235B A22B 2507",
        "raw_scores": {
          "intelligence_score": 30.0,
          "blended_cost_per_1m": 2.63,
          "latency_seconds": 1.51,
          "tokens_per_second": 40.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 30.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "ernie-50-thinking-preview",
    "canonical_name": "ERNIE 5.0 Thinking Preview",
    "model_name": "ERNIE 5.0 Thinking Preview",
    "aliases": [
      "ERNIE 5.0 Thinking Preview"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Baidu",
    "intelligence_score": 29.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402041+00:00",
        "confidence": 0.65,
        "raw_name": "ERNIE 5.0 Thinking Preview",
        "raw_scores": {
          "intelligence_score": 29.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 29.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "grok-code-fast-1",
    "canonical_name": "Grok Code Fast 1",
    "model_name": "Grok Code Fast 1",
    "aliases": [
      "Grok Code Fast 1"
    ],
    "provider": "xAI",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "xAI",
    "intelligence_score": 29.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.53,
    "latency_seconds": 6.29,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 264.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402060+00:00",
        "confidence": 0.65,
        "raw_name": "Grok Code Fast 1",
        "raw_scores": {
          "intelligence_score": 29.0,
          "blended_cost_per_1m": 0.53,
          "latency_seconds": 6.29,
          "tokens_per_second": 264.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 29.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "apriel-v15-15b-thinker",
    "canonical_name": "Apriel-v1.5-15B-Thinker",
    "model_name": "Apriel-v1.5-15B-Thinker",
    "aliases": [
      "Apriel-v1.5-15B-Thinker"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "ServiceNow",
    "intelligence_score": 28.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.17,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 144.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402117+00:00",
        "confidence": 0.65,
        "raw_name": "Apriel-v1.5-15B-Thinker",
        "raw_scores": {
          "intelligence_score": 28.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.17,
          "tokens_per_second": 144.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 28.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-coder-next",
    "canonical_name": "Qwen3 Coder Next",
    "model_name": "Qwen3 Coder Next",
    "aliases": [
      "Qwen3 Coder Next"
    ],
    "provider": "Alibaba",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 28.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.53,
    "latency_seconds": 0.78,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 126.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402136+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 Coder Next",
        "raw_scores": {
          "intelligence_score": 28.0,
          "blended_cost_per_1m": 0.53,
          "latency_seconds": 0.78,
          "tokens_per_second": 126.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 28.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "nova-20-omni",
    "canonical_name": "Nova 2.0 Omni (medium)",
    "model_name": "Nova 2.0 Omni (medium)",
    "aliases": [
      "Nova 2.0 Omni",
      "Nova 2.0 Omni (low)",
      "Nova 2.0 Omni (medium)"
    ],
    "provider": "Amazon",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Amazon",
    "intelligence_score": 22.6667,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.85,
    "latency_seconds": 0.21,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 68.6667,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402176+00:00",
        "confidence": 0.65,
        "raw_name": "Nova 2.0 Omni (medium)",
        "raw_scores": {
          "intelligence_score": 28.0,
          "blended_cost_per_1m": 0.85,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402959+00:00",
        "confidence": 0.65,
        "raw_name": "Nova 2.0 Omni (low)",
        "raw_scores": {
          "intelligence_score": 23.0,
          "blended_cost_per_1m": 0.85,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404467+00:00",
        "confidence": 0.65,
        "raw_name": "Nova 2.0 Omni",
        "raw_scores": {
          "intelligence_score": 17.0,
          "blended_cost_per_1m": 0.85,
          "latency_seconds": 0.63,
          "tokens_per_second": 206.0,
          "context_window": 1000000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 28.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-vl-235b-a22b",
    "canonical_name": "Qwen3 VL 235B A22B",
    "model_name": "Qwen3 VL 235B A22B",
    "aliases": [
      "Qwen3 VL 235B A22B"
    ],
    "provider": "Alibaba",
    "context_window": 262000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 28.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 2.63,
    "latency_seconds": 1.26,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 38.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402233+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 VL 235B A22B",
        "raw_scores": {
          "intelligence_score": 28.0,
          "blended_cost_per_1m": 2.63,
          "latency_seconds": 1.26,
          "tokens_per_second": 38.0,
          "context_window": 262000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 28.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "apriel-v16-15b-thinker",
    "canonical_name": "Apriel-v1.6-15B-Thinker",
    "model_name": "Apriel-v1.6-15B-Thinker",
    "aliases": [
      "Apriel-v1.6-15B-Thinker"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "ServiceNow",
    "intelligence_score": 28.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.21,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 138.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402254+00:00",
        "confidence": 0.65,
        "raw_name": "Apriel-v1.6-15B-Thinker",
        "raw_scores": {
          "intelligence_score": 28.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.21,
          "tokens_per_second": 138.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 28.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "claude-opus-4",
    "canonical_name": "Claude 4 Opus",
    "model_name": "Claude 4 Opus",
    "aliases": [
      "Claude 4 Opus",
      "claude-opus-4-20250514",
      "claude-opus-4-20250514-thinking-16k"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 45304,
    "license_type": "Proprietary",
    "creator": "Anthropic",
    "intelligence_score": 27.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1418.335,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 30.0,
    "latency_seconds": 1.29,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 48.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402292+00:00",
        "confidence": 0.65,
        "raw_name": "Claude 4 Opus",
        "raw_scores": {
          "intelligence_score": 27.0,
          "blended_cost_per_1m": 30.0,
          "latency_seconds": 1.29,
          "tokens_per_second": 48.0,
          "context_window": 200000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828152+00:00",
        "confidence": 1.0,
        "raw_name": "claude-opus-4-20250514-thinking-16k",
        "raw_scores": {
          "arena_elo": 1423.71,
          "arena_votes": 37722
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828440+00:00",
        "confidence": 1.0,
        "raw_name": "claude-opus-4-20250514",
        "raw_scores": {
          "arena_elo": 1412.96,
          "arena_votes": 45304
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 27.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1423.71
      }
    },
    "confidence_score": 0.8833,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "magistral-medium-12",
    "canonical_name": "Magistral Medium 1.2",
    "model_name": "Magistral Medium 1.2",
    "aliases": [
      "Magistral Medium 1.2"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 27.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 2.75,
    "latency_seconds": 0.45,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 45.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402312+00:00",
        "confidence": 0.65,
        "raw_name": "Magistral Medium 1.2",
        "raw_scores": {
          "intelligence_score": 27.0,
          "blended_cost_per_1m": 2.75,
          "latency_seconds": 0.45,
          "tokens_per_second": 45.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 27.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-r1",
    "canonical_name": "DeepSeek R1 0528",
    "model_name": "DeepSeek R1 0528",
    "aliases": [
      "DeepSeek R1 (Jan)",
      "DeepSeek R1 0528",
      "deepseek-r1",
      "deepseek-r1-0528"
    ],
    "provider": "DeepSeek",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 19177,
    "license_type": "MIT",
    "creator": "DeepSeek",
    "intelligence_score": 23.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1408.4,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 2.36,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402330+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek R1 0528",
        "raw_scores": {
          "intelligence_score": 27.0,
          "blended_cost_per_1m": 2.36,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403794+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek R1 (Jan)",
        "raw_scores": {
          "intelligence_score": 19.0,
          "blended_cost_per_1m": 2.36,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828290+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-r1-0528",
        "raw_scores": {
          "arena_elo": 1419.15,
          "arena_votes": 19177
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828647+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-r1",
        "raw_scores": {
          "arena_elo": 1397.65,
          "arena_votes": 18537
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 27.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1419.15
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gpt-5-nano",
    "canonical_name": "GPT-5 nano (high)",
    "model_name": "GPT-5 nano (high)",
    "aliases": [
      "GPT-5 nano (high)",
      "GPT-5 nano (medium)",
      "GPT-5 nano (minimal)",
      "gpt-5-nano-high"
    ],
    "provider": "OpenAI",
    "context_window": 400000,
    "open_source": null,
    "arena_votes": 8352,
    "license_type": "Proprietary",
    "creator": "OpenAI",
    "intelligence_score": 23.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1337.83,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.14,
    "latency_seconds": 56.65,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 136.6667,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402368+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5 nano (high)",
        "raw_scores": {
          "intelligence_score": 27.0,
          "blended_cost_per_1m": 0.14,
          "latency_seconds": 116.38,
          "tokens_per_second": 125.0,
          "context_window": 400000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402484+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5 nano (medium)",
        "raw_scores": {
          "intelligence_score": 26.0,
          "blended_cost_per_1m": 0.14,
          "latency_seconds": 52.98,
          "tokens_per_second": 143.0,
          "context_window": 400000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404919+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5 nano (minimal)",
        "raw_scores": {
          "intelligence_score": 16.0,
          "blended_cost_per_1m": 0.14,
          "latency_seconds": 0.59,
          "tokens_per_second": 142.0,
          "context_window": 400000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829602+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-5-nano-high",
        "raw_scores": {
          "arena_elo": 1337.83,
          "arena_votes": 8352
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 27.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1337.83
      }
    },
    "confidence_score": 0.7375,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-next-80b-a3b",
    "canonical_name": "Qwen3 Next 80B A3B",
    "model_name": "Qwen3 Next 80B A3B",
    "aliases": [
      "Qwen3 Next 80B A3B"
    ],
    "provider": "Alibaba",
    "context_window": 262000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 27.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.88,
    "latency_seconds": 1.03,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 134.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402388+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 Next 80B A3B",
        "raw_scores": {
          "intelligence_score": 27.0,
          "blended_cost_per_1m": 1.88,
          "latency_seconds": 1.03,
          "tokens_per_second": 134.0,
          "context_window": 262000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 27.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "glm-45",
    "canonical_name": "GLM-4.5",
    "model_name": "GLM-4.5",
    "aliases": [
      "GLM-4.5",
      "glm-4.5"
    ],
    "provider": "Z.ai",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 24600,
    "license_type": "MIT",
    "creator": "Z AI",
    "intelligence_score": 26.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1410.09,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.84,
    "latency_seconds": 0.84,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 40.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402407+00:00",
        "confidence": 0.65,
        "raw_name": "GLM-4.5",
        "raw_scores": {
          "intelligence_score": 26.0,
          "blended_cost_per_1m": 0.84,
          "latency_seconds": 0.84,
          "tokens_per_second": 40.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828490+00:00",
        "confidence": 1.0,
        "raw_name": "glm-4.5",
        "raw_scores": {
          "arena_elo": 1410.09,
          "arena_votes": 24600
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 26.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1410.09
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "kimi-k2",
    "canonical_name": "Kimi K2",
    "model_name": "Kimi K2",
    "aliases": [
      "Kimi K2",
      "kimi-k2-0711-preview",
      "kimi-k2-0905-preview"
    ],
    "provider": "Moonshot",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 28440,
    "license_type": "Modified MIT",
    "creator": "Kimi",
    "intelligence_score": 26.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1417.0,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.07,
    "latency_seconds": 0.59,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 45.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402427+00:00",
        "confidence": 0.65,
        "raw_name": "Kimi K2",
        "raw_scores": {
          "intelligence_score": 26.0,
          "blended_cost_per_1m": 1.07,
          "latency_seconds": 0.59,
          "tokens_per_second": 45.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828340+00:00",
        "confidence": 1.0,
        "raw_name": "kimi-k2-0905-preview",
        "raw_scores": {
          "arena_elo": 1417.2,
          "arena_votes": 11912
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828352+00:00",
        "confidence": 1.0,
        "raw_name": "kimi-k2-0711-preview",
        "raw_scores": {
          "arena_elo": 1416.8,
          "arena_votes": 28440
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 26.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1417.2
      }
    },
    "confidence_score": 0.8833,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gpt-41",
    "canonical_name": "GPT-4.1",
    "model_name": "GPT-4.1",
    "aliases": [
      "GPT-4.1",
      "gpt-4.1-2025-04-14"
    ],
    "provider": "OpenAI",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": 51837,
    "license_type": "Proprietary",
    "creator": "OpenAI",
    "intelligence_score": 26.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1413.4,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.5,
    "latency_seconds": 0.56,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 85.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402446+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-4.1",
        "raw_scores": {
          "intelligence_score": 26.0,
          "blended_cost_per_1m": 3.5,
          "latency_seconds": 0.56,
          "tokens_per_second": 85.0,
          "context_window": 1000000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828427+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-4.1-2025-04-14",
        "raw_scores": {
          "arena_elo": 1413.4,
          "arena_votes": 51837
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 26.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1413.4
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "o3-mini",
    "canonical_name": "o3-mini (high)",
    "model_name": "o3-mini (high)",
    "aliases": [
      "o3-mini",
      "o3-mini (high)"
    ],
    "provider": "OpenAI",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 58451,
    "license_type": "Proprietary",
    "creator": "OpenAI",
    "intelligence_score": 25.5,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1348.1,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.93,
    "latency_seconds": 28.255,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 135.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402503+00:00",
        "confidence": 0.65,
        "raw_name": "o3-mini",
        "raw_scores": {
          "intelligence_score": 26.0,
          "blended_cost_per_1m": 1.93,
          "latency_seconds": 15.2,
          "tokens_per_second": 129.0,
          "context_window": 200000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402560+00:00",
        "confidence": 0.65,
        "raw_name": "o3-mini (high)",
        "raw_scores": {
          "intelligence_score": 25.0,
          "blended_cost_per_1m": 1.93,
          "latency_seconds": 41.31,
          "tokens_per_second": 141.0,
          "context_window": 200000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829418+00:00",
        "confidence": 1.0,
        "raw_name": "o3-mini",
        "raw_scores": {
          "arena_elo": 1348.1,
          "arena_votes": 58451
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 26.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1348.1
      }
    },
    "confidence_score": 0.7667,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "o1-pro",
    "canonical_name": "o1-pro",
    "model_name": "o1-pro",
    "aliases": [
      "o1-pro"
    ],
    "provider": "OpenAI",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "OpenAI",
    "intelligence_score": 26.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 262.5,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402522+00:00",
        "confidence": 0.65,
        "raw_name": "o1-pro",
        "raw_scores": {
          "intelligence_score": 26.0,
          "blended_cost_per_1m": 262.5,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 200000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 26.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "grok-3",
    "canonical_name": "Grok 3",
    "model_name": "Grok 3",
    "aliases": [
      "Grok 3",
      "grok-3-preview-02-24"
    ],
    "provider": "xAI",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": 33843,
    "license_type": "Proprietary",
    "creator": "xAI",
    "intelligence_score": 25.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1411.33,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 6.0,
    "latency_seconds": 0.74,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 70.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402579+00:00",
        "confidence": 0.65,
        "raw_name": "Grok 3",
        "raw_scores": {
          "intelligence_score": 25.0,
          "blended_cost_per_1m": 6.0,
          "latency_seconds": 0.74,
          "tokens_per_second": 70.0,
          "context_window": 1000000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828465+00:00",
        "confidence": 1.0,
        "raw_name": "grok-3-preview-02-24",
        "raw_scores": {
          "arena_elo": 1411.33,
          "arena_votes": 33843
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 25.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1411.33
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "seed-oss-36b-instruct",
    "canonical_name": "Seed-OSS-36B-Instruct",
    "model_name": "Seed-OSS-36B-Instruct",
    "aliases": [
      "Seed-OSS-36B-Instruct"
    ],
    "provider": null,
    "context_window": 512000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "ByteDance Seed",
    "intelligence_score": 25.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.3,
    "latency_seconds": 1.77,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 30.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402598+00:00",
        "confidence": 0.65,
        "raw_name": "Seed-OSS-36B-Instruct",
        "raw_scores": {
          "intelligence_score": 25.0,
          "blended_cost_per_1m": 0.3,
          "latency_seconds": 1.77,
          "tokens_per_second": 30.0,
          "context_window": 512000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 25.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-235b-2507",
    "canonical_name": "Qwen3 235B 2507",
    "model_name": "Qwen3 235B 2507",
    "aliases": [
      "Qwen3 235B 2507"
    ],
    "provider": "Alibaba",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 25.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.23,
    "latency_seconds": 1.11,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 44.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402616+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 235B 2507",
        "raw_scores": {
          "intelligence_score": 25.0,
          "blended_cost_per_1m": 1.23,
          "latency_seconds": 1.11,
          "tokens_per_second": 44.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 25.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-coder-480b",
    "canonical_name": "Qwen3 Coder 480B",
    "model_name": "Qwen3 Coder 480B",
    "aliases": [
      "Qwen3 Coder 480B"
    ],
    "provider": "Alibaba",
    "context_window": 262000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 25.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.0,
    "latency_seconds": 1.64,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 40.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402635+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 Coder 480B",
        "raw_scores": {
          "intelligence_score": 25.0,
          "blended_cost_per_1m": 3.0,
          "latency_seconds": 1.64,
          "tokens_per_second": 40.0,
          "context_window": 262000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 25.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-vl-32b",
    "canonical_name": "Qwen3 VL 32B",
    "model_name": "Qwen3 VL 32B",
    "aliases": [
      "Qwen3 VL 32B"
    ],
    "provider": "Alibaba",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 25.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 2.63,
    "latency_seconds": 1.32,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 85.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402654+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 VL 32B",
        "raw_scores": {
          "intelligence_score": 25.0,
          "blended_cost_per_1m": 2.63,
          "latency_seconds": 1.32,
          "tokens_per_second": 85.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 25.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "sonar-reasoning-pro",
    "canonical_name": "Sonar Reasoning Pro",
    "model_name": "Sonar Reasoning Pro",
    "aliases": [
      "Sonar Reasoning Pro"
    ],
    "provider": null,
    "context_window": 127000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Perplexity",
    "intelligence_score": 25.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402672+00:00",
        "confidence": 0.65,
        "raw_name": "Sonar Reasoning Pro",
        "raw_scores": {
          "intelligence_score": 25.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 127000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 25.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gpt-oss-20b",
    "canonical_name": "gpt-oss-20B (high)",
    "model_name": "gpt-oss-20B (high)",
    "aliases": [
      "gpt-oss-20B (high)",
      "gpt-oss-20B (low)",
      "gpt-oss-20b"
    ],
    "provider": "OpenAI",
    "context_window": 131000,
    "open_source": null,
    "arena_votes": 10758,
    "license_type": "Apache 2.0",
    "creator": "OpenAI",
    "intelligence_score": 22.5,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1317.02,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.105,
    "latency_seconds": 0.51,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 289.5,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402729+00:00",
        "confidence": 0.65,
        "raw_name": "gpt-oss-20B (high)",
        "raw_scores": {
          "intelligence_score": 24.0,
          "blended_cost_per_1m": 0.11,
          "latency_seconds": 0.49,
          "tokens_per_second": 310.0,
          "context_window": 131000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403378+00:00",
        "confidence": 0.65,
        "raw_name": "gpt-oss-20B (low)",
        "raw_scores": {
          "intelligence_score": 21.0,
          "blended_cost_per_1m": 0.1,
          "latency_seconds": 0.53,
          "tokens_per_second": 269.0,
          "context_window": 131000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829988+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-oss-20b",
        "raw_scores": {
          "arena_elo": 1317.02,
          "arena_votes": 10758
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 24.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1317.02
      }
    },
    "confidence_score": 0.7667,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "minimax-m1-80k",
    "canonical_name": "MiniMax M1 80k",
    "model_name": "MiniMax M1 80k",
    "aliases": [
      "MiniMax M1 80k"
    ],
    "provider": "MiniMax",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "MiniMax",
    "intelligence_score": 24.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.96,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402748+00:00",
        "confidence": 0.65,
        "raw_name": "MiniMax M1 80k",
        "raw_scores": {
          "intelligence_score": 24.0,
          "blended_cost_per_1m": 0.96,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 24.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "nvidia-nemotron-3-nano",
    "canonical_name": "NVIDIA Nemotron 3 Nano",
    "model_name": "NVIDIA Nemotron 3 Nano",
    "aliases": [
      "NVIDIA Nemotron 3 Nano"
    ],
    "provider": null,
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "NVIDIA",
    "intelligence_score": 24.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.1,
    "latency_seconds": 0.55,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 153.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402785+00:00",
        "confidence": 0.65,
        "raw_name": "NVIDIA Nemotron 3 Nano",
        "raw_scores": {
          "intelligence_score": 24.0,
          "blended_cost_per_1m": 0.1,
          "latency_seconds": 0.55,
          "tokens_per_second": 153.0,
          "context_window": 1000000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 24.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "k2-think-v2",
    "canonical_name": "K2 Think V2",
    "model_name": "K2 Think V2",
    "aliases": [
      "K2 Think V2"
    ],
    "provider": null,
    "context_window": 262000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "MBZUAI Institute of Foundation Models",
    "intelligence_score": 24.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402804+00:00",
        "confidence": 0.65,
        "raw_name": "K2 Think V2",
        "raw_scores": {
          "intelligence_score": 24.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 262000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 24.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "o1-preview",
    "canonical_name": "o1-preview",
    "model_name": "o1-preview",
    "aliases": [
      "o1-preview"
    ],
    "provider": "OpenAI",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 31120,
    "license_type": "Proprietary",
    "creator": "OpenAI",
    "intelligence_score": 24.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1388.16,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 28.88,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402843+00:00",
        "confidence": 0.65,
        "raw_name": "o1-preview",
        "raw_scores": {
          "intelligence_score": 24.0,
          "blended_cost_per_1m": 28.88,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828819+00:00",
        "confidence": 1.0,
        "raw_name": "o1-preview",
        "raw_scores": {
          "arena_elo": 1388.16,
          "arena_votes": 31120
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 24.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1388.16
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "hyperclova-x-seed-think",
    "canonical_name": "HyperCLOVA X SEED Think (32B)",
    "model_name": "HyperCLOVA X SEED Think (32B)",
    "aliases": [
      "HyperCLOVA X SEED Think (32B)"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Naver",
    "intelligence_score": 24.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402863+00:00",
        "confidence": 0.65,
        "raw_name": "HyperCLOVA X SEED Think (32B)",
        "raw_scores": {
          "intelligence_score": 24.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 24.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "glm-46v",
    "canonical_name": "GLM-4.6V",
    "model_name": "GLM-4.6V",
    "aliases": [
      "GLM-4.6V",
      "glm-4.6v"
    ],
    "provider": "Z.ai",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 2785,
    "license_type": "MIT",
    "creator": "Z AI",
    "intelligence_score": 23.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1377.44,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.45,
    "latency_seconds": 0.6,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 85.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402920+00:00",
        "confidence": 0.65,
        "raw_name": "GLM-4.6V",
        "raw_scores": {
          "intelligence_score": 23.0,
          "blended_cost_per_1m": 0.45,
          "latency_seconds": 0.6,
          "tokens_per_second": 85.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828944+00:00",
        "confidence": 1.0,
        "raw_name": "glm-4.6v",
        "raw_scores": {
          "arena_elo": 1377.44,
          "arena_votes": 2785
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 23.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1377.44
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "glm-45-air",
    "canonical_name": "GLM-4.5-Air",
    "model_name": "GLM-4.5-Air",
    "aliases": [
      "GLM-4.5-Air",
      "glm-4.5-air"
    ],
    "provider": "Z.ai",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 31154,
    "license_type": "MIT",
    "creator": "Z AI",
    "intelligence_score": 23.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1371.75,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.42,
    "latency_seconds": 0.61,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 124.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.402978+00:00",
        "confidence": 0.65,
        "raw_name": "GLM-4.5-Air",
        "raw_scores": {
          "intelligence_score": 23.0,
          "blended_cost_per_1m": 0.42,
          "latency_seconds": 0.61,
          "tokens_per_second": 124.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829024+00:00",
        "confidence": 1.0,
        "raw_name": "glm-4.5-air",
        "raw_scores": {
          "arena_elo": 1371.75,
          "arena_votes": 31154
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 23.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1371.75
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "midm-k-25-pro",
    "canonical_name": "Mi:dm K 2.5 Pro",
    "model_name": "Mi:dm K 2.5 Pro",
    "aliases": [
      "Mi:dm K 2.5 Pro"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Korea Telecom",
    "intelligence_score": 23.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403036+00:00",
        "confidence": 0.65,
        "raw_name": "Mi:dm K 2.5 Pro",
        "raw_scores": {
          "intelligence_score": 23.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 23.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gpt-41-mini",
    "canonical_name": "GPT-4.1 mini",
    "model_name": "GPT-4.1 mini",
    "aliases": [
      "GPT-4.1 mini",
      "gpt-4.1-mini-2025-04-14"
    ],
    "provider": "OpenAI",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": 40313,
    "license_type": "Proprietary",
    "creator": "OpenAI",
    "intelligence_score": 23.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1381.85,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.7,
    "latency_seconds": 0.5,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 64.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403056+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-4.1 mini",
        "raw_scores": {
          "intelligence_score": 23.0,
          "blended_cost_per_1m": 0.7,
          "latency_seconds": 0.5,
          "tokens_per_second": 64.0,
          "context_window": 1000000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828919+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-4.1-mini-2025-04-14",
        "raw_scores": {
          "arena_elo": 1381.85,
          "arena_votes": 40313
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 23.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1381.85
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "mistral-large-3",
    "canonical_name": "Mistral Large 3",
    "model_name": "Mistral Large 3",
    "aliases": [
      "Mistral Large 3",
      "mistral-large-3"
    ],
    "provider": "Mistral",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": 27128,
    "license_type": "Apache 2.0",
    "creator": "Mistral",
    "intelligence_score": 23.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1414.85,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.75,
    "latency_seconds": 0.6,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 50.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403075+00:00",
        "confidence": 0.65,
        "raw_name": "Mistral Large 3",
        "raw_scores": {
          "intelligence_score": 23.0,
          "blended_cost_per_1m": 0.75,
          "latency_seconds": 0.6,
          "tokens_per_second": 50.0,
          "context_window": 256000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828402+00:00",
        "confidence": 1.0,
        "raw_name": "mistral-large-3",
        "raw_scores": {
          "arena_elo": 1414.85,
          "arena_votes": 27128
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 23.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1414.85
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "ring-1t",
    "canonical_name": "Ring-1T",
    "model_name": "Ring-1T",
    "aliases": [
      "Ring-1T"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "InclusionAI",
    "intelligence_score": 23.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403094+00:00",
        "confidence": 0.65,
        "raw_name": "Ring-1T",
        "raw_scores": {
          "intelligence_score": 23.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 23.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-30b-a3b-2507",
    "canonical_name": "Qwen3 30B A3B 2507",
    "model_name": "Qwen3 30B A3B 2507",
    "aliases": [
      "Qwen3 30B A3B 2507"
    ],
    "provider": "Alibaba",
    "context_window": 262000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 22.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.75,
    "latency_seconds": 1.05,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 164.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403113+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 30B A3B 2507",
        "raw_scores": {
          "intelligence_score": 22.0,
          "blended_cost_per_1m": 0.75,
          "latency_seconds": 1.05,
          "tokens_per_second": 164.0,
          "context_window": 262000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 22.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-v3-0324",
    "canonical_name": "DeepSeek V3 0324",
    "model_name": "DeepSeek V3 0324",
    "aliases": [
      "DeepSeek V3 0324",
      "deepseek-v3-0324"
    ],
    "provider": "DeepSeek",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 46431,
    "license_type": "MIT",
    "creator": "DeepSeek",
    "intelligence_score": 22.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1394.16,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.25,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403132+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek V3 0324",
        "raw_scores": {
          "intelligence_score": 22.0,
          "blended_cost_per_1m": 1.25,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828687+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-v3-0324",
        "raw_scores": {
          "arena_elo": 1394.16,
          "arena_votes": 46431
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 22.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1394.16
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "intellect-3",
    "canonical_name": "INTELLECT-3",
    "model_name": "INTELLECT-3",
    "aliases": [
      "INTELLECT-3",
      "intellect-3"
    ],
    "provider": "Prime Intellect",
    "context_window": 131000,
    "open_source": null,
    "arena_votes": 5290,
    "license_type": "MIT",
    "creator": "Prime Intellect",
    "intelligence_score": 22.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1356.04,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403170+00:00",
        "confidence": 0.65,
        "raw_name": "INTELLECT-3",
        "raw_scores": {
          "intelligence_score": 22.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 131000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829306+00:00",
        "confidence": 1.0,
        "raw_name": "intellect-3",
        "raw_scores": {
          "arena_elo": 1356.04,
          "arena_votes": 5290
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 22.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1356.04
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "devstral-2",
    "canonical_name": "Devstral 2",
    "model_name": "Devstral 2",
    "aliases": [
      "Devstral 2"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 22.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.39,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 75.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403223+00:00",
        "confidence": 0.65,
        "raw_name": "Devstral 2",
        "raw_scores": {
          "intelligence_score": 22.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.39,
          "tokens_per_second": 75.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 22.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "solar-open-100b",
    "canonical_name": "Solar Open 100B",
    "model_name": "Solar Open 100B",
    "aliases": [
      "Solar Open 100B"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Upstage",
    "intelligence_score": 22.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403264+00:00",
        "confidence": 0.65,
        "raw_name": "Solar Open 100B",
        "raw_scores": {
          "intelligence_score": 22.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 22.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemini-25-flash-lite",
    "canonical_name": "Gemini 2.5 Flash-Lite (Sep)",
    "model_name": "Gemini 2.5 Flash-Lite (Sep)",
    "aliases": [
      "Gemini 2.5 Flash-Lite",
      "Gemini 2.5 Flash-Lite (Sep)"
    ],
    "provider": "Google",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Google",
    "intelligence_score": 20.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.17,
    "latency_seconds": 10.065,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 448.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403283+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 2.5 Flash-Lite (Sep)",
        "raw_scores": {
          "intelligence_score": 22.0,
          "blended_cost_per_1m": 0.17,
          "latency_seconds": 7.95,
          "tokens_per_second": 482.0,
          "context_window": 1000000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404258+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 2.5 Flash-Lite",
        "raw_scores": {
          "intelligence_score": 18.0,
          "blended_cost_per_1m": 0.17,
          "latency_seconds": 12.18,
          "tokens_per_second": 414.0,
          "context_window": 1000000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 22.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "grok-3-reasoning-beta",
    "canonical_name": "Grok 3 Reasoning Beta",
    "model_name": "Grok 3 Reasoning Beta",
    "aliases": [
      "Grok 3 Reasoning Beta"
    ],
    "provider": "xAI",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "xAI",
    "intelligence_score": 22.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403302+00:00",
        "confidence": 0.65,
        "raw_name": "Grok 3 Reasoning Beta",
        "raw_scores": {
          "intelligence_score": 22.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 22.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "mistral-medium-31",
    "canonical_name": "Mistral Medium 3.1",
    "model_name": "Mistral Medium 3.1",
    "aliases": [
      "Mistral Medium 3.1"
    ],
    "provider": "Mistral AI",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 21.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.8,
    "latency_seconds": 0.42,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 74.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403321+00:00",
        "confidence": 0.65,
        "raw_name": "Mistral Medium 3.1",
        "raw_scores": {
          "intelligence_score": 21.0,
          "blended_cost_per_1m": 0.8,
          "latency_seconds": 0.42,
          "tokens_per_second": 74.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 21.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "nvidia-nemotron-nano-12b-v2-vl",
    "canonical_name": "NVIDIA Nemotron Nano 12B v2 VL",
    "model_name": "NVIDIA Nemotron Nano 12B v2 VL",
    "aliases": [
      "NVIDIA Nemotron Nano 12B v2 VL"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "NVIDIA",
    "intelligence_score": 21.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.3,
    "latency_seconds": 0.41,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 129.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403340+00:00",
        "confidence": 0.65,
        "raw_name": "NVIDIA Nemotron Nano 12B v2 VL",
        "raw_scores": {
          "intelligence_score": 21.0,
          "blended_cost_per_1m": 0.3,
          "latency_seconds": 0.41,
          "tokens_per_second": 129.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 21.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "minimax-m1-40k",
    "canonical_name": "MiniMax M1 40k",
    "model_name": "MiniMax M1 40k",
    "aliases": [
      "MiniMax M1 40k"
    ],
    "provider": "MiniMax",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "MiniMax",
    "intelligence_score": 21.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403359+00:00",
        "confidence": 0.65,
        "raw_name": "MiniMax M1 40k",
        "raw_scores": {
          "intelligence_score": 21.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 21.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "k2-v2",
    "canonical_name": "K2-V2 (high)",
    "model_name": "K2-V2 (high)",
    "aliases": [
      "K2-V2 (high)",
      "K2-V2 (low)",
      "K2-V2 (medium)"
    ],
    "provider": null,
    "context_window": 512000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "MBZUAI Institute of Foundation Models",
    "intelligence_score": 18.6667,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403435+00:00",
        "confidence": 0.65,
        "raw_name": "K2-V2 (high)",
        "raw_scores": {
          "intelligence_score": 21.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 512000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403907+00:00",
        "confidence": 0.65,
        "raw_name": "K2-V2 (medium)",
        "raw_scores": {
          "intelligence_score": 19.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 512000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404505+00:00",
        "confidence": 0.65,
        "raw_name": "K2-V2 (low)",
        "raw_scores": {
          "intelligence_score": 16.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 512000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 21.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "ring-flash-20",
    "canonical_name": "Ring-flash-2.0",
    "model_name": "Ring-flash-2.0",
    "aliases": [
      "Ring-flash-2.0",
      "ring-flash-2.0"
    ],
    "provider": "Ant Group",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 7148,
    "license_type": "MIT",
    "creator": "InclusionAI",
    "intelligence_score": 21.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1320.45,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.25,
    "latency_seconds": 1.52,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 83.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403454+00:00",
        "confidence": 0.65,
        "raw_name": "Ring-flash-2.0",
        "raw_scores": {
          "intelligence_score": 21.0,
          "blended_cost_per_1m": 0.25,
          "latency_seconds": 1.52,
          "tokens_per_second": 83.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829914+00:00",
        "confidence": 1.0,
        "raw_name": "ring-flash-2.0",
        "raw_scores": {
          "arena_elo": 1320.45,
          "arena_votes": 7148
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 21.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1320.45
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "o1-mini",
    "canonical_name": "o1-mini",
    "model_name": "o1-mini",
    "aliases": [
      "o1-mini"
    ],
    "provider": "OpenAI",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 51986,
    "license_type": "Proprietary",
    "creator": "OpenAI",
    "intelligence_score": 20.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1336.76,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403491+00:00",
        "confidence": 0.65,
        "raw_name": "o1-mini",
        "raw_scores": {
          "intelligence_score": 20.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829627+00:00",
        "confidence": 1.0,
        "raw_name": "o1-mini",
        "raw_scores": {
          "arena_elo": 1336.76,
          "arena_votes": 51986
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 20.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1336.76
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "tri-21b-think-preview",
    "canonical_name": "Tri-21B-think Preview",
    "model_name": "Tri-21B-think Preview",
    "aliases": [
      "Tri-21B-think Preview"
    ],
    "provider": null,
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Trillion Labs",
    "intelligence_score": 20.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403530+00:00",
        "confidence": 0.65,
        "raw_name": "Tri-21B-think Preview",
        "raw_scores": {
          "intelligence_score": 20.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 20.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-coder-30b-a3b",
    "canonical_name": "Qwen3 Coder 30B A3B",
    "model_name": "Qwen3 Coder 30B A3B",
    "aliases": [
      "Qwen3 Coder 30B A3B"
    ],
    "provider": "Alibaba",
    "context_window": 262000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 20.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.9,
    "latency_seconds": 1.49,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 21.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403550+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 Coder 30B A3B",
        "raw_scores": {
          "intelligence_score": 20.0,
          "blended_cost_per_1m": 0.9,
          "latency_seconds": 1.49,
          "tokens_per_second": 21.0,
          "context_window": 262000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 20.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gpt-45",
    "canonical_name": "GPT-4.5 (Preview)",
    "model_name": "GPT-4.5 (Preview)",
    "aliases": [
      "GPT-4.5 (Preview)"
    ],
    "provider": "OpenAI",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "OpenAI",
    "intelligence_score": 20.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403568+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-4.5 (Preview)",
        "raw_scores": {
          "intelligence_score": 20.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 20.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-235b",
    "canonical_name": "Qwen3 235B",
    "model_name": "Qwen3 235B",
    "aliases": [
      "Qwen3 235B",
      "qwen3-235b-a22b-instruct-2507",
      "qwen3-235b-a22b-no-thinking"
    ],
    "provider": "Alibaba",
    "context_window": 33000,
    "open_source": null,
    "arena_votes": 71551,
    "license_type": "Apache 2.0",
    "creator": "Alibaba",
    "intelligence_score": 20.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1412.025,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 2.63,
    "latency_seconds": 1.2,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 37.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403587+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 235B",
        "raw_scores": {
          "intelligence_score": 20.0,
          "blended_cost_per_1m": 2.63,
          "latency_seconds": 1.2,
          "tokens_per_second": 37.0,
          "context_window": 33000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828193+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-235b-a22b-instruct-2507",
        "raw_scores": {
          "arena_elo": 1422.1,
          "arena_votes": 71551
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828559+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-235b-a22b-no-thinking",
        "raw_scores": {
          "arena_elo": 1401.95,
          "arena_votes": 39295
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 20.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1422.1
      }
    },
    "confidence_score": 0.8833,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwq-32b",
    "canonical_name": "QwQ-32B",
    "model_name": "QwQ-32B",
    "aliases": [
      "QwQ-32B",
      "qwq-32b"
    ],
    "provider": "Alibaba",
    "context_window": 131000,
    "open_source": null,
    "arena_votes": 26000,
    "license_type": "Apache 2.0",
    "creator": "Alibaba",
    "intelligence_score": 20.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1335.78,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.47,
    "latency_seconds": 0.49,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 29.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403606+00:00",
        "confidence": 0.65,
        "raw_name": "QwQ-32B",
        "raw_scores": {
          "intelligence_score": 20.0,
          "blended_cost_per_1m": 0.47,
          "latency_seconds": 0.49,
          "tokens_per_second": 29.0,
          "context_window": 131000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829639+00:00",
        "confidence": 1.0,
        "raw_name": "qwq-32b",
        "raw_scores": {
          "arena_elo": 1335.78,
          "arena_votes": 26000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 20.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1335.78
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-vl-30b-a3b",
    "canonical_name": "Qwen3 VL 30B A3B",
    "model_name": "Qwen3 VL 30B A3B",
    "aliases": [
      "Qwen3 VL 30B A3B"
    ],
    "provider": "Alibaba",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 20.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.75,
    "latency_seconds": 1.01,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 77.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403625+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 VL 30B A3B",
        "raw_scores": {
          "intelligence_score": 20.0,
          "blended_cost_per_1m": 0.75,
          "latency_seconds": 1.01,
          "tokens_per_second": 77.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 20.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemini-20-flash-thinking-exp",
    "canonical_name": "Gemini 2.0 Flash Thinking exp. (Jan)",
    "model_name": "Gemini 2.0 Flash Thinking exp. (Jan)",
    "aliases": [
      "Gemini 2.0 Flash Thinking exp. (Dec)",
      "Gemini 2.0 Flash Thinking exp. (Jan)"
    ],
    "provider": "Google",
    "context_window": 2000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Google",
    "intelligence_score": 16.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403644+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 2.0 Flash Thinking exp. (Jan)",
        "raw_scores": {
          "intelligence_score": 20.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406368+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 2.0 Flash Thinking exp. (Dec)",
        "raw_scores": {
          "intelligence_score": 12.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 2000000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 20.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "devstral-small-2",
    "canonical_name": "Devstral Small 2",
    "model_name": "Devstral Small 2",
    "aliases": [
      "Devstral Small 2"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 19.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.36,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 200.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403663+00:00",
        "confidence": 0.65,
        "raw_name": "Devstral Small 2",
        "raw_scores": {
          "intelligence_score": 19.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.36,
          "tokens_per_second": 200.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "glm-45v",
    "canonical_name": "GLM-4.5V",
    "model_name": "GLM-4.5V",
    "aliases": [
      "GLM-4.5V",
      "glm-4.5v"
    ],
    "provider": "Z.ai",
    "context_window": 64000,
    "open_source": null,
    "arena_votes": 4950,
    "license_type": "MIT",
    "creator": "Z AI",
    "intelligence_score": 19.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1353.13,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.9,
    "latency_seconds": 1.01,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 40.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403701+00:00",
        "confidence": 0.65,
        "raw_name": "GLM-4.5V",
        "raw_scores": {
          "intelligence_score": 19.0,
          "blended_cost_per_1m": 0.9,
          "latency_seconds": 1.01,
          "tokens_per_second": 40.0,
          "context_window": 64000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829355+00:00",
        "confidence": 1.0,
        "raw_name": "glm-4.5v",
        "raw_scores": {
          "arena_elo": 1353.13,
          "arena_votes": 4950
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1353.13
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "motif-2-127b",
    "canonical_name": "Motif-2-12.7B",
    "model_name": "Motif-2-12.7B",
    "aliases": [
      "Motif-2-12.7B"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Motif Technologies",
    "intelligence_score": 19.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403720+00:00",
        "confidence": 0.65,
        "raw_name": "Motif-2-12.7B",
        "raw_scores": {
          "intelligence_score": 19.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "ling-1t",
    "canonical_name": "Ling-1T",
    "model_name": "Ling-1T",
    "aliases": [
      "Ling-1T"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "InclusionAI",
    "intelligence_score": 19.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403738+00:00",
        "confidence": 0.65,
        "raw_name": "Ling-1T",
        "raw_scores": {
          "intelligence_score": 19.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "nova-premier",
    "canonical_name": "Nova Premier",
    "model_name": "Nova Premier",
    "aliases": [
      "Nova Premier"
    ],
    "provider": "Amazon",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Amazon",
    "intelligence_score": 19.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 5.0,
    "latency_seconds": 0.83,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 77.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403757+00:00",
        "confidence": 0.65,
        "raw_name": "Nova Premier",
        "raw_scores": {
          "intelligence_score": 19.0,
          "blended_cost_per_1m": 5.0,
          "latency_seconds": 0.83,
          "tokens_per_second": 77.0,
          "context_window": 1000000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "olmo-3-32b-think",
    "canonical_name": "Olmo 3 32B Think",
    "model_name": "Olmo 3 32B Think",
    "aliases": [
      "Olmo 3 32B Think",
      "olmo-3-32b-think"
    ],
    "provider": "Ai2",
    "context_window": 66000,
    "open_source": null,
    "arena_votes": 5868,
    "license_type": "Apache 2.0",
    "creator": "Allen Institute for AI",
    "intelligence_score": 19.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1305.64,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403775+00:00",
        "confidence": 0.65,
        "raw_name": "Olmo 3 32B Think",
        "raw_scores": {
          "intelligence_score": 19.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 66000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830147+00:00",
        "confidence": 1.0,
        "raw_name": "olmo-3-32b-think",
        "raw_scores": {
          "arena_elo": 1305.64,
          "arena_votes": 5868
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1305.64
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "solar-pro-2",
    "canonical_name": "Solar Pro 2",
    "model_name": "Solar Pro 2",
    "aliases": [
      "Solar Pro 2"
    ],
    "provider": null,
    "context_window": 64000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Upstage",
    "intelligence_score": 19.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403813+00:00",
        "confidence": 0.65,
        "raw_name": "Solar Pro 2",
        "raw_scores": {
          "intelligence_score": 19.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 64000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "nvidia-nemotron-nano-9b-v2",
    "canonical_name": "NVIDIA Nemotron Nano 9B V2",
    "model_name": "NVIDIA Nemotron Nano 9B V2",
    "aliases": [
      "NVIDIA Nemotron Nano 9B V2"
    ],
    "provider": null,
    "context_window": 131000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "NVIDIA",
    "intelligence_score": 19.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.1,
    "latency_seconds": 0.53,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 119.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403832+00:00",
        "confidence": 0.65,
        "raw_name": "NVIDIA Nemotron Nano 9B V2",
        "raw_scores": {
          "intelligence_score": 19.0,
          "blended_cost_per_1m": 0.1,
          "latency_seconds": 0.53,
          "tokens_per_second": 119.0,
          "context_window": 131000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "magistral-medium-1",
    "canonical_name": "Magistral Medium 1",
    "model_name": "Magistral Medium 1",
    "aliases": [
      "Magistral Medium 1"
    ],
    "provider": null,
    "context_window": 40000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 19.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403851+00:00",
        "confidence": 0.65,
        "raw_name": "Magistral Medium 1",
        "raw_scores": {
          "intelligence_score": 19.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 40000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "mistral-medium-3",
    "canonical_name": "Mistral Medium 3",
    "model_name": "Mistral Medium 3",
    "aliases": [
      "Mistral Medium 3"
    ],
    "provider": "Mistral AI",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 19.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.8,
    "latency_seconds": 0.41,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 50.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403870+00:00",
        "confidence": 0.65,
        "raw_name": "Mistral Medium 3",
        "raw_scores": {
          "intelligence_score": 19.0,
          "blended_cost_per_1m": 0.8,
          "latency_seconds": 0.41,
          "tokens_per_second": 50.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-nemotron-super-49b-v15",
    "canonical_name": "Llama Nemotron Super 49B v1.5",
    "model_name": "Llama Nemotron Super 49B v1.5",
    "aliases": [
      "Llama Nemotron Super 49B v1.5"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "NVIDIA",
    "intelligence_score": 19.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.17,
    "latency_seconds": 0.22,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 76.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403889+00:00",
        "confidence": 0.65,
        "raw_name": "Llama Nemotron Super 49B v1.5",
        "raw_scores": {
          "intelligence_score": 19.0,
          "blended_cost_per_1m": 0.17,
          "latency_seconds": 0.22,
          "tokens_per_second": 76.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "claude-35-haiku",
    "canonical_name": "Claude 3.5 Haiku",
    "model_name": "Claude 3.5 Haiku",
    "aliases": [
      "Claude 3.5 Haiku",
      "claude-3.5-haiku-20241022"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 70972,
    "license_type": "Proprietary",
    "creator": "Anthropic",
    "intelligence_score": 19.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1323.39,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.6,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403926+00:00",
        "confidence": 0.65,
        "raw_name": "Claude 3.5 Haiku",
        "raw_scores": {
          "intelligence_score": 19.0,
          "blended_cost_per_1m": 1.6,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 200000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829827+00:00",
        "confidence": 1.0,
        "raw_name": "claude-3.5-haiku-20241022",
        "raw_scores": {
          "arena_elo": 1323.39,
          "arena_votes": 70972
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1323.39
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "devstral-medium",
    "canonical_name": "Devstral Medium",
    "model_name": "Devstral Medium",
    "aliases": [
      "Devstral Medium"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 19.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.8,
    "latency_seconds": 0.45,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 107.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403944+00:00",
        "confidence": 0.65,
        "raw_name": "Devstral Medium",
        "raw_scores": {
          "intelligence_score": 19.0,
          "blended_cost_per_1m": 0.8,
          "latency_seconds": 0.45,
          "tokens_per_second": 107.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gpt-4o",
    "canonical_name": "GPT-4o (Aug)",
    "model_name": "GPT-4o (Aug)",
    "aliases": [
      "GPT-4o (Aug)",
      "GPT-4o (ChatGPT)",
      "GPT-4o (Mar)",
      "GPT-4o (May)",
      "GPT-4o (Nov)",
      "chatgpt-4o-latest-20250326",
      "gpt-4o-2024-05-13"
    ],
    "provider": "OpenAI",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 112863,
    "license_type": "Proprietary",
    "creator": "OpenAI",
    "intelligence_score": 16.6,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1394.235,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.252,
    "latency_seconds": 0.292,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 66.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403963+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-4o (Aug)",
        "raw_scores": {
          "intelligence_score": 19.0,
          "blended_cost_per_1m": 4.38,
          "latency_seconds": 0.55,
          "tokens_per_second": 87.0,
          "context_window": 128000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404019+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-4o (Mar)",
        "raw_scores": {
          "intelligence_score": 19.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404277+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-4o (Nov)",
        "raw_scores": {
          "intelligence_score": 17.0,
          "blended_cost_per_1m": 4.38,
          "latency_seconds": 0.4,
          "tokens_per_second": 151.0,
          "context_window": 128000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.405468+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-4o (May)",
        "raw_scores": {
          "intelligence_score": 14.0,
          "blended_cost_per_1m": 7.5,
          "latency_seconds": 0.51,
          "tokens_per_second": 92.0,
          "context_window": 128000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.405715+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-4o (ChatGPT)",
        "raw_scores": {
          "intelligence_score": 14.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.827953+00:00",
        "confidence": 1.0,
        "raw_name": "chatgpt-4o-latest-20250326",
        "raw_scores": {
          "arena_elo": 1442.76,
          "arena_votes": 82938
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829521+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-4o-2024-05-13",
        "raw_scores": {
          "arena_elo": 1345.71,
          "arena_votes": 112863
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1442.76
      }
    },
    "confidence_score": 0.75,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "tri-21b-think",
    "canonical_name": "Tri-21B-Think",
    "model_name": "Tri-21B-Think",
    "aliases": [
      "Tri-21B-Think"
    ],
    "provider": null,
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Trillion Labs",
    "intelligence_score": 19.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.403981+00:00",
        "confidence": 0.65,
        "raw_name": "Tri-21B-Think",
        "raw_scores": {
          "intelligence_score": 19.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "hermes-4-405b",
    "canonical_name": "Hermes 4 405B",
    "model_name": "Hermes 4 405B",
    "aliases": [
      "Hermes 4 405B"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Nous Research",
    "intelligence_score": 19.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.5,
    "latency_seconds": 0.78,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 33.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404000+00:00",
        "confidence": 0.65,
        "raw_name": "Hermes 4 405B",
        "raw_scores": {
          "intelligence_score": 19.0,
          "blended_cost_per_1m": 1.5,
          "latency_seconds": 0.78,
          "tokens_per_second": 33.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemini-20-flash",
    "canonical_name": "Gemini 2.0 Flash",
    "model_name": "Gemini 2.0 Flash",
    "aliases": [
      "Gemini 2.0 Flash",
      "Gemini 2.0 Flash (exp)",
      "gemini-2.0-flash-001"
    ],
    "provider": "Google",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": 44686,
    "license_type": "Proprietary",
    "creator": "Google",
    "intelligence_score": 18.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1360.78,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.13,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404038+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 2.0 Flash",
        "raw_scores": {
          "intelligence_score": 19.0,
          "blended_cost_per_1m": 0.26,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404410+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 2.0 Flash (exp)",
        "raw_scores": {
          "intelligence_score": 17.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829269+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-2.0-flash-001",
        "raw_scores": {
          "arena_elo": 1360.78,
          "arena_votes": 44686
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1360.78
      }
    },
    "confidence_score": 0.7667,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-33-nemotron-super-49b",
    "canonical_name": "Llama 3.3 Nemotron Super 49B",
    "model_name": "Llama 3.3 Nemotron Super 49B",
    "aliases": [
      "Llama 3.3 Nemotron Super 49B"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "NVIDIA",
    "intelligence_score": 18.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404056+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 3.3 Nemotron Super 49B",
        "raw_scores": {
          "intelligence_score": 18.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 18.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-4-maverick",
    "canonical_name": "Llama 4 Maverick",
    "model_name": "Llama 4 Maverick",
    "aliases": [
      "Llama 4 Maverick",
      "llama-4-maverick-17b-128e-instruct"
    ],
    "provider": "Meta",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": 40932,
    "license_type": "Llama 4",
    "creator": "Meta",
    "intelligence_score": 18.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1327.62,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.46,
    "latency_seconds": 0.47,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 120.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404075+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 4 Maverick",
        "raw_scores": {
          "intelligence_score": 18.0,
          "blended_cost_per_1m": 0.46,
          "latency_seconds": 0.47,
          "tokens_per_second": 120.0,
          "context_window": 1000000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829774+00:00",
        "confidence": 1.0,
        "raw_name": "llama-4-maverick-17b-128e-instruct",
        "raw_scores": {
          "arena_elo": 1327.62,
          "arena_votes": 40932
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 18.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1327.62
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-4b-2507",
    "canonical_name": "Qwen3 4B 2507",
    "model_name": "Qwen3 4B 2507",
    "aliases": [
      "Qwen3 4B 2507"
    ],
    "provider": "Alibaba",
    "context_window": 262000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 18.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404094+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 4B 2507",
        "raw_scores": {
          "intelligence_score": 18.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 262000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 18.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "magistral-small-12",
    "canonical_name": "Magistral Small 1.2",
    "model_name": "Magistral Small 1.2",
    "aliases": [
      "Magistral Small 1.2"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 18.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.75,
    "latency_seconds": 0.34,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 202.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404112+00:00",
        "confidence": 0.65,
        "raw_name": "Magistral Small 1.2",
        "raw_scores": {
          "intelligence_score": 18.0,
          "blended_cost_per_1m": 0.75,
          "latency_seconds": 0.34,
          "tokens_per_second": 202.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 18.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemini-20-pro-experimental",
    "canonical_name": "Gemini 2.0 Pro Experimental",
    "model_name": "Gemini 2.0 Pro Experimental",
    "aliases": [
      "Gemini 2.0 Pro Experimental"
    ],
    "provider": "Google",
    "context_window": 2000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Google",
    "intelligence_score": 18.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404131+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 2.0 Pro Experimental",
        "raw_scores": {
          "intelligence_score": 18.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 2000000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 18.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "devstral-small",
    "canonical_name": "Devstral Small (May)",
    "model_name": "Devstral Small (May)",
    "aliases": [
      "Devstral Small",
      "Devstral Small (May)"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 16.5,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.11,
    "latency_seconds": 0.185,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 117.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404168+00:00",
        "confidence": 0.65,
        "raw_name": "Devstral Small (May)",
        "raw_scores": {
          "intelligence_score": 18.0,
          "blended_cost_per_1m": 0.07,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 256000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.405070+00:00",
        "confidence": 0.65,
        "raw_name": "Devstral Small",
        "raw_scores": {
          "intelligence_score": 15.0,
          "blended_cost_per_1m": 0.15,
          "latency_seconds": 0.37,
          "tokens_per_second": 234.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 18.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "sonar-reasoning",
    "canonical_name": "Sonar Reasoning",
    "model_name": "Sonar Reasoning",
    "aliases": [
      "Sonar Reasoning"
    ],
    "provider": null,
    "context_window": 127000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Perplexity",
    "intelligence_score": 18.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404186+00:00",
        "confidence": 0.65,
        "raw_name": "Sonar Reasoning",
        "raw_scores": {
          "intelligence_score": 18.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 127000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 18.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-r1-distill-qwen-32b",
    "canonical_name": "DeepSeek R1 Distill Qwen 32B",
    "model_name": "DeepSeek R1 Distill Qwen 32B",
    "aliases": [
      "DeepSeek R1 Distill Qwen 32B"
    ],
    "provider": "Alibaba",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "DeepSeek",
    "intelligence_score": 17.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.27,
    "latency_seconds": 0.25,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 56.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404315+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek R1 Distill Qwen 32B",
        "raw_scores": {
          "intelligence_score": 17.0,
          "blended_cost_per_1m": 0.27,
          "latency_seconds": 0.25,
          "tokens_per_second": 56.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 17.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "olmo-3-7b-think",
    "canonical_name": "Olmo 3 7B Think",
    "model_name": "Olmo 3 7B Think",
    "aliases": [
      "Olmo 3 7B Think"
    ],
    "provider": null,
    "context_window": 66000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Allen Institute for AI",
    "intelligence_score": 17.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.14,
    "latency_seconds": 0.42,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 68.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404373+00:00",
        "confidence": 0.65,
        "raw_name": "Olmo 3 7B Think",
        "raw_scores": {
          "intelligence_score": 17.0,
          "blended_cost_per_1m": 0.14,
          "latency_seconds": 0.42,
          "tokens_per_second": 68.0,
          "context_window": 66000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 17.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "magistral-small-1",
    "canonical_name": "Magistral Small 1",
    "model_name": "Magistral Small 1",
    "aliases": [
      "Magistral Small 1"
    ],
    "provider": null,
    "context_window": 40000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 17.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404392+00:00",
        "confidence": 0.65,
        "raw_name": "Magistral Small 1",
        "raw_scores": {
          "intelligence_score": 17.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 40000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 17.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "exaone-40-32b",
    "canonical_name": "EXAONE 4.0 32B",
    "model_name": "EXAONE 4.0 32B",
    "aliases": [
      "EXAONE 4.0 32B"
    ],
    "provider": null,
    "context_window": 131000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "LG AI Research",
    "intelligence_score": 17.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.7,
    "latency_seconds": 0.35,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 96.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404430+00:00",
        "confidence": 0.65,
        "raw_name": "EXAONE 4.0 32B",
        "raw_scores": {
          "intelligence_score": 17.0,
          "blended_cost_per_1m": 0.7,
          "latency_seconds": 0.35,
          "tokens_per_second": 96.0,
          "context_window": 131000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 17.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-vl-8b",
    "canonical_name": "Qwen3 VL 8B",
    "model_name": "Qwen3 VL 8B",
    "aliases": [
      "Qwen3 VL 8B"
    ],
    "provider": "Alibaba",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 17.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.66,
    "latency_seconds": 1.02,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 119.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404449+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 VL 8B",
        "raw_scores": {
          "intelligence_score": 17.0,
          "blended_cost_per_1m": 0.66,
          "latency_seconds": 1.02,
          "tokens_per_second": 119.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 17.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-32b",
    "canonical_name": "Qwen3 32B",
    "model_name": "Qwen3 32B",
    "aliases": [
      "Qwen3 32B",
      "qwen3-32b"
    ],
    "provider": "Alibaba",
    "context_window": 33000,
    "open_source": null,
    "arena_votes": 3932,
    "license_type": "Apache 2.0",
    "creator": "Alibaba",
    "intelligence_score": 17.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1347.0,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 2.63,
    "latency_seconds": 1.01,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 69.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404486+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 32B",
        "raw_scores": {
          "intelligence_score": 17.0,
          "blended_cost_per_1m": 2.63,
          "latency_seconds": 1.01,
          "tokens_per_second": 69.0,
          "context_window": 33000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829457+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-32b",
        "raw_scores": {
          "arena_elo": 1347.0,
          "arena_votes": 3932
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 17.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1347.0
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-v3",
    "canonical_name": "DeepSeek V3 (Dec)",
    "model_name": "DeepSeek V3 (Dec)",
    "aliases": [
      "DeepSeek V3 (Dec)",
      "deepseek-v3"
    ],
    "provider": "DeepSeek",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 21788,
    "license_type": "DeepSeek",
    "creator": "DeepSeek",
    "intelligence_score": 16.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1358.47,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.63,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404524+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek V3 (Dec)",
        "raw_scores": {
          "intelligence_score": 16.0,
          "blended_cost_per_1m": 0.63,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829281+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-v3",
        "raw_scores": {
          "arena_elo": 1358.47,
          "arena_votes": 21788
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 16.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1358.47
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-r1-0528-qwen3-8b",
    "canonical_name": "DeepSeek R1 0528 Qwen3 8B",
    "model_name": "DeepSeek R1 0528 Qwen3 8B",
    "aliases": [
      "DeepSeek R1 0528 Qwen3 8B"
    ],
    "provider": "Alibaba",
    "context_window": 33000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "DeepSeek",
    "intelligence_score": 16.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404542+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek R1 0528 Qwen3 8B",
        "raw_scores": {
          "intelligence_score": 16.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 33000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 16.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen25-max",
    "canonical_name": "Qwen2.5 Max",
    "model_name": "Qwen2.5 Max",
    "aliases": [
      "Qwen2.5 Max",
      "qwen2.5-max"
    ],
    "provider": "Alibaba",
    "context_window": 32000,
    "open_source": null,
    "arena_votes": 33204,
    "license_type": "Proprietary",
    "creator": "Alibaba",
    "intelligence_score": 16.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1374.18,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 2.8,
    "latency_seconds": 1.12,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 39.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404560+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen2.5 Max",
        "raw_scores": {
          "intelligence_score": 16.0,
          "blended_cost_per_1m": 2.8,
          "latency_seconds": 1.12,
          "tokens_per_second": 39.0,
          "context_window": 32000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828995+00:00",
        "confidence": 1.0,
        "raw_name": "qwen2.5-max",
        "raw_scores": {
          "arena_elo": 1374.18,
          "arena_votes": 33204
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 16.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1374.18
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-14b",
    "canonical_name": "Qwen3 14B",
    "model_name": "Qwen3 14B",
    "aliases": [
      "Qwen3 14B"
    ],
    "provider": "Alibaba",
    "context_window": 33000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 16.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.31,
    "latency_seconds": 1.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 56.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404579+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 14B",
        "raw_scores": {
          "intelligence_score": 16.0,
          "blended_cost_per_1m": 1.31,
          "latency_seconds": 1.0,
          "tokens_per_second": 56.0,
          "context_window": 33000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 16.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-omni-30b-a3b",
    "canonical_name": "Qwen3 Omni 30B A3B",
    "model_name": "Qwen3 Omni 30B A3B",
    "aliases": [
      "Qwen3 Omni 30B A3B"
    ],
    "provider": "Alibaba",
    "context_window": 66000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 16.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.43,
    "latency_seconds": 0.86,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 88.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404654+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 Omni 30B A3B",
        "raw_scores": {
          "intelligence_score": 16.0,
          "blended_cost_per_1m": 0.43,
          "latency_seconds": 0.86,
          "tokens_per_second": 88.0,
          "context_window": 66000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 16.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemini-15-pro",
    "canonical_name": "Gemini 1.5 Pro (Sep)",
    "model_name": "Gemini 1.5 Pro (Sep)",
    "aliases": [
      "Gemini 1.5 Pro (May)",
      "Gemini 1.5 Pro (Sep)",
      "gemini-1.5-pro-001",
      "gemini-1.5-pro-002"
    ],
    "provider": "Google",
    "context_window": 2000000,
    "open_source": null,
    "arena_votes": 79132,
    "license_type": "Proprietary",
    "creator": "Google",
    "intelligence_score": 14.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1337.125,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404711+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 1.5 Pro (Sep)",
        "raw_scores": {
          "intelligence_score": 16.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 2000000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406442+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 1.5 Pro (May)",
        "raw_scores": {
          "intelligence_score": 12.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 2000000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829381+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-1.5-pro-002",
        "raw_scores": {
          "arena_elo": 1351.24,
          "arena_votes": 55607
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829853+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-1.5-pro-001",
        "raw_scores": {
          "arena_elo": 1323.01,
          "arena_votes": 79132
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 16.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1351.24
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "hermes-4-70b",
    "canonical_name": "Hermes 4 70B",
    "model_name": "Hermes 4 70B",
    "aliases": [
      "Hermes 4 70B"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Nous Research",
    "intelligence_score": 16.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.2,
    "latency_seconds": 0.65,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 79.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404749+00:00",
        "confidence": 0.65,
        "raw_name": "Hermes 4 70B",
        "raw_scores": {
          "intelligence_score": 16.0,
          "blended_cost_per_1m": 0.2,
          "latency_seconds": 0.65,
          "tokens_per_second": 79.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 16.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "ministral-3-14b",
    "canonical_name": "Ministral 3 14B",
    "model_name": "Ministral 3 14B",
    "aliases": [
      "Ministral 3 14B"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 16.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.2,
    "latency_seconds": 0.28,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 140.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404768+00:00",
        "confidence": 0.65,
        "raw_name": "Ministral 3 14B",
        "raw_scores": {
          "intelligence_score": 16.0,
          "blended_cost_per_1m": 0.2,
          "latency_seconds": 0.28,
          "tokens_per_second": 140.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 16.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-r1-distill-llama-70b",
    "canonical_name": "DeepSeek R1 Distill Llama 70B",
    "model_name": "DeepSeek R1 Distill Llama 70B",
    "aliases": [
      "DeepSeek R1 Distill Llama 70B"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "DeepSeek",
    "intelligence_score": 16.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.88,
    "latency_seconds": 0.81,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 57.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404787+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek R1 Distill Llama 70B",
        "raw_scores": {
          "intelligence_score": 16.0,
          "blended_cost_per_1m": 0.88,
          "latency_seconds": 0.81,
          "tokens_per_second": 57.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 16.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "claude-35-sonnet",
    "canonical_name": "Claude 3.5 Sonnet (Oct)",
    "model_name": "Claude 3.5 Sonnet (Oct)",
    "aliases": [
      "Claude 3.5 Sonnet (June)",
      "Claude 3.5 Sonnet (Oct)",
      "claude-3.5-sonnet-20241022"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 89293,
    "license_type": "Proprietary",
    "creator": "Anthropic",
    "intelligence_score": 15.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1372.29,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 6.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404806+00:00",
        "confidence": 0.65,
        "raw_name": "Claude 3.5 Sonnet (Oct)",
        "raw_scores": {
          "intelligence_score": 16.0,
          "blended_cost_per_1m": 6.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 200000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.405658+00:00",
        "confidence": 0.65,
        "raw_name": "Claude 3.5 Sonnet (June)",
        "raw_scores": {
          "intelligence_score": 14.0,
          "blended_cost_per_1m": 6.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 200000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829011+00:00",
        "confidence": 1.0,
        "raw_name": "claude-3.5-sonnet-20241022",
        "raw_scores": {
          "arena_elo": 1372.29,
          "arena_votes": 89293
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 16.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1372.29
      }
    },
    "confidence_score": 0.7667,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-r1-distill-qwen-14b",
    "canonical_name": "DeepSeek R1 Distill Qwen 14B",
    "model_name": "DeepSeek R1 Distill Qwen 14B",
    "aliases": [
      "DeepSeek R1 Distill Qwen 14B"
    ],
    "provider": "Alibaba",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "DeepSeek",
    "intelligence_score": 16.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404824+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek R1 Distill Qwen 14B",
        "raw_scores": {
          "intelligence_score": 16.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 16.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "falcon-h1r-7b",
    "canonical_name": "Falcon-H1R-7B",
    "model_name": "Falcon-H1R-7B",
    "aliases": [
      "Falcon-H1R-7B"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "TII UAE",
    "intelligence_score": 16.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404843+00:00",
        "confidence": 0.65,
        "raw_name": "Falcon-H1R-7B",
        "raw_scores": {
          "intelligence_score": 16.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 16.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "ling-flash-20",
    "canonical_name": "Ling-flash-2.0",
    "model_name": "Ling-flash-2.0",
    "aliases": [
      "Ling-flash-2.0",
      "ling-flash-2.0"
    ],
    "provider": "Ant Group",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 6995,
    "license_type": "MIT",
    "creator": "InclusionAI",
    "intelligence_score": 16.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1346.92,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.25,
    "latency_seconds": 1.71,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 59.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404862+00:00",
        "confidence": 0.65,
        "raw_name": "Ling-flash-2.0",
        "raw_scores": {
          "intelligence_score": 16.0,
          "blended_cost_per_1m": 0.25,
          "latency_seconds": 1.71,
          "tokens_per_second": 59.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829483+00:00",
        "confidence": 1.0,
        "raw_name": "ling-flash-2.0",
        "raw_scores": {
          "arena_elo": 1346.92,
          "arena_votes": 6995
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 16.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1346.92
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen25-72b",
    "canonical_name": "Qwen2.5 72B",
    "model_name": "Qwen2.5 72B",
    "aliases": [
      "Qwen2.5 72B"
    ],
    "provider": "Alibaba",
    "context_window": 131000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 16.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 1.12,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 46.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404938+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen2.5 72B",
        "raw_scores": {
          "intelligence_score": 16.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 1.12,
          "tokens_per_second": 46.0,
          "context_window": 131000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 16.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "sonar",
    "canonical_name": "Sonar",
    "model_name": "Sonar",
    "aliases": [
      "Sonar"
    ],
    "provider": null,
    "context_window": 127000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Perplexity",
    "intelligence_score": 15.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.0,
    "latency_seconds": 1.34,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 119.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404957+00:00",
        "confidence": 0.65,
        "raw_name": "Sonar",
        "raw_scores": {
          "intelligence_score": 15.0,
          "blended_cost_per_1m": 1.0,
          "latency_seconds": 1.34,
          "tokens_per_second": 119.0,
          "context_window": 127000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "step3-vl-10b",
    "canonical_name": "Step3 VL 10B",
    "model_name": "Step3 VL 10B",
    "aliases": [
      "Step3 VL 10B"
    ],
    "provider": null,
    "context_window": 66000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "StepFun",
    "intelligence_score": 15.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404975+00:00",
        "confidence": 0.65,
        "raw_name": "Step3 VL 10B",
        "raw_scores": {
          "intelligence_score": 15.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 66000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-30b",
    "canonical_name": "Qwen3 30B",
    "model_name": "Qwen3 30B",
    "aliases": [
      "Qwen3 30B"
    ],
    "provider": "Alibaba",
    "context_window": 33000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 15.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.75,
    "latency_seconds": 1.08,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 68.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.404994+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 30B",
        "raw_scores": {
          "intelligence_score": 15.0,
          "blended_cost_per_1m": 0.75,
          "latency_seconds": 1.08,
          "tokens_per_second": 68.0,
          "context_window": 33000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-8b",
    "canonical_name": "Qwen3 8B",
    "model_name": "Qwen3 8B",
    "aliases": [
      "Qwen3 8B"
    ],
    "provider": "Alibaba",
    "context_window": 131000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 15.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.66,
    "latency_seconds": 0.98,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 59.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.405013+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 8B",
        "raw_scores": {
          "intelligence_score": 15.0,
          "blended_cost_per_1m": 0.66,
          "latency_seconds": 0.98,
          "tokens_per_second": 59.0,
          "context_window": 131000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "ministral-3-8b",
    "canonical_name": "Ministral 3 8B",
    "model_name": "Ministral 3 8B",
    "aliases": [
      "Ministral 3 8B"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 15.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.15,
    "latency_seconds": 0.29,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 179.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.405032+00:00",
        "confidence": 0.65,
        "raw_name": "Ministral 3 8B",
        "raw_scores": {
          "intelligence_score": 15.0,
          "blended_cost_per_1m": 0.15,
          "latency_seconds": 0.29,
          "tokens_per_second": 179.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "sonar-pro",
    "canonical_name": "Sonar Pro",
    "model_name": "Sonar Pro",
    "aliases": [
      "Sonar Pro"
    ],
    "provider": null,
    "context_window": 200000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Perplexity",
    "intelligence_score": 15.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 6.0,
    "latency_seconds": 1.56,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 111.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.405051+00:00",
        "confidence": 0.65,
        "raw_name": "Sonar Pro",
        "raw_scores": {
          "intelligence_score": 15.0,
          "blended_cost_per_1m": 6.0,
          "latency_seconds": 1.56,
          "tokens_per_second": 111.0,
          "context_window": 200000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-405b",
    "canonical_name": "Llama 3.1 405B",
    "model_name": "Llama 3.1 405B",
    "aliases": [
      "Llama 3.1 405B"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Meta",
    "intelligence_score": 15.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 4.38,
    "latency_seconds": 0.66,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 25.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.405088+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 3.1 405B",
        "raw_scores": {
          "intelligence_score": 15.0,
          "blended_cost_per_1m": 4.38,
          "latency_seconds": 0.66,
          "tokens_per_second": 25.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwq-32b-preview",
    "canonical_name": "QwQ 32B-Preview",
    "model_name": "QwQ 32B-Preview",
    "aliases": [
      "QwQ 32B-Preview",
      "qwq-32b-preview"
    ],
    "provider": "Alibaba",
    "context_window": 33000,
    "open_source": null,
    "arena_votes": 3233,
    "license_type": "Apache 2.0",
    "creator": "Alibaba",
    "intelligence_score": 15.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1157.0,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.14,
    "latency_seconds": 0.27,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 56.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.405107+00:00",
        "confidence": 0.65,
        "raw_name": "QwQ 32B-Preview",
        "raw_scores": {
          "intelligence_score": 15.0,
          "blended_cost_per_1m": 0.14,
          "latency_seconds": 0.27,
          "tokens_per_second": 56.0,
          "context_window": 33000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831255+00:00",
        "confidence": 1.0,
        "raw_name": "qwq-32b-preview",
        "raw_scores": {
          "arena_elo": 1157.0,
          "arena_votes": 3233
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1157.0
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "ling-mini-20",
    "canonical_name": "Ling-mini-2.0",
    "model_name": "Ling-mini-2.0",
    "aliases": [
      "Ling-mini-2.0"
    ],
    "provider": null,
    "context_window": 131000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "InclusionAI",
    "intelligence_score": 15.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.12,
    "latency_seconds": 1.65,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 149.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.405126+00:00",
        "confidence": 0.65,
        "raw_name": "Ling-mini-2.0",
        "raw_scores": {
          "intelligence_score": 15.0,
          "blended_cost_per_1m": 0.12,
          "latency_seconds": 1.65,
          "tokens_per_second": 149.0,
          "context_window": 131000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "mistral-large-2",
    "canonical_name": "Mistral Large 2 (Nov)",
    "model_name": "Mistral Large 2 (Nov)",
    "aliases": [
      "Mistral Large 2 (Jul)",
      "Mistral Large 2 (Nov)"
    ],
    "provider": "Mistral AI",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 14.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.0,
    "latency_seconds": 0.25,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 18.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.405145+00:00",
        "confidence": 0.65,
        "raw_name": "Mistral Large 2 (Nov)",
        "raw_scores": {
          "intelligence_score": 15.0,
          "blended_cost_per_1m": 3.0,
          "latency_seconds": 0.5,
          "tokens_per_second": 36.0,
          "context_window": 128000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406071+00:00",
        "confidence": 0.65,
        "raw_name": "Mistral Large 2 (Jul)",
        "raw_scores": {
          "intelligence_score": 13.0,
          "blended_cost_per_1m": 3.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "mistral-small-32",
    "canonical_name": "Mistral Small 3.2",
    "model_name": "Mistral Small 3.2",
    "aliases": [
      "Mistral Small 3.2"
    ],
    "provider": "Mistral AI",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 15.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.15,
    "latency_seconds": 0.3,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 147.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.405164+00:00",
        "confidence": 0.65,
        "raw_name": "Mistral Small 3.2",
        "raw_scores": {
          "intelligence_score": 15.0,
          "blended_cost_per_1m": 0.15,
          "latency_seconds": 0.3,
          "tokens_per_second": 147.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-nemotron-ultra",
    "canonical_name": "Llama Nemotron Ultra",
    "model_name": "Llama Nemotron Ultra",
    "aliases": [
      "Llama Nemotron Ultra"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "NVIDIA",
    "intelligence_score": 15.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.9,
    "latency_seconds": 0.7,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 38.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.405182+00:00",
        "confidence": 0.65,
        "raw_name": "Llama Nemotron Ultra",
        "raw_scores": {
          "intelligence_score": 15.0,
          "blended_cost_per_1m": 0.9,
          "latency_seconds": 0.7,
          "tokens_per_second": 38.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "ernie-45-300b-a47b",
    "canonical_name": "ERNIE 4.5 300B A47B",
    "model_name": "ERNIE 4.5 300B A47B",
    "aliases": [
      "ERNIE 4.5 300B A47B"
    ],
    "provider": null,
    "context_window": 131000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Baidu",
    "intelligence_score": 15.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.48,
    "latency_seconds": 1.93,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 21.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.405256+00:00",
        "confidence": 0.65,
        "raw_name": "ERNIE 4.5 300B A47B",
        "raw_scores": {
          "intelligence_score": 15.0,
          "blended_cost_per_1m": 0.48,
          "latency_seconds": 1.93,
          "tokens_per_second": 21.0,
          "context_window": 131000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gpt-41-nano",
    "canonical_name": "GPT-4.1 nano",
    "model_name": "GPT-4.1 nano",
    "aliases": [
      "GPT-4.1 nano",
      "gpt-4.1-nano-2025-04-14"
    ],
    "provider": "OpenAI",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": 6107,
    "license_type": "Proprietary",
    "creator": "OpenAI",
    "intelligence_score": 15.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1321.71,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.17,
    "latency_seconds": 0.35,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 90.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.405295+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-4.1 nano",
        "raw_scores": {
          "intelligence_score": 15.0,
          "blended_cost_per_1m": 0.17,
          "latency_seconds": 0.35,
          "tokens_per_second": 90.0,
          "context_window": 1000000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829902+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-4.1-nano-2025-04-14",
        "raw_scores": {
          "arena_elo": 1321.71,
          "arena_votes": 6107
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1321.71
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "command-a",
    "canonical_name": "Command A",
    "model_name": "Command A",
    "aliases": [
      "Command A",
      "command-a-03-2025"
    ],
    "provider": "Cohere",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": 57098,
    "license_type": "CC-BY-NC-4.0",
    "creator": "Cohere",
    "intelligence_score": 15.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1353.06,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 4.38,
    "latency_seconds": 0.35,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 44.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.405355+00:00",
        "confidence": 0.65,
        "raw_name": "Command A",
        "raw_scores": {
          "intelligence_score": 15.0,
          "blended_cost_per_1m": 4.38,
          "latency_seconds": 0.35,
          "tokens_per_second": 44.0,
          "context_window": 256000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829368+00:00",
        "confidence": 1.0,
        "raw_name": "command-a-03-2025",
        "raw_scores": {
          "arena_elo": 1353.06,
          "arena_votes": 57098
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1353.06
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemini-20-flash-lite",
    "canonical_name": "Gemini 2.0 Flash-Lite (Feb)",
    "model_name": "Gemini 2.0 Flash-Lite (Feb)",
    "aliases": [
      "Gemini 2.0 Flash-Lite (Feb)",
      "Gemini 2.0 Flash-Lite (Preview)"
    ],
    "provider": "Google",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Google",
    "intelligence_score": 14.5,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.405374+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 2.0 Flash-Lite (Feb)",
        "raw_scores": {
          "intelligence_score": 15.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.405507+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 2.0 Flash-Lite (Preview)",
        "raw_scores": {
          "intelligence_score": 14.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "exaone-40-12b",
    "canonical_name": "Exaone 4.0 1.2B",
    "model_name": "Exaone 4.0 1.2B",
    "aliases": [
      "Exaone 4.0 1.2B"
    ],
    "provider": null,
    "context_window": 64000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "LG AI Research",
    "intelligence_score": 15.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.405392+00:00",
        "confidence": 0.65,
        "raw_name": "Exaone 4.0 1.2B",
        "raw_scores": {
          "intelligence_score": 15.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 64000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-33-70b",
    "canonical_name": "Llama 3.3 70B",
    "model_name": "Llama 3.3 70B",
    "aliases": [
      "Llama 3.3 70B"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Meta",
    "intelligence_score": 14.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.64,
    "latency_seconds": 0.54,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 85.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.405487+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 3.3 70B",
        "raw_scores": {
          "intelligence_score": 14.0,
          "blended_cost_per_1m": 0.64,
          "latency_seconds": 0.54,
          "tokens_per_second": 85.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-nemotron-nano-4b-v11",
    "canonical_name": "Llama 3.1 Nemotron Nano 4B v1.1",
    "model_name": "Llama 3.1 Nemotron Nano 4B v1.1",
    "aliases": [
      "Llama 3.1 Nemotron Nano 4B v1.1"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "NVIDIA",
    "intelligence_score": 14.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.405526+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 3.1 Nemotron Nano 4B v1.1",
        "raw_scores": {
          "intelligence_score": 14.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "kimi-linear-48b-a3b-instruct",
    "canonical_name": "Kimi Linear 48B A3B Instruct",
    "model_name": "Kimi Linear 48B A3B Instruct",
    "aliases": [
      "Kimi Linear 48B A3B Instruct"
    ],
    "provider": "Moonshot",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Kimi",
    "intelligence_score": 14.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.405544+00:00",
        "confidence": 0.65,
        "raw_name": "Kimi Linear 48B A3B Instruct",
        "raw_scores": {
          "intelligence_score": 14.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "reka-flash-3",
    "canonical_name": "Reka Flash 3",
    "model_name": "Reka Flash 3",
    "aliases": [
      "Reka Flash 3"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Reka AI",
    "intelligence_score": 14.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.35,
    "latency_seconds": 1.31,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 49.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.405582+00:00",
        "confidence": 0.65,
        "raw_name": "Reka Flash 3",
        "raw_scores": {
          "intelligence_score": 14.0,
          "blended_cost_per_1m": 0.35,
          "latency_seconds": 1.31,
          "tokens_per_second": 49.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-4b",
    "canonical_name": "Qwen3 4B",
    "model_name": "Qwen3 4B",
    "aliases": [
      "Qwen3 4B"
    ],
    "provider": "Alibaba",
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 14.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.4,
    "latency_seconds": 0.96,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 92.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.405620+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 4B",
        "raw_scores": {
          "intelligence_score": 14.0,
          "blended_cost_per_1m": 0.4,
          "latency_seconds": 0.96,
          "tokens_per_second": 92.0,
          "context_window": 32000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "tulu3-405b",
    "canonical_name": "Tulu3 405B",
    "model_name": "Tulu3 405B",
    "aliases": [
      "Tulu3 405B"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Allen Institute for AI",
    "intelligence_score": 14.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.405696+00:00",
        "confidence": 0.65,
        "raw_name": "Tulu3 405B",
        "raw_scores": {
          "intelligence_score": 14.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-vl-4b",
    "canonical_name": "Qwen3 VL 4B",
    "model_name": "Qwen3 VL 4B",
    "aliases": [
      "Qwen3 VL 4B"
    ],
    "provider": "Alibaba",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 14.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.405734+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 VL 4B",
        "raw_scores": {
          "intelligence_score": 14.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "nova-pro",
    "canonical_name": "Nova Pro",
    "model_name": "Nova Pro",
    "aliases": [
      "Nova Pro",
      "amazon-nova-pro-v1.0"
    ],
    "provider": "Amazon",
    "context_window": 300000,
    "open_source": null,
    "arena_votes": 24753,
    "license_type": "Proprietary",
    "creator": "Amazon",
    "intelligence_score": 14.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1290.18,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.4,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.405753+00:00",
        "confidence": 0.65,
        "raw_name": "Nova Pro",
        "raw_scores": {
          "intelligence_score": 14.0,
          "blended_cost_per_1m": 1.4,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 300000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830279+00:00",
        "confidence": 1.0,
        "raw_name": "amazon-nova-pro-v1.0",
        "raw_scores": {
          "arena_elo": 1290.18,
          "arena_votes": 24753
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1290.18
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "pixtral-large",
    "canonical_name": "Pixtral Large",
    "model_name": "Pixtral Large",
    "aliases": [
      "Pixtral Large"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 14.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.0,
    "latency_seconds": 0.43,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 51.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.405771+00:00",
        "confidence": 0.65,
        "raw_name": "Pixtral Large",
        "raw_scores": {
          "intelligence_score": 14.0,
          "blended_cost_per_1m": 3.0,
          "latency_seconds": 0.43,
          "tokens_per_second": 51.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "mistral-small-31",
    "canonical_name": "Mistral Small 3.1",
    "model_name": "Mistral Small 3.1",
    "aliases": [
      "Mistral Small 3.1"
    ],
    "provider": "Mistral AI",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 14.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.15,
    "latency_seconds": 0.33,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 144.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.405790+00:00",
        "confidence": 0.65,
        "raw_name": "Mistral Small 3.1",
        "raw_scores": {
          "intelligence_score": 14.0,
          "blended_cost_per_1m": 0.15,
          "latency_seconds": 0.33,
          "tokens_per_second": 144.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "grok-2",
    "canonical_name": "Grok 2",
    "model_name": "Grok 2",
    "aliases": [
      "Grok 2"
    ],
    "provider": "xAI",
    "context_window": 131000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "xAI",
    "intelligence_score": 14.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.405809+00:00",
        "confidence": 0.65,
        "raw_name": "Grok 2",
        "raw_scores": {
          "intelligence_score": 14.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 131000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemini-15-flash",
    "canonical_name": "Gemini 1.5 Flash (Sep)",
    "model_name": "Gemini 1.5 Flash (Sep)",
    "aliases": [
      "Gemini 1.5 Flash (May)",
      "Gemini 1.5 Flash (Sep)",
      "gemini-1.5-flash-001",
      "gemini-1.5-flash-002"
    ],
    "provider": "Google",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": 62823,
    "license_type": "Proprietary",
    "creator": "Google",
    "intelligence_score": 12.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1297.625,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.405827+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 1.5 Flash (Sep)",
        "raw_scores": {
          "intelligence_score": 14.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406973+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 1.5 Flash (May)",
        "raw_scores": {
          "intelligence_score": 10.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830086+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-1.5-flash-002",
        "raw_scores": {
          "arena_elo": 1309.7,
          "arena_votes": 34909
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830376+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-1.5-flash-001",
        "raw_scores": {
          "arena_elo": 1285.55,
          "arena_votes": 62823
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1309.7
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gpt-4-turbo",
    "canonical_name": "GPT-4 Turbo",
    "model_name": "GPT-4 Turbo",
    "aliases": [
      "GPT-4 Turbo",
      "gpt-4-turbo-2024-04-09"
    ],
    "provider": "OpenAI",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 98130,
    "license_type": "Proprietary",
    "creator": "OpenAI",
    "intelligence_score": 14.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1324.13,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 15.0,
    "latency_seconds": 1.15,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 28.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.405864+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-4 Turbo",
        "raw_scores": {
          "intelligence_score": 14.0,
          "blended_cost_per_1m": 15.0,
          "latency_seconds": 1.15,
          "tokens_per_second": 28.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829811+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-4-turbo-2024-04-09",
        "raw_scores": {
          "arena_elo": 1324.13,
          "arena_votes": 98130
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1324.13
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-4-scout",
    "canonical_name": "Llama 4 Scout",
    "model_name": "Llama 4 Scout",
    "aliases": [
      "Llama 4 Scout",
      "llama-4-scout-17b-16e-instruct"
    ],
    "provider": "Meta",
    "context_window": 10000000,
    "open_source": null,
    "arena_votes": 31053,
    "license_type": "Llama",
    "creator": "Meta",
    "intelligence_score": 14.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1322.39,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.29,
    "latency_seconds": 0.44,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 134.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.405902+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 4 Scout",
        "raw_scores": {
          "intelligence_score": 14.0,
          "blended_cost_per_1m": 0.29,
          "latency_seconds": 0.44,
          "tokens_per_second": 134.0,
          "context_window": 10000000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829865+00:00",
        "confidence": 1.0,
        "raw_name": "llama-4-scout-17b-16e-instruct",
        "raw_scores": {
          "arena_elo": 1322.39,
          "arena_votes": 31053
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1322.39
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-nemotron-70b",
    "canonical_name": "Llama 3.1 Nemotron 70B",
    "model_name": "Llama 3.1 Nemotron 70B",
    "aliases": [
      "Llama 3.1 Nemotron 70B"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "NVIDIA",
    "intelligence_score": 14.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.2,
    "latency_seconds": 0.56,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 30.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.405921+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 3.1 Nemotron 70B",
        "raw_scores": {
          "intelligence_score": 14.0,
          "blended_cost_per_1m": 1.2,
          "latency_seconds": 0.56,
          "tokens_per_second": 30.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "grok-beta",
    "canonical_name": "Grok Beta",
    "model_name": "Grok Beta",
    "aliases": [
      "Grok Beta"
    ],
    "provider": "xAI",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "xAI",
    "intelligence_score": 13.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.405940+00:00",
        "confidence": 0.65,
        "raw_name": "Grok Beta",
        "raw_scores": {
          "intelligence_score": 13.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen25-instruct-32b",
    "canonical_name": "Qwen2.5 Instruct 32B",
    "model_name": "Qwen2.5 Instruct 32B",
    "aliases": [
      "Qwen2.5 Instruct 32B"
    ],
    "provider": "Alibaba",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 13.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.405977+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen2.5 Instruct 32B",
        "raw_scores": {
          "intelligence_score": 13.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "granite-40-h-small",
    "canonical_name": "Granite 4.0 H Small",
    "model_name": "Granite 4.0 H Small",
    "aliases": [
      "Granite 4.0 H Small"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "IBM",
    "intelligence_score": 13.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.11,
    "latency_seconds": 8.75,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 453.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.405996+00:00",
        "confidence": 0.65,
        "raw_name": "Granite 4.0 H Small",
        "raw_scores": {
          "intelligence_score": 13.0,
          "blended_cost_per_1m": 0.11,
          "latency_seconds": 8.75,
          "tokens_per_second": 453.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "phi-4",
    "canonical_name": "Phi-4",
    "model_name": "Phi-4",
    "aliases": [
      "Phi-4",
      "phi-4"
    ],
    "provider": "Microsoft",
    "context_window": 16000,
    "open_source": null,
    "arena_votes": 24126,
    "license_type": "MIT",
    "creator": "Microsoft Azure",
    "intelligence_score": 13.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1256.07,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.22,
    "latency_seconds": 0.81,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 7.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406015+00:00",
        "confidence": 0.65,
        "raw_name": "Phi-4",
        "raw_scores": {
          "intelligence_score": 13.0,
          "blended_cost_per_1m": 0.22,
          "latency_seconds": 0.81,
          "tokens_per_second": 7.0,
          "context_window": 16000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830621+00:00",
        "confidence": 1.0,
        "raw_name": "phi-4",
        "raw_scores": {
          "arena_elo": 1256.07,
          "arena_votes": 24126
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1256.07
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-70b",
    "canonical_name": "Llama 3.1 70B",
    "model_name": "Llama 3.1 70B",
    "aliases": [
      "Llama 3.1 70B"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Meta",
    "intelligence_score": 13.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.56,
    "latency_seconds": 0.47,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 42.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406034+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 3.1 70B",
        "raw_scores": {
          "intelligence_score": 13.0,
          "blended_cost_per_1m": 0.56,
          "latency_seconds": 0.47,
          "tokens_per_second": 42.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-17b",
    "canonical_name": "Qwen3 1.7B",
    "model_name": "Qwen3 1.7B",
    "aliases": [
      "Qwen3 1.7B"
    ],
    "provider": "Alibaba",
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 13.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.4,
    "latency_seconds": 1.04,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 124.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406053+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 1.7B",
        "raw_scores": {
          "intelligence_score": 13.0,
          "blended_cost_per_1m": 0.4,
          "latency_seconds": 1.04,
          "tokens_per_second": 124.0,
          "context_window": 32000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "olmo-3-7b",
    "canonical_name": "Olmo 3 7B",
    "model_name": "Olmo 3 7B",
    "aliases": [
      "Olmo 3 7B"
    ],
    "provider": null,
    "context_window": 66000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Allen Institute for AI",
    "intelligence_score": 13.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.13,
    "latency_seconds": 0.44,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 39.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406090+00:00",
        "confidence": 0.65,
        "raw_name": "Olmo 3 7B",
        "raw_scores": {
          "intelligence_score": 13.0,
          "blended_cost_per_1m": 0.13,
          "latency_seconds": 0.44,
          "tokens_per_second": 39.0,
          "context_window": 66000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen25-coder-32b",
    "canonical_name": "Qwen2.5 Coder 32B",
    "model_name": "Qwen2.5 Coder 32B",
    "aliases": [
      "Qwen2.5 Coder 32B"
    ],
    "provider": "Alibaba",
    "context_window": 131000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 13.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.2,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406109+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen2.5 Coder 32B",
        "raw_scores": {
          "intelligence_score": 13.0,
          "blended_cost_per_1m": 0.2,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 131000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "ministral-3-3b",
    "canonical_name": "Ministral 3 3B",
    "model_name": "Ministral 3 3B",
    "aliases": [
      "Ministral 3 3B"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 13.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.1,
    "latency_seconds": 0.27,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 293.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406127+00:00",
        "confidence": 0.65,
        "raw_name": "Ministral 3 3B",
        "raw_scores": {
          "intelligence_score": 13.0,
          "blended_cost_per_1m": 0.1,
          "latency_seconds": 0.27,
          "tokens_per_second": 293.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gpt-4",
    "canonical_name": "GPT-4",
    "model_name": "GPT-4",
    "aliases": [
      "GPT-4"
    ],
    "provider": "OpenAI",
    "context_window": 8000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "OpenAI",
    "intelligence_score": 13.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 37.5,
    "latency_seconds": 0.69,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 30.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406146+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-4",
        "raw_scores": {
          "intelligence_score": 13.0,
          "blended_cost_per_1m": 37.5,
          "latency_seconds": 0.69,
          "tokens_per_second": 30.0,
          "context_window": 8000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "nova-lite",
    "canonical_name": "Nova Lite",
    "model_name": "Nova Lite",
    "aliases": [
      "Nova Lite",
      "amazon-nova-lite-v1.0"
    ],
    "provider": "Amazon",
    "context_window": 300000,
    "open_source": null,
    "arena_votes": 19376,
    "license_type": "Proprietary",
    "creator": "Amazon",
    "intelligence_score": 13.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1260.66,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.1,
    "latency_seconds": 0.4,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 212.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406165+00:00",
        "confidence": 0.65,
        "raw_name": "Nova Lite",
        "raw_scores": {
          "intelligence_score": 13.0,
          "blended_cost_per_1m": 0.1,
          "latency_seconds": 0.4,
          "tokens_per_second": 212.0,
          "context_window": 300000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830597+00:00",
        "confidence": 1.0,
        "raw_name": "amazon-nova-lite-v1.0",
        "raw_scores": {
          "arena_elo": 1260.66,
          "arena_votes": 19376
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1260.66
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "mistral-small-3",
    "canonical_name": "Mistral Small 3",
    "model_name": "Mistral Small 3",
    "aliases": [
      "Mistral Small 3"
    ],
    "provider": "Mistral AI",
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 13.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.15,
    "latency_seconds": 0.35,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 234.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406184+00:00",
        "confidence": 0.65,
        "raw_name": "Mistral Small 3",
        "raw_scores": {
          "intelligence_score": 13.0,
          "blended_cost_per_1m": 0.15,
          "latency_seconds": 0.35,
          "tokens_per_second": 234.0,
          "context_window": 32000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gpt-4o-mini",
    "canonical_name": "GPT-4o mini",
    "model_name": "GPT-4o mini",
    "aliases": [
      "GPT-4o mini",
      "gpt-4o-mini-2024-07-18"
    ],
    "provider": "OpenAI",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 68794,
    "license_type": "Proprietary",
    "creator": "OpenAI",
    "intelligence_score": 13.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1317.68,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.26,
    "latency_seconds": 0.57,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 51.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406216+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-4o mini",
        "raw_scores": {
          "intelligence_score": 13.0,
          "blended_cost_per_1m": 0.26,
          "latency_seconds": 0.57,
          "tokens_per_second": 51.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829975+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-4o-mini-2024-07-18",
        "raw_scores": {
          "arena_elo": 1317.68,
          "arena_votes": 68794
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1317.68
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "jamba-reasoning-3b",
    "canonical_name": "Jamba Reasoning 3B",
    "model_name": "Jamba Reasoning 3B",
    "aliases": [
      "Jamba Reasoning 3B"
    ],
    "provider": null,
    "context_window": 262000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "AI21 Labs",
    "intelligence_score": 13.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406237+00:00",
        "confidence": 0.65,
        "raw_name": "Jamba Reasoning 3B",
        "raw_scores": {
          "intelligence_score": 13.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 262000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "jamba-17-large",
    "canonical_name": "Jamba 1.7 Large",
    "model_name": "Jamba 1.7 Large",
    "aliases": [
      "Jamba 1.7 Large"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "AI21 Labs",
    "intelligence_score": 13.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.5,
    "latency_seconds": 0.83,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 54.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406256+00:00",
        "confidence": 0.65,
        "raw_name": "Jamba 1.7 Large",
        "raw_scores": {
          "intelligence_score": 13.0,
          "blended_cost_per_1m": 3.5,
          "latency_seconds": 0.83,
          "tokens_per_second": 54.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-v25",
    "canonical_name": "DeepSeek-V2.5 (Dec)",
    "model_name": "DeepSeek-V2.5 (Dec)",
    "aliases": [
      "DeepSeek-V2.5",
      "DeepSeek-V2.5 (Dec)",
      "deepseek-v2.5"
    ],
    "provider": "DeepSeek",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 24574,
    "license_type": "DeepSeek",
    "creator": "DeepSeek",
    "intelligence_score": 12.5,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1306.99,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406275+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek-V2.5 (Dec)",
        "raw_scores": {
          "intelligence_score": 13.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406386+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek-V2.5",
        "raw_scores": {
          "intelligence_score": 12.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830123+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-v2.5",
        "raw_scores": {
          "arena_elo": 1306.99,
          "arena_votes": 24574
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1306.99
      }
    },
    "confidence_score": 0.7667,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "claude-3-opus",
    "canonical_name": "Claude 3 Opus",
    "model_name": "Claude 3 Opus",
    "aliases": [
      "Claude 3 Opus",
      "claude-3-opus-20240229"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 194904,
    "license_type": "Proprietary",
    "creator": "Anthropic",
    "intelligence_score": 12.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1321.93,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 30.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406312+00:00",
        "confidence": 0.65,
        "raw_name": "Claude 3 Opus",
        "raw_scores": {
          "intelligence_score": 12.0,
          "blended_cost_per_1m": 30.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 200000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829890+00:00",
        "confidence": 1.0,
        "raw_name": "claude-3-opus-20240229",
        "raw_scores": {
          "arena_elo": 1321.93,
          "arena_votes": 194904
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1321.93
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemma-3-12b",
    "canonical_name": "Gemma 3 12B",
    "model_name": "Gemma 3 12B",
    "aliases": [
      "Gemma 3 12B"
    ],
    "provider": "Google",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Google",
    "intelligence_score": 12.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 28.89,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 33.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406350+00:00",
        "confidence": 0.65,
        "raw_name": "Gemma 3 12B",
        "raw_scores": {
          "intelligence_score": 12.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 28.89,
          "tokens_per_second": 33.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "mistral-saba",
    "canonical_name": "Mistral Saba",
    "model_name": "Mistral Saba",
    "aliases": [
      "Mistral Saba"
    ],
    "provider": "Mistral AI",
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 12.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406405+00:00",
        "confidence": 0.65,
        "raw_name": "Mistral Saba",
        "raw_scores": {
          "intelligence_score": 12.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-r1-distill-llama-8b",
    "canonical_name": "DeepSeek R1 Distill Llama 8B",
    "model_name": "DeepSeek R1 Distill Llama 8B",
    "aliases": [
      "DeepSeek R1 Distill Llama 8B"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "DeepSeek",
    "intelligence_score": 12.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406423+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek R1 Distill Llama 8B",
        "raw_scores": {
          "intelligence_score": 12.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "r1-1776",
    "canonical_name": "R1 1776",
    "model_name": "R1 1776",
    "aliases": [
      "R1 1776"
    ],
    "provider": "DeepSeek",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Perplexity",
    "intelligence_score": 12.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406460+00:00",
        "confidence": 0.65,
        "raw_name": "R1 1776",
        "raw_scores": {
          "intelligence_score": 12.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen25-turbo",
    "canonical_name": "Qwen2.5 Turbo",
    "model_name": "Qwen2.5 Turbo",
    "aliases": [
      "Qwen2.5 Turbo"
    ],
    "provider": "Alibaba",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 12.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.09,
    "latency_seconds": 1.04,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 69.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406480+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen2.5 Turbo",
        "raw_scores": {
          "intelligence_score": 12.0,
          "blended_cost_per_1m": 0.09,
          "latency_seconds": 1.04,
          "tokens_per_second": 69.0,
          "context_window": 1000000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "reka-flash",
    "canonical_name": "Reka Flash",
    "model_name": "Reka Flash",
    "aliases": [
      "Reka Flash"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Reka AI",
    "intelligence_score": 12.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.35,
    "latency_seconds": 1.3,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 68.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406499+00:00",
        "confidence": 0.65,
        "raw_name": "Reka Flash",
        "raw_scores": {
          "intelligence_score": 12.0,
          "blended_cost_per_1m": 0.35,
          "latency_seconds": 1.3,
          "tokens_per_second": 68.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-32-90b",
    "canonical_name": "Llama 3.2 90B (Vision)",
    "model_name": "Llama 3.2 90B (Vision)",
    "aliases": [
      "Llama 3.2 90B (Vision)"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Meta",
    "intelligence_score": 12.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.72,
    "latency_seconds": 0.4,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 42.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406518+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 3.2 90B (Vision)",
        "raw_scores": {
          "intelligence_score": 12.0,
          "blended_cost_per_1m": 0.72,
          "latency_seconds": 0.4,
          "tokens_per_second": 42.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "solar-mini",
    "canonical_name": "Solar Mini",
    "model_name": "Solar Mini",
    "aliases": [
      "Solar Mini"
    ],
    "provider": null,
    "context_window": 4000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Upstage",
    "intelligence_score": 12.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.15,
    "latency_seconds": 1.36,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 82.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406537+00:00",
        "confidence": 0.65,
        "raw_name": "Solar Mini",
        "raw_scores": {
          "intelligence_score": 12.0,
          "blended_cost_per_1m": 0.15,
          "latency_seconds": 1.36,
          "tokens_per_second": 82.0,
          "context_window": 4000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "grok-1",
    "canonical_name": "Grok-1",
    "model_name": "Grok-1",
    "aliases": [
      "Grok-1"
    ],
    "provider": "xAI",
    "context_window": 8000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "xAI",
    "intelligence_score": 12.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406555+00:00",
        "confidence": 0.65,
        "raw_name": "Grok-1",
        "raw_scores": {
          "intelligence_score": 12.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 8000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen2-72b",
    "canonical_name": "Qwen2 72B",
    "model_name": "Qwen2 72B",
    "aliases": [
      "Qwen2 72B"
    ],
    "provider": "Alibaba",
    "context_window": 131000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 12.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406573+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen2 72B",
        "raw_scores": {
          "intelligence_score": 12.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 131000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "nova-micro",
    "canonical_name": "Nova Micro",
    "model_name": "Nova Micro",
    "aliases": [
      "Nova Micro",
      "amazon-nova-micro-v1.0"
    ],
    "provider": "Amazon",
    "context_window": 130000,
    "open_source": null,
    "arena_votes": 19355,
    "license_type": "Proprietary",
    "creator": "Amazon",
    "intelligence_score": 12.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1240.88,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.06,
    "latency_seconds": 0.37,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 395.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406592+00:00",
        "confidence": 0.65,
        "raw_name": "Nova Micro",
        "raw_scores": {
          "intelligence_score": 12.0,
          "blended_cost_per_1m": 0.06,
          "latency_seconds": 0.37,
          "tokens_per_second": 395.0,
          "context_window": 130000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830670+00:00",
        "confidence": 1.0,
        "raw_name": "amazon-nova-micro-v1.0",
        "raw_scores": {
          "arena_elo": 1240.88,
          "arena_votes": 19355
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1240.88
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "lfm2-8b-a1b",
    "canonical_name": "LFM2 8B A1B",
    "model_name": "LFM2 8B A1B",
    "aliases": [
      "LFM2 8B A1B"
    ],
    "provider": null,
    "context_window": 33000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Liquid AI",
    "intelligence_score": 11.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406611+00:00",
        "confidence": 0.65,
        "raw_name": "LFM2 8B A1B",
        "raw_scores": {
          "intelligence_score": 11.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 33000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 11.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-8b",
    "canonical_name": "Llama 3.1 8B",
    "model_name": "Llama 3.1 8B",
    "aliases": [
      "Llama 3.1 8B"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Meta",
    "intelligence_score": 11.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.1,
    "latency_seconds": 0.45,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 171.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406630+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 3.1 8B",
        "raw_scores": {
          "intelligence_score": 11.0,
          "blended_cost_per_1m": 0.1,
          "latency_seconds": 0.45,
          "tokens_per_second": 171.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 11.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemini-15-flash-8b",
    "canonical_name": "Gemini 1.5 Flash-8B",
    "model_name": "Gemini 1.5 Flash-8B",
    "aliases": [
      "Gemini 1.5 Flash-8B"
    ],
    "provider": "Google",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Google",
    "intelligence_score": 11.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406648+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 1.5 Flash-8B",
        "raw_scores": {
          "intelligence_score": 11.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 11.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "granite-40-micro",
    "canonical_name": "Granite 4.0 Micro",
    "model_name": "Granite 4.0 Micro",
    "aliases": [
      "Granite 4.0 Micro"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "IBM",
    "intelligence_score": 11.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406666+00:00",
        "confidence": 0.65,
        "raw_name": "Granite 4.0 Micro",
        "raw_scores": {
          "intelligence_score": 11.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 11.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "phi-4-mini",
    "canonical_name": "Phi-4 Mini",
    "model_name": "Phi-4 Mini",
    "aliases": [
      "Phi-4 Mini"
    ],
    "provider": "Microsoft",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Microsoft Azure",
    "intelligence_score": 11.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.32,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 44.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406686+00:00",
        "confidence": 0.65,
        "raw_name": "Phi-4 Mini",
        "raw_scores": {
          "intelligence_score": 11.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.32,
          "tokens_per_second": 44.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 11.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "deephermes-3---mistral-24b",
    "canonical_name": "DeepHermes 3 - Mistral 24B",
    "model_name": "DeepHermes 3 - Mistral 24B",
    "aliases": [
      "DeepHermes 3 - Mistral 24B"
    ],
    "provider": "Mistral AI",
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Nous Research",
    "intelligence_score": 11.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406705+00:00",
        "confidence": 0.65,
        "raw_name": "DeepHermes 3 - Mistral 24B",
        "raw_scores": {
          "intelligence_score": 11.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 11.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-32-11b",
    "canonical_name": "Llama 3.2 11B (Vision)",
    "model_name": "Llama 3.2 11B (Vision)",
    "aliases": [
      "Llama 3.2 11B (Vision)"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Meta",
    "intelligence_score": 11.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.16,
    "latency_seconds": 0.43,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 59.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406724+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 3.2 11B (Vision)",
        "raw_scores": {
          "intelligence_score": 11.0,
          "blended_cost_per_1m": 0.16,
          "latency_seconds": 0.43,
          "tokens_per_second": 59.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 11.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemma-3n-e4b",
    "canonical_name": "Gemma 3n E4B",
    "model_name": "Gemma 3n E4B",
    "aliases": [
      "Gemma 3n E4B",
      "Gemma 3n E4B (May)"
    ],
    "provider": "Google",
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Google",
    "intelligence_score": 10.5,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.015,
    "latency_seconds": 0.185,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 22.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406743+00:00",
        "confidence": 0.65,
        "raw_name": "Gemma 3n E4B",
        "raw_scores": {
          "intelligence_score": 11.0,
          "blended_cost_per_1m": 0.03,
          "latency_seconds": 0.37,
          "tokens_per_second": 44.0,
          "context_window": 32000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407323+00:00",
        "confidence": 0.65,
        "raw_name": "Gemma 3n E4B (May)",
        "raw_scores": {
          "intelligence_score": 10.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 11.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "granite-33-8b",
    "canonical_name": "Granite 3.3 8B",
    "model_name": "Granite 3.3 8B",
    "aliases": [
      "Granite 3.3 8B"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "IBM",
    "intelligence_score": 11.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.09,
    "latency_seconds": 8.23,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 454.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406761+00:00",
        "confidence": 0.65,
        "raw_name": "Granite 3.3 8B",
        "raw_scores": {
          "intelligence_score": 11.0,
          "blended_cost_per_1m": 0.09,
          "latency_seconds": 8.23,
          "tokens_per_second": 454.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 11.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "jamba-15-large",
    "canonical_name": "Jamba 1.5 Large",
    "model_name": "Jamba 1.5 Large",
    "aliases": [
      "Jamba 1.5 Large",
      "jamba-1.5-large"
    ],
    "provider": "AI21 Labs",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": 8659,
    "license_type": "Jamba Open",
    "creator": "AI21 Labs",
    "intelligence_score": 11.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1288.66,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.5,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406780+00:00",
        "confidence": 0.65,
        "raw_name": "Jamba 1.5 Large",
        "raw_scores": {
          "intelligence_score": 11.0,
          "blended_cost_per_1m": 3.5,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 256000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830291+00:00",
        "confidence": 1.0,
        "raw_name": "jamba-1.5-large",
        "raw_scores": {
          "arena_elo": 1288.66,
          "arena_votes": 8659
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 11.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1288.66
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "jamba-17-mini",
    "canonical_name": "Jamba 1.7 Mini",
    "model_name": "Jamba 1.7 Mini",
    "aliases": [
      "Jamba 1.7 Mini"
    ],
    "provider": null,
    "context_window": 258000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "AI21 Labs",
    "intelligence_score": 11.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406799+00:00",
        "confidence": 0.65,
        "raw_name": "Jamba 1.7 Mini",
        "raw_scores": {
          "intelligence_score": 11.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 258000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 11.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemma-3-4b",
    "canonical_name": "Gemma 3 4B",
    "model_name": "Gemma 3 4B",
    "aliases": [
      "Gemma 3 4B"
    ],
    "provider": "Google",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Google",
    "intelligence_score": 11.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 1.03,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 32.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406818+00:00",
        "confidence": 0.65,
        "raw_name": "Gemma 3 4B",
        "raw_scores": {
          "intelligence_score": 11.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 1.03,
          "tokens_per_second": 32.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 11.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "hermes-3---llama-31-70b",
    "canonical_name": "Hermes 3 - Llama-3.1 70B",
    "model_name": "Hermes 3 - Llama-3.1 70B",
    "aliases": [
      "Hermes 3 - Llama-3.1 70B"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Nous Research",
    "intelligence_score": 11.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.3,
    "latency_seconds": 0.53,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 34.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406838+00:00",
        "confidence": 0.65,
        "raw_name": "Hermes 3 - Llama-3.1 70B",
        "raw_scores": {
          "intelligence_score": 11.0,
          "blended_cost_per_1m": 0.3,
          "latency_seconds": 0.53,
          "tokens_per_second": 34.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 11.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-coder-v2",
    "canonical_name": "DeepSeek-Coder-V2",
    "model_name": "DeepSeek-Coder-V2",
    "aliases": [
      "DeepSeek-Coder-V2",
      "deepseek-coder-v2"
    ],
    "provider": "DeepSeek",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 15147,
    "license_type": "DeepSeek License",
    "creator": "DeepSeek",
    "intelligence_score": 11.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1264.19,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406858+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek-Coder-V2",
        "raw_scores": {
          "intelligence_score": 11.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830549+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-coder-v2",
        "raw_scores": {
          "arena_elo": 1264.19,
          "arena_votes": 15147
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 11.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1264.19
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "olmo-2-32b",
    "canonical_name": "OLMo 2 32B",
    "model_name": "OLMo 2 32B",
    "aliases": [
      "OLMo 2 32B"
    ],
    "provider": null,
    "context_window": 4000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Allen Institute for AI",
    "intelligence_score": 11.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406896+00:00",
        "confidence": 0.65,
        "raw_name": "OLMo 2 32B",
        "raw_scores": {
          "intelligence_score": 11.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 4000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 11.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "jamba-16-large",
    "canonical_name": "Jamba 1.6 Large",
    "model_name": "Jamba 1.6 Large",
    "aliases": [
      "Jamba 1.6 Large"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "AI21 Labs",
    "intelligence_score": 11.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.5,
    "latency_seconds": 0.84,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 54.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406916+00:00",
        "confidence": 0.65,
        "raw_name": "Jamba 1.6 Large",
        "raw_scores": {
          "intelligence_score": 11.0,
          "blended_cost_per_1m": 3.5,
          "latency_seconds": 0.84,
          "tokens_per_second": 54.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 11.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-06b",
    "canonical_name": "Qwen3 0.6B",
    "model_name": "Qwen3 0.6B",
    "aliases": [
      "Qwen3 0.6B"
    ],
    "provider": "Alibaba",
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 11.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.4,
    "latency_seconds": 0.87,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 200.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406935+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 0.6B",
        "raw_scores": {
          "intelligence_score": 11.0,
          "blended_cost_per_1m": 0.4,
          "latency_seconds": 0.87,
          "tokens_per_second": 200.0,
          "context_window": 32000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 11.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "lfm2-24b-a2b",
    "canonical_name": "LFM2 24B A2B",
    "model_name": "LFM2 24B A2B",
    "aliases": [
      "LFM2 24B A2B"
    ],
    "provider": null,
    "context_window": 33000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Liquid AI",
    "intelligence_score": 10.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.05,
    "latency_seconds": 0.22,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 132.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406954+00:00",
        "confidence": 0.65,
        "raw_name": "LFM2 24B A2B",
        "raw_scores": {
          "intelligence_score": 10.0,
          "blended_cost_per_1m": 0.05,
          "latency_seconds": 0.22,
          "tokens_per_second": 132.0,
          "context_window": 33000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "granite-40-h-1b",
    "canonical_name": "Granite 4.0 H 1B",
    "model_name": "Granite 4.0 H 1B",
    "aliases": [
      "Granite 4.0 H 1B"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "IBM",
    "intelligence_score": 10.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.406991+00:00",
        "confidence": 0.65,
        "raw_name": "Granite 4.0 H 1B",
        "raw_scores": {
          "intelligence_score": 10.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemma-3-27b",
    "canonical_name": "Gemma 3 27B",
    "model_name": "Gemma 3 27B",
    "aliases": [
      "Gemma 3 27B"
    ],
    "provider": "Google",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Google",
    "intelligence_score": 10.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 1.04,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 34.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407173+00:00",
        "confidence": 0.65,
        "raw_name": "Gemma 3 27B",
        "raw_scores": {
          "intelligence_score": 10.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 1.04,
          "tokens_per_second": 34.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "claude-3-sonnet",
    "canonical_name": "Claude 3 Sonnet",
    "model_name": "Claude 3 Sonnet",
    "aliases": [
      "Claude 3 Sonnet"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Anthropic",
    "intelligence_score": 10.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 6.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407195+00:00",
        "confidence": 0.65,
        "raw_name": "Claude 3 Sonnet",
        "raw_scores": {
          "intelligence_score": 10.0,
          "blended_cost_per_1m": 6.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 200000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "granite-40-1b",
    "canonical_name": "Granite 4.0 1B",
    "model_name": "Granite 4.0 1B",
    "aliases": [
      "Granite 4.0 1B"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "IBM",
    "intelligence_score": 10.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407226+00:00",
        "confidence": 0.65,
        "raw_name": "Granite 4.0 1B",
        "raw_scores": {
          "intelligence_score": 10.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-3-70b",
    "canonical_name": "Llama 3 70B",
    "model_name": "Llama 3 70B",
    "aliases": [
      "Llama 3 70B"
    ],
    "provider": "Meta",
    "context_window": 8000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Meta",
    "intelligence_score": 10.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.87,
    "latency_seconds": 0.42,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 39.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407246+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 3 70B",
        "raw_scores": {
          "intelligence_score": 10.0,
          "blended_cost_per_1m": 0.87,
          "latency_seconds": 0.42,
          "tokens_per_second": 39.0,
          "context_window": 8000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "mistral-small",
    "canonical_name": "Mistral Small (Sep)",
    "model_name": "Mistral Small (Sep)",
    "aliases": [
      "Mistral Small (Feb)",
      "Mistral Small (Sep)"
    ],
    "provider": "Mistral AI",
    "context_window": 33000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 9.5,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.9,
    "latency_seconds": 0.33,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 142.5,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407266+00:00",
        "confidence": 0.65,
        "raw_name": "Mistral Small (Sep)",
        "raw_scores": {
          "intelligence_score": 10.0,
          "blended_cost_per_1m": 0.3,
          "latency_seconds": 0.34,
          "tokens_per_second": 147.0,
          "context_window": 33000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407701+00:00",
        "confidence": 0.65,
        "raw_name": "Mistral Small (Feb)",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 1.5,
          "latency_seconds": 0.32,
          "tokens_per_second": 138.0,
          "context_window": 33000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemini-10-ultra",
    "canonical_name": "Gemini 1.0 Ultra",
    "model_name": "Gemini 1.0 Ultra",
    "aliases": [
      "Gemini 1.0 Ultra"
    ],
    "provider": "Google",
    "context_window": 33000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Google",
    "intelligence_score": 10.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407285+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 1.0 Ultra",
        "raw_scores": {
          "intelligence_score": 10.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 33000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "phi-3-mini",
    "canonical_name": "Phi-3 Mini",
    "model_name": "Phi-3 Mini",
    "aliases": [
      "Phi-3 Mini"
    ],
    "provider": "Microsoft",
    "context_window": 4000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Microsoft Azure",
    "intelligence_score": 10.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.23,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407304+00:00",
        "confidence": 0.65,
        "raw_name": "Phi-3 Mini",
        "raw_scores": {
          "intelligence_score": 10.0,
          "blended_cost_per_1m": 0.23,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 4000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "phi-4-multimodal",
    "canonical_name": "Phi-4 Multimodal",
    "model_name": "Phi-4 Multimodal",
    "aliases": [
      "Phi-4 Multimodal"
    ],
    "provider": "Microsoft",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Microsoft Azure",
    "intelligence_score": 10.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.35,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 17.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407343+00:00",
        "confidence": 0.65,
        "raw_name": "Phi-4 Multimodal",
        "raw_scores": {
          "intelligence_score": 10.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.35,
          "tokens_per_second": 17.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen25-coder-7b",
    "canonical_name": "Qwen2.5 Coder 7B",
    "model_name": "Qwen2.5 Coder 7B",
    "aliases": [
      "Qwen2.5 Coder 7B"
    ],
    "provider": "Alibaba",
    "context_window": 131000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 10.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407361+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen2.5 Coder 7B",
        "raw_scores": {
          "intelligence_score": 10.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 131000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "mistral-large",
    "canonical_name": "Mistral Large (Feb)",
    "model_name": "Mistral Large (Feb)",
    "aliases": [
      "Mistral Large (Feb)"
    ],
    "provider": "Mistral AI",
    "context_window": 33000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 10.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 6.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407380+00:00",
        "confidence": 0.65,
        "raw_name": "Mistral Large (Feb)",
        "raw_scores": {
          "intelligence_score": 10.0,
          "blended_cost_per_1m": 6.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 33000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "lfm2-26b",
    "canonical_name": "LFM2 2.6B",
    "model_name": "LFM2 2.6B",
    "aliases": [
      "LFM2 2.6B"
    ],
    "provider": null,
    "context_window": 33000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Liquid AI",
    "intelligence_score": 10.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407398+00:00",
        "confidence": 0.65,
        "raw_name": "LFM2 2.6B",
        "raw_scores": {
          "intelligence_score": 10.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 33000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "mixtral-8x22b",
    "canonical_name": "Mixtral 8x22B",
    "model_name": "Mixtral 8x22B",
    "aliases": [
      "Mixtral 8x22B"
    ],
    "provider": "Mistral AI",
    "context_window": 65000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 10.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407416+00:00",
        "confidence": 0.65,
        "raw_name": "Mixtral 8x22B",
        "raw_scores": {
          "intelligence_score": 10.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 65000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-2-chat-7b",
    "canonical_name": "Llama 2 Chat 7B",
    "model_name": "Llama 2 Chat 7B",
    "aliases": [
      "Llama 2 Chat 7B"
    ],
    "provider": "Meta",
    "context_window": 4000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Meta",
    "intelligence_score": 10.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.1,
    "latency_seconds": 0.43,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 117.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407435+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 2 Chat 7B",
        "raw_scores": {
          "intelligence_score": 10.0,
          "blended_cost_per_1m": 0.1,
          "latency_seconds": 0.43,
          "tokens_per_second": 117.0,
          "context_window": 4000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemma-3n-e2b",
    "canonical_name": "Gemma 3n E2B",
    "model_name": "Gemma 3n E2B",
    "aliases": [
      "Gemma 3n E2B"
    ],
    "provider": "Google",
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Google",
    "intelligence_score": 10.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.34,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 47.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407454+00:00",
        "confidence": 0.65,
        "raw_name": "Gemma 3n E2B",
        "raw_scores": {
          "intelligence_score": 10.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.34,
          "tokens_per_second": 47.0,
          "context_window": 32000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-32-3b",
    "canonical_name": "Llama 3.2 3B",
    "model_name": "Llama 3.2 3B",
    "aliases": [
      "Llama 3.2 3B"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Meta",
    "intelligence_score": 10.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.08,
    "latency_seconds": 0.49,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 47.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407473+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 3.2 3B",
        "raw_scores": {
          "intelligence_score": 10.0,
          "blended_cost_per_1m": 0.08,
          "latency_seconds": 0.49,
          "tokens_per_second": 47.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen15-chat-110b",
    "canonical_name": "Qwen1.5 Chat 110B",
    "model_name": "Qwen1.5 Chat 110B",
    "aliases": [
      "Qwen1.5 Chat 110B"
    ],
    "provider": "Alibaba",
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 10.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407510+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen1.5 Chat 110B",
        "raw_scores": {
          "intelligence_score": 10.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "lfm2-12b",
    "canonical_name": "LFM2 1.2B",
    "model_name": "LFM2 1.2B",
    "aliases": [
      "LFM2 1.2B"
    ],
    "provider": null,
    "context_window": 33000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Liquid AI",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407529+00:00",
        "confidence": 0.65,
        "raw_name": "LFM2 1.2B",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 33000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "claude-21",
    "canonical_name": "Claude 2.1",
    "model_name": "Claude 2.1",
    "aliases": [
      "Claude 2.1"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Anthropic",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407547+00:00",
        "confidence": 0.65,
        "raw_name": "Claude 2.1",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 200000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "claude-3-haiku",
    "canonical_name": "Claude 3 Haiku",
    "model_name": "Claude 3 Haiku",
    "aliases": [
      "Claude 3 Haiku"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Anthropic",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.5,
    "latency_seconds": 0.45,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 119.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407566+00:00",
        "confidence": 0.65,
        "raw_name": "Claude 3 Haiku",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 0.5,
          "latency_seconds": 0.45,
          "tokens_per_second": 119.0,
          "context_window": 200000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "olmo-2-7b",
    "canonical_name": "OLMo 2 7B",
    "model_name": "OLMo 2 7B",
    "aliases": [
      "OLMo 2 7B"
    ],
    "provider": null,
    "context_window": 4000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Allen Institute for AI",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407585+00:00",
        "confidence": 0.65,
        "raw_name": "OLMo 2 7B",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 4000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "molmo-7b-d",
    "canonical_name": "Molmo 7B-D",
    "model_name": "Molmo 7B-D",
    "aliases": [
      "Molmo 7B-D"
    ],
    "provider": null,
    "context_window": 4000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Allen Institute for AI",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407603+00:00",
        "confidence": 0.65,
        "raw_name": "Molmo 7B-D",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 4000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-32-1b",
    "canonical_name": "Llama 3.2 1B",
    "model_name": "Llama 3.2 1B",
    "aliases": [
      "Llama 3.2 1B"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Meta",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.1,
    "latency_seconds": 0.54,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 133.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407627+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 3.2 1B",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 0.1,
          "latency_seconds": 0.54,
          "tokens_per_second": 133.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-r1-distill-qwen-15b",
    "canonical_name": "DeepSeek R1 Distill Qwen 1.5B",
    "model_name": "DeepSeek R1 Distill Qwen 1.5B",
    "aliases": [
      "DeepSeek R1 Distill Qwen 1.5B"
    ],
    "provider": "Alibaba",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "DeepSeek",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407645+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek R1 Distill Qwen 1.5B",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "claude-20",
    "canonical_name": "Claude 2.0",
    "model_name": "Claude 2.0",
    "aliases": [
      "Claude 2.0"
    ],
    "provider": "Anthropic",
    "context_window": 100000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Anthropic",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407664+00:00",
        "confidence": 0.65,
        "raw_name": "Claude 2.0",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 100000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-v2",
    "canonical_name": "DeepSeek-V2",
    "model_name": "DeepSeek-V2",
    "aliases": [
      "DeepSeek-V2"
    ],
    "provider": "DeepSeek",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "DeepSeek",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407682+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek-V2",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "mistral-medium",
    "canonical_name": "Mistral Medium",
    "model_name": "Mistral Medium",
    "aliases": [
      "Mistral Medium",
      "mistral-medium",
      "mistral-medium-2508"
    ],
    "provider": "Mistral",
    "context_window": 33000,
    "open_source": null,
    "arena_votes": 65627,
    "license_type": "Proprietary",
    "creator": "Mistral",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1317.175,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 4.09,
    "latency_seconds": 0.42,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 76.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407720+00:00",
        "confidence": 0.65,
        "raw_name": "Mistral Medium",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 4.09,
          "latency_seconds": 0.42,
          "tokens_per_second": 76.0,
          "context_window": 33000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828452+00:00",
        "confidence": 1.0,
        "raw_name": "mistral-medium-2508",
        "raw_scores": {
          "arena_elo": 1411.39,
          "arena_votes": 65627
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830840+00:00",
        "confidence": 1.0,
        "raw_name": "mistral-medium",
        "raw_scores": {
          "arena_elo": 1222.96,
          "arena_votes": 34552
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1411.39
      }
    },
    "confidence_score": 0.8833,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gpt-35-turbo",
    "canonical_name": "GPT-3.5 Turbo",
    "model_name": "GPT-3.5 Turbo",
    "aliases": [
      "GPT-3.5 Turbo",
      "GPT-3.5 Turbo (0613)"
    ],
    "provider": "OpenAI",
    "context_window": 4000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "OpenAI",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.3963,
    "latency_seconds": 0.222,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 47.561,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407739+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-3.5 Turbo",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 0.75,
          "latency_seconds": 0.42,
          "tokens_per_second": 90.0,
          "context_window": 4000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.408445+00:00",
        "confidence": 0.5800000000000001,
        "raw_name": "GPT-3.5 Turbo (0613)",
        "raw_scores": {
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 4000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      }
    },
    "confidence_score": 0.615,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "granite-40-h-350m",
    "canonical_name": "Granite 4.0 H 350M",
    "model_name": "Granite 4.0 H 350M",
    "aliases": [
      "Granite 4.0 H 350M"
    ],
    "provider": null,
    "context_window": 33000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "IBM",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407757+00:00",
        "confidence": 0.65,
        "raw_name": "Granite 4.0 H 350M",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 33000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "granite-40-350m",
    "canonical_name": "Granite 4.0 350M",
    "model_name": "Granite 4.0 350M",
    "aliases": [
      "Granite 4.0 350M"
    ],
    "provider": null,
    "context_window": 33000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "IBM",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407775+00:00",
        "confidence": 0.65,
        "raw_name": "Granite 4.0 350M",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 33000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "arctic",
    "canonical_name": "Arctic",
    "model_name": "Arctic",
    "aliases": [
      "Arctic"
    ],
    "provider": null,
    "context_window": 4000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Snowflake",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407793+00:00",
        "confidence": 0.65,
        "raw_name": "Arctic",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 4000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen-chat-72b",
    "canonical_name": "Qwen Chat 72B",
    "model_name": "Qwen Chat 72B",
    "aliases": [
      "Qwen Chat 72B"
    ],
    "provider": "Alibaba",
    "context_window": 34000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407812+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen Chat 72B",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 34000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "lfm-40b",
    "canonical_name": "LFM 40B",
    "model_name": "LFM 40B",
    "aliases": [
      "LFM 40B"
    ],
    "provider": null,
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Liquid AI",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407830+00:00",
        "confidence": 0.65,
        "raw_name": "LFM 40B",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-3-8b",
    "canonical_name": "Llama 3 8B",
    "model_name": "Llama 3 8B",
    "aliases": [
      "Llama 3 8B"
    ],
    "provider": "Meta",
    "context_window": 8000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Meta",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.07,
    "latency_seconds": 0.37,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 72.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407849+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 3 8B",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 0.07,
          "latency_seconds": 0.37,
          "tokens_per_second": 72.0,
          "context_window": 8000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemma-3-1b",
    "canonical_name": "Gemma 3 1B",
    "model_name": "Gemma 3 1B",
    "aliases": [
      "Gemma 3 1B"
    ],
    "provider": "Google",
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Google",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.58,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 44.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407867+00:00",
        "confidence": 0.65,
        "raw_name": "Gemma 3 1B",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.58,
          "tokens_per_second": 44.0,
          "context_window": 32000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "palm-2",
    "canonical_name": "PALM-2",
    "model_name": "PALM-2",
    "aliases": [
      "PALM-2",
      "palm-2"
    ],
    "provider": "Google",
    "context_window": 8000,
    "open_source": null,
    "arena_votes": 8554,
    "license_type": "Proprietary",
    "creator": "Google",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1137.12,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407886+00:00",
        "confidence": 0.65,
        "raw_name": "PALM-2",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 8000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831427+00:00",
        "confidence": 1.0,
        "raw_name": "palm-2",
        "raw_scores": {
          "arena_elo": 1137.12,
          "arena_votes": 8554
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1137.12
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemini-10-pro",
    "canonical_name": "Gemini 1.0 Pro",
    "model_name": "Gemini 1.0 Pro",
    "aliases": [
      "Gemini 1.0 Pro"
    ],
    "provider": "Google",
    "context_window": 33000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Google",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407904+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 1.0 Pro",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 33000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-coder-v2-lite",
    "canonical_name": "DeepSeek Coder V2 Lite",
    "model_name": "DeepSeek Coder V2 Lite",
    "aliases": [
      "DeepSeek Coder V2 Lite"
    ],
    "provider": "DeepSeek",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "DeepSeek",
    "intelligence_score": 8.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407922+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek Coder V2 Lite",
        "raw_scores": {
          "intelligence_score": 8.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemma-3-270m",
    "canonical_name": "Gemma 3 270M",
    "model_name": "Gemma 3 270M",
    "aliases": [
      "Gemma 3 270M"
    ],
    "provider": "Google",
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Google",
    "intelligence_score": 8.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407941+00:00",
        "confidence": 0.65,
        "raw_name": "Gemma 3 270M",
        "raw_scores": {
          "intelligence_score": 8.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-2-chat-70b",
    "canonical_name": "Llama 2 Chat 70B",
    "model_name": "Llama 2 Chat 70B",
    "aliases": [
      "Llama 2 Chat 70B"
    ],
    "provider": "Meta",
    "context_window": 4000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Meta",
    "intelligence_score": 8.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407959+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 2 Chat 70B",
        "raw_scores": {
          "intelligence_score": 8.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 4000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-llm-67b",
    "canonical_name": "DeepSeek LLM 67B (V1)",
    "model_name": "DeepSeek LLM 67B (V1)",
    "aliases": [
      "DeepSeek LLM 67B (V1)"
    ],
    "provider": "DeepSeek",
    "context_window": 4000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "DeepSeek",
    "intelligence_score": 8.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407977+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek LLM 67B (V1)",
        "raw_scores": {
          "intelligence_score": 8.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 4000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-2-chat-13b",
    "canonical_name": "Llama 2 Chat 13B",
    "model_name": "Llama 2 Chat 13B",
    "aliases": [
      "Llama 2 Chat 13B"
    ],
    "provider": "Meta",
    "context_window": 4000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Meta",
    "intelligence_score": 8.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.407995+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 2 Chat 13B",
        "raw_scores": {
          "intelligence_score": 8.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 4000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "command-r",
    "canonical_name": "Command-R+ (Apr)",
    "model_name": "Command-R+ (Apr)",
    "aliases": [
      "Command-R (Mar)",
      "Command-R+ (Apr)",
      "command-r"
    ],
    "provider": "Cohere",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 54038,
    "license_type": "CC-BY-NC-4.0",
    "creator": "Cohere",
    "intelligence_score": 7.5,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1226.94,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.375,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.408014+00:00",
        "confidence": 0.65,
        "raw_name": "Command-R+ (Apr)",
        "raw_scores": {
          "intelligence_score": 8.0,
          "blended_cost_per_1m": 6.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.408232+00:00",
        "confidence": 0.65,
        "raw_name": "Command-R (Mar)",
        "raw_scores": {
          "intelligence_score": 7.0,
          "blended_cost_per_1m": 0.75,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830779+00:00",
        "confidence": 1.0,
        "raw_name": "command-r",
        "raw_scores": {
          "arena_elo": 1226.94,
          "arena_votes": 54038
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1226.94
      }
    },
    "confidence_score": 0.7667,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "openchat-35",
    "canonical_name": "OpenChat 3.5",
    "model_name": "OpenChat 3.5",
    "aliases": [
      "OpenChat 3.5",
      "openchat-3.5"
    ],
    "provider": "OpenChat",
    "context_window": 8000,
    "open_source": null,
    "arena_votes": 7967,
    "license_type": "Apache-2.0",
    "creator": "OpenChat",
    "intelligence_score": 8.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1182.2,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.408032+00:00",
        "confidence": 0.65,
        "raw_name": "OpenChat 3.5",
        "raw_scores": {
          "intelligence_score": 8.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 8000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831072+00:00",
        "confidence": 1.0,
        "raw_name": "openchat-3.5",
        "raw_scores": {
          "arena_elo": 1182.2,
          "arena_votes": 7967
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1182.2
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "dbrx",
    "canonical_name": "DBRX",
    "model_name": "DBRX",
    "aliases": [
      "DBRX"
    ],
    "provider": "Databricks",
    "context_window": 33000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Databricks",
    "intelligence_score": 8.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.408050+00:00",
        "confidence": 0.65,
        "raw_name": "DBRX",
        "raw_scores": {
          "intelligence_score": 8.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 33000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "jamba-15-mini",
    "canonical_name": "Jamba 1.5 Mini",
    "model_name": "Jamba 1.5 Mini",
    "aliases": [
      "Jamba 1.5 Mini",
      "jamba-1.5-mini"
    ],
    "provider": "AI21 Labs",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": 8854,
    "license_type": "Jamba Open",
    "creator": "AI21 Labs",
    "intelligence_score": 8.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1238.91,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.25,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.408069+00:00",
        "confidence": 0.65,
        "raw_name": "Jamba 1.5 Mini",
        "raw_scores": {
          "intelligence_score": 8.0,
          "blended_cost_per_1m": 0.25,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 256000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830682+00:00",
        "confidence": 1.0,
        "raw_name": "jamba-1.5-mini",
        "raw_scores": {
          "arena_elo": 1238.91,
          "arena_votes": 8854
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1238.91
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "jamba-16-mini",
    "canonical_name": "Jamba 1.6 Mini",
    "model_name": "Jamba 1.6 Mini",
    "aliases": [
      "Jamba 1.6 Mini"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "AI21 Labs",
    "intelligence_score": 8.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.25,
    "latency_seconds": 0.65,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 156.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.408088+00:00",
        "confidence": 0.65,
        "raw_name": "Jamba 1.6 Mini",
        "raw_scores": {
          "intelligence_score": 8.0,
          "blended_cost_per_1m": 0.25,
          "latency_seconds": 0.65,
          "tokens_per_second": 156.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "mixtral-8x7b",
    "canonical_name": "Mixtral 8x7B",
    "model_name": "Mixtral 8x7B",
    "aliases": [
      "Mixtral 8x7B"
    ],
    "provider": "Mistral AI",
    "context_window": 33000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 8.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.54,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.408106+00:00",
        "confidence": 0.65,
        "raw_name": "Mixtral 8x7B",
        "raw_scores": {
          "intelligence_score": 8.0,
          "blended_cost_per_1m": 0.54,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 33000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "deephermes-3---llama-31-8b",
    "canonical_name": "DeepHermes 3 - Llama-3.1 8B",
    "model_name": "DeepHermes 3 - Llama-3.1 8B",
    "aliases": [
      "DeepHermes 3 - Llama-3.1 8B"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Nous Research",
    "intelligence_score": 8.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.408125+00:00",
        "confidence": 0.65,
        "raw_name": "DeepHermes 3 - Llama-3.1 8B",
        "raw_scores": {
          "intelligence_score": 8.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-65b",
    "canonical_name": "Llama 65B",
    "model_name": "Llama 65B",
    "aliases": [
      "Llama 65B"
    ],
    "provider": "Meta",
    "context_window": 2000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Meta",
    "intelligence_score": 7.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.408144+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 65B",
        "raw_scores": {
          "intelligence_score": 7.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 2000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 7.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen-chat-14b",
    "canonical_name": "Qwen Chat 14B",
    "model_name": "Qwen Chat 14B",
    "aliases": [
      "Qwen Chat 14B"
    ],
    "provider": "Alibaba",
    "context_window": 8000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 7.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.408163+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen Chat 14B",
        "raw_scores": {
          "intelligence_score": 7.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 8000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 7.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "claude-instant",
    "canonical_name": "Claude Instant",
    "model_name": "Claude Instant",
    "aliases": [
      "Claude Instant"
    ],
    "provider": "Anthropic",
    "context_window": 100000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Anthropic",
    "intelligence_score": 7.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.408182+00:00",
        "confidence": 0.65,
        "raw_name": "Claude Instant",
        "raw_scores": {
          "intelligence_score": 7.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 100000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 7.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "mistral-7b",
    "canonical_name": "Mistral 7B",
    "model_name": "Mistral 7B",
    "aliases": [
      "Mistral 7B"
    ],
    "provider": "Mistral AI",
    "context_window": 8000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 7.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.25,
    "latency_seconds": 0.29,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 186.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.408213+00:00",
        "confidence": 0.65,
        "raw_name": "Mistral 7B",
        "raw_scores": {
          "intelligence_score": 7.0,
          "blended_cost_per_1m": 0.25,
          "latency_seconds": 0.29,
          "tokens_per_second": 186.0,
          "context_window": 8000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 7.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "grok-voice-agent",
    "canonical_name": "Grok Voice Agent",
    "model_name": "Grok Voice Agent",
    "aliases": [
      "Grok Voice Agent"
    ],
    "provider": "xAI",
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "xAI",
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.408250+00:00",
        "confidence": 0.5800000000000001,
        "raw_name": "Grok Voice Agent",
        "raw_scores": {
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32000
        }
      }
    ],
    "benchmark_breakdown": {},
    "confidence_score": 0.58,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "lfm25-vl-16b",
    "canonical_name": "LFM2.5-VL-1.6B",
    "model_name": "LFM2.5-VL-1.6B",
    "aliases": [
      "LFM2.5-VL-1.6B"
    ],
    "provider": null,
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Liquid AI",
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.408267+00:00",
        "confidence": 0.5800000000000001,
        "raw_name": "LFM2.5-VL-1.6B",
        "raw_scores": {
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32000
        }
      }
    ],
    "benchmark_breakdown": {},
    "confidence_score": 0.58,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "lfm25-12b-thinking",
    "canonical_name": "LFM2.5-1.2B-Thinking",
    "model_name": "LFM2.5-1.2B-Thinking",
    "aliases": [
      "LFM2.5-1.2B-Thinking"
    ],
    "provider": null,
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Liquid AI",
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.408284+00:00",
        "confidence": 0.5800000000000001,
        "raw_name": "LFM2.5-1.2B-Thinking",
        "raw_scores": {
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32000
        }
      }
    ],
    "benchmark_breakdown": {},
    "confidence_score": 0.58,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "lfm25-12b-instruct",
    "canonical_name": "LFM2.5-1.2B-Instruct",
    "model_name": "LFM2.5-1.2B-Instruct",
    "aliases": [
      "LFM2.5-1.2B-Instruct"
    ],
    "provider": null,
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Liquid AI",
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.408302+00:00",
        "confidence": 0.5800000000000001,
        "raw_name": "LFM2.5-1.2B-Instruct",
        "raw_scores": {
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32000
        }
      }
    ],
    "benchmark_breakdown": {},
    "confidence_score": 0.58,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "molmo2-8b",
    "canonical_name": "Molmo2-8B",
    "model_name": "Molmo2-8B",
    "aliases": [
      "Molmo2-8B"
    ],
    "provider": null,
    "context_window": 37000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Allen Institute for AI",
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.43,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 114.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.408320+00:00",
        "confidence": 0.5800000000000001,
        "raw_name": "Molmo2-8B",
        "raw_scores": {
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.43,
          "tokens_per_second": 114.0,
          "context_window": 37000
        }
      }
    ],
    "benchmark_breakdown": {},
    "confidence_score": 0.58,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "olmo-31-32b-think",
    "canonical_name": "Olmo 3.1 32B Think",
    "model_name": "Olmo 3.1 32B Think",
    "aliases": [
      "Olmo 3.1 32B Think",
      "olmo-3.1-32b-think"
    ],
    "provider": "Ai2",
    "context_window": 66000,
    "open_source": null,
    "arena_votes": 8442,
    "license_type": "Apache 2.0",
    "creator": "Allen Institute for AI",
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1285.07,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.5,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 74.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.408338+00:00",
        "confidence": 0.5800000000000001,
        "raw_name": "Olmo 3.1 32B Think",
        "raw_scores": {
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.5,
          "tokens_per_second": 74.0,
          "context_window": 66000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830388+00:00",
        "confidence": 1.0,
        "raw_name": "olmo-3.1-32b-think",
        "raw_scores": {
          "arena_elo": 1285.07,
          "arena_votes": 8442
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1285.07
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "olmo-31-32b-instruct",
    "canonical_name": "Olmo 3.1 32B Instruct",
    "model_name": "Olmo 3.1 32B Instruct",
    "aliases": [
      "Olmo 3.1 32B Instruct",
      "olmo-3.1-32b-instruct"
    ],
    "provider": "Ai2",
    "context_window": 66000,
    "open_source": null,
    "arena_votes": 12252,
    "license_type": "Apache 2.0",
    "creator": "Allen Institute for AI",
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1330.45,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.3,
    "latency_seconds": 0.25,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 44.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.408356+00:00",
        "confidence": 0.5800000000000001,
        "raw_name": "Olmo 3.1 32B Instruct",
        "raw_scores": {
          "blended_cost_per_1m": 0.3,
          "latency_seconds": 0.25,
          "tokens_per_second": 44.0,
          "context_window": 66000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829724+00:00",
        "confidence": 1.0,
        "raw_name": "olmo-3.1-32b-instruct",
        "raw_scores": {
          "arena_elo": 1330.45,
          "arena_votes": 12252
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1330.45
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "cogito-v21",
    "canonical_name": "Cogito v2.1",
    "model_name": "Cogito v2.1",
    "aliases": [
      "Cogito v2.1"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Deep Cogito",
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.25,
    "latency_seconds": 0.38,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 74.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.408375+00:00",
        "confidence": 0.5800000000000001,
        "raw_name": "Cogito v2.1",
        "raw_scores": {
          "blended_cost_per_1m": 1.25,
          "latency_seconds": 0.38,
          "tokens_per_second": 74.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {},
    "confidence_score": 0.58,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "midm-k-25-pro-preview",
    "canonical_name": "Mi:dm K 2.5 Pro Preview",
    "model_name": "Mi:dm K 2.5 Pro Preview",
    "aliases": [
      "Mi:dm K 2.5 Pro Preview"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Korea Telecom",
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.408392+00:00",
        "confidence": 0.5800000000000001,
        "raw_name": "Mi:dm K 2.5 Pro Preview",
        "raw_scores": {
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {},
    "confidence_score": 0.58,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "tiny-aya-global",
    "canonical_name": "Tiny Aya Global",
    "model_name": "Tiny Aya Global",
    "aliases": [
      "Tiny Aya Global"
    ],
    "provider": null,
    "context_window": 8000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Cohere",
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.408410+00:00",
        "confidence": 0.5800000000000001,
        "raw_name": "Tiny Aya Global",
        "raw_scores": {
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 8000
        }
      }
    ],
    "benchmark_breakdown": {},
    "confidence_score": 0.58,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gpt-4o-mini-realtime",
    "canonical_name": "GPT-4o mini Realtime (Dec)",
    "model_name": "GPT-4o mini Realtime (Dec)",
    "aliases": [
      "GPT-4o mini Realtime (Dec)"
    ],
    "provider": "OpenAI",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "OpenAI",
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.408427+00:00",
        "confidence": 0.5800000000000001,
        "raw_name": "GPT-4o mini Realtime (Dec)",
        "raw_scores": {
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {},
    "confidence_score": 0.58,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gpt-4o-realtime",
    "canonical_name": "GPT-4o Realtime (Dec)",
    "model_name": "GPT-4o Realtime (Dec)",
    "aliases": [
      "GPT-4o Realtime (Dec)"
    ],
    "provider": "OpenAI",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "OpenAI",
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-28T10:50:49.408463+00:00",
        "confidence": 0.5800000000000001,
        "raw_name": "GPT-4o Realtime (Dec)",
        "raw_scores": {
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {},
    "confidence_score": 0.58,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "grok-420-beta1",
    "canonical_name": "grok-4.20-beta1",
    "model_name": "grok-4.20-beta1",
    "aliases": [
      "grok-4.20-beta1"
    ],
    "provider": "xAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3818,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1495.42,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.827625+00:00",
        "confidence": 1.0,
        "raw_name": "grok-4.20-beta1",
        "raw_scores": {
          "arena_elo": 1495.42,
          "arena_votes": 3818
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1495.42
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "grok-41",
    "canonical_name": "grok-4.1-thinking",
    "model_name": "grok-4.1-thinking",
    "aliases": [
      "grok-4.1",
      "grok-4.1-thinking"
    ],
    "provider": "xAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 41700,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1467.7,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.827682+00:00",
        "confidence": 1.0,
        "raw_name": "grok-4.1-thinking",
        "raw_scores": {
          "arena_elo": 1472.97,
          "arena_votes": 37474
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.827747+00:00",
        "confidence": 1.0,
        "raw_name": "grok-4.1",
        "raw_scores": {
          "arena_elo": 1462.43,
          "arena_votes": 41700
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1472.97
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "dola-seed-20",
    "canonical_name": "dola-seed-2.0-preview",
    "model_name": "dola-seed-2.0-preview",
    "aliases": [
      "dola-seed-2.0-preview"
    ],
    "provider": "Bytedance",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4620,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1469.86,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.827717+00:00",
        "confidence": 1.0,
        "raw_name": "dola-seed-2.0-preview",
        "raw_scores": {
          "arena_elo": 1469.86,
          "arena_votes": 4620
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1469.86
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "ernie-50",
    "canonical_name": "ernie-5.0-0110",
    "model_name": "ernie-5.0-0110",
    "aliases": [
      "ernie-5.0-0110"
    ],
    "provider": "Baidu",
    "context_window": null,
    "open_source": null,
    "arena_votes": 13833,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1452.82,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.827827+00:00",
        "confidence": 1.0,
        "raw_name": "ernie-5.0-0110",
        "raw_scores": {
          "arena_elo": 1452.82,
          "arena_votes": 13833
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1452.82
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "claude-sonnet-45",
    "canonical_name": "claude-sonnet-4.5-20250929-thinking-32k",
    "model_name": "claude-sonnet-4.5-20250929-thinking-32k",
    "aliases": [
      "claude-sonnet-4.5-20250929",
      "claude-sonnet-4.5-20250929-thinking-32k"
    ],
    "provider": "Anthropic",
    "context_window": null,
    "open_source": null,
    "arena_votes": 48912,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1449.755,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.827855+00:00",
        "confidence": 1.0,
        "raw_name": "claude-sonnet-4.5-20250929-thinking-32k",
        "raw_scores": {
          "arena_elo": 1449.92,
          "arena_votes": 48912
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.827871+00:00",
        "confidence": 1.0,
        "raw_name": "claude-sonnet-4.5-20250929",
        "raw_scores": {
          "arena_elo": 1449.59,
          "arena_votes": 46720
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1449.92
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "ernie-50-preview",
    "canonical_name": "ernie-5.0-preview-1203",
    "model_name": "ernie-5.0-preview-1203",
    "aliases": [
      "ernie-5.0-preview-1022",
      "ernie-5.0-preview-1203"
    ],
    "provider": "Baidu",
    "context_window": null,
    "open_source": null,
    "arena_votes": 9725,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1433.805,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.827896+00:00",
        "confidence": 1.0,
        "raw_name": "ernie-5.0-preview-1203",
        "raw_scores": {
          "arena_elo": 1449.09,
          "arena_votes": 9725
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828302+00:00",
        "confidence": 1.0,
        "raw_name": "ernie-5.0-preview-1022",
        "raw_scores": {
          "arena_elo": 1418.52,
          "arena_votes": 4561
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1449.09
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gpt-45-preview",
    "canonical_name": "gpt-4.5-preview-2025-02-27",
    "model_name": "gpt-4.5-preview-2025-02-27",
    "aliases": [
      "gpt-4.5-preview-2025-02-27"
    ],
    "provider": "OpenAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 14549,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1444.26,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.827941+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-4.5-preview-2025-02-27",
        "raw_scores": {
          "arena_elo": 1444.26,
          "arena_votes": 14549
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1444.26
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "kimi-k25-instant",
    "canonical_name": "kimi-k2.5-instant",
    "model_name": "kimi-k2.5-instant",
    "aliases": [
      "kimi-k2.5-instant"
    ],
    "provider": "Moonshot",
    "context_window": null,
    "open_source": null,
    "arena_votes": 7125,
    "license_type": "Modified MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1434.17,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828028+00:00",
        "confidence": 1.0,
        "raw_name": "kimi-k2.5-instant",
        "raw_scores": {
          "arena_elo": 1434.17,
          "arena_votes": 7125
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1434.17
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "kimi-k2-turbo",
    "canonical_name": "kimi-k2-thinking-turbo",
    "model_name": "kimi-k2-thinking-turbo",
    "aliases": [
      "kimi-k2-thinking-turbo"
    ],
    "provider": "Moonshot",
    "context_window": null,
    "open_source": null,
    "arena_votes": 36099,
    "license_type": "Modified MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1428.7,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828101+00:00",
        "confidence": 1.0,
        "raw_name": "kimi-k2-thinking-turbo",
        "raw_scores": {
          "arena_elo": 1428.7,
          "arena_votes": 36099
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1428.7
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "amazon-nova-experimental-chat-26-01-10",
    "canonical_name": "amazon-nova-experimental-chat-26-01-10",
    "model_name": "amazon-nova-experimental-chat-26-01-10",
    "aliases": [
      "amazon-nova-experimental-chat-26-01-10"
    ],
    "provider": "Amazon",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3421,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1415.62,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828390+00:00",
        "confidence": 1.0,
        "raw_name": "amazon-nova-experimental-chat-26-01-10",
        "raw_scores": {
          "arena_elo": 1415.62,
          "arena_votes": 3421
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1415.62
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-vl-235b",
    "canonical_name": "qwen3-vl-235b-a22b-instruct",
    "model_name": "qwen3-vl-235b-a22b-instruct",
    "aliases": [
      "qwen3-vl-235b-a22b-instruct",
      "qwen3-vl-235b-a22b-thinking"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 11598,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1404.88,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828415+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-vl-235b-a22b-instruct",
        "raw_scores": {
          "arena_elo": 1414.74,
          "arena_votes": 11598
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828661+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-vl-235b-a22b-thinking",
        "raw_scores": {
          "arena_elo": 1395.02,
          "arena_votes": 7924
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1414.74
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-next-80b",
    "canonical_name": "qwen3-next-80b-a3b-instruct",
    "model_name": "qwen3-next-80b-a3b-instruct",
    "aliases": [
      "qwen3-next-80b-a3b-instruct"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 22670,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1401.65,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828585+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-next-80b-a3b-instruct",
        "raw_scores": {
          "arena_elo": 1401.65,
          "arena_votes": 22670
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1401.65
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "longcat-flash-chat",
    "canonical_name": "longcat-flash-chat",
    "model_name": "longcat-flash-chat",
    "aliases": [
      "longcat-flash-chat"
    ],
    "provider": "Meituan",
    "context_window": null,
    "open_source": null,
    "arena_votes": 11486,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1399.96,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828610+00:00",
        "confidence": 1.0,
        "raw_name": "longcat-flash-chat",
        "raw_scores": {
          "arena_elo": 1399.96,
          "arena_votes": 11486
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1399.96
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "claude-sonnet-4",
    "canonical_name": "claude-sonnet-4-20250514-thinking-32k",
    "model_name": "claude-sonnet-4-20250514-thinking-32k",
    "aliases": [
      "claude-sonnet-4-20250514",
      "claude-sonnet-4-20250514-thinking-32k"
    ],
    "provider": "Anthropic",
    "context_window": null,
    "open_source": null,
    "arena_votes": 41365,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1394.675,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828622+00:00",
        "confidence": 1.0,
        "raw_name": "claude-sonnet-4-20250514-thinking-32k",
        "raw_scores": {
          "arena_elo": 1399.79,
          "arena_votes": 35975
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828773+00:00",
        "confidence": 1.0,
        "raw_name": "claude-sonnet-4-20250514",
        "raw_scores": {
          "arena_elo": 1389.56,
          "arena_votes": 41365
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1399.79
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-235b-a22b-thinking-2507",
    "canonical_name": "qwen3-235b-a22b-thinking-2507",
    "model_name": "qwen3-235b-a22b-thinking-2507",
    "aliases": [
      "qwen3-235b-a22b-thinking-2507"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 9186,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1398.63,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828634+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-235b-a22b-thinking-2507",
        "raw_scores": {
          "arena_elo": 1398.63,
          "arena_votes": 9186
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1398.63
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "nova-experimental",
    "canonical_name": "amazon-nova-experimental-chat-12-10",
    "model_name": "amazon-nova-experimental-chat-12-10",
    "aliases": [
      "amazon-nova-experimental-chat-12-10"
    ],
    "provider": "Amazon",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3699,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1394.64,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828674+00:00",
        "confidence": 1.0,
        "raw_name": "amazon-nova-experimental-chat-12-10",
        "raw_scores": {
          "arena_elo": 1394.64,
          "arena_votes": 3699
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1394.64
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "hunyuan-vision-15",
    "canonical_name": "hunyuan-vision-1.5-thinking",
    "model_name": "hunyuan-vision-1.5-thinking",
    "aliases": [
      "hunyuan-vision-1.5-thinking"
    ],
    "provider": "Tencent",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2216,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1393.73,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828699+00:00",
        "confidence": 1.0,
        "raw_name": "hunyuan-vision-1.5-thinking",
        "raw_scores": {
          "arena_elo": 1393.73,
          "arena_votes": 2216
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1393.73
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "mai-1-preview",
    "canonical_name": "mai-1-preview",
    "model_name": "mai-1-preview",
    "aliases": [
      "mai-1-preview"
    ],
    "provider": "Microsoft AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 18018,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1392.0,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828711+00:00",
        "confidence": 1.0,
        "raw_name": "mai-1-preview",
        "raw_scores": {
          "arena_elo": 1392.0,
          "arena_votes": 18018
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1392.0
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "step-35-flash",
    "canonical_name": "step-3.5-flash",
    "model_name": "step-3.5-flash",
    "aliases": [
      "step-3.5-flash"
    ],
    "provider": "StepFun",
    "context_window": null,
    "open_source": null,
    "arena_votes": 8624,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1389.7,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828760+00:00",
        "confidence": 1.0,
        "raw_name": "step-3.5-flash",
        "raw_scores": {
          "arena_elo": 1389.7,
          "arena_votes": 8624
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1389.7
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "claude-37-sonnet-20250219-thinking-32k",
    "canonical_name": "claude-3.7-sonnet-20250219-thinking-32k",
    "model_name": "claude-3.7-sonnet-20250219-thinking-32k",
    "aliases": [
      "claude-3.7-sonnet-20250219-thinking-32k"
    ],
    "provider": "Anthropic",
    "context_window": null,
    "open_source": null,
    "arena_votes": 39731,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1388.19,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828803+00:00",
        "confidence": 1.0,
        "raw_name": "claude-3.7-sonnet-20250219-thinking-32k",
        "raw_scores": {
          "arena_elo": 1388.19,
          "arena_votes": 39731
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1388.19
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "hunyuan-t1-20250711",
    "canonical_name": "hunyuan-t1-20250711",
    "model_name": "hunyuan-t1-20250711",
    "aliases": [
      "hunyuan-t1-20250711"
    ],
    "provider": "Tencent",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4767,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1386.69,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828844+00:00",
        "confidence": 1.0,
        "raw_name": "hunyuan-t1-20250711",
        "raw_scores": {
          "arena_elo": 1386.69,
          "arena_votes": 4767
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1386.69
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-coder-480b-a35b-instruct",
    "canonical_name": "qwen3-coder-480b-a35b-instruct",
    "model_name": "qwen3-coder-480b-a35b-instruct",
    "aliases": [
      "qwen3-coder-480b-a35b-instruct"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 26406,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1386.54,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828857+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-coder-480b-a35b-instruct",
        "raw_scores": {
          "arena_elo": 1386.54,
          "arena_votes": 26406
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1386.54
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "minimax-m21-preview",
    "canonical_name": "minimax-m2.1-preview",
    "model_name": "minimax-m2.1-preview",
    "aliases": [
      "minimax-m2.1-preview"
    ],
    "provider": "MiniMax",
    "context_window": null,
    "open_source": null,
    "arena_votes": 17092,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1385.37,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828869+00:00",
        "confidence": 1.0,
        "raw_name": "minimax-m2.1-preview",
        "raw_scores": {
          "arena_elo": 1385.37,
          "arena_votes": 17092
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1385.37
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "mistral-medium-2505",
    "canonical_name": "mistral-medium-2505",
    "model_name": "mistral-medium-2505",
    "aliases": [
      "mistral-medium-2505"
    ],
    "provider": "Mistral",
    "context_window": null,
    "open_source": null,
    "arena_votes": 34386,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1384.53,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828881+00:00",
        "confidence": 1.0,
        "raw_name": "mistral-medium-2505",
        "raw_scores": {
          "arena_elo": 1384.53,
          "arena_votes": 34386
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1384.53
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-30b-a3b-instruct-2507",
    "canonical_name": "qwen3-30b-a3b-instruct-2507",
    "model_name": "qwen3-30b-a3b-instruct-2507",
    "aliases": [
      "qwen3-30b-a3b-instruct-2507"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 23940,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1383.75,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828894+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-30b-a3b-instruct-2507",
        "raw_scores": {
          "arena_elo": 1383.75,
          "arena_votes": 23940
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1383.75
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "hunyuan-turbos-20250416",
    "canonical_name": "hunyuan-turbos-20250416",
    "model_name": "hunyuan-turbos-20250416",
    "aliases": [
      "hunyuan-turbos-20250416"
    ],
    "provider": "Tencent",
    "context_window": null,
    "open_source": null,
    "arena_votes": 11000,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1382.57,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828907+00:00",
        "confidence": 1.0,
        "raw_name": "hunyuan-turbos-20250416",
        "raw_scores": {
          "arena_elo": 1382.57,
          "arena_votes": 11000
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1382.57
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemini-25-flash-lite-preview-09-2025-no-thinking",
    "canonical_name": "gemini-2.5-flash-lite-preview-09-2025-no-thinking",
    "model_name": "gemini-2.5-flash-lite-preview-09-2025-no-thinking",
    "aliases": [
      "gemini-2.5-flash-lite-preview-09-2025-no-thinking"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 46858,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1379.57,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828932+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-2.5-flash-lite-preview-09-2025-no-thinking",
        "raw_scores": {
          "arena_elo": 1379.57,
          "arena_votes": 46858
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1379.57
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "trinity-large",
    "canonical_name": "trinity-large",
    "model_name": "trinity-large",
    "aliases": [
      "trinity-large"
    ],
    "provider": "Arcee AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2166,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1375.1,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828958+00:00",
        "confidence": 1.0,
        "raw_name": "trinity-large",
        "raw_scores": {
          "arena_elo": 1375.1,
          "arena_votes": 2166
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1375.1
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-235b-a22b",
    "canonical_name": "qwen3-235b-a22b",
    "model_name": "qwen3-235b-a22b",
    "aliases": [
      "qwen3-235b-a22b"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 27019,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1374.77,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828971+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-235b-a22b",
        "raw_scores": {
          "arena_elo": 1374.77,
          "arena_votes": 27019
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1374.77
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemini-25-flash-lite-preview-06-17-thinking",
    "canonical_name": "gemini-2.5-flash-lite-preview-06-17-thinking",
    "model_name": "gemini-2.5-flash-lite-preview-06-17-thinking",
    "aliases": [
      "gemini-2.5-flash-lite-preview-06-17-thinking"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 33674,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1374.68,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.828983+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-2.5-flash-lite-preview-06-17-thinking",
        "raw_scores": {
          "arena_elo": 1374.68,
          "arena_votes": 33674
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1374.68
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-next-80b-a3b-thinking",
    "canonical_name": "qwen3-next-80b-a3b-thinking",
    "model_name": "qwen3-next-80b-a3b-thinking",
    "aliases": [
      "qwen3-next-80b-a3b-thinking"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 13767,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1368.86,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829052+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-next-80b-a3b-thinking",
        "raw_scores": {
          "arena_elo": 1368.86,
          "arena_votes": 13767
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1368.86
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "minimax-m1",
    "canonical_name": "minimax-m1",
    "model_name": "minimax-m1",
    "aliases": [
      "minimax-m1"
    ],
    "provider": "MiniMax",
    "context_window": null,
    "open_source": null,
    "arena_votes": 36564,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1367.33,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829065+00:00",
        "confidence": 1.0,
        "raw_name": "minimax-m1",
        "raw_scores": {
          "arena_elo": 1367.33,
          "arena_votes": 36564
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1367.33
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "amazon-nova-experimental-chat-11-10",
    "canonical_name": "amazon-nova-experimental-chat-11-10",
    "model_name": "amazon-nova-experimental-chat-11-10",
    "aliases": [
      "amazon-nova-experimental-chat-11-10"
    ],
    "provider": "Amazon",
    "context_window": null,
    "open_source": null,
    "arena_votes": 19082,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1365.22,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829188+00:00",
        "confidence": 1.0,
        "raw_name": "amazon-nova-experimental-chat-11-10",
        "raw_scores": {
          "arena_elo": 1365.22,
          "arena_votes": 19082
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1365.22
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemma-3-27b-it",
    "canonical_name": "gemma-3-27b-it",
    "model_name": "gemma-3-27b-it",
    "aliases": [
      "gemma-3-27b-it"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 48453,
    "license_type": "Gemma",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1365.18,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829224+00:00",
        "confidence": 1.0,
        "raw_name": "gemma-3-27b-it",
        "raw_scores": {
          "arena_elo": 1365.18,
          "arena_votes": 48453
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1365.18
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "o3-mini-high",
    "canonical_name": "o3-mini-high",
    "model_name": "o3-mini-high",
    "aliases": [
      "o3-mini-high"
    ],
    "provider": "OpenAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 18584,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1363.97,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829243+00:00",
        "confidence": 1.0,
        "raw_name": "o3-mini-high",
        "raw_scores": {
          "arena_elo": 1363.97,
          "arena_votes": 18584
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1363.97
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "grok-3-mini-beta",
    "canonical_name": "grok-3-mini-beta",
    "model_name": "grok-3-mini-beta",
    "aliases": [
      "grok-3-mini-beta"
    ],
    "provider": "xAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 23615,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1356.75,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829293+00:00",
        "confidence": 1.0,
        "raw_name": "grok-3-mini-beta",
        "raw_scores": {
          "arena_elo": 1356.75,
          "arena_votes": 23615
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1356.75
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "mistral-small-2506",
    "canonical_name": "mistral-small-2506",
    "model_name": "mistral-small-2506",
    "aliases": [
      "mistral-small-2506"
    ],
    "provider": "Mistral",
    "context_window": null,
    "open_source": null,
    "arena_votes": 18237,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1356.02,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829318+00:00",
        "confidence": 1.0,
        "raw_name": "mistral-small-2506",
        "raw_scores": {
          "arena_elo": 1356.02,
          "arena_votes": 18237
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1356.02
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemini-20-flash-lite-preview-02-05",
    "canonical_name": "gemini-2.0-flash-lite-preview-02-05",
    "model_name": "gemini-2.0-flash-lite-preview-02-05",
    "aliases": [
      "gemini-2.0-flash-lite-preview-02-05"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 24951,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1353.28,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829343+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-2.0-flash-lite-preview-02-05",
        "raw_scores": {
          "arena_elo": 1353.28,
          "arena_votes": 24951
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1353.28
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "amazon-nova-experimental-chat-10-20",
    "canonical_name": "amazon-nova-experimental-chat-10-20",
    "model_name": "amazon-nova-experimental-chat-10-20",
    "aliases": [
      "amazon-nova-experimental-chat-10-20"
    ],
    "provider": "Amazon",
    "context_window": null,
    "open_source": null,
    "arena_votes": 11338,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1350.29,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829393+00:00",
        "confidence": 1.0,
        "raw_name": "amazon-nova-experimental-chat-10-20",
        "raw_scores": {
          "arena_elo": 1350.29,
          "arena_votes": 11338
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1350.29
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "hunyuan-turbos-20250226",
    "canonical_name": "hunyuan-turbos-20250226",
    "model_name": "hunyuan-turbos-20250226",
    "aliases": [
      "hunyuan-turbos-20250226"
    ],
    "provider": "Tencent",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2226,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1348.79,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829405+00:00",
        "confidence": 1.0,
        "raw_name": "hunyuan-turbos-20250226",
        "raw_scores": {
          "arena_elo": 1348.79,
          "arena_votes": 2226
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1348.79
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "amazon-nova-experimental-chat-10-09",
    "canonical_name": "amazon-nova-experimental-chat-10-09",
    "model_name": "amazon-nova-experimental-chat-10-09",
    "aliases": [
      "amazon-nova-experimental-chat-10-09"
    ],
    "provider": "Amazon",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2874,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1347.44,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829430+00:00",
        "confidence": 1.0,
        "raw_name": "amazon-nova-experimental-chat-10-09",
        "raw_scores": {
          "arena_elo": 1347.44,
          "arena_votes": 2874
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1347.44
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-nemotron-ultra-253b-v1",
    "canonical_name": "llama-3.1-nemotron-ultra-253b-v1",
    "model_name": "llama-3.1-nemotron-ultra-253b-v1",
    "aliases": [
      "llama-3.1-nemotron-ultra-253b-v1"
    ],
    "provider": "Nvidia",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2546,
    "license_type": "Nvidia Open Model",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1347.23,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829443+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.1-nemotron-ultra-253b-v1",
        "raw_scores": {
          "arena_elo": 1347.23,
          "arena_votes": 2546
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1347.23
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "step-3",
    "canonical_name": "step-3",
    "model_name": "step-3",
    "aliases": [
      "step-3"
    ],
    "provider": "StepFun",
    "context_window": null,
    "open_source": null,
    "arena_votes": 6567,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1346.54,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829496+00:00",
        "confidence": 1.0,
        "raw_name": "step-3",
        "raw_scores": {
          "arena_elo": 1346.54,
          "arena_votes": 6567
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1346.54
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen-plus-0125",
    "canonical_name": "qwen-plus-0125",
    "model_name": "qwen-plus-0125",
    "aliases": [
      "qwen-plus-0125"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 5823,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1346.19,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829509+00:00",
        "confidence": 1.0,
        "raw_name": "qwen-plus-0125",
        "raw_scores": {
          "arena_elo": 1346.19,
          "arena_votes": 5823
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1346.19
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "glm-4-plus-0111",
    "canonical_name": "glm-4-plus-0111",
    "model_name": "glm-4-plus-0111",
    "aliases": [
      "glm-4-plus-0111"
    ],
    "provider": "Zhipu",
    "context_window": null,
    "open_source": null,
    "arena_votes": 5760,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1343.16,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829534+00:00",
        "confidence": 1.0,
        "raw_name": "glm-4-plus-0111",
        "raw_scores": {
          "arena_elo": 1343.16,
          "arena_votes": 5760
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1343.16
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "claude-35-sonnet-20240620",
    "canonical_name": "claude-3.5-sonnet-20240620",
    "model_name": "claude-3.5-sonnet-20240620",
    "aliases": [
      "claude-3.5-sonnet-20240620"
    ],
    "provider": "Anthropic",
    "context_window": null,
    "open_source": null,
    "arena_votes": 82417,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1342.44,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829551+00:00",
        "confidence": 1.0,
        "raw_name": "claude-3.5-sonnet-20240620",
        "raw_scores": {
          "arena_elo": 1342.44,
          "arena_votes": 82417
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1342.44
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemma-3-12b-it",
    "canonical_name": "gemma-3-12b-it",
    "model_name": "gemma-3-12b-it",
    "aliases": [
      "gemma-3-12b-it"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3829,
    "license_type": "Gemma",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1341.62,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829565+00:00",
        "confidence": 1.0,
        "raw_name": "gemma-3-12b-it",
        "raw_scores": {
          "arena_elo": 1341.62,
          "arena_votes": 3829
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1341.62
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "nvidia-llama-33-nemotron-super-49b-v15",
    "canonical_name": "nvidia-llama-3.3-nemotron-super-49b-v1.5",
    "model_name": "nvidia-llama-3.3-nemotron-super-49b-v1.5",
    "aliases": [
      "nvidia-llama-3.3-nemotron-super-49b-v1.5"
    ],
    "provider": "Nvidia",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3400,
    "license_type": "Nvidia Open",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1341.3,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829578+00:00",
        "confidence": 1.0,
        "raw_name": "nvidia-llama-3.3-nemotron-super-49b-v1.5",
        "raw_scores": {
          "arena_elo": 1341.3,
          "arena_votes": 3400
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1341.3
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "hunyuan-turbo-0110",
    "canonical_name": "hunyuan-turbo-0110",
    "model_name": "hunyuan-turbo-0110",
    "aliases": [
      "hunyuan-turbo-0110"
    ],
    "provider": "Tencent",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2295,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1340.43,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829590+00:00",
        "confidence": 1.0,
        "raw_name": "hunyuan-turbo-0110",
        "raw_scores": {
          "arena_elo": 1340.43,
          "arena_votes": 2295
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1340.43
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "nova-2-lite",
    "canonical_name": "nova-2-lite",
    "model_name": "nova-2-lite",
    "aliases": [
      "nova-2-lite"
    ],
    "provider": "Amazon",
    "context_window": null,
    "open_source": null,
    "arena_votes": 12111,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1337.17,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829614+00:00",
        "confidence": 1.0,
        "raw_name": "nova-2-lite",
        "raw_scores": {
          "arena_elo": 1337.17,
          "arena_votes": 12111
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1337.17
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-405b-instruct-bf16",
    "canonical_name": "llama-3.1-405b-instruct-bf16",
    "model_name": "llama-3.1-405b-instruct-bf16",
    "aliases": [
      "llama-3.1-405b-instruct-bf16"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 41392,
    "license_type": "Llama 3.1 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1335.21,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829651+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.1-405b-instruct-bf16",
        "raw_scores": {
          "arena_elo": 1335.21,
          "arena_votes": 41392
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1335.21
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "grok-2-2024-08-13",
    "canonical_name": "grok-2-2024-08-13",
    "model_name": "grok-2-2024-08-13",
    "aliases": [
      "grok-2-2024-08-13"
    ],
    "provider": "xAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 63495,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1335.09,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829663+00:00",
        "confidence": 1.0,
        "raw_name": "grok-2-2024-08-13",
        "raw_scores": {
          "arena_elo": 1335.09,
          "arena_votes": 63495
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1335.09
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gpt-4o-2024-08-06",
    "canonical_name": "gpt-4o-2024-08-06",
    "model_name": "gpt-4o-2024-08-06",
    "aliases": [
      "gpt-4o-2024-08-06"
    ],
    "provider": "OpenAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 45498,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1334.94,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829676+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-4o-2024-08-06",
        "raw_scores": {
          "arena_elo": 1334.94,
          "arena_votes": 45498
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1334.94
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemini-advanced-0514",
    "canonical_name": "gemini-advanced-0514",
    "model_name": "gemini-advanced-0514",
    "aliases": [
      "gemini-advanced-0514"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 50142,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1334.77,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829688+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-advanced-0514",
        "raw_scores": {
          "arena_elo": 1334.77,
          "arena_votes": 50142
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1334.77
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "step-2-16k-exp-202412",
    "canonical_name": "step-2-16k-exp-202412",
    "model_name": "step-2-16k-exp-202412",
    "aliases": [
      "step-2-16k-exp-202412"
    ],
    "provider": "StepFun",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4829,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1334.03,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829700+00:00",
        "confidence": 1.0,
        "raw_name": "step-2-16k-exp-202412",
        "raw_scores": {
          "arena_elo": 1334.03,
          "arena_votes": 4829
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1334.03
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-405b-instruct-fp8",
    "canonical_name": "llama-3.1-405b-instruct-fp8",
    "model_name": "llama-3.1-405b-instruct-fp8",
    "aliases": [
      "llama-3.1-405b-instruct-fp8"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 59655,
    "license_type": "Llama 3.1 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1333.39,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829712+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.1-405b-instruct-fp8",
        "raw_scores": {
          "arena_elo": 1333.39,
          "arena_votes": 59655
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1333.39
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "molmo-2-8b",
    "canonical_name": "molmo-2-8b",
    "model_name": "molmo-2-8b",
    "aliases": [
      "molmo-2-8b"
    ],
    "provider": "Ai2",
    "context_window": null,
    "open_source": null,
    "arena_votes": 816,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1329.22,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829737+00:00",
        "confidence": 1.0,
        "raw_name": "molmo-2-8b",
        "raw_scores": {
          "arena_elo": 1329.22,
          "arena_votes": 816
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1329.22
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "yi-lightning",
    "canonical_name": "yi-lightning",
    "model_name": "yi-lightning",
    "aliases": [
      "yi-lightning"
    ],
    "provider": "01 AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 27340,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1328.48,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829749+00:00",
        "confidence": 1.0,
        "raw_name": "yi-lightning",
        "raw_scores": {
          "arena_elo": 1328.48,
          "arena_votes": 27340
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1328.48
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-30b-a3b",
    "canonical_name": "qwen3-30b-a3b",
    "model_name": "qwen3-30b-a3b",
    "aliases": [
      "qwen3-30b-a3b"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 27282,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1328.13,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829762+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-30b-a3b",
        "raw_scores": {
          "arena_elo": 1328.13,
          "arena_votes": 27282
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1328.13
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-33-nemotron-49b-super-v1",
    "canonical_name": "llama-3.3-nemotron-49b-super-v1",
    "model_name": "llama-3.3-nemotron-49b-super-v1",
    "aliases": [
      "llama-3.3-nemotron-49b-super-v1"
    ],
    "provider": "Nvidia",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2230,
    "license_type": "Nvidia",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1327.07,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829786+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.3-nemotron-49b-super-v1",
        "raw_scores": {
          "arena_elo": 1327.07,
          "arena_votes": 2230
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1327.07
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "hunyuan-large-2025-02-10",
    "canonical_name": "hunyuan-large-2025-02-10",
    "model_name": "hunyuan-large-2025-02-10",
    "aliases": [
      "hunyuan-large-2025-02-10"
    ],
    "provider": "Tencent",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3738,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1326.42,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829799+00:00",
        "confidence": 1.0,
        "raw_name": "hunyuan-large-2025-02-10",
        "raw_scores": {
          "arena_elo": 1326.42,
          "arena_votes": 3738
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1326.42
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-v25-1210",
    "canonical_name": "deepseek-v2.5-1210",
    "model_name": "deepseek-v2.5-1210",
    "aliases": [
      "deepseek-v2.5-1210"
    ],
    "provider": "DeepSeek",
    "context_window": null,
    "open_source": null,
    "arena_votes": 6793,
    "license_type": "DeepSeek",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1323.24,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829840+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-v2.5-1210",
        "raw_scores": {
          "arena_elo": 1323.24,
          "arena_votes": 6793
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1323.24
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "step-1o-turbo-202506",
    "canonical_name": "step-1o-turbo-202506",
    "model_name": "step-1o-turbo-202506",
    "aliases": [
      "step-1o-turbo-202506"
    ],
    "provider": "StepFun",
    "context_window": null,
    "open_source": null,
    "arena_votes": 9622,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1321.97,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829878+00:00",
        "confidence": 1.0,
        "raw_name": "step-1o-turbo-202506",
        "raw_scores": {
          "arena_elo": 1321.97,
          "arena_votes": 9622
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1321.97
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "glm-4-plus",
    "canonical_name": "glm-4-plus",
    "model_name": "glm-4-plus",
    "aliases": [
      "glm-4-plus"
    ],
    "provider": "Zhipu AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 26134,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1319.33,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829927+00:00",
        "confidence": 1.0,
        "raw_name": "glm-4-plus",
        "raw_scores": {
          "arena_elo": 1319.33,
          "arena_votes": 26134
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1319.33
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-33-70b-instruct",
    "canonical_name": "llama-3.3-70b-instruct",
    "model_name": "llama-3.3-70b-instruct",
    "aliases": [
      "llama-3.3-70b-instruct"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 55454,
    "license_type": "Llama-3.3",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1319.32,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829939+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.3-70b-instruct",
        "raw_scores": {
          "arena_elo": 1319.32,
          "arena_votes": 55454
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1319.32
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemma-3n-e4b-it",
    "canonical_name": "gemma-3n-e4b-it",
    "model_name": "gemma-3n-e4b-it",
    "aliases": [
      "gemma-3n-e4b-it"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 23193,
    "license_type": "Gemma",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1319.29,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829951+00:00",
        "confidence": 1.0,
        "raw_name": "gemma-3n-e4b-it",
        "raw_scores": {
          "arena_elo": 1319.29,
          "arena_votes": 23193
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1319.29
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen-max-0919",
    "canonical_name": "qwen-max-0919",
    "model_name": "qwen-max-0919",
    "aliases": [
      "qwen-max-0919"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 16479,
    "license_type": "Qwen",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1318.05,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.829963+00:00",
        "confidence": 1.0,
        "raw_name": "qwen-max-0919",
        "raw_scores": {
          "arena_elo": 1318.05,
          "arena_votes": 16479
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1318.05
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "nvidia-nemotron-3-nano-30b-a3b-bf16",
    "canonical_name": "nvidia-nemotron-3-nano-30b-a3b-bf16",
    "model_name": "nvidia-nemotron-3-nano-30b-a3b-bf16",
    "aliases": [
      "nvidia-nemotron-3-nano-30b-a3b-bf16"
    ],
    "provider": "Nvidia",
    "context_window": null,
    "open_source": null,
    "arena_votes": 15408,
    "license_type": "NVIDIA Open Model",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1317.0,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830000+00:00",
        "confidence": 1.0,
        "raw_name": "nvidia-nemotron-3-nano-30b-a3b-bf16",
        "raw_scores": {
          "arena_elo": 1317.0,
          "arena_votes": 15408
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1317.0
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen25-plus-1127",
    "canonical_name": "qwen2.5-plus-1127",
    "model_name": "qwen2.5-plus-1127",
    "aliases": [
      "qwen2.5-plus-1127"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 10179,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1315.38,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830012+00:00",
        "confidence": 1.0,
        "raw_name": "qwen2.5-plus-1127",
        "raw_scores": {
          "arena_elo": 1315.38,
          "arena_votes": 10179
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1315.38
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "athene-v2-chat",
    "canonical_name": "athene-v2-chat",
    "model_name": "athene-v2-chat",
    "aliases": [
      "athene-v2-chat"
    ],
    "provider": "NexusFlow",
    "context_window": null,
    "open_source": null,
    "arena_votes": 24746,
    "license_type": "NexusFlow",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1314.44,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830024+00:00",
        "confidence": 1.0,
        "raw_name": "athene-v2-chat",
        "raw_scores": {
          "arena_elo": 1314.44,
          "arena_votes": 24746
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1314.44
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "mistral-large-2407",
    "canonical_name": "mistral-large-2407",
    "model_name": "mistral-large-2407",
    "aliases": [
      "mistral-large-2407"
    ],
    "provider": "Mistral",
    "context_window": null,
    "open_source": null,
    "arena_votes": 45460,
    "license_type": "Mistral Research",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1314.0,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830037+00:00",
        "confidence": 1.0,
        "raw_name": "mistral-large-2407",
        "raw_scores": {
          "arena_elo": 1314.0,
          "arena_votes": 45460
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1314.0
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gpt-4-0125-preview",
    "canonical_name": "gpt-4-0125-preview",
    "model_name": "gpt-4-0125-preview",
    "aliases": [
      "gpt-4-0125-preview"
    ],
    "provider": "OpenAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 93439,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1313.13,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830049+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-4-0125-preview",
        "raw_scores": {
          "arena_elo": 1313.13,
          "arena_votes": 93439
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1313.13
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gpt-4-1106-preview",
    "canonical_name": "gpt-4-1106-preview",
    "model_name": "gpt-4-1106-preview",
    "aliases": [
      "gpt-4-1106-preview"
    ],
    "provider": "OpenAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 100107,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1313.07,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830061+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-4-1106-preview",
        "raw_scores": {
          "arena_elo": 1313.07,
          "arena_votes": 100107
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1313.07
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "hunyuan-standard-2025-02-10",
    "canonical_name": "hunyuan-standard-2025-02-10",
    "model_name": "hunyuan-standard-2025-02-10",
    "aliases": [
      "hunyuan-standard-2025-02-10"
    ],
    "provider": "Tencent",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3905,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1311.55,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830074+00:00",
        "confidence": 1.0,
        "raw_name": "hunyuan-standard-2025-02-10",
        "raw_scores": {
          "arena_elo": 1311.55,
          "arena_votes": 3905
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1311.55
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "mercury",
    "canonical_name": "mercury",
    "model_name": "mercury",
    "aliases": [
      "mercury"
    ],
    "provider": "Inception AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 1886,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1308.55,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830098+00:00",
        "confidence": 1.0,
        "raw_name": "mercury",
        "raw_scores": {
          "arena_elo": 1308.55,
          "arena_votes": 1886
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1308.55
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "grok-2-mini-2024-08-13",
    "canonical_name": "grok-2-mini-2024-08-13",
    "model_name": "grok-2-mini-2024-08-13",
    "aliases": [
      "grok-2-mini-2024-08-13"
    ],
    "provider": "xAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 52574,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1307.96,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830111+00:00",
        "confidence": 1.0,
        "raw_name": "grok-2-mini-2024-08-13",
        "raw_scores": {
          "arena_elo": 1307.96,
          "arena_votes": 52574
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1307.96
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "athene-70b-0725",
    "canonical_name": "athene-70b-0725",
    "model_name": "athene-70b-0725",
    "aliases": [
      "athene-70b-0725"
    ],
    "provider": "NexusFlow",
    "context_window": null,
    "open_source": null,
    "arena_votes": 19622,
    "license_type": "CC-BY-NC-4.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1305.96,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830135+00:00",
        "confidence": 1.0,
        "raw_name": "athene-70b-0725",
        "raw_scores": {
          "arena_elo": 1305.96,
          "arena_votes": 19622
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1305.96
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "mistral-large-2411",
    "canonical_name": "mistral-large-2411",
    "model_name": "mistral-large-2411",
    "aliases": [
      "mistral-large-2411"
    ],
    "provider": "Mistral",
    "context_window": null,
    "open_source": null,
    "arena_votes": 28081,
    "license_type": "MRL",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1305.07,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830159+00:00",
        "confidence": 1.0,
        "raw_name": "mistral-large-2411",
        "raw_scores": {
          "arena_elo": 1305.07,
          "arena_votes": 28081
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1305.07
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "magistral-medium-2506",
    "canonical_name": "magistral-medium-2506",
    "model_name": "magistral-medium-2506",
    "aliases": [
      "magistral-medium-2506"
    ],
    "provider": "Mistral",
    "context_window": null,
    "open_source": null,
    "arena_votes": 11985,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1304.79,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830171+00:00",
        "confidence": 1.0,
        "raw_name": "magistral-medium-2506",
        "raw_scores": {
          "arena_elo": 1304.79,
          "arena_votes": 11985
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1304.79
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "mistral-small-31-24b-instruct-2503",
    "canonical_name": "mistral-small-3.1-24b-instruct-2503",
    "model_name": "mistral-small-3.1-24b-instruct-2503",
    "aliases": [
      "mistral-small-3.1-24b-instruct-2503"
    ],
    "provider": "Mistral",
    "context_window": null,
    "open_source": null,
    "arena_votes": 33897,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1304.36,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830184+00:00",
        "confidence": 1.0,
        "raw_name": "mistral-small-3.1-24b-instruct-2503",
        "raw_scores": {
          "arena_elo": 1304.36,
          "arena_votes": 33897
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1304.36
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemma-3-4b-it",
    "canonical_name": "gemma-3-4b-it",
    "model_name": "gemma-3-4b-it",
    "aliases": [
      "gemma-3-4b-it"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4177,
    "license_type": "Gemma",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1303.26,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830196+00:00",
        "confidence": 1.0,
        "raw_name": "gemma-3-4b-it",
        "raw_scores": {
          "arena_elo": 1303.26,
          "arena_votes": 4177
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1303.26
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen25-72b-instruct",
    "canonical_name": "qwen2.5-72b-instruct",
    "model_name": "qwen2.5-72b-instruct",
    "aliases": [
      "qwen2.5-72b-instruct"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 39409,
    "license_type": "Qwen",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1302.64,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830229+00:00",
        "confidence": 1.0,
        "raw_name": "qwen2.5-72b-instruct",
        "raw_scores": {
          "arena_elo": 1302.64,
          "arena_votes": 39409
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1302.64
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-nemotron-70b-instruct",
    "canonical_name": "llama-3.1-nemotron-70b-instruct",
    "model_name": "llama-3.1-nemotron-70b-instruct",
    "aliases": [
      "llama-3.1-nemotron-70b-instruct"
    ],
    "provider": "Nvidia",
    "context_window": null,
    "open_source": null,
    "arena_votes": 7136,
    "license_type": "Llama 3.1",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1298.63,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830242+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.1-nemotron-70b-instruct",
        "raw_scores": {
          "arena_elo": 1298.63,
          "arena_votes": 7136
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1298.63
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "hunyuan-large-vision",
    "canonical_name": "hunyuan-large-vision",
    "model_name": "hunyuan-large-vision",
    "aliases": [
      "hunyuan-large-vision"
    ],
    "provider": "Tencent",
    "context_window": null,
    "open_source": null,
    "arena_votes": 5565,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1295.96,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830255+00:00",
        "confidence": 1.0,
        "raw_name": "hunyuan-large-vision",
        "raw_scores": {
          "arena_elo": 1295.96,
          "arena_votes": 5565
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1295.96
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-70b-instruct",
    "canonical_name": "llama-3.1-70b-instruct",
    "model_name": "llama-3.1-70b-instruct",
    "aliases": [
      "llama-3.1-70b-instruct"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 55234,
    "license_type": "Llama 3.1 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1293.43,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830267+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.1-70b-instruct",
        "raw_scores": {
          "arena_elo": 1293.43,
          "arena_votes": 55234
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1293.43
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemma-2-27b-it",
    "canonical_name": "gemma-2-27b-it",
    "model_name": "gemma-2-27b-it",
    "aliases": [
      "gemma-2-27b-it"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 75764,
    "license_type": "Gemma license",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1288.04,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830303+00:00",
        "confidence": 1.0,
        "raw_name": "gemma-2-27b-it",
        "raw_scores": {
          "arena_elo": 1288.04,
          "arena_votes": 75764
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1288.04
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "reka-core-20240904",
    "canonical_name": "reka-core-20240904",
    "model_name": "reka-core-20240904",
    "aliases": [
      "reka-core-20240904"
    ],
    "provider": "Reka AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 7309,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1287.81,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830316+00:00",
        "confidence": 1.0,
        "raw_name": "reka-core-20240904",
        "raw_scores": {
          "arena_elo": 1287.81,
          "arena_votes": 7309
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1287.81
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "ibm-granite-h-small",
    "canonical_name": "ibm-granite-h-small",
    "model_name": "ibm-granite-h-small",
    "aliases": [
      "ibm-granite-h-small"
    ],
    "provider": "IBM",
    "context_window": null,
    "open_source": null,
    "arena_votes": 5622,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1287.04,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830328+00:00",
        "confidence": 1.0,
        "raw_name": "ibm-granite-h-small",
        "raw_scores": {
          "arena_elo": 1287.04,
          "arena_votes": 5622
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1287.04
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gpt-4-0314",
    "canonical_name": "gpt-4-0314",
    "model_name": "gpt-4-0314",
    "aliases": [
      "gpt-4-0314"
    ],
    "provider": "OpenAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 54167,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1286.93,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830340+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-4-0314",
        "raw_scores": {
          "arena_elo": 1286.93,
          "arena_votes": 54167
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1286.93
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-tulu-3-70b",
    "canonical_name": "llama-3.1-tulu-3-70b",
    "model_name": "llama-3.1-tulu-3-70b",
    "aliases": [
      "llama-3.1-tulu-3-70b"
    ],
    "provider": "Ai2",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2846,
    "license_type": "Llama 3.1",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1286.53,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830352+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.1-tulu-3-70b",
        "raw_scores": {
          "arena_elo": 1286.53,
          "arena_votes": 2846
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1286.53
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-nemotron-51b-instruct",
    "canonical_name": "llama-3.1-nemotron-51b-instruct",
    "model_name": "llama-3.1-nemotron-51b-instruct",
    "aliases": [
      "llama-3.1-nemotron-51b-instruct"
    ],
    "provider": "Nvidia",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3749,
    "license_type": "Llama 3.1",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1286.25,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830364+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.1-nemotron-51b-instruct",
        "raw_scores": {
          "arena_elo": 1286.25,
          "arena_votes": 3749
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1286.25
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "claude-3-sonnet-20240229",
    "canonical_name": "claude-3-sonnet-20240229",
    "model_name": "claude-3-sonnet-20240229",
    "aliases": [
      "claude-3-sonnet-20240229"
    ],
    "provider": "Anthropic",
    "context_window": null,
    "open_source": null,
    "arena_votes": 109289,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1280.97,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830401+00:00",
        "confidence": 1.0,
        "raw_name": "claude-3-sonnet-20240229",
        "raw_scores": {
          "arena_elo": 1280.97,
          "arena_votes": 109289
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1280.97
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemma-2-9b-it-simpo",
    "canonical_name": "gemma-2-9b-it-simpo",
    "model_name": "gemma-2-9b-it-simpo",
    "aliases": [
      "gemma-2-9b-it-simpo"
    ],
    "provider": "Princeton",
    "context_window": null,
    "open_source": null,
    "arena_votes": 10069,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1279.39,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830413+00:00",
        "confidence": 1.0,
        "raw_name": "gemma-2-9b-it-simpo",
        "raw_scores": {
          "arena_elo": 1279.39,
          "arena_votes": 10069
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1279.39
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "nemotron-4-340b-instruct",
    "canonical_name": "nemotron-4-340b-instruct",
    "model_name": "nemotron-4-340b-instruct",
    "aliases": [
      "nemotron-4-340b-instruct"
    ],
    "provider": "Nvidia",
    "context_window": null,
    "open_source": null,
    "arena_votes": 19661,
    "license_type": "NVIDIA Open Model",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1277.38,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830426+00:00",
        "confidence": 1.0,
        "raw_name": "nemotron-4-340b-instruct",
        "raw_scores": {
          "arena_elo": 1277.38,
          "arena_votes": 19661
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1277.38
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "command-r-plus-08-2024",
    "canonical_name": "command-r-plus-08-2024",
    "model_name": "command-r-plus-08-2024",
    "aliases": [
      "command-r-plus-08-2024"
    ],
    "provider": "Cohere",
    "context_window": null,
    "open_source": null,
    "arena_votes": 9869,
    "license_type": "CC-BY-NC-4.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1276.4,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830438+00:00",
        "confidence": 1.0,
        "raw_name": "command-r-plus-08-2024",
        "raw_scores": {
          "arena_elo": 1276.4,
          "arena_votes": 9869
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1276.4
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-3-70b-instruct",
    "canonical_name": "llama-3-70b-instruct",
    "model_name": "llama-3-70b-instruct",
    "aliases": [
      "llama-3-70b-instruct"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 156880,
    "license_type": "Llama 3 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1275.95,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830450+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3-70b-instruct",
        "raw_scores": {
          "arena_elo": 1275.95,
          "arena_votes": 156880
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1275.95
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gpt-4-0613",
    "canonical_name": "gpt-4-0613",
    "model_name": "gpt-4-0613",
    "aliases": [
      "gpt-4-0613"
    ],
    "provider": "OpenAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 88721,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1275.06,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830463+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-4-0613",
        "raw_scores": {
          "arena_elo": 1275.06,
          "arena_votes": 88721
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1275.06
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "mistral-small-24b-instruct-2501",
    "canonical_name": "mistral-small-24b-instruct-2501",
    "model_name": "mistral-small-24b-instruct-2501",
    "aliases": [
      "mistral-small-24b-instruct-2501"
    ],
    "provider": "Mistral",
    "context_window": null,
    "open_source": null,
    "arena_votes": 14677,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1273.85,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830475+00:00",
        "confidence": 1.0,
        "raw_name": "mistral-small-24b-instruct-2501",
        "raw_scores": {
          "arena_elo": 1273.85,
          "arena_votes": 14677
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1273.85
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "glm-4-0520",
    "canonical_name": "glm-4-0520",
    "model_name": "glm-4-0520",
    "aliases": [
      "glm-4-0520"
    ],
    "provider": "Zhipu AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 9788,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1273.36,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830487+00:00",
        "confidence": 1.0,
        "raw_name": "glm-4-0520",
        "raw_scores": {
          "arena_elo": 1273.36,
          "arena_votes": 9788
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1273.36
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "reka-flash-20240904",
    "canonical_name": "reka-flash-20240904",
    "model_name": "reka-flash-20240904",
    "aliases": [
      "reka-flash-20240904"
    ],
    "provider": "Reka AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 7537,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1272.12,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830499+00:00",
        "confidence": 1.0,
        "raw_name": "reka-flash-20240904",
        "raw_scores": {
          "arena_elo": 1272.12,
          "arena_votes": 7537
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1272.12
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen25-coder-32b-instruct",
    "canonical_name": "qwen2.5-coder-32b-instruct",
    "model_name": "qwen2.5-coder-32b-instruct",
    "aliases": [
      "qwen2.5-coder-32b-instruct"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 5430,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1270.57,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830512+00:00",
        "confidence": 1.0,
        "raw_name": "qwen2.5-coder-32b-instruct",
        "raw_scores": {
          "arena_elo": 1270.57,
          "arena_votes": 5430
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1270.57
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "c4ai-aya-expanse-32b",
    "canonical_name": "c4ai-aya-expanse-32b",
    "model_name": "c4ai-aya-expanse-32b",
    "aliases": [
      "c4ai-aya-expanse-32b"
    ],
    "provider": "Cohere",
    "context_window": null,
    "open_source": null,
    "arena_votes": 27123,
    "license_type": "CC-BY-NC-4.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1267.03,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830524+00:00",
        "confidence": 1.0,
        "raw_name": "c4ai-aya-expanse-32b",
        "raw_scores": {
          "arena_elo": 1267.03,
          "arena_votes": 27123
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1267.03
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemma-2-9b-it",
    "canonical_name": "gemma-2-9b-it",
    "model_name": "gemma-2-9b-it",
    "aliases": [
      "gemma-2-9b-it"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 54615,
    "license_type": "Gemma license",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1265.46,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830536+00:00",
        "confidence": 1.0,
        "raw_name": "gemma-2-9b-it",
        "raw_scores": {
          "arena_elo": 1265.46,
          "arena_votes": 54615
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1265.46
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "command-r-plus",
    "canonical_name": "command-r-plus",
    "model_name": "command-r-plus",
    "aliases": [
      "command-r-plus"
    ],
    "provider": "Cohere",
    "context_window": null,
    "open_source": null,
    "arena_votes": 77556,
    "license_type": "CC-BY-NC-4.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1261.9,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830561+00:00",
        "confidence": 1.0,
        "raw_name": "command-r-plus",
        "raw_scores": {
          "arena_elo": 1261.9,
          "arena_votes": 77556
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1261.9
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen2-72b-instruct",
    "canonical_name": "qwen2-72b-instruct",
    "model_name": "qwen2-72b-instruct",
    "aliases": [
      "qwen2-72b-instruct"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 37325,
    "license_type": "Qianwen LICENSE",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1261.79,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830573+00:00",
        "confidence": 1.0,
        "raw_name": "qwen2-72b-instruct",
        "raw_scores": {
          "arena_elo": 1261.79,
          "arena_votes": 37325
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1261.79
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "claude-3-haiku-20240307",
    "canonical_name": "claude-3-haiku-20240307",
    "model_name": "claude-3-haiku-20240307",
    "aliases": [
      "claude-3-haiku-20240307"
    ],
    "provider": "Anthropic",
    "context_window": null,
    "open_source": null,
    "arena_votes": 117705,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1261.08,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830585+00:00",
        "confidence": 1.0,
        "raw_name": "claude-3-haiku-20240307",
        "raw_scores": {
          "arena_elo": 1261.08,
          "arena_votes": 117705
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1261.08
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemini-15-flash-8b-001",
    "canonical_name": "gemini-1.5-flash-8b-001",
    "model_name": "gemini-1.5-flash-8b-001",
    "aliases": [
      "gemini-1.5-flash-8b-001"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 35556,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1258.67,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830609+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-1.5-flash-8b-001",
        "raw_scores": {
          "arena_elo": 1258.67,
          "arena_votes": 35556
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1258.67
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "olmo-2-0325-32b-instruct",
    "canonical_name": "olmo-2-0325-32b-instruct",
    "model_name": "olmo-2-0325-32b-instruct",
    "aliases": [
      "olmo-2-0325-32b-instruct"
    ],
    "provider": "Ai2",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3335,
    "license_type": "Apache-2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1251.98,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830634+00:00",
        "confidence": 1.0,
        "raw_name": "olmo-2-0325-32b-instruct",
        "raw_scores": {
          "arena_elo": 1251.98,
          "arena_votes": 3335
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1251.98
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "command-r-08-2024",
    "canonical_name": "command-r-08-2024",
    "model_name": "command-r-08-2024",
    "aliases": [
      "command-r-08-2024"
    ],
    "provider": "Cohere",
    "context_window": null,
    "open_source": null,
    "arena_votes": 10141,
    "license_type": "CC-BY-NC-4.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1250.21,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830646+00:00",
        "confidence": 1.0,
        "raw_name": "command-r-08-2024",
        "raw_scores": {
          "arena_elo": 1250.21,
          "arena_votes": 10141
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1250.21
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "mistral-large-2402",
    "canonical_name": "mistral-large-2402",
    "model_name": "mistral-large-2402",
    "aliases": [
      "mistral-large-2402"
    ],
    "provider": "Mistral",
    "context_window": null,
    "open_source": null,
    "arena_votes": 62437,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1242.41,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830658+00:00",
        "confidence": 1.0,
        "raw_name": "mistral-large-2402",
        "raw_scores": {
          "arena_elo": 1242.41,
          "arena_votes": 62437
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1242.41
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "ministral-8b-2410",
    "canonical_name": "ministral-8b-2410",
    "model_name": "ministral-8b-2410",
    "aliases": [
      "ministral-8b-2410"
    ],
    "provider": "Mistral",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4780,
    "license_type": "MRL",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1237.03,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830694+00:00",
        "confidence": 1.0,
        "raw_name": "ministral-8b-2410",
        "raw_scores": {
          "arena_elo": 1237.03,
          "arena_votes": 4780
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1237.03
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemini-pro-dev-api",
    "canonical_name": "gemini-pro-dev-api",
    "model_name": "gemini-pro-dev-api",
    "aliases": [
      "gemini-pro-dev-api"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 18352,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1235.0,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830706+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-pro-dev-api",
        "raw_scores": {
          "arena_elo": 1235.0,
          "arena_votes": 18352
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1235.0
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen15-110b-chat",
    "canonical_name": "qwen1.5-110b-chat",
    "model_name": "qwen1.5-110b-chat",
    "aliases": [
      "qwen1.5-110b-chat"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 26191,
    "license_type": "Qianwen LICENSE",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1233.96,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830718+00:00",
        "confidence": 1.0,
        "raw_name": "qwen1.5-110b-chat",
        "raw_scores": {
          "arena_elo": 1233.96,
          "arena_votes": 26191
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1233.96
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "hunyuan-standard-256k",
    "canonical_name": "hunyuan-standard-256k",
    "model_name": "hunyuan-standard-256k",
    "aliases": [
      "hunyuan-standard-256k"
    ],
    "provider": "Tencent",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2729,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1233.36,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830730+00:00",
        "confidence": 1.0,
        "raw_name": "hunyuan-standard-256k",
        "raw_scores": {
          "arena_elo": 1233.36,
          "arena_votes": 2729
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1233.36
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "reka-flash-21b-20240226-online",
    "canonical_name": "reka-flash-21b-20240226-online",
    "model_name": "reka-flash-21b-20240226-online",
    "aliases": [
      "reka-flash-21b-20240226-online"
    ],
    "provider": "Reka AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 15451,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1233.27,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830743+00:00",
        "confidence": 1.0,
        "raw_name": "reka-flash-21b-20240226-online",
        "raw_scores": {
          "arena_elo": 1233.27,
          "arena_votes": 15451
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1233.27
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen15-72b-chat",
    "canonical_name": "qwen1.5-72b-chat",
    "model_name": "qwen1.5-72b-chat",
    "aliases": [
      "qwen1.5-72b-chat"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 39296,
    "license_type": "Qianwen LICENSE",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1233.14,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830755+00:00",
        "confidence": 1.0,
        "raw_name": "qwen1.5-72b-chat",
        "raw_scores": {
          "arena_elo": 1233.14,
          "arena_votes": 39296
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1233.14
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "mixtral-8x22b-instruct-v01",
    "canonical_name": "mixtral-8x22b-instruct-v0.1",
    "model_name": "mixtral-8x22b-instruct-v0.1",
    "aliases": [
      "mixtral-8x22b-instruct-v0.1"
    ],
    "provider": "Mistral",
    "context_window": null,
    "open_source": null,
    "arena_votes": 51417,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1229.48,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830767+00:00",
        "confidence": 1.0,
        "raw_name": "mixtral-8x22b-instruct-v0.1",
        "raw_scores": {
          "arena_elo": 1229.48,
          "arena_votes": 51417
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1229.48
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "reka-flash-21b-20240226",
    "canonical_name": "reka-flash-21b-20240226",
    "model_name": "reka-flash-21b-20240226",
    "aliases": [
      "reka-flash-21b-20240226"
    ],
    "provider": "Reka AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 24806,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1226.51,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830791+00:00",
        "confidence": 1.0,
        "raw_name": "reka-flash-21b-20240226",
        "raw_scores": {
          "arena_elo": 1226.51,
          "arena_votes": 24806
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1226.51
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gpt-35-turbo-0125",
    "canonical_name": "gpt-3.5-turbo-0125",
    "model_name": "gpt-3.5-turbo-0125",
    "aliases": [
      "gpt-3.5-turbo-0125"
    ],
    "provider": "OpenAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 66191,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1223.96,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830804+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-3.5-turbo-0125",
        "raw_scores": {
          "arena_elo": 1223.96,
          "arena_votes": 66191
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1223.96
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-3-8b-instruct",
    "canonical_name": "llama-3-8b-instruct",
    "model_name": "llama-3-8b-instruct",
    "aliases": [
      "llama-3-8b-instruct"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 104636,
    "license_type": "Llama 3 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1223.12,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830816+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3-8b-instruct",
        "raw_scores": {
          "arena_elo": 1223.12,
          "arena_votes": 104636
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1223.12
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "c4ai-aya-expanse-8b",
    "canonical_name": "c4ai-aya-expanse-8b",
    "model_name": "c4ai-aya-expanse-8b",
    "aliases": [
      "c4ai-aya-expanse-8b"
    ],
    "provider": "Cohere",
    "context_window": null,
    "open_source": null,
    "arena_votes": 9827,
    "license_type": "CC-BY-NC-4.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1223.0,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830828+00:00",
        "confidence": 1.0,
        "raw_name": "c4ai-aya-expanse-8b",
        "raw_scores": {
          "arena_elo": 1223.0,
          "arena_votes": 9827
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1223.0
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemini-pro",
    "canonical_name": "gemini-pro",
    "model_name": "gemini-pro",
    "aliases": [
      "gemini-pro"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 6390,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1221.71,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830852+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-pro",
        "raw_scores": {
          "arena_elo": 1221.71,
          "arena_votes": 6390
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1221.71
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-tulu-3-8b",
    "canonical_name": "llama-3.1-tulu-3-8b",
    "model_name": "llama-3.1-tulu-3-8b",
    "aliases": [
      "llama-3.1-tulu-3-8b"
    ],
    "provider": "Ai2",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2895,
    "license_type": "Llama 3.1",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1220.55,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830864+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.1-tulu-3-8b",
        "raw_scores": {
          "arena_elo": 1220.55,
          "arena_votes": 2895
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1220.55
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "yi-15-34b-chat",
    "canonical_name": "yi-1.5-34b-chat",
    "model_name": "yi-1.5-34b-chat",
    "aliases": [
      "yi-1.5-34b-chat"
    ],
    "provider": "01 AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 24142,
    "license_type": "Apache-2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1213.33,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830876+00:00",
        "confidence": 1.0,
        "raw_name": "yi-1.5-34b-chat",
        "raw_scores": {
          "arena_elo": 1213.33,
          "arena_votes": 24142
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1213.33
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "zephyr-orpo-141b-a35b-v01",
    "canonical_name": "zephyr-orpo-141b-A35b-v0.1",
    "model_name": "zephyr-orpo-141b-A35b-v0.1",
    "aliases": [
      "zephyr-orpo-141b-A35b-v0.1"
    ],
    "provider": "HuggingFace",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4653,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1212.74,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830888+00:00",
        "confidence": 1.0,
        "raw_name": "zephyr-orpo-141b-A35b-v0.1",
        "raw_scores": {
          "arena_elo": 1212.74,
          "arena_votes": 4653
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1212.74
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-8b-instruct",
    "canonical_name": "llama-3.1-8b-instruct",
    "model_name": "llama-3.1-8b-instruct",
    "aliases": [
      "llama-3.1-8b-instruct"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 49605,
    "license_type": "Llama 3.1 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1211.47,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830900+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.1-8b-instruct",
        "raw_scores": {
          "arena_elo": 1211.47,
          "arena_votes": 49605
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1211.47
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "granite-31-8b-instruct",
    "canonical_name": "granite-3.1-8b-instruct",
    "model_name": "granite-3.1-8b-instruct",
    "aliases": [
      "granite-3.1-8b-instruct"
    ],
    "provider": "IBM",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3092,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1208.56,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830912+00:00",
        "confidence": 1.0,
        "raw_name": "granite-3.1-8b-instruct",
        "raw_scores": {
          "arena_elo": 1208.56,
          "arena_votes": 3092
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1208.56
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen15-32b-chat",
    "canonical_name": "qwen1.5-32b-chat",
    "model_name": "qwen1.5-32b-chat",
    "aliases": [
      "qwen1.5-32b-chat"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 21744,
    "license_type": "Qianwen LICENSE",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1203.87,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830925+00:00",
        "confidence": 1.0,
        "raw_name": "qwen1.5-32b-chat",
        "raw_scores": {
          "arena_elo": 1203.87,
          "arena_votes": 21744
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1203.87
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gpt-35-turbo-1106",
    "canonical_name": "gpt-3.5-turbo-1106",
    "model_name": "gpt-3.5-turbo-1106",
    "aliases": [
      "gpt-3.5-turbo-1106"
    ],
    "provider": "OpenAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 16616,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1202.4,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830937+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-3.5-turbo-1106",
        "raw_scores": {
          "arena_elo": 1202.4,
          "arena_votes": 16616
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1202.4
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemma-2-2b-it",
    "canonical_name": "gemma-2-2b-it",
    "model_name": "gemma-2-2b-it",
    "aliases": [
      "gemma-2-2b-it"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 46618,
    "license_type": "Gemma license",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1198.7,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830949+00:00",
        "confidence": 1.0,
        "raw_name": "gemma-2-2b-it",
        "raw_scores": {
          "arena_elo": 1198.7,
          "arena_votes": 46618
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1198.7
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "phi-3-medium-4k-instruct",
    "canonical_name": "phi-3-medium-4k-instruct",
    "model_name": "phi-3-medium-4k-instruct",
    "aliases": [
      "phi-3-medium-4k-instruct"
    ],
    "provider": "Microsoft",
    "context_window": null,
    "open_source": null,
    "arena_votes": 25055,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1197.96,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830961+00:00",
        "confidence": 1.0,
        "raw_name": "phi-3-medium-4k-instruct",
        "raw_scores": {
          "arena_elo": 1197.96,
          "arena_votes": 25055
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1197.96
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "mixtral-8x7b-instruct-v01",
    "canonical_name": "mixtral-8x7b-instruct-v0.1",
    "model_name": "mixtral-8x7b-instruct-v0.1",
    "aliases": [
      "mixtral-8x7b-instruct-v0.1"
    ],
    "provider": "Mistral",
    "context_window": null,
    "open_source": null,
    "arena_votes": 73505,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1197.12,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830973+00:00",
        "confidence": 1.0,
        "raw_name": "mixtral-8x7b-instruct-v0.1",
        "raw_scores": {
          "arena_elo": 1197.12,
          "arena_votes": 73505
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1197.12
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "dbrx-instruct-preview",
    "canonical_name": "dbrx-instruct-preview",
    "model_name": "dbrx-instruct-preview",
    "aliases": [
      "dbrx-instruct-preview"
    ],
    "provider": "Databricks",
    "context_window": null,
    "open_source": null,
    "arena_votes": 32196,
    "license_type": "DBRX LICENSE",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1194.93,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830985+00:00",
        "confidence": 1.0,
        "raw_name": "dbrx-instruct-preview",
        "raw_scores": {
          "arena_elo": 1194.93,
          "arena_votes": 32196
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1194.93
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "internlm2_5-20b-chat",
    "canonical_name": "internlm2_5-20b-chat",
    "model_name": "internlm2_5-20b-chat",
    "aliases": [
      "internlm2_5-20b-chat"
    ],
    "provider": "InternLM",
    "context_window": null,
    "open_source": null,
    "arena_votes": 9902,
    "license_type": "Other",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1191.28,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.830997+00:00",
        "confidence": 1.0,
        "raw_name": "internlm2_5-20b-chat",
        "raw_scores": {
          "arena_elo": 1191.28,
          "arena_votes": 9902
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1191.28
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen15-14b-chat",
    "canonical_name": "qwen1.5-14b-chat",
    "model_name": "qwen1.5-14b-chat",
    "aliases": [
      "qwen1.5-14b-chat"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 17841,
    "license_type": "Qianwen LICENSE",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1190.83,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831011+00:00",
        "confidence": 1.0,
        "raw_name": "qwen1.5-14b-chat",
        "raw_scores": {
          "arena_elo": 1190.83,
          "arena_votes": 17841
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1190.83
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "wizardlm-70b",
    "canonical_name": "wizardlm-70b",
    "model_name": "wizardlm-70b",
    "aliases": [
      "wizardlm-70b"
    ],
    "provider": "Microsoft",
    "context_window": null,
    "open_source": null,
    "arena_votes": 8214,
    "license_type": "Llama 2 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1184.64,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831023+00:00",
        "confidence": 1.0,
        "raw_name": "wizardlm-70b",
        "raw_scores": {
          "arena_elo": 1184.64,
          "arena_votes": 8214
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1184.64
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-llm-67b-chat",
    "canonical_name": "deepseek-llm-67b-chat",
    "model_name": "deepseek-llm-67b-chat",
    "aliases": [
      "deepseek-llm-67b-chat"
    ],
    "provider": "DeepSeek",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4933,
    "license_type": "DeepSeek License",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1184.35,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831035+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-llm-67b-chat",
        "raw_scores": {
          "arena_elo": 1184.35,
          "arena_votes": 4933
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1184.35
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "yi-34b-chat",
    "canonical_name": "yi-34b-chat",
    "model_name": "yi-34b-chat",
    "aliases": [
      "yi-34b-chat"
    ],
    "provider": "01 AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 15483,
    "license_type": "Yi License",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1183.75,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831048+00:00",
        "confidence": 1.0,
        "raw_name": "yi-34b-chat",
        "raw_scores": {
          "arena_elo": 1183.75,
          "arena_votes": 15483
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1183.75
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "openchat-35-0106",
    "canonical_name": "openchat-3.5-0106",
    "model_name": "openchat-3.5-0106",
    "aliases": [
      "openchat-3.5-0106"
    ],
    "provider": "OpenChat",
    "context_window": null,
    "open_source": null,
    "arena_votes": 12636,
    "license_type": "Apache-2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1182.27,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831060+00:00",
        "confidence": 1.0,
        "raw_name": "openchat-3.5-0106",
        "raw_scores": {
          "arena_elo": 1182.27,
          "arena_votes": 12636
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1182.27
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "granite-30-8b-instruct",
    "canonical_name": "granite-3.0-8b-instruct",
    "model_name": "granite-3.0-8b-instruct",
    "aliases": [
      "granite-3.0-8b-instruct"
    ],
    "provider": "IBM",
    "context_window": null,
    "open_source": null,
    "arena_votes": 6643,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1181.92,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831084+00:00",
        "confidence": 1.0,
        "raw_name": "granite-3.0-8b-instruct",
        "raw_scores": {
          "arena_elo": 1181.92,
          "arena_votes": 6643
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1181.92
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemma-11-7b-it",
    "canonical_name": "gemma-1.1-7b-it",
    "model_name": "gemma-1.1-7b-it",
    "aliases": [
      "gemma-1.1-7b-it"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 23893,
    "license_type": "Gemma license",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1180.13,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831096+00:00",
        "confidence": 1.0,
        "raw_name": "gemma-1.1-7b-it",
        "raw_scores": {
          "arena_elo": 1180.13,
          "arena_votes": 23893
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1180.13
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "snowflake-arctic-instruct",
    "canonical_name": "snowflake-arctic-instruct",
    "model_name": "snowflake-arctic-instruct",
    "aliases": [
      "snowflake-arctic-instruct"
    ],
    "provider": "Snowflake",
    "context_window": null,
    "open_source": null,
    "arena_votes": 32836,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1179.46,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831108+00:00",
        "confidence": 1.0,
        "raw_name": "snowflake-arctic-instruct",
        "raw_scores": {
          "arena_elo": 1179.46,
          "arena_votes": 32836
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1179.46
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "granite-31-2b-instruct",
    "canonical_name": "granite-3.1-2b-instruct",
    "model_name": "granite-3.1-2b-instruct",
    "aliases": [
      "granite-3.1-2b-instruct"
    ],
    "provider": "IBM",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3191,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1179.3,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831121+00:00",
        "confidence": 1.0,
        "raw_name": "granite-3.1-2b-instruct",
        "raw_scores": {
          "arena_elo": 1179.3,
          "arena_votes": 3191
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1179.3
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "tulu-2-dpo-70b",
    "canonical_name": "tulu-2-dpo-70b",
    "model_name": "tulu-2-dpo-70b",
    "aliases": [
      "tulu-2-dpo-70b"
    ],
    "provider": "AllenAI/UW",
    "context_window": null,
    "open_source": null,
    "arena_votes": 6534,
    "license_type": "AI2 ImpACT Low-risk",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1178.01,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831133+00:00",
        "confidence": 1.0,
        "raw_name": "tulu-2-dpo-70b",
        "raw_scores": {
          "arena_elo": 1178.01,
          "arena_votes": 6534
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1178.01
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "openhermes-25-mistral-7b",
    "canonical_name": "openhermes-2.5-mistral-7b",
    "model_name": "openhermes-2.5-mistral-7b",
    "aliases": [
      "openhermes-2.5-mistral-7b"
    ],
    "provider": "NousResearch",
    "context_window": null,
    "open_source": null,
    "arena_votes": 5006,
    "license_type": "Apache-2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1175.12,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831145+00:00",
        "confidence": 1.0,
        "raw_name": "openhermes-2.5-mistral-7b",
        "raw_scores": {
          "arena_elo": 1175.12,
          "arena_votes": 5006
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1175.12
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "vicuna-33b",
    "canonical_name": "vicuna-33b",
    "model_name": "vicuna-33b",
    "aliases": [
      "vicuna-33b"
    ],
    "provider": "LMSYS",
    "context_window": null,
    "open_source": null,
    "arena_votes": 22479,
    "license_type": "Non-commercial",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1172.78,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831157+00:00",
        "confidence": 1.0,
        "raw_name": "vicuna-33b",
        "raw_scores": {
          "arena_elo": 1172.78,
          "arena_votes": 22479
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1172.78
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "starling-lm-7b-beta",
    "canonical_name": "starling-lm-7b-beta",
    "model_name": "starling-lm-7b-beta",
    "aliases": [
      "starling-lm-7b-beta"
    ],
    "provider": "Nexusflow",
    "context_window": null,
    "open_source": null,
    "arena_votes": 16057,
    "license_type": "Apache-2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1171.59,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831169+00:00",
        "confidence": 1.0,
        "raw_name": "starling-lm-7b-beta",
        "raw_scores": {
          "arena_elo": 1171.59,
          "arena_votes": 16057
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1171.59
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "phi-3-small-8k-instruct",
    "canonical_name": "phi-3-small-8k-instruct",
    "model_name": "phi-3-small-8k-instruct",
    "aliases": [
      "phi-3-small-8k-instruct"
    ],
    "provider": "Microsoft",
    "context_window": null,
    "open_source": null,
    "arena_votes": 17763,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1171.16,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831181+00:00",
        "confidence": 1.0,
        "raw_name": "phi-3-small-8k-instruct",
        "raw_scores": {
          "arena_elo": 1171.16,
          "arena_votes": 17763
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1171.16
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-2-70b-chat",
    "canonical_name": "llama-2-70b-chat",
    "model_name": "llama-2-70b-chat",
    "aliases": [
      "llama-2-70b-chat"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 38491,
    "license_type": "Llama 2 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1170.79,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831193+00:00",
        "confidence": 1.0,
        "raw_name": "llama-2-70b-chat",
        "raw_scores": {
          "arena_elo": 1170.79,
          "arena_votes": 38491
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1170.79
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "starling-lm-7b-alpha",
    "canonical_name": "starling-lm-7b-alpha",
    "model_name": "starling-lm-7b-alpha",
    "aliases": [
      "starling-lm-7b-alpha"
    ],
    "provider": "UC Berkeley",
    "context_window": null,
    "open_source": null,
    "arena_votes": 10224,
    "license_type": "CC-BY-NC-4.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1167.52,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831217+00:00",
        "confidence": 1.0,
        "raw_name": "starling-lm-7b-alpha",
        "raw_scores": {
          "arena_elo": 1167.52,
          "arena_votes": 10224
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1167.52
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-32-3b-instruct",
    "canonical_name": "llama-3.2-3b-instruct",
    "model_name": "llama-3.2-3b-instruct",
    "aliases": [
      "llama-3.2-3b-instruct"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 7936,
    "license_type": "Llama 3.2",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1166.61,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831230+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.2-3b-instruct",
        "raw_scores": {
          "arena_elo": 1166.61,
          "arena_votes": 7936
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1166.61
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "nous-hermes-2-mixtral-8x7b-dpo",
    "canonical_name": "nous-hermes-2-mixtral-8x7b-dpo",
    "model_name": "nous-hermes-2-mixtral-8x7b-dpo",
    "aliases": [
      "nous-hermes-2-mixtral-8x7b-dpo"
    ],
    "provider": "NousResearch",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3776,
    "license_type": "Apache-2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1164.66,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831243+00:00",
        "confidence": 1.0,
        "raw_name": "nous-hermes-2-mixtral-8x7b-dpo",
        "raw_scores": {
          "arena_elo": 1164.66,
          "arena_votes": 3776
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1164.66
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "granite-30-2b-instruct",
    "canonical_name": "granite-3.0-2b-instruct",
    "model_name": "granite-3.0-2b-instruct",
    "aliases": [
      "granite-3.0-2b-instruct"
    ],
    "provider": "IBM",
    "context_window": null,
    "open_source": null,
    "arena_votes": 6837,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1155.93,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831267+00:00",
        "confidence": 1.0,
        "raw_name": "granite-3.0-2b-instruct",
        "raw_scores": {
          "arena_elo": 1155.93,
          "arena_votes": 6837
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1155.93
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama2-70b-steerlm-chat",
    "canonical_name": "llama2-70b-steerlm-chat",
    "model_name": "llama2-70b-steerlm-chat",
    "aliases": [
      "llama2-70b-steerlm-chat"
    ],
    "provider": "Nvidia",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3584,
    "license_type": "Llama 2 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1155.29,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831280+00:00",
        "confidence": 1.0,
        "raw_name": "llama2-70b-steerlm-chat",
        "raw_scores": {
          "arena_elo": 1155.29,
          "arena_votes": 3584
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1155.29
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "solar-107b-instruct-v10",
    "canonical_name": "solar-10.7b-instruct-v1.0",
    "model_name": "solar-10.7b-instruct-v1.0",
    "aliases": [
      "solar-10.7b-instruct-v1.0"
    ],
    "provider": "Upstage AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4155,
    "license_type": "CC-BY-NC-4.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1152.34,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831292+00:00",
        "confidence": 1.0,
        "raw_name": "solar-10.7b-instruct-v1.0",
        "raw_scores": {
          "arena_elo": 1152.34,
          "arena_votes": 4155
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1152.34
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "dolphin-221-mistral-7b",
    "canonical_name": "dolphin-2.2.1-mistral-7b",
    "model_name": "dolphin-2.2.1-mistral-7b",
    "aliases": [
      "dolphin-2.2.1-mistral-7b"
    ],
    "provider": "Cognitive Computations",
    "context_window": null,
    "open_source": null,
    "arena_votes": 1679,
    "license_type": "Apache-2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1151.95,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831304+00:00",
        "confidence": 1.0,
        "raw_name": "dolphin-2.2.1-mistral-7b",
        "raw_scores": {
          "arena_elo": 1151.95,
          "arena_votes": 1679
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1151.95
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "mpt-30b-chat",
    "canonical_name": "mpt-30b-chat",
    "model_name": "mpt-30b-chat",
    "aliases": [
      "mpt-30b-chat"
    ],
    "provider": "MosaicML",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2571,
    "license_type": "CC-BY-NC-SA-4.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1150.09,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831316+00:00",
        "confidence": 1.0,
        "raw_name": "mpt-30b-chat",
        "raw_scores": {
          "arena_elo": 1150.09,
          "arena_votes": 2571
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1150.09
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "mistral-7b-instruct-v02",
    "canonical_name": "mistral-7b-instruct-v0.2",
    "model_name": "mistral-7b-instruct-v0.2",
    "aliases": [
      "mistral-7b-instruct-v0.2"
    ],
    "provider": "Mistral",
    "context_window": null,
    "open_source": null,
    "arena_votes": 19402,
    "license_type": "Apache-2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1149.61,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831329+00:00",
        "confidence": 1.0,
        "raw_name": "mistral-7b-instruct-v0.2",
        "raw_scores": {
          "arena_elo": 1149.61,
          "arena_votes": 19402
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1149.61
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "wizardlm-13b",
    "canonical_name": "wizardlm-13b",
    "model_name": "wizardlm-13b",
    "aliases": [
      "wizardlm-13b"
    ],
    "provider": "Microsoft",
    "context_window": null,
    "open_source": null,
    "arena_votes": 7046,
    "license_type": "Llama 2 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1149.12,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831341+00:00",
        "confidence": 1.0,
        "raw_name": "wizardlm-13b",
        "raw_scores": {
          "arena_elo": 1149.12,
          "arena_votes": 7046
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1149.12
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "falcon-180b-chat",
    "canonical_name": "falcon-180b-chat",
    "model_name": "falcon-180b-chat",
    "aliases": [
      "falcon-180b-chat"
    ],
    "provider": "TII",
    "context_window": null,
    "open_source": null,
    "arena_votes": 1295,
    "license_type": "Falcon-180B TII License",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1146.96,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831353+00:00",
        "confidence": 1.0,
        "raw_name": "falcon-180b-chat",
        "raw_scores": {
          "arena_elo": 1146.96,
          "arena_votes": 1295
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1146.96
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen15-7b-chat",
    "canonical_name": "qwen1.5-7b-chat",
    "model_name": "qwen1.5-7b-chat",
    "aliases": [
      "qwen1.5-7b-chat"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4735,
    "license_type": "Qianwen LICENSE",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1143.86,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831366+00:00",
        "confidence": 1.0,
        "raw_name": "qwen1.5-7b-chat",
        "raw_scores": {
          "arena_elo": 1143.86,
          "arena_votes": 4735
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1143.86
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "phi-3-mini-4k-instruct-june-2024",
    "canonical_name": "phi-3-mini-4k-instruct-june-2024",
    "model_name": "phi-3-mini-4k-instruct-june-2024",
    "aliases": [
      "phi-3-mini-4k-instruct-june-2024"
    ],
    "provider": "Microsoft",
    "context_window": null,
    "open_source": null,
    "arena_votes": 12296,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1142.99,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831378+00:00",
        "confidence": 1.0,
        "raw_name": "phi-3-mini-4k-instruct-june-2024",
        "raw_scores": {
          "arena_elo": 1142.99,
          "arena_votes": 12296
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1142.99
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-2-13b-chat",
    "canonical_name": "llama-2-13b-chat",
    "model_name": "llama-2-13b-chat",
    "aliases": [
      "llama-2-13b-chat"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 19171,
    "license_type": "Llama 2 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1141.46,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831390+00:00",
        "confidence": 1.0,
        "raw_name": "llama-2-13b-chat",
        "raw_scores": {
          "arena_elo": 1141.46,
          "arena_votes": 19171
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1141.46
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "vicuna-13b",
    "canonical_name": "vicuna-13b",
    "model_name": "vicuna-13b",
    "aliases": [
      "vicuna-13b"
    ],
    "provider": "LMSYS",
    "context_window": null,
    "open_source": null,
    "arena_votes": 19366,
    "license_type": "Llama 2 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1140.86,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831402+00:00",
        "confidence": 1.0,
        "raw_name": "vicuna-13b",
        "raw_scores": {
          "arena_elo": 1140.86,
          "arena_votes": 19366
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1140.86
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen-14b-chat",
    "canonical_name": "qwen-14b-chat",
    "model_name": "qwen-14b-chat",
    "aliases": [
      "qwen-14b-chat"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4964,
    "license_type": "Qianwen LICENSE",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1138.51,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831414+00:00",
        "confidence": 1.0,
        "raw_name": "qwen-14b-chat",
        "raw_scores": {
          "arena_elo": 1138.51,
          "arena_votes": 4964
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1138.51
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "codellama-34b-instruct",
    "canonical_name": "codellama-34b-instruct",
    "model_name": "codellama-34b-instruct",
    "aliases": [
      "codellama-34b-instruct"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 7363,
    "license_type": "Llama 2 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1136.55,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831439+00:00",
        "confidence": 1.0,
        "raw_name": "codellama-34b-instruct",
        "raw_scores": {
          "arena_elo": 1136.55,
          "arena_votes": 7363
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1136.55
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemma-7b-it",
    "canonical_name": "gemma-7b-it",
    "model_name": "gemma-7b-it",
    "aliases": [
      "gemma-7b-it"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 8925,
    "license_type": "Gemma license",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1135.91,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831451+00:00",
        "confidence": 1.0,
        "raw_name": "gemma-7b-it",
        "raw_scores": {
          "arena_elo": 1135.91,
          "arena_votes": 8925
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1135.91
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "zephyr-7b-beta",
    "canonical_name": "zephyr-7b-beta",
    "model_name": "zephyr-7b-beta",
    "aliases": [
      "zephyr-7b-beta"
    ],
    "provider": "HuggingFace",
    "context_window": null,
    "open_source": null,
    "arena_votes": 11116,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1131.04,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831463+00:00",
        "confidence": 1.0,
        "raw_name": "zephyr-7b-beta",
        "raw_scores": {
          "arena_elo": 1131.04,
          "arena_votes": 11116
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1131.04
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "phi-3-mini-128k-instruct",
    "canonical_name": "phi-3-mini-128k-instruct",
    "model_name": "phi-3-mini-128k-instruct",
    "aliases": [
      "phi-3-mini-128k-instruct"
    ],
    "provider": "Microsoft",
    "context_window": null,
    "open_source": null,
    "arena_votes": 20691,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1129.15,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831475+00:00",
        "confidence": 1.0,
        "raw_name": "phi-3-mini-128k-instruct",
        "raw_scores": {
          "arena_elo": 1129.15,
          "arena_votes": 20691
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1129.15
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "phi-3-mini-4k-instruct",
    "canonical_name": "phi-3-mini-4k-instruct",
    "model_name": "phi-3-mini-4k-instruct",
    "aliases": [
      "phi-3-mini-4k-instruct"
    ],
    "provider": "Microsoft",
    "context_window": null,
    "open_source": null,
    "arena_votes": 20115,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1128.34,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831487+00:00",
        "confidence": 1.0,
        "raw_name": "phi-3-mini-4k-instruct",
        "raw_scores": {
          "arena_elo": 1128.34,
          "arena_votes": 20115
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1128.34
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "guanaco-33b",
    "canonical_name": "guanaco-33b",
    "model_name": "guanaco-33b",
    "aliases": [
      "guanaco-33b"
    ],
    "provider": "UW",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2921,
    "license_type": "Non-commercial",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1127.26,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831500+00:00",
        "confidence": 1.0,
        "raw_name": "guanaco-33b",
        "raw_scores": {
          "arena_elo": 1127.26,
          "arena_votes": 2921
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1127.26
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "zephyr-7b-alpha",
    "canonical_name": "zephyr-7b-alpha",
    "model_name": "zephyr-7b-alpha",
    "aliases": [
      "zephyr-7b-alpha"
    ],
    "provider": "HuggingFace",
    "context_window": null,
    "open_source": null,
    "arena_votes": 1785,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1126.87,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831512+00:00",
        "confidence": 1.0,
        "raw_name": "zephyr-7b-alpha",
        "raw_scores": {
          "arena_elo": 1126.87,
          "arena_votes": 1785
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1126.87
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "stripedhyena-nous-7b",
    "canonical_name": "stripedhyena-nous-7b",
    "model_name": "stripedhyena-nous-7b",
    "aliases": [
      "stripedhyena-nous-7b"
    ],
    "provider": "Together AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 5184,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1120.9,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831524+00:00",
        "confidence": 1.0,
        "raw_name": "stripedhyena-nous-7b",
        "raw_scores": {
          "arena_elo": 1120.9,
          "arena_votes": 5184
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1120.9
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "codellama-70b-instruct",
    "canonical_name": "codellama-70b-instruct",
    "model_name": "codellama-70b-instruct",
    "aliases": [
      "codellama-70b-instruct"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 1143,
    "license_type": "Llama 2 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1118.94,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831536+00:00",
        "confidence": 1.0,
        "raw_name": "codellama-70b-instruct",
        "raw_scores": {
          "arena_elo": 1118.94,
          "arena_votes": 1143
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1118.94
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "vicuna-7b",
    "canonical_name": "vicuna-7b",
    "model_name": "vicuna-7b",
    "aliases": [
      "vicuna-7b"
    ],
    "provider": "LMSYS",
    "context_window": null,
    "open_source": null,
    "arena_votes": 6923,
    "license_type": "Llama 2 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1114.57,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831548+00:00",
        "confidence": 1.0,
        "raw_name": "vicuna-7b",
        "raw_scores": {
          "arena_elo": 1114.57,
          "arena_votes": 6923
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1114.57
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "smollm2-17b-instruct",
    "canonical_name": "smollm2-1.7b-instruct",
    "model_name": "smollm2-1.7b-instruct",
    "aliases": [
      "smollm2-1.7b-instruct"
    ],
    "provider": "HuggingFace",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2201,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1114.26,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831560+00:00",
        "confidence": 1.0,
        "raw_name": "smollm2-1.7b-instruct",
        "raw_scores": {
          "arena_elo": 1114.26,
          "arena_votes": 2201
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1114.26
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemma-11-2b-it",
    "canonical_name": "gemma-1.1-2b-it",
    "model_name": "gemma-1.1-2b-it",
    "aliases": [
      "gemma-1.1-2b-it"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 10853,
    "license_type": "Gemma license",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1114.08,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831572+00:00",
        "confidence": 1.0,
        "raw_name": "gemma-1.1-2b-it",
        "raw_scores": {
          "arena_elo": 1114.08,
          "arena_votes": 10853
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1114.08
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-32-1b-instruct",
    "canonical_name": "llama-3.2-1b-instruct",
    "model_name": "llama-3.2-1b-instruct",
    "aliases": [
      "llama-3.2-1b-instruct"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 8045,
    "license_type": "Llama 3.2",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1111.19,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831584+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.2-1b-instruct",
        "raw_scores": {
          "arena_elo": 1111.19,
          "arena_votes": 8045
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1111.19
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "mistral-7b-instruct",
    "canonical_name": "mistral-7b-instruct",
    "model_name": "mistral-7b-instruct",
    "aliases": [
      "mistral-7b-instruct"
    ],
    "provider": "Mistral",
    "context_window": null,
    "open_source": null,
    "arena_votes": 8977,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1109.58,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831596+00:00",
        "confidence": 1.0,
        "raw_name": "mistral-7b-instruct",
        "raw_scores": {
          "arena_elo": 1109.58,
          "arena_votes": 8977
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1109.58
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-2-7b-chat",
    "canonical_name": "llama-2-7b-chat",
    "model_name": "llama-2-7b-chat",
    "aliases": [
      "llama-2-7b-chat"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 14148,
    "license_type": "Llama 2 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1108.14,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831608+00:00",
        "confidence": 1.0,
        "raw_name": "llama-2-7b-chat",
        "raw_scores": {
          "arena_elo": 1108.14,
          "arena_votes": 14148
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1108.14
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gemma-2b-it",
    "canonical_name": "gemma-2b-it",
    "model_name": "gemma-2b-it",
    "aliases": [
      "gemma-2b-it"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4779,
    "license_type": "Gemma license",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1091.54,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831620+00:00",
        "confidence": 1.0,
        "raw_name": "gemma-2b-it",
        "raw_scores": {
          "arena_elo": 1091.54,
          "arena_votes": 4779
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1091.54
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "qwen15-4b-chat",
    "canonical_name": "qwen1.5-4b-chat",
    "model_name": "qwen1.5-4b-chat",
    "aliases": [
      "qwen1.5-4b-chat"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 7598,
    "license_type": "Qianwen LICENSE",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1090.06,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831632+00:00",
        "confidence": 1.0,
        "raw_name": "qwen1.5-4b-chat",
        "raw_scores": {
          "arena_elo": 1090.06,
          "arena_votes": 7598
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1090.06
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "olmo-7b-instruct",
    "canonical_name": "olmo-7b-instruct",
    "model_name": "olmo-7b-instruct",
    "aliases": [
      "olmo-7b-instruct"
    ],
    "provider": "Ai2",
    "context_window": null,
    "open_source": null,
    "arena_votes": 6329,
    "license_type": "Apache-2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1074.57,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831644+00:00",
        "confidence": 1.0,
        "raw_name": "olmo-7b-instruct",
        "raw_scores": {
          "arena_elo": 1074.57,
          "arena_votes": 6329
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1074.57
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "koala-13b",
    "canonical_name": "koala-13b",
    "model_name": "koala-13b",
    "aliases": [
      "koala-13b"
    ],
    "provider": "UC Berkeley",
    "context_window": null,
    "open_source": null,
    "arena_votes": 6964,
    "license_type": "Non-commercial",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1070.35,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831656+00:00",
        "confidence": 1.0,
        "raw_name": "koala-13b",
        "raw_scores": {
          "arena_elo": 1070.35,
          "arena_votes": 6964
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1070.35
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "alpaca-13b",
    "canonical_name": "alpaca-13b",
    "model_name": "alpaca-13b",
    "aliases": [
      "alpaca-13b"
    ],
    "provider": "Stanford",
    "context_window": null,
    "open_source": null,
    "arena_votes": 5745,
    "license_type": "Non-commercial",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1067.28,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831668+00:00",
        "confidence": 1.0,
        "raw_name": "alpaca-13b",
        "raw_scores": {
          "arena_elo": 1067.28,
          "arena_votes": 5745
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1067.28
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "gpt4all-13b-snoozy",
    "canonical_name": "gpt4all-13b-snoozy",
    "model_name": "gpt4all-13b-snoozy",
    "aliases": [
      "gpt4all-13b-snoozy"
    ],
    "provider": "Nomic AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 1743,
    "license_type": "Non-commercial",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1065.85,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831680+00:00",
        "confidence": 1.0,
        "raw_name": "gpt4all-13b-snoozy",
        "raw_scores": {
          "arena_elo": 1065.85,
          "arena_votes": 1743
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1065.85
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "mpt-7b-chat",
    "canonical_name": "mpt-7b-chat",
    "model_name": "mpt-7b-chat",
    "aliases": [
      "mpt-7b-chat"
    ],
    "provider": "MosaicML",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3925,
    "license_type": "CC-BY-NC-SA-4.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1061.73,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831696+00:00",
        "confidence": 1.0,
        "raw_name": "mpt-7b-chat",
        "raw_scores": {
          "arena_elo": 1061.73,
          "arena_votes": 3925
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1061.73
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "chatglm3-6b",
    "canonical_name": "chatglm3-6b",
    "model_name": "chatglm3-6b",
    "aliases": [
      "chatglm3-6b"
    ],
    "provider": "Tsinghua",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4658,
    "license_type": "Apache-2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1055.97,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831708+00:00",
        "confidence": 1.0,
        "raw_name": "chatglm3-6b",
        "raw_scores": {
          "arena_elo": 1055.97,
          "arena_votes": 4658
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1055.97
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "rwkv-4-raven-14b",
    "canonical_name": "RWKV-4-Raven-14B",
    "model_name": "RWKV-4-Raven-14B",
    "aliases": [
      "RWKV-4-Raven-14B"
    ],
    "provider": "RWKV",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4845,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1041.2,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831720+00:00",
        "confidence": 1.0,
        "raw_name": "RWKV-4-Raven-14B",
        "raw_scores": {
          "arena_elo": 1041.2,
          "arena_votes": 4845
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1041.2
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "chatglm2-6b",
    "canonical_name": "chatglm2-6b",
    "model_name": "chatglm2-6b",
    "aliases": [
      "chatglm2-6b"
    ],
    "provider": "Tsinghua",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2657,
    "license_type": "Apache-2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1024.11,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831733+00:00",
        "confidence": 1.0,
        "raw_name": "chatglm2-6b",
        "raw_scores": {
          "arena_elo": 1024.11,
          "arena_votes": 2657
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1024.11
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "oasst-pythia-12b",
    "canonical_name": "oasst-pythia-12b",
    "model_name": "oasst-pythia-12b",
    "aliases": [
      "oasst-pythia-12b"
    ],
    "provider": "OpenAssistant",
    "context_window": null,
    "open_source": null,
    "arena_votes": 6311,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1022.0,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831745+00:00",
        "confidence": 1.0,
        "raw_name": "oasst-pythia-12b",
        "raw_scores": {
          "arena_elo": 1022.0,
          "arena_votes": 6311
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1022.0
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "chatglm-6b",
    "canonical_name": "chatglm-6b",
    "model_name": "chatglm-6b",
    "aliases": [
      "chatglm-6b"
    ],
    "provider": "Tsinghua",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4914,
    "license_type": "Non-commercial",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 995.492,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831757+00:00",
        "confidence": 1.0,
        "raw_name": "chatglm-6b",
        "raw_scores": {
          "arena_elo": 995.492,
          "arena_votes": 4914
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 995.492
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "fastchat-t5-3b",
    "canonical_name": "fastchat-t5-3b",
    "model_name": "fastchat-t5-3b",
    "aliases": [
      "fastchat-t5-3b"
    ],
    "provider": "LMSYS",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4203,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 991.198,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831769+00:00",
        "confidence": 1.0,
        "raw_name": "fastchat-t5-3b",
        "raw_scores": {
          "arena_elo": 991.198,
          "arena_votes": 4203
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 991.198
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "dolly-v2-12b",
    "canonical_name": "dolly-v2-12b",
    "model_name": "dolly-v2-12b",
    "aliases": [
      "dolly-v2-12b"
    ],
    "provider": "Databricks",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3412,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 979.94,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831781+00:00",
        "confidence": 1.0,
        "raw_name": "dolly-v2-12b",
        "raw_scores": {
          "arena_elo": 979.94,
          "arena_votes": 3412
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 979.94
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "llama-13b",
    "canonical_name": "llama-13b",
    "model_name": "llama-13b",
    "aliases": [
      "llama-13b"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2391,
    "license_type": "Non-commercial",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 972.002,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831793+00:00",
        "confidence": 1.0,
        "raw_name": "llama-13b",
        "raw_scores": {
          "arena_elo": 972.002,
          "arena_votes": 2391
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 972.002
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  },
  {
    "model_id": null,
    "model_slug": "stablelm-tuned-alpha-7b",
    "canonical_name": "stablelm-tuned-alpha-7b",
    "model_name": "stablelm-tuned-alpha-7b",
    "aliases": [
      "stablelm-tuned-alpha-7b"
    ],
    "provider": "Stability AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3287,
    "license_type": "CC-BY-NC-SA-4.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 952.506,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-28T10:51:02.831805+00:00",
        "confidence": 1.0,
        "raw_name": "stablelm-tuned-alpha-7b",
        "raw_scores": {
          "arena_elo": 952.506,
          "arena_votes": 3287
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 952.506
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-28"
  }
]