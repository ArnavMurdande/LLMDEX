[
  {
    "model_id": null,
    "model_slug": "gemini-31-pro-preview",
    "canonical_name": "Gemini 3.1 Pro Preview",
    "model_name": "Gemini 3.1 Pro Preview",
    "aliases": [
      "Gemini 3.1 Pro Preview",
      "gemini-3.1-pro-preview"
    ],
    "provider": "Google",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": 4060,
    "license_type": "Proprietary",
    "creator": "Google",
    "intelligence_score": 57.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1500.34,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 4.5,
    "latency_seconds": 35.19,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 92.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.776505+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 3.1 Pro Preview",
        "raw_scores": {
          "intelligence_score": 57.0,
          "blended_cost_per_1m": 4.5,
          "latency_seconds": 35.19,
          "tokens_per_second": 92.0,
          "context_window": 1000000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.223491+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-3.1-pro-preview",
        "raw_scores": {
          "arena_elo": 1500.34,
          "arena_votes": 4060
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 57.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1500.34
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "claude-opus-46",
    "canonical_name": "Claude Opus 4.6 (max)",
    "model_name": "Claude Opus 4.6 (max)",
    "aliases": [
      "Claude Opus 4.6",
      "Claude Opus 4.6 (max)",
      "claude-opus-4.6",
      "claude-opus-4.6-thinking"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 7042,
    "license_type": "Proprietary",
    "creator": "Anthropic",
    "intelligence_score": 49.5,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1503.275,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 10.0,
    "latency_seconds": 1.735,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 70.5,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.776602+00:00",
        "confidence": 0.65,
        "raw_name": "Claude Opus 4.6 (max)",
        "raw_scores": {
          "intelligence_score": 53.0,
          "blended_cost_per_1m": 10.0,
          "latency_seconds": 1.77,
          "tokens_per_second": 73.0,
          "context_window": 200000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.776867+00:00",
        "confidence": 0.65,
        "raw_name": "Claude Opus 4.6",
        "raw_scores": {
          "intelligence_score": 46.0,
          "blended_cost_per_1m": 10.0,
          "latency_seconds": 1.7,
          "tokens_per_second": 68.0,
          "context_window": 200000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.223422+00:00",
        "confidence": 1.0,
        "raw_name": "claude-opus-4.6",
        "raw_scores": {
          "arena_elo": 1503.84,
          "arena_votes": 7042
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.223468+00:00",
        "confidence": 1.0,
        "raw_name": "claude-opus-4.6-thinking",
        "raw_scores": {
          "arena_elo": 1502.71,
          "arena_votes": 6181
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 53.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1503.84
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "claude-sonnet-46",
    "canonical_name": "Claude Sonnet 4.6 (max)",
    "model_name": "Claude Sonnet 4.6 (max)",
    "aliases": [
      "Claude Sonnet 4.6",
      "Claude Sonnet 4.6 (Non-reasoning, Low Effort)",
      "Claude Sonnet 4.6 (max)",
      "claude-sonnet-4.6"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 3294,
    "license_type": "Proprietary",
    "creator": "Anthropic",
    "intelligence_score": 46.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1456.98,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 6.0,
    "latency_seconds": 0.8967,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 57.6667,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.776633+00:00",
        "confidence": 0.65,
        "raw_name": "Claude Sonnet 4.6 (max)",
        "raw_scores": {
          "intelligence_score": 51.0,
          "blended_cost_per_1m": 6.0,
          "latency_seconds": 0.88,
          "tokens_per_second": 55.0,
          "context_window": 200000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.776943+00:00",
        "confidence": 0.65,
        "raw_name": "Claude Sonnet 4.6",
        "raw_scores": {
          "intelligence_score": 44.0,
          "blended_cost_per_1m": 6.0,
          "latency_seconds": 0.86,
          "tokens_per_second": 57.0,
          "context_window": 200000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.777002+00:00",
        "confidence": 0.65,
        "raw_name": "Claude Sonnet 4.6 (Non-reasoning, Low Effort)",
        "raw_scores": {
          "intelligence_score": 43.0,
          "blended_cost_per_1m": 6.0,
          "latency_seconds": 0.95,
          "tokens_per_second": 61.0,
          "context_window": 200000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.223685+00:00",
        "confidence": 1.0,
        "raw_name": "claude-sonnet-4.6",
        "raw_scores": {
          "arena_elo": 1456.98,
          "arena_votes": 3294
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 51.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1456.98
      }
    },
    "confidence_score": 0.7375,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gpt-52",
    "canonical_name": "GPT-5.2 (xhigh)",
    "model_name": "GPT-5.2 (xhigh)",
    "aliases": [
      "GPT-5.2",
      "GPT-5.2 (medium)",
      "GPT-5.2 (xhigh)",
      "gpt-5.2",
      "gpt-5.2-chat-latest-20260210",
      "gpt-5.2-high"
    ],
    "provider": "OpenAI",
    "context_window": 400000,
    "open_source": null,
    "arena_votes": 18792,
    "license_type": "Proprietary",
    "creator": "OpenAI",
    "intelligence_score": 44.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1452.6867,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 4.81,
    "latency_seconds": 12.79,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 52.6667,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.776657+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5.2 (xhigh)",
        "raw_scores": {
          "intelligence_score": 51.0,
          "blended_cost_per_1m": 4.81,
          "latency_seconds": 37.77,
          "tokens_per_second": 85.0,
          "context_window": 400000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.776826+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5.2 (medium)",
        "raw_scores": {
          "intelligence_score": 47.0,
          "blended_cost_per_1m": 4.81,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 400000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.777932+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5.2",
        "raw_scores": {
          "intelligence_score": 34.0,
          "blended_cost_per_1m": 4.81,
          "latency_seconds": 0.6,
          "tokens_per_second": 73.0,
          "context_window": 400000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.223559+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-5.2-chat-latest-20260210",
        "raw_scores": {
          "arena_elo": 1480.99,
          "arena_votes": 3093
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.223888+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-5.2-high",
        "raw_scores": {
          "arena_elo": 1440.38,
          "arena_votes": 18792
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.223913+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-5.2",
        "raw_scores": {
          "arena_elo": 1436.69,
          "arena_votes": 15640
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 51.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1480.99
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "claude-opus-45",
    "canonical_name": "Claude Opus 4.5",
    "model_name": "Claude Opus 4.5",
    "aliases": [
      "Claude Opus 4.5",
      "claude-opus-4.5-20251101",
      "claude-opus-4.5-20251101-thinking-32k"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 35014,
    "license_type": "Proprietary",
    "creator": "Anthropic",
    "intelligence_score": 50.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1469.485,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 10.0,
    "latency_seconds": 1.36,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 78.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.776680+00:00",
        "confidence": 0.65,
        "raw_name": "Claude Opus 4.5",
        "raw_scores": {
          "intelligence_score": 50.0,
          "blended_cost_per_1m": 10.0,
          "latency_seconds": 1.36,
          "tokens_per_second": 78.0,
          "context_window": 200000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.223625+00:00",
        "confidence": 1.0,
        "raw_name": "claude-opus-4.5-20251101-thinking-32k",
        "raw_scores": {
          "arena_elo": 1471.69,
          "arena_votes": 30067
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.223643+00:00",
        "confidence": 1.0,
        "raw_name": "claude-opus-4.5-20251101",
        "raw_scores": {
          "arena_elo": 1467.28,
          "arena_votes": 35014
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 50.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1471.69
      }
    },
    "confidence_score": 0.8833,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "glm-5",
    "canonical_name": "GLM-5",
    "model_name": "GLM-5",
    "aliases": [
      "GLM-5",
      "glm-5"
    ],
    "provider": "Z.ai",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 6061,
    "license_type": "MIT",
    "creator": "Z AI",
    "intelligence_score": 50.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1453.82,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.55,
    "latency_seconds": 1.31,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 69.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.776702+00:00",
        "confidence": 0.65,
        "raw_name": "GLM-5",
        "raw_scores": {
          "intelligence_score": 50.0,
          "blended_cost_per_1m": 1.55,
          "latency_seconds": 1.31,
          "tokens_per_second": 69.0,
          "context_window": 200000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.223711+00:00",
        "confidence": 1.0,
        "raw_name": "glm-5",
        "raw_scores": {
          "arena_elo": 1453.82,
          "arena_votes": 6061
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 50.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1453.82
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gpt-52-codex",
    "canonical_name": "GPT-5.2 Codex (xhigh)",
    "model_name": "GPT-5.2 Codex (xhigh)",
    "aliases": [
      "GPT-5.2 Codex (xhigh)"
    ],
    "provider": "OpenAI",
    "context_window": 400000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "OpenAI",
    "intelligence_score": 49.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 4.81,
    "latency_seconds": 30.08,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 85.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.776723+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5.2 Codex (xhigh)",
        "raw_scores": {
          "intelligence_score": 49.0,
          "blended_cost_per_1m": 4.81,
          "latency_seconds": 30.08,
          "tokens_per_second": 85.0,
          "context_window": 400000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 49.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemini-3-pro",
    "canonical_name": "Gemini 3 Pro Preview (high)",
    "model_name": "Gemini 3 Pro Preview (high)",
    "aliases": [
      "Gemini 3 Pro Preview (high)",
      "Gemini 3 Pro Preview (low)",
      "gemini-3-pro"
    ],
    "provider": "Google",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": 37854,
    "license_type": "Proprietary",
    "creator": "Google",
    "intelligence_score": 44.5,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1485.78,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 4.5,
    "latency_seconds": 16.605,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 133.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.776755+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 3 Pro Preview (high)",
        "raw_scores": {
          "intelligence_score": 48.0,
          "blended_cost_per_1m": 4.5,
          "latency_seconds": 29.13,
          "tokens_per_second": 129.0,
          "context_window": 1000000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.777191+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 3 Pro Preview (low)",
        "raw_scores": {
          "intelligence_score": 41.0,
          "blended_cost_per_1m": 4.5,
          "latency_seconds": 4.08,
          "tokens_per_second": 137.0,
          "context_window": 1000000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.223540+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-3-pro",
        "raw_scores": {
          "arena_elo": 1485.78,
          "arena_votes": 37854
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 48.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1485.78
      }
    },
    "confidence_score": 0.7667,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gpt-51",
    "canonical_name": "GPT-5.1 (high)",
    "model_name": "GPT-5.1 (high)",
    "aliases": [
      "GPT-5.1",
      "GPT-5.1 (high)",
      "gpt-5.1",
      "gpt-5.1-high"
    ],
    "provider": "OpenAI",
    "context_window": 400000,
    "open_source": null,
    "arena_votes": 36267,
    "license_type": "Proprietary",
    "creator": "OpenAI",
    "intelligence_score": 37.5,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1446.885,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.44,
    "latency_seconds": 19.66,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 102.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.776782+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5.1 (high)",
        "raw_scores": {
          "intelligence_score": 48.0,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 38.51,
          "tokens_per_second": 110.0,
          "context_window": 400000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778782+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5.1",
        "raw_scores": {
          "intelligence_score": 27.0,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 0.81,
          "tokens_per_second": 94.0,
          "context_window": 400000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.223699+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-5.1-high",
        "raw_scores": {
          "arena_elo": 1456.73,
          "arena_votes": 33984
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.223901+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-5.1",
        "raw_scores": {
          "arena_elo": 1437.04,
          "arena_votes": 36267
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 48.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1456.73
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "kimi-k25",
    "canonical_name": "Kimi K2.5",
    "model_name": "Kimi K2.5",
    "aliases": [
      "Kimi K2.5",
      "kimi-k2.5-thinking"
    ],
    "provider": "Moonshot",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": 10687,
    "license_type": "Modified MIT",
    "creator": "Kimi",
    "intelligence_score": 47.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1450.29,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.2,
    "latency_seconds": 1.28,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 41.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.776805+00:00",
        "confidence": 0.65,
        "raw_name": "Kimi K2.5",
        "raw_scores": {
          "intelligence_score": 47.0,
          "blended_cost_per_1m": 1.2,
          "latency_seconds": 1.28,
          "tokens_per_second": 41.0,
          "context_window": 256000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.223749+00:00",
        "confidence": 1.0,
        "raw_name": "kimi-k2.5-thinking",
        "raw_scores": {
          "arena_elo": 1450.29,
          "arena_votes": 10687
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 47.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1450.29
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemini-3-flash",
    "canonical_name": "Gemini 3 Flash",
    "model_name": "Gemini 3 Flash",
    "aliases": [
      "Gemini 3 Flash",
      "gemini-3-flash",
      "gemini-3-flash (thinking-minimal)"
    ],
    "provider": "Google",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": 28847,
    "license_type": "Proprietary",
    "creator": "Google",
    "intelligence_score": 46.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1467.57,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.13,
    "latency_seconds": 12.67,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 214.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.776847+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 3 Flash",
        "raw_scores": {
          "intelligence_score": 46.0,
          "blended_cost_per_1m": 1.13,
          "latency_seconds": 12.67,
          "tokens_per_second": 214.0,
          "context_window": 1000000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.223573+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-3-flash",
        "raw_scores": {
          "arena_elo": 1473.06,
          "arena_votes": 28847
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.223670+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-3-flash (thinking-minimal)",
        "raw_scores": {
          "arena_elo": 1462.08,
          "arena_votes": 20204
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 46.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1473.06
      }
    },
    "confidence_score": 0.8833,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen35-397b",
    "canonical_name": "Qwen3.5 397B A17B",
    "model_name": "Qwen3.5 397B A17B",
    "aliases": [
      "Qwen3.5 397B A17B",
      "qwen3.5-397b-a17b"
    ],
    "provider": "Alibaba",
    "context_window": 262000,
    "open_source": null,
    "arena_votes": 4541,
    "license_type": "Apache 2.0",
    "creator": "Alibaba",
    "intelligence_score": 45.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1450.54,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.35,
    "latency_seconds": 1.44,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 74.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.776886+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3.5 397B A17B",
        "raw_scores": {
          "intelligence_score": 45.0,
          "blended_cost_per_1m": 1.35,
          "latency_seconds": 1.44,
          "tokens_per_second": 74.0,
          "context_window": 262000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.223736+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3.5-397b-a17b",
        "raw_scores": {
          "arena_elo": 1450.54,
          "arena_votes": 4541
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 45.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1450.54
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gpt-5",
    "canonical_name": "GPT-5 (high)",
    "model_name": "GPT-5 (high)",
    "aliases": [
      "GPT-5 (ChatGPT)",
      "GPT-5 (high)",
      "GPT-5 (low)",
      "GPT-5 (medium)",
      "GPT-5 (minimal)",
      "gpt-5-chat",
      "gpt-5-high"
    ],
    "provider": "OpenAI",
    "context_window": 400000,
    "open_source": null,
    "arena_votes": 32357,
    "license_type": "Proprietary",
    "creator": "OpenAI",
    "intelligence_score": 34.4,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1430.145,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.44,
    "latency_seconds": 37.338,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 107.4,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.776905+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5 (high)",
        "raw_scores": {
          "intelligence_score": 45.0,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 103.29,
          "tokens_per_second": 91.0,
          "context_window": 400000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.777098+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5 (medium)",
        "raw_scores": {
          "intelligence_score": 42.0,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 54.76,
          "tokens_per_second": 91.0,
          "context_window": 400000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.777361+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5 (low)",
        "raw_scores": {
          "intelligence_score": 39.0,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 27.13,
          "tokens_per_second": 87.0,
          "context_window": 400000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779332+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5 (minimal)",
        "raw_scores": {
          "intelligence_score": 24.0,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 1.03,
          "tokens_per_second": 66.0,
          "context_window": 400000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779676+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5 (ChatGPT)",
        "raw_scores": {
          "intelligence_score": 22.0,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 0.48,
          "tokens_per_second": 202.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.223952+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-5-high",
        "raw_scores": {
          "arena_elo": 1434.22,
          "arena_votes": 32357
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224027+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-5-chat",
        "raw_scores": {
          "arena_elo": 1426.07,
          "arena_votes": 31614
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 45.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1434.22
      }
    },
    "confidence_score": 0.75,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gpt-5-codex",
    "canonical_name": "GPT-5 Codex (high)",
    "model_name": "GPT-5 Codex (high)",
    "aliases": [
      "GPT-5 Codex (high)"
    ],
    "provider": "OpenAI",
    "context_window": 400000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "OpenAI",
    "intelligence_score": 45.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.44,
    "latency_seconds": 12.34,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 305.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.776923+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5 Codex (high)",
        "raw_scores": {
          "intelligence_score": 45.0,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 12.34,
          "tokens_per_second": 305.0,
          "context_window": 400000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 45.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "claude-45-sonnet",
    "canonical_name": "Claude 4.5 Sonnet",
    "model_name": "Claude 4.5 Sonnet",
    "aliases": [
      "Claude 4.5 Sonnet"
    ],
    "provider": "Anthropic",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Anthropic",
    "intelligence_score": 43.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 6.0,
    "latency_seconds": 1.11,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 78.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.776980+00:00",
        "confidence": 0.65,
        "raw_name": "Claude 4.5 Sonnet",
        "raw_scores": {
          "intelligence_score": 43.0,
          "blended_cost_per_1m": 6.0,
          "latency_seconds": 1.11,
          "tokens_per_second": 78.0,
          "context_window": 1000000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 43.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gpt-51-codex",
    "canonical_name": "GPT-5.1 Codex (high)",
    "model_name": "GPT-5.1 Codex (high)",
    "aliases": [
      "GPT-5.1 Codex (high)"
    ],
    "provider": "OpenAI",
    "context_window": 400000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "OpenAI",
    "intelligence_score": 42.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.44,
    "latency_seconds": 15.42,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 250.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.777022+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5.1 Codex (high)",
        "raw_scores": {
          "intelligence_score": 42.0,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 15.42,
          "tokens_per_second": 250.0,
          "context_window": 400000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 42.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "glm-47",
    "canonical_name": "GLM-4.7",
    "model_name": "GLM-4.7",
    "aliases": [
      "GLM-4.7",
      "glm-4.7"
    ],
    "provider": "Z.ai",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 11936,
    "license_type": "MIT",
    "creator": "Z AI",
    "intelligence_score": 42.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1440.85,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.94,
    "latency_seconds": 0.64,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 111.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.777042+00:00",
        "confidence": 0.65,
        "raw_name": "GLM-4.7",
        "raw_scores": {
          "intelligence_score": 42.0,
          "blended_cost_per_1m": 0.94,
          "latency_seconds": 0.64,
          "tokens_per_second": 111.0,
          "context_window": 200000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.223876+00:00",
        "confidence": 1.0,
        "raw_name": "glm-4.7",
        "raw_scores": {
          "arena_elo": 1440.85,
          "arena_votes": 11936
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 42.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1440.85
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "minimax-m25",
    "canonical_name": "MiniMax-M2.5",
    "model_name": "MiniMax-M2.5",
    "aliases": [
      "MiniMax-M2.5",
      "minimax-m2.5"
    ],
    "provider": "MiniMax",
    "context_window": 205000,
    "open_source": null,
    "arena_votes": 5631,
    "license_type": "Modified MIT",
    "creator": "MiniMax",
    "intelligence_score": 42.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1399.03,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.53,
    "latency_seconds": 4.24,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 57.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.777061+00:00",
        "confidence": 0.65,
        "raw_name": "MiniMax-M2.5",
        "raw_scores": {
          "intelligence_score": 42.0,
          "blended_cost_per_1m": 0.53,
          "latency_seconds": 4.24,
          "tokens_per_second": 57.0,
          "context_window": 205000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224486+00:00",
        "confidence": 1.0,
        "raw_name": "minimax-m2.5",
        "raw_scores": {
          "arena_elo": 1399.03,
          "arena_votes": 5631
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 42.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1399.03
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen35-27b",
    "canonical_name": "Qwen3.5 27B",
    "model_name": "Qwen3.5 27B",
    "aliases": [
      "Qwen3.5 27B"
    ],
    "provider": "Alibaba",
    "context_window": 262000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 42.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.82,
    "latency_seconds": 1.41,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 100.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.777080+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3.5 27B",
        "raw_scores": {
          "intelligence_score": 42.0,
          "blended_cost_per_1m": 0.82,
          "latency_seconds": 1.41,
          "tokens_per_second": 100.0,
          "context_window": 262000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 42.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-v32",
    "canonical_name": "DeepSeek V3.2",
    "model_name": "DeepSeek V3.2",
    "aliases": [
      "DeepSeek V3.2",
      "deepseek-v3.2",
      "deepseek-v3.2-thinking"
    ],
    "provider": "DeepSeek",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 30323,
    "license_type": "MIT",
    "creator": "DeepSeek",
    "intelligence_score": 42.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1420.03,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.32,
    "latency_seconds": 1.27,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 50.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.777117+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek V3.2",
        "raw_scores": {
          "intelligence_score": 42.0,
          "blended_cost_per_1m": 0.32,
          "latency_seconds": 1.27,
          "tokens_per_second": 50.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224129+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-v3.2-thinking",
        "raw_scores": {
          "arena_elo": 1420.89,
          "arena_votes": 25287
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224141+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-v3.2",
        "raw_scores": {
          "arena_elo": 1419.17,
          "arena_votes": 30323
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 42.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1420.89
      }
    },
    "confidence_score": 0.8833,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen35-122b-a10b",
    "canonical_name": "Qwen3.5 122B A10B",
    "model_name": "Qwen3.5 122B A10B",
    "aliases": [
      "Qwen3.5 122B A10B"
    ],
    "provider": "Alibaba",
    "context_window": 262000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 41.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.1,
    "latency_seconds": 1.34,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 106.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.777135+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3.5 122B A10B",
        "raw_scores": {
          "intelligence_score": 41.0,
          "blended_cost_per_1m": 1.1,
          "latency_seconds": 1.34,
          "tokens_per_second": 106.0,
          "context_window": 262000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 41.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "grok-4",
    "canonical_name": "Grok 4",
    "model_name": "Grok 4",
    "aliases": [
      "Grok 4",
      "grok-4-0709"
    ],
    "provider": "xAI",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": 41771,
    "license_type": "Proprietary",
    "creator": "xAI",
    "intelligence_score": 41.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1409.46,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 6.0,
    "latency_seconds": 16.72,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 39.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.777154+00:00",
        "confidence": 0.65,
        "raw_name": "Grok 4",
        "raw_scores": {
          "intelligence_score": 41.0,
          "blended_cost_per_1m": 6.0,
          "latency_seconds": 16.72,
          "tokens_per_second": 39.0,
          "context_window": 256000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224367+00:00",
        "confidence": 1.0,
        "raw_name": "grok-4-0709",
        "raw_scores": {
          "arena_elo": 1409.46,
          "arena_votes": 41771
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 41.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1409.46
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "mimo-v2-flash",
    "canonical_name": "MiMo-V2-Flash (Feb 2026)",
    "model_name": "MiMo-V2-Flash (Feb 2026)",
    "aliases": [
      "MiMo-V2-Flash",
      "MiMo-V2-Flash (Feb 2026)",
      "mimo-v2-flash (non-thinking)",
      "mimo-v2-flash (thinking)"
    ],
    "provider": "Xiaomi",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": 19235,
    "license_type": "MIT",
    "creator": "Xiaomi",
    "intelligence_score": 40.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1388.32,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.15,
    "latency_seconds": 1.39,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 164.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.777172+00:00",
        "confidence": 0.65,
        "raw_name": "MiMo-V2-Flash (Feb 2026)",
        "raw_scores": {
          "intelligence_score": 41.0,
          "blended_cost_per_1m": 0.15,
          "latency_seconds": 1.29,
          "tokens_per_second": 161.0,
          "context_window": 256000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.777342+00:00",
        "confidence": 0.65,
        "raw_name": "MiMo-V2-Flash",
        "raw_scores": {
          "intelligence_score": 39.0,
          "blended_cost_per_1m": 0.15,
          "latency_seconds": 1.49,
          "tokens_per_second": 167.0,
          "context_window": 256000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224653+00:00",
        "confidence": 1.0,
        "raw_name": "mimo-v2-flash (non-thinking)",
        "raw_scores": {
          "arena_elo": 1389.86,
          "arena_votes": 19235
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224724+00:00",
        "confidence": 1.0,
        "raw_name": "mimo-v2-flash (thinking)",
        "raw_scores": {
          "arena_elo": 1386.78,
          "arena_votes": 10877
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 41.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1389.86
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gpt-5-mini",
    "canonical_name": "GPT-5 mini (high)",
    "model_name": "GPT-5 mini (high)",
    "aliases": [
      "GPT-5 mini (high)",
      "GPT-5 mini (medium)",
      "GPT-5 mini (minimal)",
      "gpt-5-mini-high"
    ],
    "provider": "OpenAI",
    "context_window": 400000,
    "open_source": null,
    "arena_votes": 26951,
    "license_type": "Proprietary",
    "creator": "OpenAI",
    "intelligence_score": 33.6667,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1390.43,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.69,
    "latency_seconds": 46.0367,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 71.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.777210+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5 mini (high)",
        "raw_scores": {
          "intelligence_score": 41.0,
          "blended_cost_per_1m": 0.69,
          "latency_seconds": 94.95,
          "tokens_per_second": 75.0,
          "context_window": 400000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.777379+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5 mini (medium)",
        "raw_scores": {
          "intelligence_score": 39.0,
          "blended_cost_per_1m": 0.69,
          "latency_seconds": 42.49,
          "tokens_per_second": 68.0,
          "context_window": 400000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779861+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5 mini (minimal)",
        "raw_scores": {
          "intelligence_score": 21.0,
          "blended_cost_per_1m": 0.69,
          "latency_seconds": 0.67,
          "tokens_per_second": 70.0,
          "context_window": 400000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224641+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-5-mini-high",
        "raw_scores": {
          "arena_elo": 1390.43,
          "arena_votes": 26951
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 41.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1390.43
      }
    },
    "confidence_score": 0.7375,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "kimi-k2-thinking",
    "canonical_name": "Kimi K2 Thinking",
    "model_name": "Kimi K2 Thinking",
    "aliases": [
      "Kimi K2 Thinking"
    ],
    "provider": "Moonshot",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Kimi",
    "intelligence_score": 41.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.07,
    "latency_seconds": 0.65,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 72.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.777228+00:00",
        "confidence": 0.65,
        "raw_name": "Kimi K2 Thinking",
        "raw_scores": {
          "intelligence_score": 41.0,
          "blended_cost_per_1m": 1.07,
          "latency_seconds": 0.65,
          "tokens_per_second": 72.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 41.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "o3-pro",
    "canonical_name": "o3-pro",
    "model_name": "o3-pro",
    "aliases": [
      "o3-pro"
    ],
    "provider": "OpenAI",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "OpenAI",
    "intelligence_score": 41.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 35.0,
    "latency_seconds": 121.51,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 22.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.777246+00:00",
        "confidence": 0.65,
        "raw_name": "o3-pro",
        "raw_scores": {
          "intelligence_score": 41.0,
          "blended_cost_per_1m": 35.0,
          "latency_seconds": 121.51,
          "tokens_per_second": 22.0,
          "context_window": 200000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 41.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-max",
    "canonical_name": "Qwen3 Max Thinking",
    "model_name": "Qwen3 Max Thinking",
    "aliases": [
      "Qwen3 Max",
      "Qwen3 Max (Preview)",
      "Qwen3 Max Thinking",
      "Qwen3 Max Thinking (Preview)",
      "qwen3-max-2025-09-23",
      "qwen3-max-preview"
    ],
    "provider": "Alibaba",
    "context_window": 262000,
    "open_source": null,
    "arena_votes": 27649,
    "license_type": "Proprietary",
    "creator": "Alibaba",
    "intelligence_score": 32.25,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1429.43,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 2.4,
    "latency_seconds": 1.8375,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 35.75,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.777305+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 Max Thinking",
        "raw_scores": {
          "intelligence_score": 40.0,
          "blended_cost_per_1m": 2.4,
          "latency_seconds": 1.68,
          "tokens_per_second": 34.0,
          "context_window": 256000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778215+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 Max Thinking (Preview)",
        "raw_scores": {
          "intelligence_score": 32.0,
          "blended_cost_per_1m": 2.4,
          "latency_seconds": 1.72,
          "tokens_per_second": 52.0,
          "context_window": 262000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778326+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 Max",
        "raw_scores": {
          "intelligence_score": 31.0,
          "blended_cost_per_1m": 2.4,
          "latency_seconds": 2.17,
          "tokens_per_second": 27.0,
          "context_window": 262000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778949+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 Max (Preview)",
        "raw_scores": {
          "intelligence_score": 26.0,
          "blended_cost_per_1m": 2.4,
          "latency_seconds": 1.78,
          "tokens_per_second": 30.0,
          "context_window": 262000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.223938+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-max-preview",
        "raw_scores": {
          "arena_elo": 1434.24,
          "arena_votes": 27649
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224052+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-max-2025-09-23",
        "raw_scores": {
          "arena_elo": 1424.62,
          "arena_votes": 9172
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 40.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1434.24
      }
    },
    "confidence_score": 0.7667,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "minimax-m21",
    "canonical_name": "MiniMax-M2.1",
    "model_name": "MiniMax-M2.1",
    "aliases": [
      "MiniMax-M2.1"
    ],
    "provider": "MiniMax",
    "context_window": 205000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "MiniMax",
    "intelligence_score": 40.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.53,
    "latency_seconds": 3.2,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 55.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.777324+00:00",
        "confidence": 0.65,
        "raw_name": "MiniMax-M2.1",
        "raw_scores": {
          "intelligence_score": 40.0,
          "blended_cost_per_1m": 0.53,
          "latency_seconds": 3.2,
          "tokens_per_second": 55.0,
          "context_window": 205000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 40.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "claude-4-sonnet",
    "canonical_name": "Claude 4 Sonnet",
    "model_name": "Claude 4 Sonnet",
    "aliases": [
      "Claude 4 Sonnet"
    ],
    "provider": "Anthropic",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Anthropic",
    "intelligence_score": 39.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 6.0,
    "latency_seconds": 1.17,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 76.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.777398+00:00",
        "confidence": 0.65,
        "raw_name": "Claude 4 Sonnet",
        "raw_scores": {
          "intelligence_score": 39.0,
          "blended_cost_per_1m": 6.0,
          "latency_seconds": 1.17,
          "tokens_per_second": 76.0,
          "context_window": 1000000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 39.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gpt-51-codex-mini",
    "canonical_name": "GPT-5.1 Codex mini (high)",
    "model_name": "GPT-5.1 Codex mini (high)",
    "aliases": [
      "GPT-5.1 Codex mini (high)"
    ],
    "provider": "OpenAI",
    "context_window": 400000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "OpenAI",
    "intelligence_score": 39.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.69,
    "latency_seconds": 11.62,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 149.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.777415+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5.1 Codex mini (high)",
        "raw_scores": {
          "intelligence_score": 39.0,
          "blended_cost_per_1m": 0.69,
          "latency_seconds": 11.62,
          "tokens_per_second": 149.0,
          "context_window": 400000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 39.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "grok-41-fast",
    "canonical_name": "Grok 4.1 Fast",
    "model_name": "Grok 4.1 Fast",
    "aliases": [
      "Grok 4.1 Fast",
      "grok-4.1-fast-reasoning"
    ],
    "provider": "xAI",
    "context_window": 2000000,
    "open_source": null,
    "arena_votes": 30701,
    "license_type": "Proprietary",
    "creator": "xAI",
    "intelligence_score": 39.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1430.73,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.28,
    "latency_seconds": 10.1,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 167.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.777434+00:00",
        "confidence": 0.65,
        "raw_name": "Grok 4.1 Fast",
        "raw_scores": {
          "intelligence_score": 39.0,
          "blended_cost_per_1m": 0.28,
          "latency_seconds": 10.1,
          "tokens_per_second": 167.0,
          "context_window": 2000000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.223998+00:00",
        "confidence": 1.0,
        "raw_name": "grok-4.1-fast-reasoning",
        "raw_scores": {
          "arena_elo": 1430.73,
          "arena_votes": 30701
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 39.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1430.73
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "o3",
    "canonical_name": "o3",
    "model_name": "o3",
    "aliases": [
      "o3",
      "o3-2025-04-16"
    ],
    "provider": "OpenAI",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 60965,
    "license_type": "Proprietary",
    "creator": "OpenAI",
    "intelligence_score": 38.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1432.55,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.5,
    "latency_seconds": 22.75,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 105.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.777453+00:00",
        "confidence": 0.65,
        "raw_name": "o3",
        "raw_scores": {
          "intelligence_score": 38.0,
          "blended_cost_per_1m": 3.5,
          "latency_seconds": 22.75,
          "tokens_per_second": 105.0,
          "context_window": 200000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.223965+00:00",
        "confidence": 1.0,
        "raw_name": "o3-2025-04-16",
        "raw_scores": {
          "arena_elo": 1432.55,
          "arena_votes": 60965
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 38.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1432.55
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "claude-45-haiku",
    "canonical_name": "Claude 4.5 Haiku",
    "model_name": "Claude 4.5 Haiku",
    "aliases": [
      "Claude 4.5 Haiku",
      "claude-haiku-4.5-20251001"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 46912,
    "license_type": "Proprietary",
    "creator": "Anthropic",
    "intelligence_score": 37.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1405.22,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 2.0,
    "latency_seconds": 0.47,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 121.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.777507+00:00",
        "confidence": 0.65,
        "raw_name": "Claude 4.5 Haiku",
        "raw_scores": {
          "intelligence_score": 37.0,
          "blended_cost_per_1m": 2.0,
          "latency_seconds": 0.47,
          "tokens_per_second": 121.0,
          "context_window": 200000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224384+00:00",
        "confidence": 1.0,
        "raw_name": "claude-haiku-4.5-20251001",
        "raw_scores": {
          "arena_elo": 1405.22,
          "arena_votes": 46912
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 37.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1405.22
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen35-35b-a3b",
    "canonical_name": "Qwen3.5 35B A3B",
    "model_name": "Qwen3.5 35B A3B",
    "aliases": [
      "Qwen3.5 35B A3B"
    ],
    "provider": "Alibaba",
    "context_window": 262000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 37.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.69,
    "latency_seconds": 0.96,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 169.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.777556+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3.5 35B A3B",
        "raw_scores": {
          "intelligence_score": 37.0,
          "blended_cost_per_1m": 0.69,
          "latency_seconds": 0.96,
          "tokens_per_second": 169.0,
          "context_window": 262000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 37.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "kat-coder-pro-v1",
    "canonical_name": "KAT-Coder-Pro V1",
    "model_name": "KAT-Coder-Pro V1",
    "aliases": [
      "KAT-Coder-Pro V1"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "KwaiKAT",
    "intelligence_score": 36.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.53,
    "latency_seconds": 1.98,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 56.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.777580+00:00",
        "confidence": 0.65,
        "raw_name": "KAT-Coder-Pro V1",
        "raw_scores": {
          "intelligence_score": 36.0,
          "blended_cost_per_1m": 0.53,
          "latency_seconds": 1.98,
          "tokens_per_second": 56.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 36.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "minimax-m2",
    "canonical_name": "MiniMax-M2",
    "model_name": "MiniMax-M2",
    "aliases": [
      "MiniMax-M2",
      "minimax-m2"
    ],
    "provider": "MiniMax",
    "context_window": 205000,
    "open_source": null,
    "arena_votes": 6688,
    "license_type": "Apache 2.0",
    "creator": "MiniMax",
    "intelligence_score": 36.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1347.0,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.53,
    "latency_seconds": 2.45,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 52.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.777599+00:00",
        "confidence": 0.65,
        "raw_name": "MiniMax-M2",
        "raw_scores": {
          "intelligence_score": 36.0,
          "blended_cost_per_1m": 0.53,
          "latency_seconds": 2.45,
          "tokens_per_second": 52.0,
          "context_window": 205000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225320+00:00",
        "confidence": 1.0,
        "raw_name": "minimax-m2",
        "raw_scores": {
          "arena_elo": 1347.0,
          "arena_votes": 6688
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 36.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1347.0
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "nova-20-pro-preview",
    "canonical_name": "Nova 2.0 Pro Preview (medium)",
    "model_name": "Nova 2.0 Pro Preview (medium)",
    "aliases": [
      "Nova 2.0 Pro Preview",
      "Nova 2.0 Pro Preview (low)",
      "Nova 2.0 Pro Preview (medium)"
    ],
    "provider": "Amazon",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Amazon",
    "intelligence_score": 30.3333,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.44,
    "latency_seconds": 10.8867,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 135.6667,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.777626+00:00",
        "confidence": 0.65,
        "raw_name": "Nova 2.0 Pro Preview (medium)",
        "raw_scores": {
          "intelligence_score": 36.0,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 19.88,
          "tokens_per_second": 129.0,
          "context_window": 256000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778307+00:00",
        "confidence": 0.65,
        "raw_name": "Nova 2.0 Pro Preview (low)",
        "raw_scores": {
          "intelligence_score": 32.0,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 12.28,
          "tokens_per_second": 129.0,
          "context_window": 256000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779497+00:00",
        "confidence": 0.65,
        "raw_name": "Nova 2.0 Pro Preview",
        "raw_scores": {
          "intelligence_score": 23.0,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 0.5,
          "tokens_per_second": 149.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 36.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "grok-4-fast",
    "canonical_name": "Grok 4 Fast",
    "model_name": "Grok 4 Fast",
    "aliases": [
      "Grok 4 Fast",
      "grok-4-fast-chat",
      "grok-4-fast-reasoning"
    ],
    "provider": "xAI",
    "context_window": 2000000,
    "open_source": null,
    "arena_votes": 18446,
    "license_type": "Proprietary",
    "creator": "xAI",
    "intelligence_score": 35.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1412.735,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.28,
    "latency_seconds": 5.38,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 122.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.777699+00:00",
        "confidence": 0.65,
        "raw_name": "Grok 4 Fast",
        "raw_scores": {
          "intelligence_score": 35.0,
          "blended_cost_per_1m": 0.28,
          "latency_seconds": 5.38,
          "tokens_per_second": 122.0,
          "context_window": 2000000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224116+00:00",
        "confidence": 1.0,
        "raw_name": "grok-4-fast-chat",
        "raw_scores": {
          "arena_elo": 1421.87,
          "arena_votes": 6962
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224411+00:00",
        "confidence": 1.0,
        "raw_name": "grok-4-fast-reasoning",
        "raw_scores": {
          "arena_elo": 1403.6,
          "arena_votes": 18446
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 35.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1421.87
      }
    },
    "confidence_score": 0.8833,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "claude-37-sonnet",
    "canonical_name": "Claude 3.7 Sonnet",
    "model_name": "Claude 3.7 Sonnet",
    "aliases": [
      "Claude 3.7 Sonnet",
      "claude-3.7-sonnet-20250219"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 44277,
    "license_type": "Proprietary",
    "creator": "Anthropic",
    "intelligence_score": 35.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1371.4,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 6.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.777735+00:00",
        "confidence": 0.65,
        "raw_name": "Claude 3.7 Sonnet",
        "raw_scores": {
          "intelligence_score": 35.0,
          "blended_cost_per_1m": 6.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 200000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225037+00:00",
        "confidence": 1.0,
        "raw_name": "claude-3.7-sonnet-20250219",
        "raw_scores": {
          "arena_elo": 1371.4,
          "arena_votes": 44277
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 35.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1371.4
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemini-25-pro",
    "canonical_name": "Gemini 2.5 Pro",
    "model_name": "Gemini 2.5 Pro",
    "aliases": [
      "Gemini 2.5 Pro",
      "Gemini 2.5 Pro (Mar)",
      "Gemini 2.5 Pro (May)",
      "gemini-2.5-pro"
    ],
    "provider": "Google",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": 96876,
    "license_type": "Proprietary",
    "creator": "Google",
    "intelligence_score": 31.3333,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1449.29,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 2.2933,
    "latency_seconds": 11.6467,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 51.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.777771+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 2.5 Pro",
        "raw_scores": {
          "intelligence_score": 34.0,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 34.94,
          "tokens_per_second": 153.0,
          "context_window": 1000000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778453+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 2.5 Pro (Mar)",
        "raw_scores": {
          "intelligence_score": 30.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778541+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 2.5 Pro (May)",
        "raw_scores": {
          "intelligence_score": 30.0,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.223793+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-2.5-pro",
        "raw_scores": {
          "arena_elo": 1449.29,
          "arena_votes": 96876
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 34.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1449.29
      }
    },
    "confidence_score": 0.7375,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-v32-speciale",
    "canonical_name": "DeepSeek V3.2 Speciale",
    "model_name": "DeepSeek V3.2 Speciale",
    "aliases": [
      "DeepSeek V3.2 Exp",
      "DeepSeek V3.2 Speciale",
      "deepseek-v3.2-exp",
      "deepseek-v3.2-exp-thinking"
    ],
    "provider": "DeepSeek",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 11685,
    "license_type": "MIT",
    "creator": "DeepSeek",
    "intelligence_score": 33.5,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1423.46,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.16,
    "latency_seconds": 0.61,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 24.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.777849+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek V3.2 Speciale",
        "raw_scores": {
          "intelligence_score": 34.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778134+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek V3.2 Exp",
        "raw_scores": {
          "intelligence_score": 33.0,
          "blended_cost_per_1m": 0.32,
          "latency_seconds": 1.22,
          "tokens_per_second": 48.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224078+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-v3.2-exp",
        "raw_scores": {
          "arena_elo": 1423.62,
          "arena_votes": 11685
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224091+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-v3.2-exp-thinking",
        "raw_scores": {
          "arena_elo": 1423.3,
          "arena_votes": 8944
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 34.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1423.62
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-v31",
    "canonical_name": "DeepSeek V3.1 Terminus",
    "model_name": "DeepSeek V3.1 Terminus",
    "aliases": [
      "DeepSeek V3.1",
      "DeepSeek V3.1 Terminus",
      "deepseek-v3.1",
      "deepseek-v3.1-terminus",
      "deepseek-v3.1-terminus-thinking",
      "deepseek-v3.1-thinking"
    ],
    "provider": "DeepSeek",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 15198,
    "license_type": "MIT",
    "creator": "DeepSeek",
    "intelligence_score": 31.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1416.8425,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.82,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.777891+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek V3.1 Terminus",
        "raw_scores": {
          "intelligence_score": 34.0,
          "blended_cost_per_1m": 0.8,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778686+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek V3.1",
        "raw_scores": {
          "intelligence_score": 28.0,
          "blended_cost_per_1m": 0.84,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224179+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-v3.1",
        "raw_scores": {
          "arena_elo": 1418.28,
          "arena_votes": 15198
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224204+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-v3.1-thinking",
        "raw_scores": {
          "arena_elo": 1417.27,
          "arena_votes": 11919
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224228+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-v3.1-terminus",
        "raw_scores": {
          "arena_elo": 1416.06,
          "arena_votes": 3746
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224241+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-v3.1-terminus-thinking",
        "raw_scores": {
          "arena_elo": 1415.76,
          "arena_votes": 3538
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 34.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1418.28
      }
    },
    "confidence_score": 0.8833,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "doubao-seed-code",
    "canonical_name": "Doubao Seed Code",
    "model_name": "Doubao Seed Code",
    "aliases": [
      "Doubao Seed Code"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "ByteDance Seed",
    "intelligence_score": 34.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.777973+00:00",
        "confidence": 0.65,
        "raw_name": "Doubao Seed Code",
        "raw_scores": {
          "intelligence_score": 34.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 34.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gpt-oss-120b",
    "canonical_name": "gpt-oss-120B (high)",
    "model_name": "gpt-oss-120B (high)",
    "aliases": [
      "gpt-oss-120B (high)",
      "gpt-oss-120B (low)",
      "gpt-oss-120b"
    ],
    "provider": "OpenAI",
    "context_window": 131000,
    "open_source": null,
    "arena_votes": 30767,
    "license_type": "Apache 2.0",
    "creator": "OpenAI",
    "intelligence_score": 28.5,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1354.0,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.26,
    "latency_seconds": 0.455,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 305.5,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778016+00:00",
        "confidence": 0.65,
        "raw_name": "gpt-oss-120B (high)",
        "raw_scores": {
          "intelligence_score": 33.0,
          "blended_cost_per_1m": 0.26,
          "latency_seconds": 0.48,
          "tokens_per_second": 314.0,
          "context_window": 131000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779297+00:00",
        "confidence": 0.65,
        "raw_name": "gpt-oss-120B (low)",
        "raw_scores": {
          "intelligence_score": 24.0,
          "blended_cost_per_1m": 0.26,
          "latency_seconds": 0.43,
          "tokens_per_second": 297.0,
          "context_window": 131000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225199+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-oss-120b",
        "raw_scores": {
          "arena_elo": 1354.0,
          "arena_votes": 30767
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 33.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1354.0
      }
    },
    "confidence_score": 0.7667,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "o4-mini",
    "canonical_name": "o4-mini (high)",
    "model_name": "o4-mini (high)",
    "aliases": [
      "o4-mini (high)",
      "o4-mini-2025-04-16"
    ],
    "provider": "OpenAI",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 46384,
    "license_type": "Proprietary",
    "creator": "OpenAI",
    "intelligence_score": 33.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1391.06,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.93,
    "latency_seconds": 60.35,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 116.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778057+00:00",
        "confidence": 0.65,
        "raw_name": "o4-mini (high)",
        "raw_scores": {
          "intelligence_score": 33.0,
          "blended_cost_per_1m": 1.93,
          "latency_seconds": 60.35,
          "tokens_per_second": 116.0,
          "context_window": 200000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224616+00:00",
        "confidence": 1.0,
        "raw_name": "o4-mini-2025-04-16",
        "raw_scores": {
          "arena_elo": 1391.06,
          "arena_votes": 46384
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 33.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1391.06
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "mercury-2",
    "canonical_name": "Mercury 2",
    "model_name": "Mercury 2",
    "aliases": [
      "Mercury 2"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Inception",
    "intelligence_score": 33.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.38,
    "latency_seconds": 12.74,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 1196.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778173+00:00",
        "confidence": 0.65,
        "raw_name": "Mercury 2",
        "raw_scores": {
          "intelligence_score": 33.0,
          "blended_cost_per_1m": 0.38,
          "latency_seconds": 12.74,
          "tokens_per_second": 1196.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 33.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "glm-46",
    "canonical_name": "GLM-4.6",
    "model_name": "GLM-4.6",
    "aliases": [
      "GLM-4.6",
      "glm-4.6"
    ],
    "provider": "Z.ai",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 35129,
    "license_type": "MIT",
    "creator": "Z AI",
    "intelligence_score": 33.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1425.04,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.98,
    "latency_seconds": 0.58,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 97.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778196+00:00",
        "confidence": 0.65,
        "raw_name": "GLM-4.6",
        "raw_scores": {
          "intelligence_score": 33.0,
          "blended_cost_per_1m": 0.98,
          "latency_seconds": 0.58,
          "tokens_per_second": 97.0,
          "context_window": 200000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224039+00:00",
        "confidence": 1.0,
        "raw_name": "glm-4.6",
        "raw_scores": {
          "arena_elo": 1425.04,
          "arena_votes": 35129
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 33.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1425.04
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "k-exaone",
    "canonical_name": "K-EXAONE",
    "model_name": "K-EXAONE",
    "aliases": [
      "K-EXAONE"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "LG AI Research",
    "intelligence_score": 32.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778233+00:00",
        "confidence": 0.65,
        "raw_name": "K-EXAONE",
        "raw_scores": {
          "intelligence_score": 32.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 32.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "grok-3-mini",
    "canonical_name": "Grok 3 mini Reasoning (high)",
    "model_name": "Grok 3 mini Reasoning (high)",
    "aliases": [
      "Grok 3 mini Reasoning (high)",
      "grok-3-mini-high"
    ],
    "provider": "xAI",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": 17418,
    "license_type": "Proprietary",
    "creator": "xAI",
    "intelligence_score": 32.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1362.85,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.35,
    "latency_seconds": 0.71,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 177.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778271+00:00",
        "confidence": 0.65,
        "raw_name": "Grok 3 mini Reasoning (high)",
        "raw_scores": {
          "intelligence_score": 32.0,
          "blended_cost_per_1m": 0.35,
          "latency_seconds": 0.71,
          "tokens_per_second": 177.0,
          "context_window": 1000000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225124+00:00",
        "confidence": 1.0,
        "raw_name": "grok-3-mini-high",
        "raw_scores": {
          "arena_elo": 1362.85,
          "arena_votes": 17418
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 32.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1362.85
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "claude-opus-41",
    "canonical_name": "Claude 4.1 Opus",
    "model_name": "Claude 4.1 Opus",
    "aliases": [
      "Claude 4.1 Opus",
      "claude-opus-4.1-20250805",
      "claude-opus-4.1-20250805-thinking-16k"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 77242,
    "license_type": "Proprietary",
    "creator": "Anthropic",
    "intelligence_score": 32.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1447.475,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 30.0,
    "latency_seconds": 1.29,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 47.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778289+00:00",
        "confidence": 0.65,
        "raw_name": "Claude 4.1 Opus",
        "raw_scores": {
          "intelligence_score": 32.0,
          "blended_cost_per_1m": 30.0,
          "latency_seconds": 1.29,
          "tokens_per_second": 47.0,
          "context_window": 200000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.223821+00:00",
        "confidence": 1.0,
        "raw_name": "claude-opus-4.1-20250805-thinking-16k",
        "raw_scores": {
          "arena_elo": 1448.72,
          "arena_votes": 49618
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.223836+00:00",
        "confidence": 1.0,
        "raw_name": "claude-opus-4.1-20250805",
        "raw_scores": {
          "arena_elo": 1446.23,
          "arena_votes": 77242
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 32.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1448.72
      }
    },
    "confidence_score": 0.8833,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemini-25-flash",
    "canonical_name": "Gemini 2.5 Flash (Sep)",
    "model_name": "Gemini 2.5 Flash (Sep)",
    "aliases": [
      "Gemini 2.5 Flash",
      "Gemini 2.5 Flash (Sep)",
      "gemini-2.5-flash",
      "gemini-2.5-flash-preview-09-2025"
    ],
    "provider": "Google",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": 96163,
    "license_type": "Proprietary",
    "creator": "Google",
    "intelligence_score": 29.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1407.625,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.85,
    "latency_seconds": 8.115,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 144.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778344+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 2.5 Flash (Sep)",
        "raw_scores": {
          "intelligence_score": 31.0,
          "blended_cost_per_1m": 0.85,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778856+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 2.5 Flash",
        "raw_scores": {
          "intelligence_score": 27.0,
          "blended_cost_per_1m": 0.85,
          "latency_seconds": 16.23,
          "tokens_per_second": 288.0,
          "context_window": 1000000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224340+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-2.5-flash",
        "raw_scores": {
          "arena_elo": 1410.93,
          "arena_votes": 96163
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224398+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-2.5-flash-preview-09-2025",
        "raw_scores": {
          "arena_elo": 1404.32,
          "arena_votes": 32547
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 31.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1410.93
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "kimi-k2-0905",
    "canonical_name": "Kimi K2 0905",
    "model_name": "Kimi K2 0905",
    "aliases": [
      "Kimi K2 0905"
    ],
    "provider": "Moonshot",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Kimi",
    "intelligence_score": 31.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.2,
    "latency_seconds": 0.5,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 64.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778380+00:00",
        "confidence": 0.65,
        "raw_name": "Kimi K2 0905",
        "raw_scores": {
          "intelligence_score": 31.0,
          "blended_cost_per_1m": 1.2,
          "latency_seconds": 0.5,
          "tokens_per_second": 64.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 31.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "o1",
    "canonical_name": "o1",
    "model_name": "o1",
    "aliases": [
      "o1",
      "o1-2024-12-17"
    ],
    "provider": "OpenAI",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 27822,
    "license_type": "Proprietary",
    "creator": "OpenAI",
    "intelligence_score": 31.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1402.0,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 26.25,
    "latency_seconds": 18.88,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 137.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778417+00:00",
        "confidence": 0.65,
        "raw_name": "o1",
        "raw_scores": {
          "intelligence_score": 31.0,
          "blended_cost_per_1m": 26.25,
          "latency_seconds": 18.88,
          "tokens_per_second": 137.0,
          "context_window": 200000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224424+00:00",
        "confidence": 1.0,
        "raw_name": "o1-2024-12-17",
        "raw_scores": {
          "arena_elo": 1402.0,
          "arena_votes": 27822
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 31.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1402.0
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "glm-47-flash",
    "canonical_name": "GLM-4.7-Flash",
    "model_name": "GLM-4.7-Flash",
    "aliases": [
      "GLM-4.7-Flash",
      "glm-4.7-flash"
    ],
    "provider": "Z.ai",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 10247,
    "license_type": "MIT",
    "creator": "Z AI",
    "intelligence_score": 30.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1364.25,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.15,
    "latency_seconds": 0.71,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 55.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778489+00:00",
        "confidence": 0.65,
        "raw_name": "GLM-4.7-Flash",
        "raw_scores": {
          "intelligence_score": 30.0,
          "blended_cost_per_1m": 0.15,
          "latency_seconds": 0.71,
          "tokens_per_second": 55.0,
          "context_window": 200000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225100+00:00",
        "confidence": 1.0,
        "raw_name": "glm-4.7-flash",
        "raw_scores": {
          "arena_elo": 1364.25,
          "arena_votes": 10247
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 30.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1364.25
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "nova-20-lite",
    "canonical_name": "Nova 2.0 Lite (medium)",
    "model_name": "Nova 2.0 Lite (medium)",
    "aliases": [
      "Nova 2.0 Lite",
      "Nova 2.0 Lite (low)",
      "Nova 2.0 Lite (medium)"
    ],
    "provider": "Amazon",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Amazon",
    "intelligence_score": 24.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.85,
    "latency_seconds": 6.9367,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 216.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778508+00:00",
        "confidence": 0.65,
        "raw_name": "Nova 2.0 Lite (medium)",
        "raw_scores": {
          "intelligence_score": 30.0,
          "blended_cost_per_1m": 0.85,
          "latency_seconds": 15.27,
          "tokens_per_second": 239.0,
          "context_window": 1000000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779278+00:00",
        "confidence": 0.65,
        "raw_name": "Nova 2.0 Lite (low)",
        "raw_scores": {
          "intelligence_score": 24.0,
          "blended_cost_per_1m": 0.85,
          "latency_seconds": 5.01,
          "tokens_per_second": 225.0,
          "context_window": 1000000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780513+00:00",
        "confidence": 0.65,
        "raw_name": "Nova 2.0 Lite",
        "raw_scores": {
          "intelligence_score": 18.0,
          "blended_cost_per_1m": 0.85,
          "latency_seconds": 0.53,
          "tokens_per_second": 184.0,
          "context_window": 1000000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 30.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-235b-a22b-2507",
    "canonical_name": "Qwen3 235B A22B 2507",
    "model_name": "Qwen3 235B A22B 2507",
    "aliases": [
      "Qwen3 235B A22B 2507"
    ],
    "provider": "Alibaba",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 29.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 2.63,
    "latency_seconds": 1.38,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 39.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778561+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 235B A22B 2507",
        "raw_scores": {
          "intelligence_score": 29.0,
          "blended_cost_per_1m": 2.63,
          "latency_seconds": 1.38,
          "tokens_per_second": 39.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 29.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "ernie-50-thinking-preview",
    "canonical_name": "ERNIE 5.0 Thinking Preview",
    "model_name": "ERNIE 5.0 Thinking Preview",
    "aliases": [
      "ERNIE 5.0 Thinking Preview"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Baidu",
    "intelligence_score": 29.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778579+00:00",
        "confidence": 0.65,
        "raw_name": "ERNIE 5.0 Thinking Preview",
        "raw_scores": {
          "intelligence_score": 29.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 29.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "grok-code-fast-1",
    "canonical_name": "Grok Code Fast 1",
    "model_name": "Grok Code Fast 1",
    "aliases": [
      "Grok Code Fast 1"
    ],
    "provider": "xAI",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "xAI",
    "intelligence_score": 29.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.53,
    "latency_seconds": 7.02,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 264.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778597+00:00",
        "confidence": 0.65,
        "raw_name": "Grok Code Fast 1",
        "raw_scores": {
          "intelligence_score": 29.0,
          "blended_cost_per_1m": 0.53,
          "latency_seconds": 7.02,
          "tokens_per_second": 264.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 29.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "apriel-v15-15b-thinker",
    "canonical_name": "Apriel-v1.5-15B-Thinker",
    "model_name": "Apriel-v1.5-15B-Thinker",
    "aliases": [
      "Apriel-v1.5-15B-Thinker"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "ServiceNow",
    "intelligence_score": 28.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.18,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 144.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778633+00:00",
        "confidence": 0.65,
        "raw_name": "Apriel-v1.5-15B-Thinker",
        "raw_scores": {
          "intelligence_score": 28.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.18,
          "tokens_per_second": 144.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 28.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-coder-next",
    "canonical_name": "Qwen3 Coder Next",
    "model_name": "Qwen3 Coder Next",
    "aliases": [
      "Qwen3 Coder Next"
    ],
    "provider": "Alibaba",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 28.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.53,
    "latency_seconds": 0.82,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 113.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778668+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 Coder Next",
        "raw_scores": {
          "intelligence_score": 28.0,
          "blended_cost_per_1m": 0.53,
          "latency_seconds": 0.82,
          "tokens_per_second": 113.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 28.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "nova-20-omni",
    "canonical_name": "Nova 2.0 Omni (medium)",
    "model_name": "Nova 2.0 Omni (medium)",
    "aliases": [
      "Nova 2.0 Omni",
      "Nova 2.0 Omni (low)",
      "Nova 2.0 Omni (medium)"
    ],
    "provider": "Amazon",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Amazon",
    "intelligence_score": 22.6667,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.85,
    "latency_seconds": 0.2233,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 69.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778707+00:00",
        "confidence": 0.65,
        "raw_name": "Nova 2.0 Omni (medium)",
        "raw_scores": {
          "intelligence_score": 28.0,
          "blended_cost_per_1m": 0.85,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779425+00:00",
        "confidence": 0.65,
        "raw_name": "Nova 2.0 Omni (low)",
        "raw_scores": {
          "intelligence_score": 23.0,
          "blended_cost_per_1m": 0.85,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780785+00:00",
        "confidence": 0.65,
        "raw_name": "Nova 2.0 Omni",
        "raw_scores": {
          "intelligence_score": 17.0,
          "blended_cost_per_1m": 0.85,
          "latency_seconds": 0.67,
          "tokens_per_second": 207.0,
          "context_window": 1000000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 28.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "apriel-v16-15b-thinker",
    "canonical_name": "Apriel-v1.6-15B-Thinker",
    "model_name": "Apriel-v1.6-15B-Thinker",
    "aliases": [
      "Apriel-v1.6-15B-Thinker"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "ServiceNow",
    "intelligence_score": 28.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.25,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 144.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778744+00:00",
        "confidence": 0.65,
        "raw_name": "Apriel-v1.6-15B-Thinker",
        "raw_scores": {
          "intelligence_score": 28.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.25,
          "tokens_per_second": 144.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 28.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-vl-235b-a22b",
    "canonical_name": "Qwen3 VL 235B A22B",
    "model_name": "Qwen3 VL 235B A22B",
    "aliases": [
      "Qwen3 VL 235B A22B"
    ],
    "provider": "Alibaba",
    "context_window": 262000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 28.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 2.63,
    "latency_seconds": 1.09,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 47.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778762+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 VL 235B A22B",
        "raw_scores": {
          "intelligence_score": 28.0,
          "blended_cost_per_1m": 2.63,
          "latency_seconds": 1.09,
          "tokens_per_second": 47.0,
          "context_window": 262000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 28.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "claude-opus-4",
    "canonical_name": "Claude 4 Opus",
    "model_name": "Claude 4 Opus",
    "aliases": [
      "Claude 4 Opus",
      "claude-opus-4-20250514",
      "claude-opus-4-20250514-thinking-16k"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 45310,
    "license_type": "Proprietary",
    "creator": "Anthropic",
    "intelligence_score": 27.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1418.445,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 30.0,
    "latency_seconds": 1.36,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 47.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778800+00:00",
        "confidence": 0.65,
        "raw_name": "Claude 4 Opus",
        "raw_scores": {
          "intelligence_score": 27.0,
          "blended_cost_per_1m": 30.0,
          "latency_seconds": 1.36,
          "tokens_per_second": 47.0,
          "context_window": 200000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224065+00:00",
        "confidence": 1.0,
        "raw_name": "claude-opus-4-20250514-thinking-16k",
        "raw_scores": {
          "arena_elo": 1423.83,
          "arena_votes": 37728
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224303+00:00",
        "confidence": 1.0,
        "raw_name": "claude-opus-4-20250514",
        "raw_scores": {
          "arena_elo": 1413.06,
          "arena_votes": 45310
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 27.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1423.83
      }
    },
    "confidence_score": 0.8833,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "magistral-medium-12",
    "canonical_name": "Magistral Medium 1.2",
    "model_name": "Magistral Medium 1.2",
    "aliases": [
      "Magistral Medium 1.2"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 27.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 2.75,
    "latency_seconds": 0.49,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 41.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778819+00:00",
        "confidence": 0.65,
        "raw_name": "Magistral Medium 1.2",
        "raw_scores": {
          "intelligence_score": 27.0,
          "blended_cost_per_1m": 2.75,
          "latency_seconds": 0.49,
          "tokens_per_second": 41.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 27.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-r1",
    "canonical_name": "DeepSeek R1 0528",
    "model_name": "DeepSeek R1 0528",
    "aliases": [
      "DeepSeek R1 (Jan)",
      "DeepSeek R1 0528",
      "deepseek-r1",
      "deepseek-r1-0528"
    ],
    "provider": "DeepSeek",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 19178,
    "license_type": "MIT",
    "creator": "DeepSeek",
    "intelligence_score": 23.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1408.415,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 2.36,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778838+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek R1 0528",
        "raw_scores": {
          "intelligence_score": 27.0,
          "blended_cost_per_1m": 2.36,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780207+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek R1 (Jan)",
        "raw_scores": {
          "intelligence_score": 19.0,
          "blended_cost_per_1m": 2.36,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224154+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-r1-0528",
        "raw_scores": {
          "arena_elo": 1419.15,
          "arena_votes": 19178
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224510+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-r1",
        "raw_scores": {
          "arena_elo": 1397.68,
          "arena_votes": 18537
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 27.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1419.15
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gpt-5-nano",
    "canonical_name": "GPT-5 nano (high)",
    "model_name": "GPT-5 nano (high)",
    "aliases": [
      "GPT-5 nano (high)",
      "GPT-5 nano (medium)",
      "GPT-5 nano (minimal)",
      "gpt-5-nano-high"
    ],
    "provider": "OpenAI",
    "context_window": 400000,
    "open_source": null,
    "arena_votes": 8355,
    "license_type": "Proprietary",
    "creator": "OpenAI",
    "intelligence_score": 22.3333,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1338.02,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.14,
    "latency_seconds": 61.3633,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 123.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778875+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5 nano (high)",
        "raw_scores": {
          "intelligence_score": 27.0,
          "blended_cost_per_1m": 0.14,
          "latency_seconds": 136.94,
          "tokens_per_second": 124.0,
          "context_window": 400000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779003+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5 nano (medium)",
        "raw_scores": {
          "intelligence_score": 26.0,
          "blended_cost_per_1m": 0.14,
          "latency_seconds": 46.58,
          "tokens_per_second": 132.0,
          "context_window": 400000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781849+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-5 nano (minimal)",
        "raw_scores": {
          "intelligence_score": 14.0,
          "blended_cost_per_1m": 0.14,
          "latency_seconds": 0.57,
          "tokens_per_second": 113.0,
          "context_window": 400000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225460+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-5-nano-high",
        "raw_scores": {
          "arena_elo": 1338.02,
          "arena_votes": 8355
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 27.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1338.02
      }
    },
    "confidence_score": 0.7375,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-next-80b-a3b",
    "canonical_name": "Qwen3 Next 80B A3B",
    "model_name": "Qwen3 Next 80B A3B",
    "aliases": [
      "Qwen3 Next 80B A3B"
    ],
    "provider": "Alibaba",
    "context_window": 262000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 26.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.88,
    "latency_seconds": 1.06,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 131.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778893+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 Next 80B A3B",
        "raw_scores": {
          "intelligence_score": 26.0,
          "blended_cost_per_1m": 1.88,
          "latency_seconds": 1.06,
          "tokens_per_second": 131.0,
          "context_window": 262000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 26.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "glm-45",
    "canonical_name": "GLM-4.5",
    "model_name": "GLM-4.5",
    "aliases": [
      "GLM-4.5",
      "glm-4.5"
    ],
    "provider": "Z.ai",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 24608,
    "license_type": "MIT",
    "creator": "Z AI",
    "intelligence_score": 26.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1410.05,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.84,
    "latency_seconds": 0.9,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 40.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778912+00:00",
        "confidence": 0.65,
        "raw_name": "GLM-4.5",
        "raw_scores": {
          "intelligence_score": 26.0,
          "blended_cost_per_1m": 0.84,
          "latency_seconds": 0.9,
          "tokens_per_second": 40.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224353+00:00",
        "confidence": 1.0,
        "raw_name": "glm-4.5",
        "raw_scores": {
          "arena_elo": 1410.05,
          "arena_votes": 24608
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 26.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1410.05
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "kimi-k2",
    "canonical_name": "Kimi K2",
    "model_name": "Kimi K2",
    "aliases": [
      "Kimi K2",
      "kimi-k2-0711-preview",
      "kimi-k2-0905-preview"
    ],
    "provider": "Moonshot",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 28445,
    "license_type": "Modified MIT",
    "creator": "Kimi",
    "intelligence_score": 26.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1417.09,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.07,
    "latency_seconds": 0.58,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 41.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778930+00:00",
        "confidence": 0.65,
        "raw_name": "Kimi K2",
        "raw_scores": {
          "intelligence_score": 26.0,
          "blended_cost_per_1m": 1.07,
          "latency_seconds": 0.58,
          "tokens_per_second": 41.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224191+00:00",
        "confidence": 1.0,
        "raw_name": "kimi-k2-0905-preview",
        "raw_scores": {
          "arena_elo": 1417.29,
          "arena_votes": 11915
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224216+00:00",
        "confidence": 1.0,
        "raw_name": "kimi-k2-0711-preview",
        "raw_scores": {
          "arena_elo": 1416.89,
          "arena_votes": 28445
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 26.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1417.29
      }
    },
    "confidence_score": 0.8833,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "o3-mini",
    "canonical_name": "o3-mini (high)",
    "model_name": "o3-mini (high)",
    "aliases": [
      "o3-mini",
      "o3-mini (high)"
    ],
    "provider": "OpenAI",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 58461,
    "license_type": "Proprietary",
    "creator": "OpenAI",
    "intelligence_score": 25.5,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1348.21,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.93,
    "latency_seconds": 29.87,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 125.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778967+00:00",
        "confidence": 0.65,
        "raw_name": "o3-mini",
        "raw_scores": {
          "intelligence_score": 26.0,
          "blended_cost_per_1m": 1.93,
          "latency_seconds": 15.14,
          "tokens_per_second": 111.0,
          "context_window": 200000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779059+00:00",
        "confidence": 0.65,
        "raw_name": "o3-mini (high)",
        "raw_scores": {
          "intelligence_score": 25.0,
          "blended_cost_per_1m": 1.93,
          "latency_seconds": 44.6,
          "tokens_per_second": 139.0,
          "context_window": 200000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225284+00:00",
        "confidence": 1.0,
        "raw_name": "o3-mini",
        "raw_scores": {
          "arena_elo": 1348.21,
          "arena_votes": 58461
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 26.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1348.21
      }
    },
    "confidence_score": 0.7667,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "o1-pro",
    "canonical_name": "o1-pro",
    "model_name": "o1-pro",
    "aliases": [
      "o1-pro"
    ],
    "provider": "OpenAI",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "OpenAI",
    "intelligence_score": 26.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 262.5,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.778985+00:00",
        "confidence": 0.65,
        "raw_name": "o1-pro",
        "raw_scores": {
          "intelligence_score": 26.0,
          "blended_cost_per_1m": 262.5,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 200000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 26.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gpt-41",
    "canonical_name": "GPT-4.1",
    "model_name": "GPT-4.1",
    "aliases": [
      "GPT-4.1",
      "gpt-4.1-2025-04-14"
    ],
    "provider": "OpenAI",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": 51856,
    "license_type": "Proprietary",
    "creator": "OpenAI",
    "intelligence_score": 26.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1413.44,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.5,
    "latency_seconds": 0.52,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 86.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779023+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-4.1",
        "raw_scores": {
          "intelligence_score": 26.0,
          "blended_cost_per_1m": 3.5,
          "latency_seconds": 0.52,
          "tokens_per_second": 86.0,
          "context_window": 1000000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224290+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-4.1-2025-04-14",
        "raw_scores": {
          "arena_elo": 1413.44,
          "arena_votes": 51856
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 26.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1413.44
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "grok-3",
    "canonical_name": "Grok 3",
    "model_name": "Grok 3",
    "aliases": [
      "Grok 3",
      "grok-3-preview-02-24"
    ],
    "provider": "xAI",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": 33845,
    "license_type": "Proprietary",
    "creator": "xAI",
    "intelligence_score": 25.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1411.33,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 6.0,
    "latency_seconds": 0.75,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 71.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779077+00:00",
        "confidence": 0.65,
        "raw_name": "Grok 3",
        "raw_scores": {
          "intelligence_score": 25.0,
          "blended_cost_per_1m": 6.0,
          "latency_seconds": 0.75,
          "tokens_per_second": 71.0,
          "context_window": 1000000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224315+00:00",
        "confidence": 1.0,
        "raw_name": "grok-3-preview-02-24",
        "raw_scores": {
          "arena_elo": 1411.33,
          "arena_votes": 33845
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 25.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1411.33
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "seed-oss-36b-instruct",
    "canonical_name": "Seed-OSS-36B-Instruct",
    "model_name": "Seed-OSS-36B-Instruct",
    "aliases": [
      "Seed-OSS-36B-Instruct"
    ],
    "provider": null,
    "context_window": 512000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "ByteDance Seed",
    "intelligence_score": 25.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.3,
    "latency_seconds": 1.6,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 32.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779096+00:00",
        "confidence": 0.65,
        "raw_name": "Seed-OSS-36B-Instruct",
        "raw_scores": {
          "intelligence_score": 25.0,
          "blended_cost_per_1m": 0.3,
          "latency_seconds": 1.6,
          "tokens_per_second": 32.0,
          "context_window": 512000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 25.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-235b-2507",
    "canonical_name": "Qwen3 235B 2507",
    "model_name": "Qwen3 235B 2507",
    "aliases": [
      "Qwen3 235B 2507"
    ],
    "provider": "Alibaba",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 25.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.23,
    "latency_seconds": 1.06,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 47.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779114+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 235B 2507",
        "raw_scores": {
          "intelligence_score": 25.0,
          "blended_cost_per_1m": 1.23,
          "latency_seconds": 1.06,
          "tokens_per_second": 47.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 25.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-coder-480b",
    "canonical_name": "Qwen3 Coder 480B",
    "model_name": "Qwen3 Coder 480B",
    "aliases": [
      "Qwen3 Coder 480B"
    ],
    "provider": "Alibaba",
    "context_window": 262000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 25.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.0,
    "latency_seconds": 1.58,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 41.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779132+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 Coder 480B",
        "raw_scores": {
          "intelligence_score": 25.0,
          "blended_cost_per_1m": 3.0,
          "latency_seconds": 1.58,
          "tokens_per_second": 41.0,
          "context_window": 262000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 25.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "sonar-reasoning-pro",
    "canonical_name": "Sonar Reasoning Pro",
    "model_name": "Sonar Reasoning Pro",
    "aliases": [
      "Sonar Reasoning Pro"
    ],
    "provider": null,
    "context_window": 127000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Perplexity",
    "intelligence_score": 25.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779150+00:00",
        "confidence": 0.65,
        "raw_name": "Sonar Reasoning Pro",
        "raw_scores": {
          "intelligence_score": 25.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 127000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 25.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "k2-think-v2",
    "canonical_name": "K2 Think V2",
    "model_name": "K2 Think V2",
    "aliases": [
      "K2 Think V2"
    ],
    "provider": null,
    "context_window": 262000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "MBZUAI Institute of Foundation Models",
    "intelligence_score": 25.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779168+00:00",
        "confidence": 0.65,
        "raw_name": "K2 Think V2",
        "raw_scores": {
          "intelligence_score": 25.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 262000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 25.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-vl-32b",
    "canonical_name": "Qwen3 VL 32B",
    "model_name": "Qwen3 VL 32B",
    "aliases": [
      "Qwen3 VL 32B"
    ],
    "provider": "Alibaba",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 25.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 2.63,
    "latency_seconds": 1.22,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 84.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779186+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 VL 32B",
        "raw_scores": {
          "intelligence_score": 25.0,
          "blended_cost_per_1m": 2.63,
          "latency_seconds": 1.22,
          "tokens_per_second": 84.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 25.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gpt-oss-20b",
    "canonical_name": "gpt-oss-20B (high)",
    "model_name": "gpt-oss-20B (high)",
    "aliases": [
      "gpt-oss-20B (high)",
      "gpt-oss-20B (low)",
      "gpt-oss-20b"
    ],
    "provider": "OpenAI",
    "context_window": 131000,
    "open_source": null,
    "arena_votes": 10760,
    "license_type": "Apache 2.0",
    "creator": "OpenAI",
    "intelligence_score": 22.5,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1317.09,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.105,
    "latency_seconds": 0.505,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 305.5,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779205+00:00",
        "confidence": 0.65,
        "raw_name": "gpt-oss-20B (high)",
        "raw_scores": {
          "intelligence_score": 24.0,
          "blended_cost_per_1m": 0.11,
          "latency_seconds": 0.48,
          "tokens_per_second": 305.0,
          "context_window": 131000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779825+00:00",
        "confidence": 0.65,
        "raw_name": "gpt-oss-20B (low)",
        "raw_scores": {
          "intelligence_score": 21.0,
          "blended_cost_per_1m": 0.1,
          "latency_seconds": 0.53,
          "tokens_per_second": 306.0,
          "context_window": 131000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225876+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-oss-20b",
        "raw_scores": {
          "arena_elo": 1317.09,
          "arena_votes": 10760
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 24.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1317.09
      }
    },
    "confidence_score": 0.7667,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "nvidia-nemotron-3-nano",
    "canonical_name": "NVIDIA Nemotron 3 Nano",
    "model_name": "NVIDIA Nemotron 3 Nano",
    "aliases": [
      "NVIDIA Nemotron 3 Nano"
    ],
    "provider": null,
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "NVIDIA",
    "intelligence_score": 24.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.1,
    "latency_seconds": 0.46,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 135.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779241+00:00",
        "confidence": 0.65,
        "raw_name": "NVIDIA Nemotron 3 Nano",
        "raw_scores": {
          "intelligence_score": 24.0,
          "blended_cost_per_1m": 0.1,
          "latency_seconds": 0.46,
          "tokens_per_second": 135.0,
          "context_window": 1000000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 24.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "minimax-m1-80k",
    "canonical_name": "MiniMax M1 80k",
    "model_name": "MiniMax M1 80k",
    "aliases": [
      "MiniMax M1 80k"
    ],
    "provider": "MiniMax",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "MiniMax",
    "intelligence_score": 24.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.96,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779260+00:00",
        "confidence": 0.65,
        "raw_name": "MiniMax M1 80k",
        "raw_scores": {
          "intelligence_score": 24.0,
          "blended_cost_per_1m": 0.96,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 24.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "o1-preview",
    "canonical_name": "o1-preview",
    "model_name": "o1-preview",
    "aliases": [
      "o1-preview"
    ],
    "provider": "OpenAI",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 31120,
    "license_type": "Proprietary",
    "creator": "OpenAI",
    "intelligence_score": 24.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1388.22,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 28.88,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779315+00:00",
        "confidence": 0.65,
        "raw_name": "o1-preview",
        "raw_scores": {
          "intelligence_score": 24.0,
          "blended_cost_per_1m": 28.88,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224711+00:00",
        "confidence": 1.0,
        "raw_name": "o1-preview",
        "raw_scores": {
          "arena_elo": 1388.22,
          "arena_votes": 31120
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 24.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1388.22
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "hyperclova-x-seed-think",
    "canonical_name": "HyperCLOVA X SEED Think (32B)",
    "model_name": "HyperCLOVA X SEED Think (32B)",
    "aliases": [
      "HyperCLOVA X SEED Think (32B)"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Naver",
    "intelligence_score": 24.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779351+00:00",
        "confidence": 0.65,
        "raw_name": "HyperCLOVA X SEED Think (32B)",
        "raw_scores": {
          "intelligence_score": 24.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 24.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "glm-46v",
    "canonical_name": "GLM-4.6V",
    "model_name": "GLM-4.6V",
    "aliases": [
      "GLM-4.6V",
      "glm-4.6v"
    ],
    "provider": "Z.ai",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 2785,
    "license_type": "MIT",
    "creator": "Z AI",
    "intelligence_score": 23.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1377.82,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.45,
    "latency_seconds": 0.59,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 67.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779408+00:00",
        "confidence": 0.65,
        "raw_name": "GLM-4.6V",
        "raw_scores": {
          "intelligence_score": 23.0,
          "blended_cost_per_1m": 0.45,
          "latency_seconds": 0.59,
          "tokens_per_second": 67.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224842+00:00",
        "confidence": 1.0,
        "raw_name": "glm-4.6v",
        "raw_scores": {
          "arena_elo": 1377.82,
          "arena_votes": 2785
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 23.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1377.82
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "glm-45-air",
    "canonical_name": "GLM-4.5-Air",
    "model_name": "GLM-4.5-Air",
    "aliases": [
      "GLM-4.5-Air",
      "glm-4.5-air"
    ],
    "provider": "Z.ai",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 31168,
    "license_type": "MIT",
    "creator": "Z AI",
    "intelligence_score": 23.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1371.71,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.42,
    "latency_seconds": 0.58,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 127.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779443+00:00",
        "confidence": 0.65,
        "raw_name": "GLM-4.5-Air",
        "raw_scores": {
          "intelligence_score": 23.0,
          "blended_cost_per_1m": 0.42,
          "latency_seconds": 0.58,
          "tokens_per_second": 127.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225019+00:00",
        "confidence": 1.0,
        "raw_name": "glm-4.5-air",
        "raw_scores": {
          "arena_elo": 1371.71,
          "arena_votes": 31168
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 23.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1371.71
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "midm-k-25-pro",
    "canonical_name": "Mi:dm K 2.5 Pro",
    "model_name": "Mi:dm K 2.5 Pro",
    "aliases": [
      "Mi:dm K 2.5 Pro"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Korea Telecom",
    "intelligence_score": 23.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779479+00:00",
        "confidence": 0.65,
        "raw_name": "Mi:dm K 2.5 Pro",
        "raw_scores": {
          "intelligence_score": 23.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 23.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "mistral-large-3",
    "canonical_name": "Mistral Large 3",
    "model_name": "Mistral Large 3",
    "aliases": [
      "Mistral Large 3",
      "mistral-large-3"
    ],
    "provider": "Mistral",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": 26713,
    "license_type": "Apache 2.0",
    "creator": "Mistral",
    "intelligence_score": 23.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1415.12,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.75,
    "latency_seconds": 0.59,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 51.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779515+00:00",
        "confidence": 0.65,
        "raw_name": "Mistral Large 3",
        "raw_scores": {
          "intelligence_score": 23.0,
          "blended_cost_per_1m": 0.75,
          "latency_seconds": 0.59,
          "tokens_per_second": 51.0,
          "context_window": 256000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224253+00:00",
        "confidence": 1.0,
        "raw_name": "mistral-large-3",
        "raw_scores": {
          "arena_elo": 1415.12,
          "arena_votes": 26713
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 23.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1415.12
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "ring-1t",
    "canonical_name": "Ring-1T",
    "model_name": "Ring-1T",
    "aliases": [
      "Ring-1T"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "InclusionAI",
    "intelligence_score": 23.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779565+00:00",
        "confidence": 0.65,
        "raw_name": "Ring-1T",
        "raw_scores": {
          "intelligence_score": 23.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 23.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-30b-a3b-2507",
    "canonical_name": "Qwen3 30B A3B 2507",
    "model_name": "Qwen3 30B A3B 2507",
    "aliases": [
      "Qwen3 30B A3B 2507"
    ],
    "provider": "Alibaba",
    "context_window": 262000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 22.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.75,
    "latency_seconds": 0.98,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 147.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779584+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 30B A3B 2507",
        "raw_scores": {
          "intelligence_score": 22.0,
          "blended_cost_per_1m": 0.75,
          "latency_seconds": 0.98,
          "tokens_per_second": 147.0,
          "context_window": 262000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 22.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gpt-41-mini",
    "canonical_name": "GPT-4.1 mini",
    "model_name": "GPT-4.1 mini",
    "aliases": [
      "GPT-4.1 mini",
      "gpt-4.1-mini-2025-04-14"
    ],
    "provider": "OpenAI",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": 40321,
    "license_type": "Proprietary",
    "creator": "OpenAI",
    "intelligence_score": 22.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1381.93,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.7,
    "latency_seconds": 0.46,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 64.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779603+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-4.1 mini",
        "raw_scores": {
          "intelligence_score": 22.0,
          "blended_cost_per_1m": 0.7,
          "latency_seconds": 0.46,
          "tokens_per_second": 64.0,
          "context_window": 1000000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224817+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-4.1-mini-2025-04-14",
        "raw_scores": {
          "arena_elo": 1381.93,
          "arena_votes": 40321
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 22.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1381.93
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "intellect-3",
    "canonical_name": "INTELLECT-3",
    "model_name": "INTELLECT-3",
    "aliases": [
      "INTELLECT-3",
      "intellect-3"
    ],
    "provider": "Prime Intellect",
    "context_window": 131000,
    "open_source": null,
    "arena_votes": 5289,
    "license_type": "MIT",
    "creator": "Prime Intellect",
    "intelligence_score": 22.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1356.09,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779639+00:00",
        "confidence": 0.65,
        "raw_name": "INTELLECT-3",
        "raw_scores": {
          "intelligence_score": 22.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 131000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225174+00:00",
        "confidence": 1.0,
        "raw_name": "intellect-3",
        "raw_scores": {
          "arena_elo": 1356.09,
          "arena_votes": 5289
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 22.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1356.09
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "devstral-2",
    "canonical_name": "Devstral 2",
    "model_name": "Devstral 2",
    "aliases": [
      "Devstral 2"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 22.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.39,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 77.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779657+00:00",
        "confidence": 0.65,
        "raw_name": "Devstral 2",
        "raw_scores": {
          "intelligence_score": 22.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.39,
          "tokens_per_second": 77.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 22.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-v3-0324",
    "canonical_name": "DeepSeek V3 0324",
    "model_name": "DeepSeek V3 0324",
    "aliases": [
      "DeepSeek V3 0324",
      "deepseek-v3-0324"
    ],
    "provider": "DeepSeek",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 46442,
    "license_type": "MIT",
    "creator": "DeepSeek",
    "intelligence_score": 22.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1394.16,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.25,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779695+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek V3 0324",
        "raw_scores": {
          "intelligence_score": 22.0,
          "blended_cost_per_1m": 1.25,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224580+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-v3-0324",
        "raw_scores": {
          "arena_elo": 1394.16,
          "arena_votes": 46442
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 22.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1394.16
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "grok-3-reasoning-beta",
    "canonical_name": "Grok 3 Reasoning Beta",
    "model_name": "Grok 3 Reasoning Beta",
    "aliases": [
      "Grok 3 Reasoning Beta"
    ],
    "provider": "xAI",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "xAI",
    "intelligence_score": 22.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779713+00:00",
        "confidence": 0.65,
        "raw_name": "Grok 3 Reasoning Beta",
        "raw_scores": {
          "intelligence_score": 22.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 22.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemini-25-flash-lite",
    "canonical_name": "Gemini 2.5 Flash-Lite (Sep)",
    "model_name": "Gemini 2.5 Flash-Lite (Sep)",
    "aliases": [
      "Gemini 2.5 Flash-Lite",
      "Gemini 2.5 Flash-Lite (Sep)"
    ],
    "provider": "Google",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Google",
    "intelligence_score": 19.5,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.17,
    "latency_seconds": 11.94,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 426.5,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779732+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 2.5 Flash-Lite (Sep)",
        "raw_scores": {
          "intelligence_score": 22.0,
          "blended_cost_per_1m": 0.17,
          "latency_seconds": 8.62,
          "tokens_per_second": 473.0,
          "context_window": 1000000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780600+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 2.5 Flash-Lite",
        "raw_scores": {
          "intelligence_score": 17.0,
          "blended_cost_per_1m": 0.17,
          "latency_seconds": 15.26,
          "tokens_per_second": 380.0,
          "context_window": 1000000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 22.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "solar-open-100b",
    "canonical_name": "Solar Open 100B",
    "model_name": "Solar Open 100B",
    "aliases": [
      "Solar Open 100B"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Upstage",
    "intelligence_score": 22.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779751+00:00",
        "confidence": 0.65,
        "raw_name": "Solar Open 100B",
        "raw_scores": {
          "intelligence_score": 22.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 22.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "mistral-medium-31",
    "canonical_name": "Mistral Medium 3.1",
    "model_name": "Mistral Medium 3.1",
    "aliases": [
      "Mistral Medium 3.1"
    ],
    "provider": "Mistral AI",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 21.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.8,
    "latency_seconds": 0.41,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 93.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779787+00:00",
        "confidence": 0.65,
        "raw_name": "Mistral Medium 3.1",
        "raw_scores": {
          "intelligence_score": 21.0,
          "blended_cost_per_1m": 0.8,
          "latency_seconds": 0.41,
          "tokens_per_second": 93.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 21.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "minimax-m1-40k",
    "canonical_name": "MiniMax M1 40k",
    "model_name": "MiniMax M1 40k",
    "aliases": [
      "MiniMax M1 40k"
    ],
    "provider": "MiniMax",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "MiniMax",
    "intelligence_score": 21.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779806+00:00",
        "confidence": 0.65,
        "raw_name": "MiniMax M1 40k",
        "raw_scores": {
          "intelligence_score": 21.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 21.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "k2-v2",
    "canonical_name": "K2-V2 (high)",
    "model_name": "K2-V2 (high)",
    "aliases": [
      "K2-V2 (high)",
      "K2-V2 (low)",
      "K2-V2 (medium)"
    ],
    "provider": null,
    "context_window": 512000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "MBZUAI Institute of Foundation Models",
    "intelligence_score": 18.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779843+00:00",
        "confidence": 0.65,
        "raw_name": "K2-V2 (high)",
        "raw_scores": {
          "intelligence_score": 21.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 512000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780261+00:00",
        "confidence": 0.65,
        "raw_name": "K2-V2 (medium)",
        "raw_scores": {
          "intelligence_score": 19.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 512000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781492+00:00",
        "confidence": 0.65,
        "raw_name": "K2-V2 (low)",
        "raw_scores": {
          "intelligence_score": 14.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 512000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 21.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "tri-21b-think-preview",
    "canonical_name": "Tri-21B-think Preview",
    "model_name": "Tri-21B-think Preview",
    "aliases": [
      "Tri-21B-think Preview"
    ],
    "provider": null,
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Trillion Labs",
    "intelligence_score": 20.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779916+00:00",
        "confidence": 0.65,
        "raw_name": "Tri-21B-think Preview",
        "raw_scores": {
          "intelligence_score": 20.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 20.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "o1-mini",
    "canonical_name": "o1-mini",
    "model_name": "o1-mini",
    "aliases": [
      "o1-mini"
    ],
    "provider": "OpenAI",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 51986,
    "license_type": "Proprietary",
    "creator": "OpenAI",
    "intelligence_score": 20.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1336.79,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779934+00:00",
        "confidence": 0.65,
        "raw_name": "o1-mini",
        "raw_scores": {
          "intelligence_score": 20.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225485+00:00",
        "confidence": 1.0,
        "raw_name": "o1-mini",
        "raw_scores": {
          "arena_elo": 1336.79,
          "arena_votes": 51986
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 20.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1336.79
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-coder-30b-a3b",
    "canonical_name": "Qwen3 Coder 30B A3B",
    "model_name": "Qwen3 Coder 30B A3B",
    "aliases": [
      "Qwen3 Coder 30B A3B"
    ],
    "provider": "Alibaba",
    "context_window": 262000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 20.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.9,
    "latency_seconds": 1.46,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 21.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779970+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 Coder 30B A3B",
        "raw_scores": {
          "intelligence_score": 20.0,
          "blended_cost_per_1m": 0.9,
          "latency_seconds": 1.46,
          "tokens_per_second": 21.0,
          "context_window": 262000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 20.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gpt-45",
    "canonical_name": "GPT-4.5 (Preview)",
    "model_name": "GPT-4.5 (Preview)",
    "aliases": [
      "GPT-4.5 (Preview)"
    ],
    "provider": "OpenAI",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "OpenAI",
    "intelligence_score": 20.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.779988+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-4.5 (Preview)",
        "raw_scores": {
          "intelligence_score": 20.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 20.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-235b",
    "canonical_name": "Qwen3 235B",
    "model_name": "Qwen3 235B",
    "aliases": [
      "Qwen3 235B",
      "qwen3-235b-a22b-instruct-2507",
      "qwen3-235b-a22b-no-thinking"
    ],
    "provider": "Alibaba",
    "context_window": 33000,
    "open_source": null,
    "arena_votes": 71166,
    "license_type": "Apache 2.0",
    "creator": "Alibaba",
    "intelligence_score": 20.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1412.1,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 2.63,
    "latency_seconds": 1.15,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 41.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780006+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 235B",
        "raw_scores": {
          "intelligence_score": 20.0,
          "blended_cost_per_1m": 2.63,
          "latency_seconds": 1.15,
          "tokens_per_second": 41.0,
          "context_window": 33000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224104+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-235b-a22b-instruct-2507",
        "raw_scores": {
          "arena_elo": 1422.22,
          "arena_votes": 71166
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224437+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-235b-a22b-no-thinking",
        "raw_scores": {
          "arena_elo": 1401.98,
          "arena_votes": 39301
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 20.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1422.22
      }
    },
    "confidence_score": 0.8833,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwq-32b",
    "canonical_name": "QwQ-32B",
    "model_name": "QwQ-32B",
    "aliases": [
      "QwQ-32B",
      "qwq-32b"
    ],
    "provider": "Alibaba",
    "context_window": 131000,
    "open_source": null,
    "arena_votes": 26003,
    "license_type": "Apache 2.0",
    "creator": "Alibaba",
    "intelligence_score": 20.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1335.78,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.47,
    "latency_seconds": 0.52,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 29.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780025+00:00",
        "confidence": 0.65,
        "raw_name": "QwQ-32B",
        "raw_scores": {
          "intelligence_score": 20.0,
          "blended_cost_per_1m": 0.47,
          "latency_seconds": 0.52,
          "tokens_per_second": 29.0,
          "context_window": 131000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225497+00:00",
        "confidence": 1.0,
        "raw_name": "qwq-32b",
        "raw_scores": {
          "arena_elo": 1335.78,
          "arena_votes": 26003
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 20.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1335.78
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-vl-30b-a3b",
    "canonical_name": "Qwen3 VL 30B A3B",
    "model_name": "Qwen3 VL 30B A3B",
    "aliases": [
      "Qwen3 VL 30B A3B"
    ],
    "provider": "Alibaba",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 20.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.75,
    "latency_seconds": 1.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 100.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780042+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 VL 30B A3B",
        "raw_scores": {
          "intelligence_score": 20.0,
          "blended_cost_per_1m": 0.75,
          "latency_seconds": 1.0,
          "tokens_per_second": 100.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 20.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemini-20-flash-thinking-exp",
    "canonical_name": "Gemini 2.0 Flash Thinking exp. (Jan)",
    "model_name": "Gemini 2.0 Flash Thinking exp. (Jan)",
    "aliases": [
      "Gemini 2.0 Flash Thinking exp. (Dec)",
      "Gemini 2.0 Flash Thinking exp. (Jan)"
    ],
    "provider": "Google",
    "context_window": 2000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Google",
    "intelligence_score": 16.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780060+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 2.0 Flash Thinking exp. (Jan)",
        "raw_scores": {
          "intelligence_score": 20.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782337+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 2.0 Flash Thinking exp. (Dec)",
        "raw_scores": {
          "intelligence_score": 12.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 2000000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 20.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "devstral-small-2",
    "canonical_name": "Devstral Small 2",
    "model_name": "Devstral Small 2",
    "aliases": [
      "Devstral Small 2"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 19.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.38,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 201.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780097+00:00",
        "confidence": 0.65,
        "raw_name": "Devstral Small 2",
        "raw_scores": {
          "intelligence_score": 19.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.38,
          "tokens_per_second": 201.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "motif-2-127b",
    "canonical_name": "Motif-2-12.7B",
    "model_name": "Motif-2-12.7B",
    "aliases": [
      "Motif-2-12.7B"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Motif Technologies",
    "intelligence_score": 19.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780116+00:00",
        "confidence": 0.65,
        "raw_name": "Motif-2-12.7B",
        "raw_scores": {
          "intelligence_score": 19.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "ling-1t",
    "canonical_name": "Ling-1T",
    "model_name": "Ling-1T",
    "aliases": [
      "Ling-1T"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "InclusionAI",
    "intelligence_score": 19.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780134+00:00",
        "confidence": 0.65,
        "raw_name": "Ling-1T",
        "raw_scores": {
          "intelligence_score": 19.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "nova-premier",
    "canonical_name": "Nova Premier",
    "model_name": "Nova Premier",
    "aliases": [
      "Nova Premier"
    ],
    "provider": "Amazon",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Amazon",
    "intelligence_score": 19.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 5.0,
    "latency_seconds": 0.85,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 77.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780152+00:00",
        "confidence": 0.65,
        "raw_name": "Nova Premier",
        "raw_scores": {
          "intelligence_score": 19.0,
          "blended_cost_per_1m": 5.0,
          "latency_seconds": 0.85,
          "tokens_per_second": 77.0,
          "context_window": 1000000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gpt-4o",
    "canonical_name": "GPT-4o (Aug)",
    "model_name": "GPT-4o (Aug)",
    "aliases": [
      "GPT-4o (Aug)",
      "GPT-4o (ChatGPT)",
      "GPT-4o (Mar)",
      "GPT-4o (May)",
      "GPT-4o (Nov)",
      "chatgpt-4o-latest-20250326",
      "gpt-4o-2024-05-13"
    ],
    "provider": "OpenAI",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 112863,
    "license_type": "Proprietary",
    "creator": "OpenAI",
    "intelligence_score": 17.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1394.265,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.252,
    "latency_seconds": 0.304,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 62.2,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780171+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-4o (Aug)",
        "raw_scores": {
          "intelligence_score": 19.0,
          "blended_cost_per_1m": 4.38,
          "latency_seconds": 0.49,
          "tokens_per_second": 84.0,
          "context_window": 128000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780388+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-4o (Mar)",
        "raw_scores": {
          "intelligence_score": 19.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780620+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-4o (Nov)",
        "raw_scores": {
          "intelligence_score": 17.0,
          "blended_cost_per_1m": 4.38,
          "latency_seconds": 0.44,
          "tokens_per_second": 140.0,
          "context_window": 128000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780931+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-4o (May)",
        "raw_scores": {
          "intelligence_score": 16.0,
          "blended_cost_per_1m": 7.5,
          "latency_seconds": 0.59,
          "tokens_per_second": 87.0,
          "context_window": 128000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781722+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-4o (ChatGPT)",
        "raw_scores": {
          "intelligence_score": 14.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.223863+00:00",
        "confidence": 1.0,
        "raw_name": "chatgpt-4o-latest-20250326",
        "raw_scores": {
          "arena_elo": 1442.73,
          "arena_votes": 82954
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225383+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-4o-2024-05-13",
        "raw_scores": {
          "arena_elo": 1345.8,
          "arena_votes": 112863
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1442.73
      }
    },
    "confidence_score": 0.75,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "solar-pro-2",
    "canonical_name": "Solar Pro 2",
    "model_name": "Solar Pro 2",
    "aliases": [
      "Solar Pro 2"
    ],
    "provider": null,
    "context_window": 64000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Upstage",
    "intelligence_score": 19.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780189+00:00",
        "confidence": 0.65,
        "raw_name": "Solar Pro 2",
        "raw_scores": {
          "intelligence_score": 19.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 64000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "magistral-medium-1",
    "canonical_name": "Magistral Medium 1",
    "model_name": "Magistral Medium 1",
    "aliases": [
      "Magistral Medium 1"
    ],
    "provider": null,
    "context_window": 40000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 19.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 2.75,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780225+00:00",
        "confidence": 0.65,
        "raw_name": "Magistral Medium 1",
        "raw_scores": {
          "intelligence_score": 19.0,
          "blended_cost_per_1m": 2.75,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 40000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "mistral-medium-3",
    "canonical_name": "Mistral Medium 3",
    "model_name": "Mistral Medium 3",
    "aliases": [
      "Mistral Medium 3"
    ],
    "provider": "Mistral AI",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 19.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.8,
    "latency_seconds": 0.52,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 49.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780243+00:00",
        "confidence": 0.65,
        "raw_name": "Mistral Medium 3",
        "raw_scores": {
          "intelligence_score": 19.0,
          "blended_cost_per_1m": 0.8,
          "latency_seconds": 0.52,
          "tokens_per_second": 49.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "claude-35-haiku",
    "canonical_name": "Claude 3.5 Haiku",
    "model_name": "Claude 3.5 Haiku",
    "aliases": [
      "Claude 3.5 Haiku",
      "claude-3.5-haiku-20241022"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 70983,
    "license_type": "Proprietary",
    "creator": "Anthropic",
    "intelligence_score": 19.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1323.5,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.6,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780280+00:00",
        "confidence": 0.65,
        "raw_name": "Claude 3.5 Haiku",
        "raw_scores": {
          "intelligence_score": 19.0,
          "blended_cost_per_1m": 1.6,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 200000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225712+00:00",
        "confidence": 1.0,
        "raw_name": "claude-3.5-haiku-20241022",
        "raw_scores": {
          "arena_elo": 1323.5,
          "arena_votes": 70983
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1323.5
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-nemotron-super-49b-v15",
    "canonical_name": "Llama Nemotron Super 49B v1.5",
    "model_name": "Llama Nemotron Super 49B v1.5",
    "aliases": [
      "Llama Nemotron Super 49B v1.5"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "NVIDIA",
    "intelligence_score": 19.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.17,
    "latency_seconds": 0.23,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 75.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780298+00:00",
        "confidence": 0.65,
        "raw_name": "Llama Nemotron Super 49B v1.5",
        "raw_scores": {
          "intelligence_score": 19.0,
          "blended_cost_per_1m": 0.17,
          "latency_seconds": 0.23,
          "tokens_per_second": 75.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "tri-21b-think",
    "canonical_name": "Tri-21B-Think",
    "model_name": "Tri-21B-Think",
    "aliases": [
      "Tri-21B-Think"
    ],
    "provider": null,
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Trillion Labs",
    "intelligence_score": 19.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780316+00:00",
        "confidence": 0.65,
        "raw_name": "Tri-21B-Think",
        "raw_scores": {
          "intelligence_score": 19.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "devstral-medium",
    "canonical_name": "Devstral Medium",
    "model_name": "Devstral Medium",
    "aliases": [
      "Devstral Medium"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 19.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.8,
    "latency_seconds": 0.43,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 106.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780334+00:00",
        "confidence": 0.65,
        "raw_name": "Devstral Medium",
        "raw_scores": {
          "intelligence_score": 19.0,
          "blended_cost_per_1m": 0.8,
          "latency_seconds": 0.43,
          "tokens_per_second": 106.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-4b-2507",
    "canonical_name": "Qwen3 4B 2507",
    "model_name": "Qwen3 4B 2507",
    "aliases": [
      "Qwen3 4B 2507"
    ],
    "provider": "Alibaba",
    "context_window": 262000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 19.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780352+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 4B 2507",
        "raw_scores": {
          "intelligence_score": 19.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 262000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "hermes-4-405b",
    "canonical_name": "Hermes 4 405B",
    "model_name": "Hermes 4 405B",
    "aliases": [
      "Hermes 4 405B"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Nous Research",
    "intelligence_score": 19.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.5,
    "latency_seconds": 0.78,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 34.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780370+00:00",
        "confidence": 0.65,
        "raw_name": "Hermes 4 405B",
        "raw_scores": {
          "intelligence_score": 19.0,
          "blended_cost_per_1m": 1.5,
          "latency_seconds": 0.78,
          "tokens_per_second": 34.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemini-20-flash",
    "canonical_name": "Gemini 2.0 Flash",
    "model_name": "Gemini 2.0 Flash",
    "aliases": [
      "Gemini 2.0 Flash",
      "Gemini 2.0 Flash (exp)",
      "gemini-2.0-flash-001"
    ],
    "provider": "Google",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": 44689,
    "license_type": "Proprietary",
    "creator": "Google",
    "intelligence_score": 18.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1360.83,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.13,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780405+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 2.0 Flash",
        "raw_scores": {
          "intelligence_score": 19.0,
          "blended_cost_per_1m": 0.26,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780730+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 2.0 Flash (exp)",
        "raw_scores": {
          "intelligence_score": 17.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225137+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-2.0-flash-001",
        "raw_scores": {
          "arena_elo": 1360.83,
          "arena_votes": 44689
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1360.83
      }
    },
    "confidence_score": 0.7667,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-33-nemotron-super-49b",
    "canonical_name": "Llama 3.3 Nemotron Super 49B",
    "model_name": "Llama 3.3 Nemotron Super 49B",
    "aliases": [
      "Llama 3.3 Nemotron Super 49B"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "NVIDIA",
    "intelligence_score": 18.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780423+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 3.3 Nemotron Super 49B",
        "raw_scores": {
          "intelligence_score": 18.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 18.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-4-maverick",
    "canonical_name": "Llama 4 Maverick",
    "model_name": "Llama 4 Maverick",
    "aliases": [
      "Llama 4 Maverick",
      "llama-4-maverick-17b-128e-instruct"
    ],
    "provider": "Meta",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": 40938,
    "license_type": "Llama 4",
    "creator": "Meta",
    "intelligence_score": 18.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1327.69,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.46,
    "latency_seconds": 0.51,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 115.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780441+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 4 Maverick",
        "raw_scores": {
          "intelligence_score": 18.0,
          "blended_cost_per_1m": 0.46,
          "latency_seconds": 0.51,
          "tokens_per_second": 115.0,
          "context_window": 1000000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225658+00:00",
        "confidence": 1.0,
        "raw_name": "llama-4-maverick-17b-128e-instruct",
        "raw_scores": {
          "arena_elo": 1327.69,
          "arena_votes": 40938
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 18.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1327.69
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "magistral-small-12",
    "canonical_name": "Magistral Small 1.2",
    "model_name": "Magistral Small 1.2",
    "aliases": [
      "Magistral Small 1.2"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 18.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.75,
    "latency_seconds": 0.34,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 214.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780459+00:00",
        "confidence": 0.65,
        "raw_name": "Magistral Small 1.2",
        "raw_scores": {
          "intelligence_score": 18.0,
          "blended_cost_per_1m": 0.75,
          "latency_seconds": 0.34,
          "tokens_per_second": 214.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 18.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemini-20-pro-experimental",
    "canonical_name": "Gemini 2.0 Pro Experimental",
    "model_name": "Gemini 2.0 Pro Experimental",
    "aliases": [
      "Gemini 2.0 Pro Experimental"
    ],
    "provider": "Google",
    "context_window": 2000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Google",
    "intelligence_score": 18.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780477+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 2.0 Pro Experimental",
        "raw_scores": {
          "intelligence_score": 18.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 2000000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 18.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "devstral-small",
    "canonical_name": "Devstral Small (May)",
    "model_name": "Devstral Small (May)",
    "aliases": [
      "Devstral Small",
      "Devstral Small (May)"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 16.5,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.15,
    "latency_seconds": 0.2,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 116.5,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780495+00:00",
        "confidence": 0.65,
        "raw_name": "Devstral Small (May)",
        "raw_scores": {
          "intelligence_score": 18.0,
          "blended_cost_per_1m": 0.15,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 256000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781201+00:00",
        "confidence": 0.65,
        "raw_name": "Devstral Small",
        "raw_scores": {
          "intelligence_score": 15.0,
          "blended_cost_per_1m": 0.15,
          "latency_seconds": 0.4,
          "tokens_per_second": 233.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 18.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "sonar-reasoning",
    "canonical_name": "Sonar Reasoning",
    "model_name": "Sonar Reasoning",
    "aliases": [
      "Sonar Reasoning"
    ],
    "provider": null,
    "context_window": 127000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Perplexity",
    "intelligence_score": 18.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780544+00:00",
        "confidence": 0.65,
        "raw_name": "Sonar Reasoning",
        "raw_scores": {
          "intelligence_score": 18.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 127000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 18.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-r1-distill-qwen-32b",
    "canonical_name": "DeepSeek R1 Distill Qwen 32B",
    "model_name": "DeepSeek R1 Distill Qwen 32B",
    "aliases": [
      "DeepSeek R1 Distill Qwen 32B"
    ],
    "provider": "Alibaba",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "DeepSeek",
    "intelligence_score": 17.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.27,
    "latency_seconds": 0.24,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 57.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780657+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek R1 Distill Qwen 32B",
        "raw_scores": {
          "intelligence_score": 17.0,
          "blended_cost_per_1m": 0.27,
          "latency_seconds": 0.24,
          "tokens_per_second": 57.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 17.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "magistral-small-1",
    "canonical_name": "Magistral Small 1",
    "model_name": "Magistral Small 1",
    "aliases": [
      "Magistral Small 1"
    ],
    "provider": null,
    "context_window": 40000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 17.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780711+00:00",
        "confidence": 0.65,
        "raw_name": "Magistral Small 1",
        "raw_scores": {
          "intelligence_score": 17.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 40000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 17.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "exaone-40-32b",
    "canonical_name": "EXAONE 4.0 32B",
    "model_name": "EXAONE 4.0 32B",
    "aliases": [
      "EXAONE 4.0 32B"
    ],
    "provider": null,
    "context_window": 131000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "LG AI Research",
    "intelligence_score": 17.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.7,
    "latency_seconds": 0.34,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 99.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780748+00:00",
        "confidence": 0.65,
        "raw_name": "EXAONE 4.0 32B",
        "raw_scores": {
          "intelligence_score": 17.0,
          "blended_cost_per_1m": 0.7,
          "latency_seconds": 0.34,
          "tokens_per_second": 99.0,
          "context_window": 131000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 17.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-vl-8b",
    "canonical_name": "Qwen3 VL 8B",
    "model_name": "Qwen3 VL 8B",
    "aliases": [
      "Qwen3 VL 8B"
    ],
    "provider": "Alibaba",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 17.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.66,
    "latency_seconds": 0.98,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 122.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780766+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 VL 8B",
        "raw_scores": {
          "intelligence_score": 17.0,
          "blended_cost_per_1m": 0.66,
          "latency_seconds": 0.98,
          "tokens_per_second": 122.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 17.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-32b",
    "canonical_name": "Qwen3 32B",
    "model_name": "Qwen3 32B",
    "aliases": [
      "Qwen3 32B",
      "qwen3-32b"
    ],
    "provider": "Alibaba",
    "context_window": 33000,
    "open_source": null,
    "arena_votes": 3932,
    "license_type": "Apache 2.0",
    "creator": "Alibaba",
    "intelligence_score": 17.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1347.0,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 2.63,
    "latency_seconds": 1.01,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 93.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780803+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 32B",
        "raw_scores": {
          "intelligence_score": 17.0,
          "blended_cost_per_1m": 2.63,
          "latency_seconds": 1.01,
          "tokens_per_second": 93.0,
          "context_window": 33000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225333+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-32b",
        "raw_scores": {
          "arena_elo": 1347.0,
          "arena_votes": 3932
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 17.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1347.0
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-r1-0528-qwen3-8b",
    "canonical_name": "DeepSeek R1 0528 Qwen3 8B",
    "model_name": "DeepSeek R1 0528 Qwen3 8B",
    "aliases": [
      "DeepSeek R1 0528 Qwen3 8B"
    ],
    "provider": "Alibaba",
    "context_window": 33000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "DeepSeek",
    "intelligence_score": 16.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780822+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek R1 0528 Qwen3 8B",
        "raw_scores": {
          "intelligence_score": 16.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 33000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 16.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-v3",
    "canonical_name": "DeepSeek V3 (Dec)",
    "model_name": "DeepSeek V3 (Dec)",
    "aliases": [
      "DeepSeek V3 (Dec)",
      "deepseek-v3"
    ],
    "provider": "DeepSeek",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 21788,
    "license_type": "DeepSeek",
    "creator": "DeepSeek",
    "intelligence_score": 16.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1358.52,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.63,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780840+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek V3 (Dec)",
        "raw_scores": {
          "intelligence_score": 16.0,
          "blended_cost_per_1m": 0.63,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225149+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-v3",
        "raw_scores": {
          "arena_elo": 1358.52,
          "arena_votes": 21788
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 16.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1358.52
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen25-max",
    "canonical_name": "Qwen2.5 Max",
    "model_name": "Qwen2.5 Max",
    "aliases": [
      "Qwen2.5 Max",
      "qwen2.5-max"
    ],
    "provider": "Alibaba",
    "context_window": 32000,
    "open_source": null,
    "arena_votes": 33204,
    "license_type": "Proprietary",
    "creator": "Alibaba",
    "intelligence_score": 16.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1374.2,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 2.8,
    "latency_seconds": 1.12,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 40.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780858+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen2.5 Max",
        "raw_scores": {
          "intelligence_score": 16.0,
          "blended_cost_per_1m": 2.8,
          "latency_seconds": 1.12,
          "tokens_per_second": 40.0,
          "context_window": 32000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224893+00:00",
        "confidence": 1.0,
        "raw_name": "qwen2.5-max",
        "raw_scores": {
          "arena_elo": 1374.2,
          "arena_votes": 33204
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 16.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1374.2
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-14b",
    "canonical_name": "Qwen3 14B",
    "model_name": "Qwen3 14B",
    "aliases": [
      "Qwen3 14B"
    ],
    "provider": "Alibaba",
    "context_window": 33000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 16.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.31,
    "latency_seconds": 1.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 56.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780876+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 14B",
        "raw_scores": {
          "intelligence_score": 16.0,
          "blended_cost_per_1m": 1.31,
          "latency_seconds": 1.0,
          "tokens_per_second": 56.0,
          "context_window": 33000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 16.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "hermes-4-70b",
    "canonical_name": "Hermes 4 70B",
    "model_name": "Hermes 4 70B",
    "aliases": [
      "Hermes 4 70B"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Nous Research",
    "intelligence_score": 16.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.2,
    "latency_seconds": 0.64,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 80.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780913+00:00",
        "confidence": 0.65,
        "raw_name": "Hermes 4 70B",
        "raw_scores": {
          "intelligence_score": 16.0,
          "blended_cost_per_1m": 0.2,
          "latency_seconds": 0.64,
          "tokens_per_second": 80.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 16.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemini-15-pro",
    "canonical_name": "Gemini 1.5 Pro (Sep)",
    "model_name": "Gemini 1.5 Pro (Sep)",
    "aliases": [
      "Gemini 1.5 Pro (May)",
      "Gemini 1.5 Pro (Sep)",
      "gemini-1.5-pro-001",
      "gemini-1.5-pro-002"
    ],
    "provider": "Google",
    "context_window": 2000000,
    "open_source": null,
    "arena_votes": 79132,
    "license_type": "Proprietary",
    "creator": "Google",
    "intelligence_score": 14.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1337.205,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780949+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 1.5 Pro (Sep)",
        "raw_scores": {
          "intelligence_score": 16.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 2000000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782462+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 1.5 Pro (May)",
        "raw_scores": {
          "intelligence_score": 12.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 2000000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225248+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-1.5-pro-002",
        "raw_scores": {
          "arena_elo": 1351.33,
          "arena_votes": 55607
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225738+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-1.5-pro-001",
        "raw_scores": {
          "arena_elo": 1323.08,
          "arena_votes": 79132
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 16.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1351.33
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "ministral-3-14b",
    "canonical_name": "Ministral 3 14B",
    "model_name": "Ministral 3 14B",
    "aliases": [
      "Ministral 3 14B"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 16.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.2,
    "latency_seconds": 0.29,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 129.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.780985+00:00",
        "confidence": 0.65,
        "raw_name": "Ministral 3 14B",
        "raw_scores": {
          "intelligence_score": 16.0,
          "blended_cost_per_1m": 0.2,
          "latency_seconds": 0.29,
          "tokens_per_second": 129.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 16.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-r1-distill-llama-70b",
    "canonical_name": "DeepSeek R1 Distill Llama 70B",
    "model_name": "DeepSeek R1 Distill Llama 70B",
    "aliases": [
      "DeepSeek R1 Distill Llama 70B"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "DeepSeek",
    "intelligence_score": 16.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.88,
    "latency_seconds": 0.85,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 58.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781003+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek R1 Distill Llama 70B",
        "raw_scores": {
          "intelligence_score": 16.0,
          "blended_cost_per_1m": 0.88,
          "latency_seconds": 0.85,
          "tokens_per_second": 58.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 16.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "claude-35-sonnet",
    "canonical_name": "Claude 3.5 Sonnet (Oct)",
    "model_name": "Claude 3.5 Sonnet (Oct)",
    "aliases": [
      "Claude 3.5 Sonnet (June)",
      "Claude 3.5 Sonnet (Oct)",
      "claude-3.5-sonnet-20241022"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 89297,
    "license_type": "Proprietary",
    "creator": "Anthropic",
    "intelligence_score": 15.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1372.42,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 6.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781020+00:00",
        "confidence": 0.65,
        "raw_name": "Claude 3.5 Sonnet (Oct)",
        "raw_scores": {
          "intelligence_score": 16.0,
          "blended_cost_per_1m": 6.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 200000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781685+00:00",
        "confidence": 0.65,
        "raw_name": "Claude 3.5 Sonnet (June)",
        "raw_scores": {
          "intelligence_score": 14.0,
          "blended_cost_per_1m": 6.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 200000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225002+00:00",
        "confidence": 1.0,
        "raw_name": "claude-3.5-sonnet-20241022",
        "raw_scores": {
          "arena_elo": 1372.42,
          "arena_votes": 89297
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 16.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1372.42
      }
    },
    "confidence_score": 0.7667,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-r1-distill-qwen-14b",
    "canonical_name": "DeepSeek R1 Distill Qwen 14B",
    "model_name": "DeepSeek R1 Distill Qwen 14B",
    "aliases": [
      "DeepSeek R1 Distill Qwen 14B"
    ],
    "provider": "Alibaba",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "DeepSeek",
    "intelligence_score": 16.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781038+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek R1 Distill Qwen 14B",
        "raw_scores": {
          "intelligence_score": 16.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 16.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "falcon-h1r-7b",
    "canonical_name": "Falcon-H1R-7B",
    "model_name": "Falcon-H1R-7B",
    "aliases": [
      "Falcon-H1R-7B"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "TII UAE",
    "intelligence_score": 16.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781056+00:00",
        "confidence": 0.65,
        "raw_name": "Falcon-H1R-7B",
        "raw_scores": {
          "intelligence_score": 16.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 16.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-omni-30b-a3b",
    "canonical_name": "Qwen3 Omni 30B A3B",
    "model_name": "Qwen3 Omni 30B A3B",
    "aliases": [
      "Qwen3 Omni 30B A3B"
    ],
    "provider": "Alibaba",
    "context_window": 66000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 16.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.43,
    "latency_seconds": 1.12,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 89.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781074+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 Omni 30B A3B",
        "raw_scores": {
          "intelligence_score": 16.0,
          "blended_cost_per_1m": 0.43,
          "latency_seconds": 1.12,
          "tokens_per_second": 89.0,
          "context_window": 66000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 16.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen25-72b",
    "canonical_name": "Qwen2.5 72B",
    "model_name": "Qwen2.5 72B",
    "aliases": [
      "Qwen2.5 72B"
    ],
    "provider": "Alibaba",
    "context_window": 131000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 16.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 1.06,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 46.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781092+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen2.5 72B",
        "raw_scores": {
          "intelligence_score": 16.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 1.06,
          "tokens_per_second": 46.0,
          "context_window": 131000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 16.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "sonar",
    "canonical_name": "Sonar",
    "model_name": "Sonar",
    "aliases": [
      "Sonar"
    ],
    "provider": null,
    "context_window": 127000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Perplexity",
    "intelligence_score": 15.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.0,
    "latency_seconds": 1.36,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 125.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781111+00:00",
        "confidence": 0.65,
        "raw_name": "Sonar",
        "raw_scores": {
          "intelligence_score": 15.0,
          "blended_cost_per_1m": 1.0,
          "latency_seconds": 1.36,
          "tokens_per_second": 125.0,
          "context_window": 127000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "ling-flash-20",
    "canonical_name": "Ling-flash-2.0",
    "model_name": "Ling-flash-2.0",
    "aliases": [
      "Ling-flash-2.0",
      "ling-flash-2.0"
    ],
    "provider": "Ant Group",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 6998,
    "license_type": "MIT",
    "creator": "InclusionAI",
    "intelligence_score": 15.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1346.87,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.25,
    "latency_seconds": 1.48,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 60.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781129+00:00",
        "confidence": 0.65,
        "raw_name": "Ling-flash-2.0",
        "raw_scores": {
          "intelligence_score": 15.0,
          "blended_cost_per_1m": 0.25,
          "latency_seconds": 1.48,
          "tokens_per_second": 60.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225346+00:00",
        "confidence": 1.0,
        "raw_name": "ling-flash-2.0",
        "raw_scores": {
          "arena_elo": 1346.87,
          "arena_votes": 6998
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1346.87
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "step3-vl-10b",
    "canonical_name": "Step3 VL 10B",
    "model_name": "Step3 VL 10B",
    "aliases": [
      "Step3 VL 10B"
    ],
    "provider": null,
    "context_window": 66000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "StepFun",
    "intelligence_score": 15.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781147+00:00",
        "confidence": 0.65,
        "raw_name": "Step3 VL 10B",
        "raw_scores": {
          "intelligence_score": 15.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 66000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-30b",
    "canonical_name": "Qwen3 30B",
    "model_name": "Qwen3 30B",
    "aliases": [
      "Qwen3 30B"
    ],
    "provider": "Alibaba",
    "context_window": 33000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 15.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.75,
    "latency_seconds": 1.03,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 72.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781165+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 30B",
        "raw_scores": {
          "intelligence_score": 15.0,
          "blended_cost_per_1m": 0.75,
          "latency_seconds": 1.03,
          "tokens_per_second": 72.0,
          "context_window": 33000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "sonar-pro",
    "canonical_name": "Sonar Pro",
    "model_name": "Sonar Pro",
    "aliases": [
      "Sonar Pro"
    ],
    "provider": null,
    "context_window": 200000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Perplexity",
    "intelligence_score": 15.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 6.0,
    "latency_seconds": 1.46,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 106.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781183+00:00",
        "confidence": 0.65,
        "raw_name": "Sonar Pro",
        "raw_scores": {
          "intelligence_score": 15.0,
          "blended_cost_per_1m": 6.0,
          "latency_seconds": 1.46,
          "tokens_per_second": 106.0,
          "context_window": 200000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwq-32b-preview",
    "canonical_name": "QwQ 32B-Preview",
    "model_name": "QwQ 32B-Preview",
    "aliases": [
      "QwQ 32B-Preview",
      "qwq-32b-preview"
    ],
    "provider": "Alibaba",
    "context_window": 33000,
    "open_source": null,
    "arena_votes": 3233,
    "license_type": "Apache 2.0",
    "creator": "Alibaba",
    "intelligence_score": 15.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1157.09,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.14,
    "latency_seconds": 0.27,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 55.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781220+00:00",
        "confidence": 0.65,
        "raw_name": "QwQ 32B-Preview",
        "raw_scores": {
          "intelligence_score": 15.0,
          "blended_cost_per_1m": 0.14,
          "latency_seconds": 0.27,
          "tokens_per_second": 55.0,
          "context_window": 33000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227143+00:00",
        "confidence": 1.0,
        "raw_name": "qwq-32b-preview",
        "raw_scores": {
          "arena_elo": 1157.09,
          "arena_votes": 3233
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1157.09
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "mistral-large-2",
    "canonical_name": "Mistral Large 2 (Nov)",
    "model_name": "Mistral Large 2 (Nov)",
    "aliases": [
      "Mistral Large 2 (Jul)",
      "Mistral Large 2 (Nov)"
    ],
    "provider": "Mistral AI",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 14.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.0,
    "latency_seconds": 0.255,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 17.5,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781238+00:00",
        "confidence": 0.65,
        "raw_name": "Mistral Large 2 (Nov)",
        "raw_scores": {
          "intelligence_score": 15.0,
          "blended_cost_per_1m": 3.0,
          "latency_seconds": 0.51,
          "tokens_per_second": 35.0,
          "context_window": 128000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782065+00:00",
        "confidence": 0.65,
        "raw_name": "Mistral Large 2 (Jul)",
        "raw_scores": {
          "intelligence_score": 13.0,
          "blended_cost_per_1m": 3.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "mistral-small-32",
    "canonical_name": "Mistral Small 3.2",
    "model_name": "Mistral Small 3.2",
    "aliases": [
      "Mistral Small 3.2"
    ],
    "provider": "Mistral AI",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 15.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.15,
    "latency_seconds": 0.31,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 139.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781257+00:00",
        "confidence": 0.65,
        "raw_name": "Mistral Small 3.2",
        "raw_scores": {
          "intelligence_score": 15.0,
          "blended_cost_per_1m": 0.15,
          "latency_seconds": 0.31,
          "tokens_per_second": 139.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-nemotron-ultra",
    "canonical_name": "Llama Nemotron Ultra",
    "model_name": "Llama Nemotron Ultra",
    "aliases": [
      "Llama Nemotron Ultra"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "NVIDIA",
    "intelligence_score": 15.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.9,
    "latency_seconds": 0.68,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 38.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781275+00:00",
        "confidence": 0.65,
        "raw_name": "Llama Nemotron Ultra",
        "raw_scores": {
          "intelligence_score": 15.0,
          "blended_cost_per_1m": 0.9,
          "latency_seconds": 0.68,
          "tokens_per_second": 38.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "ernie-45-300b-a47b",
    "canonical_name": "ERNIE 4.5 300B A47B",
    "model_name": "ERNIE 4.5 300B A47B",
    "aliases": [
      "ERNIE 4.5 300B A47B"
    ],
    "provider": null,
    "context_window": 131000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Baidu",
    "intelligence_score": 15.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.48,
    "latency_seconds": 1.99,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 21.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781311+00:00",
        "confidence": 0.65,
        "raw_name": "ERNIE 4.5 300B A47B",
        "raw_scores": {
          "intelligence_score": 15.0,
          "blended_cost_per_1m": 0.48,
          "latency_seconds": 1.99,
          "tokens_per_second": 21.0,
          "context_window": 131000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "glm-45v",
    "canonical_name": "GLM-4.5V",
    "model_name": "GLM-4.5V",
    "aliases": [
      "GLM-4.5V",
      "glm-4.5v"
    ],
    "provider": "Z.ai",
    "context_window": 64000,
    "open_source": null,
    "arena_votes": 4954,
    "license_type": "MIT",
    "creator": "Z AI",
    "intelligence_score": 15.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1353.16,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.9,
    "latency_seconds": 1.14,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 43.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781347+00:00",
        "confidence": 0.65,
        "raw_name": "GLM-4.5V",
        "raw_scores": {
          "intelligence_score": 15.0,
          "blended_cost_per_1m": 0.9,
          "latency_seconds": 1.14,
          "tokens_per_second": 43.0,
          "context_window": 64000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225223+00:00",
        "confidence": 1.0,
        "raw_name": "glm-4.5v",
        "raw_scores": {
          "arena_elo": 1353.16,
          "arena_votes": 4954
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1353.16
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "nvidia-nemotron-nano-12b-v2-vl",
    "canonical_name": "NVIDIA Nemotron Nano 12B v2 VL",
    "model_name": "NVIDIA Nemotron Nano 12B v2 VL",
    "aliases": [
      "NVIDIA Nemotron Nano 12B v2 VL"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "NVIDIA",
    "intelligence_score": 15.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.3,
    "latency_seconds": 0.24,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 131.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781365+00:00",
        "confidence": 0.65,
        "raw_name": "NVIDIA Nemotron Nano 12B v2 VL",
        "raw_scores": {
          "intelligence_score": 15.0,
          "blended_cost_per_1m": 0.3,
          "latency_seconds": 0.24,
          "tokens_per_second": 131.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "nvidia-nemotron-nano-9b-v2",
    "canonical_name": "NVIDIA Nemotron Nano 9B V2",
    "model_name": "NVIDIA Nemotron Nano 9B V2",
    "aliases": [
      "NVIDIA Nemotron Nano 9B V2"
    ],
    "provider": null,
    "context_window": 131000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "NVIDIA",
    "intelligence_score": 15.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.07,
    "latency_seconds": 0.27,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 102.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781383+00:00",
        "confidence": 0.65,
        "raw_name": "NVIDIA Nemotron Nano 9B V2",
        "raw_scores": {
          "intelligence_score": 15.0,
          "blended_cost_per_1m": 0.07,
          "latency_seconds": 0.27,
          "tokens_per_second": 102.0,
          "context_window": 131000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemini-20-flash-lite",
    "canonical_name": "Gemini 2.0 Flash-Lite (Feb)",
    "model_name": "Gemini 2.0 Flash-Lite (Feb)",
    "aliases": [
      "Gemini 2.0 Flash-Lite (Feb)",
      "Gemini 2.0 Flash-Lite (Preview)"
    ],
    "provider": "Google",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Google",
    "intelligence_score": 14.5,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781402+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 2.0 Flash-Lite (Feb)",
        "raw_scores": {
          "intelligence_score": 15.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781474+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 2.0 Flash-Lite (Preview)",
        "raw_scores": {
          "intelligence_score": 14.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "ministral-3-8b",
    "canonical_name": "Ministral 3 8B",
    "model_name": "Ministral 3 8B",
    "aliases": [
      "Ministral 3 8B"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 15.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.15,
    "latency_seconds": 0.28,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 169.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781420+00:00",
        "confidence": 0.65,
        "raw_name": "Ministral 3 8B",
        "raw_scores": {
          "intelligence_score": 15.0,
          "blended_cost_per_1m": 0.15,
          "latency_seconds": 0.28,
          "tokens_per_second": 169.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-nemotron-nano-4b-v11",
    "canonical_name": "Llama 3.1 Nemotron Nano 4B v1.1",
    "model_name": "Llama 3.1 Nemotron Nano 4B v1.1",
    "aliases": [
      "Llama 3.1 Nemotron Nano 4B v1.1"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "NVIDIA",
    "intelligence_score": 14.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781510+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 3.1 Nemotron Nano 4B v1.1",
        "raw_scores": {
          "intelligence_score": 14.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "kimi-linear-48b-a3b-instruct",
    "canonical_name": "Kimi Linear 48B A3B Instruct",
    "model_name": "Kimi Linear 48B A3B Instruct",
    "aliases": [
      "Kimi Linear 48B A3B Instruct"
    ],
    "provider": "Moonshot",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Kimi",
    "intelligence_score": 14.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781539+00:00",
        "confidence": 0.65,
        "raw_name": "Kimi Linear 48B A3B Instruct",
        "raw_scores": {
          "intelligence_score": 14.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "mistral-small-31",
    "canonical_name": "Mistral Small 3.1",
    "model_name": "Mistral Small 3.1",
    "aliases": [
      "Mistral Small 3.1"
    ],
    "provider": "Mistral AI",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 14.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.15,
    "latency_seconds": 0.3,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 140.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781559+00:00",
        "confidence": 0.65,
        "raw_name": "Mistral Small 3.1",
        "raw_scores": {
          "intelligence_score": 14.0,
          "blended_cost_per_1m": 0.15,
          "latency_seconds": 0.3,
          "tokens_per_second": 140.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "olmo-31-32b-think",
    "canonical_name": "Olmo 3.1 32B Think",
    "model_name": "Olmo 3.1 32B Think",
    "aliases": [
      "Olmo 3.1 32B Think",
      "olmo-3.1-32b-think"
    ],
    "provider": "Allen AI",
    "context_window": 66000,
    "open_source": null,
    "arena_votes": 8437,
    "license_type": "Apache 2.0",
    "creator": "Allen Institute for AI",
    "intelligence_score": 14.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1285.11,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.54,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 76.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781613+00:00",
        "confidence": 0.65,
        "raw_name": "Olmo 3.1 32B Think",
        "raw_scores": {
          "intelligence_score": 14.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.54,
          "tokens_per_second": 76.0,
          "context_window": 66000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226254+00:00",
        "confidence": 1.0,
        "raw_name": "olmo-3.1-32b-think",
        "raw_scores": {
          "arena_elo": 1285.11,
          "arena_votes": 8437
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1285.11
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-33-70b",
    "canonical_name": "Llama 3.3 70B",
    "model_name": "Llama 3.3 70B",
    "aliases": [
      "Llama 3.3 70B"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Meta",
    "intelligence_score": 14.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.64,
    "latency_seconds": 0.53,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 83.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781631+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 3.3 70B",
        "raw_scores": {
          "intelligence_score": 14.0,
          "blended_cost_per_1m": 0.64,
          "latency_seconds": 0.53,
          "tokens_per_second": 83.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-4b",
    "canonical_name": "Qwen3 4B",
    "model_name": "Qwen3 4B",
    "aliases": [
      "Qwen3 4B"
    ],
    "provider": "Alibaba",
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 14.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.4,
    "latency_seconds": 1.01,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 92.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781649+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 4B",
        "raw_scores": {
          "intelligence_score": 14.0,
          "blended_cost_per_1m": 0.4,
          "latency_seconds": 1.01,
          "tokens_per_second": 92.0,
          "context_window": 32000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-405b",
    "canonical_name": "Llama 3.1 405B",
    "model_name": "Llama 3.1 405B",
    "aliases": [
      "Llama 3.1 405B"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Meta",
    "intelligence_score": 14.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 4.38,
    "latency_seconds": 0.55,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 25.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781667+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 3.1 405B",
        "raw_scores": {
          "intelligence_score": 14.0,
          "blended_cost_per_1m": 4.38,
          "latency_seconds": 0.55,
          "tokens_per_second": 25.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "tulu3-405b",
    "canonical_name": "Tulu3 405B",
    "model_name": "Tulu3 405B",
    "aliases": [
      "Tulu3 405B"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Allen Institute for AI",
    "intelligence_score": 14.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781703+00:00",
        "confidence": 0.65,
        "raw_name": "Tulu3 405B",
        "raw_scores": {
          "intelligence_score": 14.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "pixtral-large",
    "canonical_name": "Pixtral Large",
    "model_name": "Pixtral Large",
    "aliases": [
      "Pixtral Large"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 14.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.0,
    "latency_seconds": 0.43,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 49.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781741+00:00",
        "confidence": 0.65,
        "raw_name": "Pixtral Large",
        "raw_scores": {
          "intelligence_score": 14.0,
          "blended_cost_per_1m": 3.0,
          "latency_seconds": 0.43,
          "tokens_per_second": 49.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "ring-flash-20",
    "canonical_name": "Ring-flash-2.0",
    "model_name": "Ring-flash-2.0",
    "aliases": [
      "Ring-flash-2.0",
      "ring-flash-2.0"
    ],
    "provider": "Ant Group",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 7149,
    "license_type": "MIT",
    "creator": "InclusionAI",
    "intelligence_score": 14.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1320.39,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.25,
    "latency_seconds": 1.42,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 80.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781759+00:00",
        "confidence": 0.65,
        "raw_name": "Ring-flash-2.0",
        "raw_scores": {
          "intelligence_score": 14.0,
          "blended_cost_per_1m": 0.25,
          "latency_seconds": 1.42,
          "tokens_per_second": 80.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225800+00:00",
        "confidence": 1.0,
        "raw_name": "ring-flash-2.0",
        "raw_scores": {
          "arena_elo": 1320.39,
          "arena_votes": 7149
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1320.39
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "grok-2",
    "canonical_name": "Grok 2",
    "model_name": "Grok 2",
    "aliases": [
      "Grok 2"
    ],
    "provider": "xAI",
    "context_window": 131000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "xAI",
    "intelligence_score": 14.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781777+00:00",
        "confidence": 0.65,
        "raw_name": "Grok 2",
        "raw_scores": {
          "intelligence_score": 14.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 131000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemini-15-flash",
    "canonical_name": "Gemini 1.5 Flash (Sep)",
    "model_name": "Gemini 1.5 Flash (Sep)",
    "aliases": [
      "Gemini 1.5 Flash (May)",
      "Gemini 1.5 Flash (Sep)",
      "gemini-1.5-flash-001",
      "gemini-1.5-flash-002"
    ],
    "provider": "Google",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": 62823,
    "license_type": "Proprietary",
    "creator": "Google",
    "intelligence_score": 12.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1297.695,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781795+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 1.5 Flash (Sep)",
        "raw_scores": {
          "intelligence_score": 14.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782901+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 1.5 Flash (May)",
        "raw_scores": {
          "intelligence_score": 10.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225974+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-1.5-flash-002",
        "raw_scores": {
          "arena_elo": 1309.77,
          "arena_votes": 34909
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226242+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-1.5-flash-001",
        "raw_scores": {
          "arena_elo": 1285.62,
          "arena_votes": 62823
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1309.77
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-vl-4b",
    "canonical_name": "Qwen3 VL 4B",
    "model_name": "Qwen3 VL 4B",
    "aliases": [
      "Qwen3 VL 4B"
    ],
    "provider": "Alibaba",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 14.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781813+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 VL 4B",
        "raw_scores": {
          "intelligence_score": 14.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gpt-4-turbo",
    "canonical_name": "GPT-4 Turbo",
    "model_name": "GPT-4 Turbo",
    "aliases": [
      "GPT-4 Turbo",
      "gpt-4-turbo-2024-04-09"
    ],
    "provider": "OpenAI",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 98130,
    "license_type": "Proprietary",
    "creator": "OpenAI",
    "intelligence_score": 14.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1324.25,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 15.0,
    "latency_seconds": 1.2,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 28.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781831+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-4 Turbo",
        "raw_scores": {
          "intelligence_score": 14.0,
          "blended_cost_per_1m": 15.0,
          "latency_seconds": 1.2,
          "tokens_per_second": 28.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225695+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-4-turbo-2024-04-09",
        "raw_scores": {
          "arena_elo": 1324.25,
          "arena_votes": 98130
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1324.25
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-4-scout",
    "canonical_name": "Llama 4 Scout",
    "model_name": "Llama 4 Scout",
    "aliases": [
      "Llama 4 Scout",
      "llama-4-scout-17b-16e-instruct"
    ],
    "provider": "Meta",
    "context_window": 10000000,
    "open_source": null,
    "arena_votes": 31061,
    "license_type": "Llama",
    "creator": "Meta",
    "intelligence_score": 13.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1322.51,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.29,
    "latency_seconds": 0.45,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 154.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781885+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 4 Scout",
        "raw_scores": {
          "intelligence_score": 13.0,
          "blended_cost_per_1m": 0.29,
          "latency_seconds": 0.45,
          "tokens_per_second": 154.0,
          "context_window": 10000000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225750+00:00",
        "confidence": 1.0,
        "raw_name": "llama-4-scout-17b-16e-instruct",
        "raw_scores": {
          "arena_elo": 1322.51,
          "arena_votes": 31061
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1322.51
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "nova-pro",
    "canonical_name": "Nova Pro",
    "model_name": "Nova Pro",
    "aliases": [
      "Nova Pro",
      "amazon-nova-pro-v1.0"
    ],
    "provider": "Amazon",
    "context_window": 300000,
    "open_source": null,
    "arena_votes": 24753,
    "license_type": "Proprietary",
    "creator": "Amazon",
    "intelligence_score": 13.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1290.24,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.4,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781903+00:00",
        "confidence": 0.65,
        "raw_name": "Nova Pro",
        "raw_scores": {
          "intelligence_score": 13.0,
          "blended_cost_per_1m": 1.4,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 300000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226145+00:00",
        "confidence": 1.0,
        "raw_name": "amazon-nova-pro-v1.0",
        "raw_scores": {
          "arena_elo": 1290.24,
          "arena_votes": 24753
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1290.24
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "command-a",
    "canonical_name": "Command A",
    "model_name": "Command A",
    "aliases": [
      "Command A",
      "command-a-03-2025"
    ],
    "provider": "Cohere",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": 57108,
    "license_type": "CC-BY-NC-4.0",
    "creator": "Cohere",
    "intelligence_score": 13.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1353.1,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 4.38,
    "latency_seconds": 0.41,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 45.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781921+00:00",
        "confidence": 0.65,
        "raw_name": "Command A",
        "raw_scores": {
          "intelligence_score": 13.0,
          "blended_cost_per_1m": 4.38,
          "latency_seconds": 0.41,
          "tokens_per_second": 45.0,
          "context_window": 256000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225236+00:00",
        "confidence": 1.0,
        "raw_name": "command-a-03-2025",
        "raw_scores": {
          "arena_elo": 1353.1,
          "arena_votes": 57108
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1353.1
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-nemotron-70b",
    "canonical_name": "Llama 3.1 Nemotron 70B",
    "model_name": "Llama 3.1 Nemotron 70B",
    "aliases": [
      "Llama 3.1 Nemotron 70B"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "NVIDIA",
    "intelligence_score": 13.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.2,
    "latency_seconds": 0.59,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 30.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781940+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 3.1 Nemotron 70B",
        "raw_scores": {
          "intelligence_score": 13.0,
          "blended_cost_per_1m": 1.2,
          "latency_seconds": 0.59,
          "tokens_per_second": 30.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "grok-beta",
    "canonical_name": "Grok Beta",
    "model_name": "Grok Beta",
    "aliases": [
      "Grok Beta"
    ],
    "provider": "xAI",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "xAI",
    "intelligence_score": 13.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781976+00:00",
        "confidence": 0.65,
        "raw_name": "Grok Beta",
        "raw_scores": {
          "intelligence_score": 13.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen25-instruct-32b",
    "canonical_name": "Qwen2.5 Instruct 32B",
    "model_name": "Qwen2.5 Instruct 32B",
    "aliases": [
      "Qwen2.5 Instruct 32B"
    ],
    "provider": "Alibaba",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 13.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.781993+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen2.5 Instruct 32B",
        "raw_scores": {
          "intelligence_score": 13.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-8b",
    "canonical_name": "Qwen3 8B",
    "model_name": "Qwen3 8B",
    "aliases": [
      "Qwen3 8B"
    ],
    "provider": "Alibaba",
    "context_window": 131000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 13.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.66,
    "latency_seconds": 0.94,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 64.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782047+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 8B",
        "raw_scores": {
          "intelligence_score": 13.0,
          "blended_cost_per_1m": 0.66,
          "latency_seconds": 0.94,
          "tokens_per_second": 64.0,
          "context_window": 131000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gpt-41-nano",
    "canonical_name": "GPT-4.1 nano",
    "model_name": "GPT-4.1 nano",
    "aliases": [
      "GPT-4.1 nano",
      "gpt-4.1-nano-2025-04-14"
    ],
    "provider": "OpenAI",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": 6107,
    "license_type": "Proprietary",
    "creator": "OpenAI",
    "intelligence_score": 13.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1321.77,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.17,
    "latency_seconds": 0.33,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 90.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782083+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-4.1 nano",
        "raw_scores": {
          "intelligence_score": 13.0,
          "blended_cost_per_1m": 0.17,
          "latency_seconds": 0.33,
          "tokens_per_second": 90.0,
          "context_window": 1000000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225787+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-4.1-nano-2025-04-14",
        "raw_scores": {
          "arena_elo": 1321.77,
          "arena_votes": 6107
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1321.77
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen25-coder-32b",
    "canonical_name": "Qwen2.5 Coder 32B",
    "model_name": "Qwen2.5 Coder 32B",
    "aliases": [
      "Qwen2.5 Coder 32B"
    ],
    "provider": "Alibaba",
    "context_window": 131000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 13.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.2,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782101+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen2.5 Coder 32B",
        "raw_scores": {
          "intelligence_score": 13.0,
          "blended_cost_per_1m": 0.2,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 131000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gpt-4",
    "canonical_name": "GPT-4",
    "model_name": "GPT-4",
    "aliases": [
      "GPT-4"
    ],
    "provider": "OpenAI",
    "context_window": 8000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "OpenAI",
    "intelligence_score": 13.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 37.5,
    "latency_seconds": 0.69,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 32.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782119+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-4",
        "raw_scores": {
          "intelligence_score": 13.0,
          "blended_cost_per_1m": 37.5,
          "latency_seconds": 0.69,
          "tokens_per_second": 32.0,
          "context_window": 8000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "mistral-small-3",
    "canonical_name": "Mistral Small 3",
    "model_name": "Mistral Small 3",
    "aliases": [
      "Mistral Small 3"
    ],
    "provider": "Mistral AI",
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 13.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.15,
    "latency_seconds": 0.35,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 231.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782156+00:00",
        "confidence": 0.65,
        "raw_name": "Mistral Small 3",
        "raw_scores": {
          "intelligence_score": 13.0,
          "blended_cost_per_1m": 0.15,
          "latency_seconds": 0.35,
          "tokens_per_second": 231.0,
          "context_window": 32000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gpt-4o-mini",
    "canonical_name": "GPT-4o mini",
    "model_name": "GPT-4o mini",
    "aliases": [
      "GPT-4o mini",
      "gpt-4o-mini-2024-07-18"
    ],
    "provider": "OpenAI",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 68794,
    "license_type": "Proprietary",
    "creator": "OpenAI",
    "intelligence_score": 13.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1317.74,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.26,
    "latency_seconds": 0.56,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 57.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782175+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-4o mini",
        "raw_scores": {
          "intelligence_score": 13.0,
          "blended_cost_per_1m": 0.26,
          "latency_seconds": 0.56,
          "tokens_per_second": 57.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225864+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-4o-mini-2024-07-18",
        "raw_scores": {
          "arena_elo": 1317.74,
          "arena_votes": 68794
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1317.74
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-v25",
    "canonical_name": "DeepSeek-V2.5 (Dec)",
    "model_name": "DeepSeek-V2.5 (Dec)",
    "aliases": [
      "DeepSeek-V2.5",
      "DeepSeek-V2.5 (Dec)",
      "deepseek-v2.5"
    ],
    "provider": "DeepSeek",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 24574,
    "license_type": "DeepSeek",
    "creator": "DeepSeek",
    "intelligence_score": 12.5,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1307.06,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782229+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek-V2.5 (Dec)",
        "raw_scores": {
          "intelligence_score": 13.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782355+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek-V2.5",
        "raw_scores": {
          "intelligence_score": 12.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226011+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-v2.5",
        "raw_scores": {
          "arena_elo": 1307.06,
          "arena_votes": 24574
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1307.06
      }
    },
    "confidence_score": 0.7667,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "claude-3-opus",
    "canonical_name": "Claude 3 Opus",
    "model_name": "Claude 3 Opus",
    "aliases": [
      "Claude 3 Opus",
      "claude-3-opus-20240229"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 194904,
    "license_type": "Proprietary",
    "creator": "Anthropic",
    "intelligence_score": 12.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1322.08,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 30.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782265+00:00",
        "confidence": 0.65,
        "raw_name": "Claude 3 Opus",
        "raw_scores": {
          "intelligence_score": 12.0,
          "blended_cost_per_1m": 30.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 200000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225763+00:00",
        "confidence": 1.0,
        "raw_name": "claude-3-opus-20240229",
        "raw_scores": {
          "arena_elo": 1322.08,
          "arena_votes": 194904
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1322.08
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "nova-lite",
    "canonical_name": "Nova Lite",
    "model_name": "Nova Lite",
    "aliases": [
      "Nova Lite",
      "amazon-nova-lite-v1.0"
    ],
    "provider": "Amazon",
    "context_window": 300000,
    "open_source": null,
    "arena_votes": 19376,
    "license_type": "Proprietary",
    "creator": "Amazon",
    "intelligence_score": 12.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1260.73,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.1,
    "latency_seconds": 0.4,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 220.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782301+00:00",
        "confidence": 0.65,
        "raw_name": "Nova Lite",
        "raw_scores": {
          "intelligence_score": 12.0,
          "blended_cost_per_1m": 0.1,
          "latency_seconds": 0.4,
          "tokens_per_second": 220.0,
          "context_window": 300000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226462+00:00",
        "confidence": 1.0,
        "raw_name": "amazon-nova-lite-v1.0",
        "raw_scores": {
          "arena_elo": 1260.73,
          "arena_votes": 19376
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1260.73
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-70b",
    "canonical_name": "Llama 3.1 70B",
    "model_name": "Llama 3.1 70B",
    "aliases": [
      "Llama 3.1 70B"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Meta",
    "intelligence_score": 12.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.56,
    "latency_seconds": 0.48,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 49.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782373+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 3.1 70B",
        "raw_scores": {
          "intelligence_score": 12.0,
          "blended_cost_per_1m": 0.56,
          "latency_seconds": 0.48,
          "tokens_per_second": 49.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "mistral-saba",
    "canonical_name": "Mistral Saba",
    "model_name": "Mistral Saba",
    "aliases": [
      "Mistral Saba"
    ],
    "provider": "Mistral AI",
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 12.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782390+00:00",
        "confidence": 0.65,
        "raw_name": "Mistral Saba",
        "raw_scores": {
          "intelligence_score": 12.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-r1-distill-llama-8b",
    "canonical_name": "DeepSeek R1 Distill Llama 8B",
    "model_name": "DeepSeek R1 Distill Llama 8B",
    "aliases": [
      "DeepSeek R1 Distill Llama 8B"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "DeepSeek",
    "intelligence_score": 12.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782408+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek R1 Distill Llama 8B",
        "raw_scores": {
          "intelligence_score": 12.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "claude-3-haiku",
    "canonical_name": "Claude 3 Haiku",
    "model_name": "Claude 3 Haiku",
    "aliases": [
      "Claude 3 Haiku"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Anthropic",
    "intelligence_score": 12.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.5,
    "latency_seconds": 0.45,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 108.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782427+00:00",
        "confidence": 0.65,
        "raw_name": "Claude 3 Haiku",
        "raw_scores": {
          "intelligence_score": 12.0,
          "blended_cost_per_1m": 0.5,
          "latency_seconds": 0.45,
          "tokens_per_second": 108.0,
          "context_window": 200000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "olmo-31-32b-instruct",
    "canonical_name": "Olmo 3.1 32B Instruct",
    "model_name": "Olmo 3.1 32B Instruct",
    "aliases": [
      "Olmo 3.1 32B Instruct",
      "olmo-3.1-32b-instruct"
    ],
    "provider": "Allen AI",
    "context_window": 66000,
    "open_source": null,
    "arena_votes": 12252,
    "license_type": "Apache 2.0",
    "creator": "Allen Institute for AI",
    "intelligence_score": 12.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1330.47,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.3,
    "latency_seconds": 0.24,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 44.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782445+00:00",
        "confidence": 0.65,
        "raw_name": "Olmo 3.1 32B Instruct",
        "raw_scores": {
          "intelligence_score": 12.0,
          "blended_cost_per_1m": 0.3,
          "latency_seconds": 0.24,
          "tokens_per_second": 44.0,
          "context_window": 66000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225608+00:00",
        "confidence": 1.0,
        "raw_name": "olmo-3.1-32b-instruct",
        "raw_scores": {
          "arena_elo": 1330.47,
          "arena_votes": 12252
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1330.47
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "olmo-3-32b-think",
    "canonical_name": "Olmo 3 32B Think",
    "model_name": "Olmo 3 32B Think",
    "aliases": [
      "Olmo 3 32B Think",
      "olmo-3-32b-think"
    ],
    "provider": "Allen AI",
    "context_window": 66000,
    "open_source": null,
    "arena_votes": 5869,
    "license_type": "Apache 2.0",
    "creator": "Allen Institute for AI",
    "intelligence_score": 12.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1305.68,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782480+00:00",
        "confidence": 0.65,
        "raw_name": "Olmo 3 32B Think",
        "raw_scores": {
          "intelligence_score": 12.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 66000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226035+00:00",
        "confidence": 1.0,
        "raw_name": "olmo-3-32b-think",
        "raw_scores": {
          "arena_elo": 1305.68,
          "arena_votes": 5869
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1305.68
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "r1-1776",
    "canonical_name": "R1 1776",
    "model_name": "R1 1776",
    "aliases": [
      "R1 1776"
    ],
    "provider": "DeepSeek",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Perplexity",
    "intelligence_score": 12.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782499+00:00",
        "confidence": 0.65,
        "raw_name": "R1 1776",
        "raw_scores": {
          "intelligence_score": 12.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen25-turbo",
    "canonical_name": "Qwen2.5 Turbo",
    "model_name": "Qwen2.5 Turbo",
    "aliases": [
      "Qwen2.5 Turbo"
    ],
    "provider": "Alibaba",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 12.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.09,
    "latency_seconds": 0.97,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 69.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782517+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen2.5 Turbo",
        "raw_scores": {
          "intelligence_score": 12.0,
          "blended_cost_per_1m": 0.09,
          "latency_seconds": 0.97,
          "tokens_per_second": 69.0,
          "context_window": 1000000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "reka-flash",
    "canonical_name": "Reka Flash",
    "model_name": "Reka Flash",
    "aliases": [
      "Reka Flash"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Reka AI",
    "intelligence_score": 12.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.35,
    "latency_seconds": 1.31,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 68.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782567+00:00",
        "confidence": 0.65,
        "raw_name": "Reka Flash",
        "raw_scores": {
          "intelligence_score": 12.0,
          "blended_cost_per_1m": 0.35,
          "latency_seconds": 1.31,
          "tokens_per_second": 68.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-32-90b",
    "canonical_name": "Llama 3.2 90B (Vision)",
    "model_name": "Llama 3.2 90B (Vision)",
    "aliases": [
      "Llama 3.2 90B (Vision)"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Meta",
    "intelligence_score": 12.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.72,
    "latency_seconds": 0.42,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 37.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782589+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 3.2 90B (Vision)",
        "raw_scores": {
          "intelligence_score": 12.0,
          "blended_cost_per_1m": 0.72,
          "latency_seconds": 0.42,
          "tokens_per_second": 37.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "grok-1",
    "canonical_name": "Grok-1",
    "model_name": "Grok-1",
    "aliases": [
      "Grok-1"
    ],
    "provider": "xAI",
    "context_window": 8000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "xAI",
    "intelligence_score": 12.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782608+00:00",
        "confidence": 0.65,
        "raw_name": "Grok-1",
        "raw_scores": {
          "intelligence_score": 12.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 8000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-8b",
    "canonical_name": "Llama 3.1 8B",
    "model_name": "Llama 3.1 8B",
    "aliases": [
      "Llama 3.1 8B"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Meta",
    "intelligence_score": 12.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.1,
    "latency_seconds": 0.46,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 178.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782627+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 3.1 8B",
        "raw_scores": {
          "intelligence_score": 12.0,
          "blended_cost_per_1m": 0.1,
          "latency_seconds": 0.46,
          "tokens_per_second": 178.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen2-72b",
    "canonical_name": "Qwen2 72B",
    "model_name": "Qwen2 72B",
    "aliases": [
      "Qwen2 72B"
    ],
    "provider": "Alibaba",
    "context_window": 131000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 12.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782645+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen2 72B",
        "raw_scores": {
          "intelligence_score": 12.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 131000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "ministral-3-3b",
    "canonical_name": "Ministral 3 3B",
    "model_name": "Ministral 3 3B",
    "aliases": [
      "Ministral 3 3B"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 11.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.1,
    "latency_seconds": 0.27,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 292.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782681+00:00",
        "confidence": 0.65,
        "raw_name": "Ministral 3 3B",
        "raw_scores": {
          "intelligence_score": 11.0,
          "blended_cost_per_1m": 0.1,
          "latency_seconds": 0.27,
          "tokens_per_second": 292.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 11.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemini-15-flash-8b",
    "canonical_name": "Gemini 1.5 Flash-8B",
    "model_name": "Gemini 1.5 Flash-8B",
    "aliases": [
      "Gemini 1.5 Flash-8B"
    ],
    "provider": "Google",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Google",
    "intelligence_score": 11.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782700+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 1.5 Flash-8B",
        "raw_scores": {
          "intelligence_score": 11.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 11.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "deephermes-3---mistral-24b",
    "canonical_name": "DeepHermes 3 - Mistral 24B",
    "model_name": "DeepHermes 3 - Mistral 24B",
    "aliases": [
      "DeepHermes 3 - Mistral 24B"
    ],
    "provider": "Mistral AI",
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Nous Research",
    "intelligence_score": 11.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782717+00:00",
        "confidence": 0.65,
        "raw_name": "DeepHermes 3 - Mistral 24B",
        "raw_scores": {
          "intelligence_score": 11.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 11.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "granite-40-h-small",
    "canonical_name": "Granite 4.0 H Small",
    "model_name": "Granite 4.0 H Small",
    "aliases": [
      "Granite 4.0 H Small"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "IBM",
    "intelligence_score": 11.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.11,
    "latency_seconds": 8.85,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 436.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782735+00:00",
        "confidence": 0.65,
        "raw_name": "Granite 4.0 H Small",
        "raw_scores": {
          "intelligence_score": 11.0,
          "blended_cost_per_1m": 0.11,
          "latency_seconds": 8.85,
          "tokens_per_second": 436.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 11.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "jamba-15-large",
    "canonical_name": "Jamba 1.5 Large",
    "model_name": "Jamba 1.5 Large",
    "aliases": [
      "Jamba 1.5 Large",
      "jamba-1.5-large"
    ],
    "provider": "AI21 Labs",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": 8659,
    "license_type": "Jamba Open",
    "creator": "AI21 Labs",
    "intelligence_score": 11.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1288.76,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.5,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782754+00:00",
        "confidence": 0.65,
        "raw_name": "Jamba 1.5 Large",
        "raw_scores": {
          "intelligence_score": 11.0,
          "blended_cost_per_1m": 3.5,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 256000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226157+00:00",
        "confidence": 1.0,
        "raw_name": "jamba-1.5-large",
        "raw_scores": {
          "arena_elo": 1288.76,
          "arena_votes": 8659
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 11.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1288.76
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "hermes-3---llama-31-70b",
    "canonical_name": "Hermes 3 - Llama-3.1 70B",
    "model_name": "Hermes 3 - Llama-3.1 70B",
    "aliases": [
      "Hermes 3 - Llama-3.1 70B"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Nous Research",
    "intelligence_score": 11.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.3,
    "latency_seconds": 0.45,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 36.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782792+00:00",
        "confidence": 0.65,
        "raw_name": "Hermes 3 - Llama-3.1 70B",
        "raw_scores": {
          "intelligence_score": 11.0,
          "blended_cost_per_1m": 0.3,
          "latency_seconds": 0.45,
          "tokens_per_second": 36.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 11.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-coder-v2",
    "canonical_name": "DeepSeek-Coder-V2",
    "model_name": "DeepSeek-Coder-V2",
    "aliases": [
      "DeepSeek-Coder-V2",
      "deepseek-coder-v2"
    ],
    "provider": "DeepSeek",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 15147,
    "license_type": "DeepSeek License",
    "creator": "DeepSeek",
    "intelligence_score": 11.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1264.33,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782810+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek-Coder-V2",
        "raw_scores": {
          "intelligence_score": 11.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226413+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-coder-v2",
        "raw_scores": {
          "arena_elo": 1264.33,
          "arena_votes": 15147
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 11.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1264.33
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "olmo-2-32b",
    "canonical_name": "OLMo 2 32B",
    "model_name": "OLMo 2 32B",
    "aliases": [
      "OLMo 2 32B"
    ],
    "provider": null,
    "context_window": 4000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Allen Institute for AI",
    "intelligence_score": 11.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782828+00:00",
        "confidence": 0.65,
        "raw_name": "OLMo 2 32B",
        "raw_scores": {
          "intelligence_score": 11.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 4000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 11.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "jamba-16-large",
    "canonical_name": "Jamba 1.6 Large",
    "model_name": "Jamba 1.6 Large",
    "aliases": [
      "Jamba 1.6 Large"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "AI21 Labs",
    "intelligence_score": 11.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.5,
    "latency_seconds": 0.85,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 52.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782846+00:00",
        "confidence": 0.65,
        "raw_name": "Jamba 1.6 Large",
        "raw_scores": {
          "intelligence_score": 11.0,
          "blended_cost_per_1m": 3.5,
          "latency_seconds": 0.85,
          "tokens_per_second": 52.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 11.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "phi-4",
    "canonical_name": "Phi-4",
    "model_name": "Phi-4",
    "aliases": [
      "Phi-4",
      "phi-4"
    ],
    "provider": "Microsoft",
    "context_window": 16000,
    "open_source": null,
    "arena_votes": 24126,
    "license_type": "MIT",
    "creator": "Microsoft Azure",
    "intelligence_score": 10.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1256.16,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.22,
    "latency_seconds": 1.02,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 7.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782883+00:00",
        "confidence": 0.65,
        "raw_name": "Phi-4",
        "raw_scores": {
          "intelligence_score": 10.0,
          "blended_cost_per_1m": 0.22,
          "latency_seconds": 1.02,
          "tokens_per_second": 7.0,
          "context_window": 16000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226486+00:00",
        "confidence": 1.0,
        "raw_name": "phi-4",
        "raw_scores": {
          "arena_elo": 1256.16,
          "arena_votes": 24126
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1256.16
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "jamba-reasoning-3b",
    "canonical_name": "Jamba Reasoning 3B",
    "model_name": "Jamba Reasoning 3B",
    "aliases": [
      "Jamba Reasoning 3B"
    ],
    "provider": null,
    "context_window": 262000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "AI21 Labs",
    "intelligence_score": 10.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782919+00:00",
        "confidence": 0.65,
        "raw_name": "Jamba Reasoning 3B",
        "raw_scores": {
          "intelligence_score": 10.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 262000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "claude-3-sonnet",
    "canonical_name": "Claude 3 Sonnet",
    "model_name": "Claude 3 Sonnet",
    "aliases": [
      "Claude 3 Sonnet"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Anthropic",
    "intelligence_score": 10.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 6.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782936+00:00",
        "confidence": 0.65,
        "raw_name": "Claude 3 Sonnet",
        "raw_scores": {
          "intelligence_score": 10.0,
          "blended_cost_per_1m": 6.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 200000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "nova-micro",
    "canonical_name": "Nova Micro",
    "model_name": "Nova Micro",
    "aliases": [
      "Nova Micro",
      "amazon-nova-micro-v1.0"
    ],
    "provider": "Amazon",
    "context_window": 130000,
    "open_source": null,
    "arena_votes": 19355,
    "license_type": "Proprietary",
    "creator": "Amazon",
    "intelligence_score": 10.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1240.96,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.06,
    "latency_seconds": 0.35,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 367.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782954+00:00",
        "confidence": 0.65,
        "raw_name": "Nova Micro",
        "raw_scores": {
          "intelligence_score": 10.0,
          "blended_cost_per_1m": 0.06,
          "latency_seconds": 0.35,
          "tokens_per_second": 367.0,
          "context_window": 130000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226563+00:00",
        "confidence": 1.0,
        "raw_name": "amazon-nova-micro-v1.0",
        "raw_scores": {
          "arena_elo": 1240.96,
          "arena_votes": 19355
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1240.96
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemma-3-27b",
    "canonical_name": "Gemma 3 27B",
    "model_name": "Gemma 3 27B",
    "aliases": [
      "Gemma 3 27B"
    ],
    "provider": "Google",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Google",
    "intelligence_score": 10.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.85,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 34.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782973+00:00",
        "confidence": 0.65,
        "raw_name": "Gemma 3 27B",
        "raw_scores": {
          "intelligence_score": 10.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.85,
          "tokens_per_second": 34.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "mistral-small",
    "canonical_name": "Mistral Small (Sep)",
    "model_name": "Mistral Small (Sep)",
    "aliases": [
      "Mistral Small (Feb)",
      "Mistral Small (Sep)"
    ],
    "provider": "Mistral AI",
    "context_window": 33000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 9.5,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.9,
    "latency_seconds": 0.315,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 133.5,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.782992+00:00",
        "confidence": 0.65,
        "raw_name": "Mistral Small (Sep)",
        "raw_scores": {
          "intelligence_score": 10.0,
          "blended_cost_per_1m": 0.3,
          "latency_seconds": 0.32,
          "tokens_per_second": 129.0,
          "context_window": 33000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783553+00:00",
        "confidence": 0.65,
        "raw_name": "Mistral Small (Feb)",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 1.5,
          "latency_seconds": 0.31,
          "tokens_per_second": 138.0,
          "context_window": 33000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemini-10-ultra",
    "canonical_name": "Gemini 1.0 Ultra",
    "model_name": "Gemini 1.0 Ultra",
    "aliases": [
      "Gemini 1.0 Ultra"
    ],
    "provider": "Google",
    "context_window": 33000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Google",
    "intelligence_score": 10.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783010+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 1.0 Ultra",
        "raw_scores": {
          "intelligence_score": 10.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 33000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "phi-3-mini",
    "canonical_name": "Phi-3 Mini",
    "model_name": "Phi-3 Mini",
    "aliases": [
      "Phi-3 Mini"
    ],
    "provider": "Microsoft",
    "context_window": 4000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Microsoft Azure",
    "intelligence_score": 10.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.23,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783046+00:00",
        "confidence": 0.65,
        "raw_name": "Phi-3 Mini",
        "raw_scores": {
          "intelligence_score": 10.0,
          "blended_cost_per_1m": 0.23,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 4000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemma-3n-e4b",
    "canonical_name": "Gemma 3n E4B (May)",
    "model_name": "Gemma 3n E4B (May)",
    "aliases": [
      "Gemma 3n E4B",
      "Gemma 3n E4B (May)"
    ],
    "provider": "Google",
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Google",
    "intelligence_score": 8.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.015,
    "latency_seconds": 0.185,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 23.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783065+00:00",
        "confidence": 0.65,
        "raw_name": "Gemma 3n E4B (May)",
        "raw_scores": {
          "intelligence_score": 10.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784406+00:00",
        "confidence": 0.65,
        "raw_name": "Gemma 3n E4B",
        "raw_scores": {
          "intelligence_score": 6.0,
          "blended_cost_per_1m": 0.03,
          "latency_seconds": 0.37,
          "tokens_per_second": 46.0,
          "context_window": 32000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "phi-4-multimodal",
    "canonical_name": "Phi-4 Multimodal",
    "model_name": "Phi-4 Multimodal",
    "aliases": [
      "Phi-4 Multimodal"
    ],
    "provider": "Microsoft",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Microsoft Azure",
    "intelligence_score": 10.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.36,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 17.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783083+00:00",
        "confidence": 0.65,
        "raw_name": "Phi-4 Multimodal",
        "raw_scores": {
          "intelligence_score": 10.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.36,
          "tokens_per_second": 17.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen25-coder-7b",
    "canonical_name": "Qwen2.5 Coder 7B",
    "model_name": "Qwen2.5 Coder 7B",
    "aliases": [
      "Qwen2.5 Coder 7B"
    ],
    "provider": "Alibaba",
    "context_window": 131000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 10.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783101+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen2.5 Coder 7B",
        "raw_scores": {
          "intelligence_score": 10.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 131000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "mistral-large",
    "canonical_name": "Mistral Large (Feb)",
    "model_name": "Mistral Large (Feb)",
    "aliases": [
      "Mistral Large (Feb)"
    ],
    "provider": "Mistral AI",
    "context_window": 33000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 10.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 6.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783118+00:00",
        "confidence": 0.65,
        "raw_name": "Mistral Large (Feb)",
        "raw_scores": {
          "intelligence_score": 10.0,
          "blended_cost_per_1m": 6.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 33000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "mixtral-8x22b",
    "canonical_name": "Mixtral 8x22B",
    "model_name": "Mixtral 8x22B",
    "aliases": [
      "Mixtral 8x22B"
    ],
    "provider": "Mistral AI",
    "context_window": 65000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 10.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783136+00:00",
        "confidence": 0.65,
        "raw_name": "Mixtral 8x22B",
        "raw_scores": {
          "intelligence_score": 10.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 65000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-32-3b",
    "canonical_name": "Llama 3.2 3B",
    "model_name": "Llama 3.2 3B",
    "aliases": [
      "Llama 3.2 3B"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Meta",
    "intelligence_score": 10.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.08,
    "latency_seconds": 0.46,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 48.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783154+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 3.2 3B",
        "raw_scores": {
          "intelligence_score": 10.0,
          "blended_cost_per_1m": 0.08,
          "latency_seconds": 0.46,
          "tokens_per_second": 48.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen15-chat-110b",
    "canonical_name": "Qwen1.5 Chat 110B",
    "model_name": "Qwen1.5 Chat 110B",
    "aliases": [
      "Qwen1.5 Chat 110B"
    ],
    "provider": "Alibaba",
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 10.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783172+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen1.5 Chat 110B",
        "raw_scores": {
          "intelligence_score": 10.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "reka-flash-3",
    "canonical_name": "Reka Flash 3",
    "model_name": "Reka Flash 3",
    "aliases": [
      "Reka Flash 3"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Reka AI",
    "intelligence_score": 10.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.35,
    "latency_seconds": 1.32,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 49.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783191+00:00",
        "confidence": 0.65,
        "raw_name": "Reka Flash 3",
        "raw_scores": {
          "intelligence_score": 10.0,
          "blended_cost_per_1m": 0.35,
          "latency_seconds": 1.32,
          "tokens_per_second": 49.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "olmo-3-7b-think",
    "canonical_name": "Olmo 3 7B Think",
    "model_name": "Olmo 3 7B Think",
    "aliases": [
      "Olmo 3 7B Think"
    ],
    "provider": null,
    "context_window": 66000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Allen Institute for AI",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.14,
    "latency_seconds": 0.47,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 71.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783227+00:00",
        "confidence": 0.65,
        "raw_name": "Olmo 3 7B Think",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 0.14,
          "latency_seconds": 0.47,
          "tokens_per_second": 71.0,
          "context_window": 66000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "claude-21",
    "canonical_name": "Claude 2.1",
    "model_name": "Claude 2.1",
    "aliases": [
      "Claude 2.1"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Anthropic",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783246+00:00",
        "confidence": 0.65,
        "raw_name": "Claude 2.1",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 200000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "olmo-2-7b",
    "canonical_name": "OLMo 2 7B",
    "model_name": "OLMo 2 7B",
    "aliases": [
      "OLMo 2 7B"
    ],
    "provider": null,
    "context_window": 4000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Allen Institute for AI",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783264+00:00",
        "confidence": 0.65,
        "raw_name": "OLMo 2 7B",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 4000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "jamba-17-large",
    "canonical_name": "Jamba 1.7 Large",
    "model_name": "Jamba 1.7 Large",
    "aliases": [
      "Jamba 1.7 Large"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "AI21 Labs",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.5,
    "latency_seconds": 0.78,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 52.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783282+00:00",
        "confidence": 0.65,
        "raw_name": "Jamba 1.7 Large",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 3.5,
          "latency_seconds": 0.78,
          "tokens_per_second": 52.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "molmo-7b-d",
    "canonical_name": "Molmo 7B-D",
    "model_name": "Molmo 7B-D",
    "aliases": [
      "Molmo 7B-D"
    ],
    "provider": null,
    "context_window": 4000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Allen Institute for AI",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783300+00:00",
        "confidence": 0.65,
        "raw_name": "Molmo 7B-D",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 4000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-r1-distill-qwen-15b",
    "canonical_name": "DeepSeek R1 Distill Qwen 1.5B",
    "model_name": "DeepSeek R1 Distill Qwen 1.5B",
    "aliases": [
      "DeepSeek R1 Distill Qwen 1.5B"
    ],
    "provider": "Alibaba",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "DeepSeek",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783470+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek R1 Distill Qwen 1.5B",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "claude-20",
    "canonical_name": "Claude 2.0",
    "model_name": "Claude 2.0",
    "aliases": [
      "Claude 2.0"
    ],
    "provider": "Anthropic",
    "context_window": 100000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Anthropic",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783490+00:00",
        "confidence": 0.65,
        "raw_name": "Claude 2.0",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 100000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-v2",
    "canonical_name": "DeepSeek-V2",
    "model_name": "DeepSeek-V2",
    "aliases": [
      "DeepSeek-V2"
    ],
    "provider": "DeepSeek",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "DeepSeek",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783508+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek-V2",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "mistral-medium",
    "canonical_name": "Mistral Medium",
    "model_name": "Mistral Medium",
    "aliases": [
      "Mistral Medium",
      "mistral-medium",
      "mistral-medium-2508"
    ],
    "provider": "Mistral",
    "context_window": 33000,
    "open_source": null,
    "arena_votes": 65199,
    "license_type": "Proprietary",
    "creator": "Mistral",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1317.2,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 4.09,
    "latency_seconds": 0.39,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 99.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783576+00:00",
        "confidence": 0.65,
        "raw_name": "Mistral Medium",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 4.09,
          "latency_seconds": 0.39,
          "tokens_per_second": 99.0,
          "context_window": 33000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224327+00:00",
        "confidence": 1.0,
        "raw_name": "mistral-medium-2508",
        "raw_scores": {
          "arena_elo": 1411.26,
          "arena_votes": 65199
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226727+00:00",
        "confidence": 1.0,
        "raw_name": "mistral-medium",
        "raw_scores": {
          "arena_elo": 1223.14,
          "arena_votes": 34552
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1411.26
      }
    },
    "confidence_score": 0.8833,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gpt-35-turbo",
    "canonical_name": "GPT-3.5 Turbo",
    "model_name": "GPT-3.5 Turbo",
    "aliases": [
      "GPT-3.5 Turbo",
      "GPT-3.5 Turbo (0613)"
    ],
    "provider": "OpenAI",
    "context_window": 4000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "OpenAI",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.3963,
    "latency_seconds": 0.185,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 47.0325,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783595+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-3.5 Turbo",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 0.75,
          "latency_seconds": 0.35,
          "tokens_per_second": 89.0,
          "context_window": 4000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784722+00:00",
        "confidence": 0.5800000000000001,
        "raw_name": "GPT-3.5 Turbo (0613)",
        "raw_scores": {
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 4000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      }
    },
    "confidence_score": 0.615,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "ling-mini-20",
    "canonical_name": "Ling-mini-2.0",
    "model_name": "Ling-mini-2.0",
    "aliases": [
      "Ling-mini-2.0"
    ],
    "provider": null,
    "context_window": 131000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "InclusionAI",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.12,
    "latency_seconds": 1.41,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 148.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783613+00:00",
        "confidence": 0.65,
        "raw_name": "Ling-mini-2.0",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 0.12,
          "latency_seconds": 1.41,
          "tokens_per_second": 148.0,
          "context_window": 131000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "arctic",
    "canonical_name": "Arctic",
    "model_name": "Arctic",
    "aliases": [
      "Arctic"
    ],
    "provider": null,
    "context_window": 4000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Snowflake",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783631+00:00",
        "confidence": 0.65,
        "raw_name": "Arctic",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 4000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen-chat-72b",
    "canonical_name": "Qwen Chat 72B",
    "model_name": "Qwen Chat 72B",
    "aliases": [
      "Qwen Chat 72B"
    ],
    "provider": "Alibaba",
    "context_window": 34000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783649+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen Chat 72B",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 34000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-3-70b",
    "canonical_name": "Llama 3 70B",
    "model_name": "Llama 3 70B",
    "aliases": [
      "Llama 3 70B"
    ],
    "provider": "Meta",
    "context_window": 8000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Meta",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.87,
    "latency_seconds": 0.44,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 39.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783667+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 3 70B",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 0.87,
          "latency_seconds": 0.44,
          "tokens_per_second": 39.0,
          "context_window": 8000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemma-3-12b",
    "canonical_name": "Gemma 3 12B",
    "model_name": "Gemma 3 12B",
    "aliases": [
      "Gemma 3 12B"
    ],
    "provider": "Google",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Google",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 13.68,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 32.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783685+00:00",
        "confidence": 0.65,
        "raw_name": "Gemma 3 12B",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 13.68,
          "tokens_per_second": 32.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-32-11b",
    "canonical_name": "Llama 3.2 11B (Vision)",
    "model_name": "Llama 3.2 11B (Vision)",
    "aliases": [
      "Llama 3.2 11B (Vision)"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Meta",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.16,
    "latency_seconds": 0.44,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 55.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783703+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 3.2 11B (Vision)",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 0.16,
          "latency_seconds": 0.44,
          "tokens_per_second": 55.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "lfm-40b",
    "canonical_name": "LFM 40B",
    "model_name": "LFM 40B",
    "aliases": [
      "LFM 40B"
    ],
    "provider": null,
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Liquid AI",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783721+00:00",
        "confidence": 0.65,
        "raw_name": "LFM 40B",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "palm-2",
    "canonical_name": "PALM-2",
    "model_name": "PALM-2",
    "aliases": [
      "PALM-2",
      "palm-2"
    ],
    "provider": "Google",
    "context_window": 8000,
    "open_source": null,
    "arena_votes": 8554,
    "license_type": "Proprietary",
    "creator": "Google",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1137.33,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783739+00:00",
        "confidence": 0.65,
        "raw_name": "PALM-2",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 8000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227315+00:00",
        "confidence": 1.0,
        "raw_name": "palm-2",
        "raw_scores": {
          "arena_elo": 1137.33,
          "arena_votes": 8554
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1137.33
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemini-10-pro",
    "canonical_name": "Gemini 1.0 Pro",
    "model_name": "Gemini 1.0 Pro",
    "aliases": [
      "Gemini 1.0 Pro"
    ],
    "provider": "Google",
    "context_window": 33000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Google",
    "intelligence_score": 9.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783757+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 1.0 Pro",
        "raw_scores": {
          "intelligence_score": 9.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 33000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-coder-v2-lite",
    "canonical_name": "DeepSeek Coder V2 Lite",
    "model_name": "DeepSeek Coder V2 Lite",
    "aliases": [
      "DeepSeek Coder V2 Lite"
    ],
    "provider": "DeepSeek",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "DeepSeek",
    "intelligence_score": 8.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783774+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek Coder V2 Lite",
        "raw_scores": {
          "intelligence_score": 8.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-llm-67b",
    "canonical_name": "DeepSeek LLM 67B (V1)",
    "model_name": "DeepSeek LLM 67B (V1)",
    "aliases": [
      "DeepSeek LLM 67B (V1)"
    ],
    "provider": "DeepSeek",
    "context_window": 4000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "DeepSeek",
    "intelligence_score": 8.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783792+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek LLM 67B (V1)",
        "raw_scores": {
          "intelligence_score": 8.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 4000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "command-r",
    "canonical_name": "Command-R+ (Apr)",
    "model_name": "Command-R+ (Apr)",
    "aliases": [
      "Command-R (Mar)",
      "Command-R+ (Apr)",
      "command-r"
    ],
    "provider": "Cohere",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 54038,
    "license_type": "CC-BY-NC-4.0",
    "creator": "Cohere",
    "intelligence_score": 7.5,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1227.12,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.375,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783809+00:00",
        "confidence": 0.65,
        "raw_name": "Command-R+ (Apr)",
        "raw_scores": {
          "intelligence_score": 8.0,
          "blended_cost_per_1m": 6.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784208+00:00",
        "confidence": 0.65,
        "raw_name": "Command-R (Mar)",
        "raw_scores": {
          "intelligence_score": 7.0,
          "blended_cost_per_1m": 0.75,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226676+00:00",
        "confidence": 1.0,
        "raw_name": "command-r",
        "raw_scores": {
          "arena_elo": 1227.12,
          "arena_votes": 54038
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1227.12
      }
    },
    "confidence_score": 0.7667,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "openchat-35",
    "canonical_name": "OpenChat 3.5",
    "model_name": "OpenChat 3.5",
    "aliases": [
      "OpenChat 3.5",
      "openchat-3.5"
    ],
    "provider": "OpenChat",
    "context_window": 8000,
    "open_source": null,
    "arena_votes": 7967,
    "license_type": "Apache-2.0",
    "creator": "OpenChat",
    "intelligence_score": 8.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1182.4,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783827+00:00",
        "confidence": 0.65,
        "raw_name": "OpenChat 3.5",
        "raw_scores": {
          "intelligence_score": 8.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 8000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226970+00:00",
        "confidence": 1.0,
        "raw_name": "openchat-3.5",
        "raw_scores": {
          "arena_elo": 1182.4,
          "arena_votes": 7967
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1182.4
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "dbrx",
    "canonical_name": "DBRX",
    "model_name": "DBRX",
    "aliases": [
      "DBRX"
    ],
    "provider": "Databricks",
    "context_window": 33000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Databricks",
    "intelligence_score": 8.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783845+00:00",
        "confidence": 0.65,
        "raw_name": "DBRX",
        "raw_scores": {
          "intelligence_score": 8.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 33000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "phi-4-mini",
    "canonical_name": "Phi-4 Mini",
    "model_name": "Phi-4 Mini",
    "aliases": [
      "Phi-4 Mini"
    ],
    "provider": "Microsoft",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Microsoft Azure",
    "intelligence_score": 8.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.32,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 44.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783863+00:00",
        "confidence": 0.65,
        "raw_name": "Phi-4 Mini",
        "raw_scores": {
          "intelligence_score": 8.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.32,
          "tokens_per_second": 44.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "exaone-40-12b",
    "canonical_name": "Exaone 4.0 1.2B",
    "model_name": "Exaone 4.0 1.2B",
    "aliases": [
      "Exaone 4.0 1.2B"
    ],
    "provider": null,
    "context_window": 64000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "LG AI Research",
    "intelligence_score": 8.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783880+00:00",
        "confidence": 0.65,
        "raw_name": "Exaone 4.0 1.2B",
        "raw_scores": {
          "intelligence_score": 8.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 64000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "olmo-3-7b",
    "canonical_name": "Olmo 3 7B",
    "model_name": "Olmo 3 7B",
    "aliases": [
      "Olmo 3 7B"
    ],
    "provider": null,
    "context_window": 66000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Allen Institute for AI",
    "intelligence_score": 8.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.13,
    "latency_seconds": 0.46,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 38.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783903+00:00",
        "confidence": 0.65,
        "raw_name": "Olmo 3 7B",
        "raw_scores": {
          "intelligence_score": 8.0,
          "blended_cost_per_1m": 0.13,
          "latency_seconds": 0.46,
          "tokens_per_second": 38.0,
          "context_window": 66000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "lfm25-12b-thinking",
    "canonical_name": "LFM2.5-1.2B-Thinking",
    "model_name": "LFM2.5-1.2B-Thinking",
    "aliases": [
      "LFM2.5-1.2B-Thinking"
    ],
    "provider": null,
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Liquid AI",
    "intelligence_score": 8.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783921+00:00",
        "confidence": 0.65,
        "raw_name": "LFM2.5-1.2B-Thinking",
        "raw_scores": {
          "intelligence_score": 8.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "jamba-15-mini",
    "canonical_name": "Jamba 1.5 Mini",
    "model_name": "Jamba 1.5 Mini",
    "aliases": [
      "Jamba 1.5 Mini",
      "jamba-1.5-mini"
    ],
    "provider": "AI21 Labs",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": 8854,
    "license_type": "Jamba Open",
    "creator": "AI21 Labs",
    "intelligence_score": 8.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1239.0,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.25,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783957+00:00",
        "confidence": 0.65,
        "raw_name": "Jamba 1.5 Mini",
        "raw_scores": {
          "intelligence_score": 8.0,
          "blended_cost_per_1m": 0.25,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 256000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226576+00:00",
        "confidence": 1.0,
        "raw_name": "jamba-1.5-mini",
        "raw_scores": {
          "arena_elo": 1239.0,
          "arena_votes": 8854
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1239.0
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "solar-mini",
    "canonical_name": "Solar Mini",
    "model_name": "Solar Mini",
    "aliases": [
      "Solar Mini"
    ],
    "provider": null,
    "context_window": 4000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Upstage",
    "intelligence_score": 8.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.15,
    "latency_seconds": 1.39,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 82.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783976+00:00",
        "confidence": 0.65,
        "raw_name": "Solar Mini",
        "raw_scores": {
          "intelligence_score": 8.0,
          "blended_cost_per_1m": 0.15,
          "latency_seconds": 1.39,
          "tokens_per_second": 82.0,
          "context_window": 4000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "granite-40-h-1b",
    "canonical_name": "Granite 4.0 H 1B",
    "model_name": "Granite 4.0 H 1B",
    "aliases": [
      "Granite 4.0 H 1B"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "IBM",
    "intelligence_score": 8.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.783994+00:00",
        "confidence": 0.65,
        "raw_name": "Granite 4.0 H 1B",
        "raw_scores": {
          "intelligence_score": 8.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "lfm25-12b-instruct",
    "canonical_name": "LFM2.5-1.2B-Instruct",
    "model_name": "LFM2.5-1.2B-Instruct",
    "aliases": [
      "LFM2.5-1.2B-Instruct"
    ],
    "provider": null,
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Liquid AI",
    "intelligence_score": 8.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784012+00:00",
        "confidence": 0.65,
        "raw_name": "LFM2.5-1.2B-Instruct",
        "raw_scores": {
          "intelligence_score": 8.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-17b",
    "canonical_name": "Qwen3 1.7B",
    "model_name": "Qwen3 1.7B",
    "aliases": [
      "Qwen3 1.7B"
    ],
    "provider": "Alibaba",
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 8.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.4,
    "latency_seconds": 0.91,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 125.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784030+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 1.7B",
        "raw_scores": {
          "intelligence_score": 8.0,
          "blended_cost_per_1m": 0.4,
          "latency_seconds": 0.91,
          "tokens_per_second": 125.0,
          "context_window": 32000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "jamba-16-mini",
    "canonical_name": "Jamba 1.6 Mini",
    "model_name": "Jamba 1.6 Mini",
    "aliases": [
      "Jamba 1.6 Mini"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "AI21 Labs",
    "intelligence_score": 8.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.25,
    "latency_seconds": 0.65,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 177.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784048+00:00",
        "confidence": 0.65,
        "raw_name": "Jamba 1.6 Mini",
        "raw_scores": {
          "intelligence_score": 8.0,
          "blended_cost_per_1m": 0.25,
          "latency_seconds": 0.65,
          "tokens_per_second": 177.0,
          "context_window": 256000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "lfm2-26b",
    "canonical_name": "LFM2 2.6B",
    "model_name": "LFM2 2.6B",
    "aliases": [
      "LFM2 2.6B"
    ],
    "provider": null,
    "context_window": 33000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Liquid AI",
    "intelligence_score": 8.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784066+00:00",
        "confidence": 0.65,
        "raw_name": "LFM2 2.6B",
        "raw_scores": {
          "intelligence_score": 8.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 33000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "mixtral-8x7b",
    "canonical_name": "Mixtral 8x7B",
    "model_name": "Mixtral 8x7B",
    "aliases": [
      "Mixtral 8x7B"
    ],
    "provider": "Mistral AI",
    "context_window": 33000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 8.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.54,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784084+00:00",
        "confidence": 0.65,
        "raw_name": "Mixtral 8x7B",
        "raw_scores": {
          "intelligence_score": 8.0,
          "blended_cost_per_1m": 0.54,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 33000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "granite-40-micro",
    "canonical_name": "Granite 4.0 Micro",
    "model_name": "Granite 4.0 Micro",
    "aliases": [
      "Granite 4.0 Micro"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "IBM",
    "intelligence_score": 8.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784101+00:00",
        "confidence": 0.65,
        "raw_name": "Granite 4.0 Micro",
        "raw_scores": {
          "intelligence_score": 8.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "deephermes-3---llama-31-8b",
    "canonical_name": "DeepHermes 3 - Llama-3.1 8B",
    "model_name": "DeepHermes 3 - Llama-3.1 8B",
    "aliases": [
      "DeepHermes 3 - Llama-3.1 8B"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Nous Research",
    "intelligence_score": 8.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784118+00:00",
        "confidence": 0.65,
        "raw_name": "DeepHermes 3 - Llama-3.1 8B",
        "raw_scores": {
          "intelligence_score": 8.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemma-3-270m",
    "canonical_name": "Gemma 3 270M",
    "model_name": "Gemma 3 270M",
    "aliases": [
      "Gemma 3 270M"
    ],
    "provider": "Google",
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Google",
    "intelligence_score": 7.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784136+00:00",
        "confidence": 0.65,
        "raw_name": "Gemma 3 270M",
        "raw_scores": {
          "intelligence_score": 7.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 7.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen-chat-14b",
    "canonical_name": "Qwen Chat 14B",
    "model_name": "Qwen Chat 14B",
    "aliases": [
      "Qwen Chat 14B"
    ],
    "provider": "Alibaba",
    "context_window": 8000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 7.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784154+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen Chat 14B",
        "raw_scores": {
          "intelligence_score": 7.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 8000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 7.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "claude-instant",
    "canonical_name": "Claude Instant",
    "model_name": "Claude Instant",
    "aliases": [
      "Claude Instant"
    ],
    "provider": "Anthropic",
    "context_window": 100000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Anthropic",
    "intelligence_score": 7.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784171+00:00",
        "confidence": 0.65,
        "raw_name": "Claude Instant",
        "raw_scores": {
          "intelligence_score": 7.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 100000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 7.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "mistral-7b",
    "canonical_name": "Mistral 7B",
    "model_name": "Mistral 7B",
    "aliases": [
      "Mistral 7B"
    ],
    "provider": "Mistral AI",
    "context_window": 8000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Mistral",
    "intelligence_score": 7.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.25,
    "latency_seconds": 0.29,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 145.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784190+00:00",
        "confidence": 0.65,
        "raw_name": "Mistral 7B",
        "raw_scores": {
          "intelligence_score": 7.0,
          "blended_cost_per_1m": 0.25,
          "latency_seconds": 0.29,
          "tokens_per_second": 145.0,
          "context_window": 8000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 7.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "jamba-17-mini",
    "canonical_name": "Jamba 1.7 Mini",
    "model_name": "Jamba 1.7 Mini",
    "aliases": [
      "Jamba 1.7 Mini"
    ],
    "provider": null,
    "context_window": 258000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "AI21 Labs",
    "intelligence_score": 7.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784225+00:00",
        "confidence": 0.65,
        "raw_name": "Jamba 1.7 Mini",
        "raw_scores": {
          "intelligence_score": 7.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 258000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 7.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "granite-40-1b",
    "canonical_name": "Granite 4.0 1B",
    "model_name": "Granite 4.0 1B",
    "aliases": [
      "Granite 4.0 1B"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "IBM",
    "intelligence_score": 7.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784243+00:00",
        "confidence": 0.65,
        "raw_name": "Granite 4.0 1B",
        "raw_scores": {
          "intelligence_score": 7.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 7.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-2-chat-70b",
    "canonical_name": "Llama 2 Chat 70B",
    "model_name": "Llama 2 Chat 70B",
    "aliases": [
      "Llama 2 Chat 70B"
    ],
    "provider": "Meta",
    "context_window": 4000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Meta",
    "intelligence_score": 7.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784260+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 2 Chat 70B",
        "raw_scores": {
          "intelligence_score": 7.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 4000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 7.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "lfm2-8b-a1b",
    "canonical_name": "LFM2 8B A1B",
    "model_name": "LFM2 8B A1B",
    "aliases": [
      "LFM2 8B A1B"
    ],
    "provider": null,
    "context_window": 33000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Liquid AI",
    "intelligence_score": 7.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784278+00:00",
        "confidence": 0.65,
        "raw_name": "LFM2 8B A1B",
        "raw_scores": {
          "intelligence_score": 7.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 33000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 7.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "granite-33-8b",
    "canonical_name": "Granite 3.3 8B",
    "model_name": "Granite 3.3 8B",
    "aliases": [
      "Granite 3.3 8B"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "IBM",
    "intelligence_score": 7.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.09,
    "latency_seconds": 20.5,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 529.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784296+00:00",
        "confidence": 0.65,
        "raw_name": "Granite 3.3 8B",
        "raw_scores": {
          "intelligence_score": 7.0,
          "blended_cost_per_1m": 0.09,
          "latency_seconds": 20.5,
          "tokens_per_second": 529.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 7.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "granite-40-350m",
    "canonical_name": "Granite 4.0 350M",
    "model_name": "Granite 4.0 350M",
    "aliases": [
      "Granite 4.0 350M"
    ],
    "provider": null,
    "context_window": 33000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "IBM",
    "intelligence_score": 7.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784332+00:00",
        "confidence": 0.65,
        "raw_name": "Granite 4.0 350M",
        "raw_scores": {
          "intelligence_score": 7.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 33000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 7.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-06b",
    "canonical_name": "Qwen3 0.6B",
    "model_name": "Qwen3 0.6B",
    "aliases": [
      "Qwen3 0.6B"
    ],
    "provider": "Alibaba",
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Alibaba",
    "intelligence_score": 6.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.4,
    "latency_seconds": 0.86,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 202.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784352+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 0.6B",
        "raw_scores": {
          "intelligence_score": 6.0,
          "blended_cost_per_1m": 0.4,
          "latency_seconds": 0.86,
          "tokens_per_second": 202.0,
          "context_window": 32000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 6.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "lfm2-12b",
    "canonical_name": "LFM2 1.2B",
    "model_name": "LFM2 1.2B",
    "aliases": [
      "LFM2 1.2B"
    ],
    "provider": null,
    "context_window": 33000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Liquid AI",
    "intelligence_score": 6.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784370+00:00",
        "confidence": 0.65,
        "raw_name": "LFM2 1.2B",
        "raw_scores": {
          "intelligence_score": 6.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 33000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 6.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemma-3-4b",
    "canonical_name": "Gemma 3 4B",
    "model_name": "Gemma 3 4B",
    "aliases": [
      "Gemma 3 4B"
    ],
    "provider": "Google",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Google",
    "intelligence_score": 6.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 1.03,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 33.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784388+00:00",
        "confidence": 0.65,
        "raw_name": "Gemma 3 4B",
        "raw_scores": {
          "intelligence_score": 6.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 1.03,
          "tokens_per_second": 33.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 6.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-32-1b",
    "canonical_name": "Llama 3.2 1B",
    "model_name": "Llama 3.2 1B",
    "aliases": [
      "Llama 3.2 1B"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Meta",
    "intelligence_score": 6.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.1,
    "latency_seconds": 0.53,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 140.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784428+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 3.2 1B",
        "raw_scores": {
          "intelligence_score": 6.0,
          "blended_cost_per_1m": 0.1,
          "latency_seconds": 0.53,
          "tokens_per_second": 140.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 6.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-3-8b",
    "canonical_name": "Llama 3 8B",
    "model_name": "Llama 3 8B",
    "aliases": [
      "Llama 3 8B"
    ],
    "provider": "Meta",
    "context_window": 8000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Meta",
    "intelligence_score": 6.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.07,
    "latency_seconds": 0.38,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 69.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784446+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 3 8B",
        "raw_scores": {
          "intelligence_score": 6.0,
          "blended_cost_per_1m": 0.07,
          "latency_seconds": 0.38,
          "tokens_per_second": 69.0,
          "context_window": 8000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 6.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "lfm25-vl-16b",
    "canonical_name": "LFM2.5-VL-1.6B",
    "model_name": "LFM2.5-VL-1.6B",
    "aliases": [
      "LFM2.5-VL-1.6B"
    ],
    "provider": null,
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Liquid AI",
    "intelligence_score": 6.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784464+00:00",
        "confidence": 0.65,
        "raw_name": "LFM2.5-VL-1.6B",
        "raw_scores": {
          "intelligence_score": 6.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 6.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemma-3-1b",
    "canonical_name": "Gemma 3 1B",
    "model_name": "Gemma 3 1B",
    "aliases": [
      "Gemma 3 1B"
    ],
    "provider": "Google",
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Google",
    "intelligence_score": 5.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.54,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 43.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784500+00:00",
        "confidence": 0.65,
        "raw_name": "Gemma 3 1B",
        "raw_scores": {
          "intelligence_score": 5.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.54,
          "tokens_per_second": 43.0,
          "context_window": 32000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 5.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "granite-40-h-350m",
    "canonical_name": "Granite 4.0 H 350M",
    "model_name": "Granite 4.0 H 350M",
    "aliases": [
      "Granite 4.0 H 350M"
    ],
    "provider": null,
    "context_window": 33000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "IBM",
    "intelligence_score": 5.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784518+00:00",
        "confidence": 0.65,
        "raw_name": "Granite 4.0 H 350M",
        "raw_scores": {
          "intelligence_score": 5.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 33000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 5.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-2-chat-13b",
    "canonical_name": "Llama 2 Chat 13B",
    "model_name": "Llama 2 Chat 13B",
    "aliases": [
      "Llama 2 Chat 13B"
    ],
    "provider": "Meta",
    "context_window": 4000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Meta",
    "intelligence_score": 5.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784548+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 2 Chat 13B",
        "raw_scores": {
          "intelligence_score": 5.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 4000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 5.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemma-3n-e2b",
    "canonical_name": "Gemma 3n E2B",
    "model_name": "Gemma 3n E2B",
    "aliases": [
      "Gemma 3n E2B"
    ],
    "provider": "Google",
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Google",
    "intelligence_score": 5.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.38,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 49.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784566+00:00",
        "confidence": 0.65,
        "raw_name": "Gemma 3n E2B",
        "raw_scores": {
          "intelligence_score": 5.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.38,
          "tokens_per_second": 49.0,
          "context_window": 32000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 5.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "tiny-aya-global",
    "canonical_name": "Tiny Aya Global",
    "model_name": "Tiny Aya Global",
    "aliases": [
      "Tiny Aya Global"
    ],
    "provider": null,
    "context_window": 8000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Cohere",
    "intelligence_score": 5.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784584+00:00",
        "confidence": 0.65,
        "raw_name": "Tiny Aya Global",
        "raw_scores": {
          "intelligence_score": 5.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 8000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 5.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-65b",
    "canonical_name": "Llama 65B",
    "model_name": "Llama 65B",
    "aliases": [
      "Llama 65B"
    ],
    "provider": "Meta",
    "context_window": 2000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Meta",
    "intelligence_score": 4.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784602+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 65B",
        "raw_scores": {
          "intelligence_score": 4.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 2000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 4.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-2-chat-7b",
    "canonical_name": "Llama 2 Chat 7B",
    "model_name": "Llama 2 Chat 7B",
    "aliases": [
      "Llama 2 Chat 7B"
    ],
    "provider": "Meta",
    "context_window": 4000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Meta",
    "intelligence_score": 4.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.1,
    "latency_seconds": 0.53,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 117.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784620+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 2 Chat 7B",
        "raw_scores": {
          "intelligence_score": 4.0,
          "blended_cost_per_1m": 0.1,
          "latency_seconds": 0.53,
          "tokens_per_second": 117.0,
          "context_window": 4000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 4.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "grok-voice-agent",
    "canonical_name": "Grok Voice Agent",
    "model_name": "Grok Voice Agent",
    "aliases": [
      "Grok Voice Agent"
    ],
    "provider": "xAI",
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "xAI",
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784637+00:00",
        "confidence": 0.5800000000000001,
        "raw_name": "Grok Voice Agent",
        "raw_scores": {
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32000
        }
      }
    ],
    "benchmark_breakdown": {},
    "confidence_score": 0.58,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "molmo2-8b",
    "canonical_name": "Molmo2-8B",
    "model_name": "Molmo2-8B",
    "aliases": [
      "Molmo2-8B"
    ],
    "provider": null,
    "context_window": 37000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Allen Institute for AI",
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.42,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 114.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784655+00:00",
        "confidence": 0.5800000000000001,
        "raw_name": "Molmo2-8B",
        "raw_scores": {
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.42,
          "tokens_per_second": 114.0,
          "context_window": 37000
        }
      }
    ],
    "benchmark_breakdown": {},
    "confidence_score": 0.58,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "cogito-v21",
    "canonical_name": "Cogito v2.1",
    "model_name": "Cogito v2.1",
    "aliases": [
      "Cogito v2.1"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Deep Cogito",
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.25,
    "latency_seconds": 0.35,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 73.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784672+00:00",
        "confidence": 0.5800000000000001,
        "raw_name": "Cogito v2.1",
        "raw_scores": {
          "blended_cost_per_1m": 1.25,
          "latency_seconds": 0.35,
          "tokens_per_second": 73.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {},
    "confidence_score": 0.58,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "midm-k-25-pro-preview",
    "canonical_name": "Mi:dm K 2.5 Pro Preview",
    "model_name": "Mi:dm K 2.5 Pro Preview",
    "aliases": [
      "Mi:dm K 2.5 Pro Preview"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "Korea Telecom",
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784689+00:00",
        "confidence": 0.5800000000000001,
        "raw_name": "Mi:dm K 2.5 Pro Preview",
        "raw_scores": {
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {},
    "confidence_score": 0.58,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gpt-4o-mini-realtime",
    "canonical_name": "GPT-4o mini Realtime (Dec)",
    "model_name": "GPT-4o mini Realtime (Dec)",
    "aliases": [
      "GPT-4o mini Realtime (Dec)"
    ],
    "provider": "OpenAI",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "OpenAI",
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784705+00:00",
        "confidence": 0.5800000000000001,
        "raw_name": "GPT-4o mini Realtime (Dec)",
        "raw_scores": {
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {},
    "confidence_score": 0.58,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gpt-4o-realtime",
    "canonical_name": "GPT-4o Realtime (Dec)",
    "model_name": "GPT-4o Realtime (Dec)",
    "aliases": [
      "GPT-4o Realtime (Dec)"
    ],
    "provider": "OpenAI",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": "OpenAI",
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-26T11:24:47.784738+00:00",
        "confidence": 0.5800000000000001,
        "raw_name": "GPT-4o Realtime (Dec)",
        "raw_scores": {
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {},
    "confidence_score": 0.58,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "grok-420-beta1",
    "canonical_name": "grok-4.20-beta1",
    "model_name": "grok-4.20-beta1",
    "aliases": [
      "grok-4.20-beta1"
    ],
    "provider": "xAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3695,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1492.22,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.223506+00:00",
        "confidence": 1.0,
        "raw_name": "grok-4.20-beta1",
        "raw_scores": {
          "arena_elo": 1492.22,
          "arena_votes": 3695
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1492.22
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "grok-41",
    "canonical_name": "grok-4.1-thinking",
    "model_name": "grok-4.1-thinking",
    "aliases": [
      "grok-4.1",
      "grok-4.1-thinking"
    ],
    "provider": "xAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 41343,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1467.765,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.223590+00:00",
        "confidence": 1.0,
        "raw_name": "grok-4.1-thinking",
        "raw_scores": {
          "arena_elo": 1473.0,
          "arena_votes": 37167
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.223656+00:00",
        "confidence": 1.0,
        "raw_name": "grok-4.1",
        "raw_scores": {
          "arena_elo": 1462.53,
          "arena_votes": 41343
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1473.0
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "dola-seed-20",
    "canonical_name": "dola-seed-2.0-preview",
    "model_name": "dola-seed-2.0-preview",
    "aliases": [
      "dola-seed-2.0-preview"
    ],
    "provider": "Bytedance",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4180,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1472.4,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.223604+00:00",
        "confidence": 1.0,
        "raw_name": "dola-seed-2.0-preview",
        "raw_scores": {
          "arena_elo": 1472.4,
          "arena_votes": 4180
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1472.4
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "ernie-50",
    "canonical_name": "ernie-5.0-0110",
    "model_name": "ernie-5.0-0110",
    "aliases": [
      "ernie-5.0-0110"
    ],
    "provider": "Baidu",
    "context_window": null,
    "open_source": null,
    "arena_votes": 13419,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1452.87,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.223724+00:00",
        "confidence": 1.0,
        "raw_name": "ernie-5.0-0110",
        "raw_scores": {
          "arena_elo": 1452.87,
          "arena_votes": 13419
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1452.87
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "claude-sonnet-45",
    "canonical_name": "claude-sonnet-4.5-20250929-thinking-32k",
    "model_name": "claude-sonnet-4.5-20250929-thinking-32k",
    "aliases": [
      "claude-sonnet-4.5-20250929",
      "claude-sonnet-4.5-20250929-thinking-32k"
    ],
    "provider": "Anthropic",
    "context_window": null,
    "open_source": null,
    "arena_votes": 48477,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1449.81,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.223765+00:00",
        "confidence": 1.0,
        "raw_name": "claude-sonnet-4.5-20250929-thinking-32k",
        "raw_scores": {
          "arena_elo": 1449.91,
          "arena_votes": 48477
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.223780+00:00",
        "confidence": 1.0,
        "raw_name": "claude-sonnet-4.5-20250929",
        "raw_scores": {
          "arena_elo": 1449.71,
          "arena_votes": 46264
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1449.91
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "ernie-50-preview",
    "canonical_name": "ernie-5.0-preview-1203",
    "model_name": "ernie-5.0-preview-1203",
    "aliases": [
      "ernie-5.0-preview-1022",
      "ernie-5.0-preview-1203"
    ],
    "provider": "Baidu",
    "context_window": null,
    "open_source": null,
    "arena_votes": 9723,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1433.76,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.223806+00:00",
        "confidence": 1.0,
        "raw_name": "ernie-5.0-preview-1203",
        "raw_scores": {
          "arena_elo": 1449.14,
          "arena_votes": 9723
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224166+00:00",
        "confidence": 1.0,
        "raw_name": "ernie-5.0-preview-1022",
        "raw_scores": {
          "arena_elo": 1418.38,
          "arena_votes": 4563
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1449.14
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gpt-45-preview",
    "canonical_name": "gpt-4.5-preview-2025-02-27",
    "model_name": "gpt-4.5-preview-2025-02-27",
    "aliases": [
      "gpt-4.5-preview-2025-02-27"
    ],
    "provider": "OpenAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 14549,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1444.31,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.223850+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-4.5-preview-2025-02-27",
        "raw_scores": {
          "arena_elo": 1444.31,
          "arena_votes": 14549
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1444.31
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "kimi-k25-instant",
    "canonical_name": "kimi-k2.5-instant",
    "model_name": "kimi-k2.5-instant",
    "aliases": [
      "kimi-k2.5-instant"
    ],
    "provider": "Moonshot",
    "context_window": null,
    "open_source": null,
    "arena_votes": 6722,
    "license_type": "Modified MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1435.15,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.223926+00:00",
        "confidence": 1.0,
        "raw_name": "kimi-k2.5-instant",
        "raw_scores": {
          "arena_elo": 1435.15,
          "arena_votes": 6722
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1435.15
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "kimi-k2-turbo",
    "canonical_name": "kimi-k2-thinking-turbo",
    "model_name": "kimi-k2-thinking-turbo",
    "aliases": [
      "kimi-k2-thinking-turbo"
    ],
    "provider": "Moonshot",
    "context_window": null,
    "open_source": null,
    "arena_votes": 35751,
    "license_type": "Modified MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1429.03,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224013+00:00",
        "confidence": 1.0,
        "raw_name": "kimi-k2-thinking-turbo",
        "raw_scores": {
          "arena_elo": 1429.03,
          "arena_votes": 35751
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1429.03
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-vl-235b",
    "canonical_name": "qwen3-vl-235b-a22b-instruct",
    "model_name": "qwen3-vl-235b-a22b-instruct",
    "aliases": [
      "qwen3-vl-235b-a22b-instruct",
      "qwen3-vl-235b-a22b-thinking"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 11599,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1404.87,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224265+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-vl-235b-a22b-instruct",
        "raw_scores": {
          "arena_elo": 1414.79,
          "arena_votes": 11599
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224550+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-vl-235b-a22b-thinking",
        "raw_scores": {
          "arena_elo": 1394.95,
          "arena_votes": 7926
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1414.79
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "amazon-nova-experimental-chat-26-01-10",
    "canonical_name": "amazon-nova-experimental-chat-26-01-10",
    "model_name": "amazon-nova-experimental-chat-26-01-10",
    "aliases": [
      "amazon-nova-experimental-chat-26-01-10"
    ],
    "provider": "Amazon",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3252,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1414.54,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224278+00:00",
        "confidence": 1.0,
        "raw_name": "amazon-nova-experimental-chat-26-01-10",
        "raw_scores": {
          "arena_elo": 1414.54,
          "arena_votes": 3252
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1414.54
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-next-80b",
    "canonical_name": "qwen3-next-80b-a3b-instruct",
    "model_name": "qwen3-next-80b-a3b-instruct",
    "aliases": [
      "qwen3-next-80b-a3b-instruct"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 22675,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1401.65,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224449+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-next-80b-a3b-instruct",
        "raw_scores": {
          "arena_elo": 1401.65,
          "arena_votes": 22675
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1401.65
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "longcat-flash-chat",
    "canonical_name": "longcat-flash-chat",
    "model_name": "longcat-flash-chat",
    "aliases": [
      "longcat-flash-chat"
    ],
    "provider": "Meituan",
    "context_window": null,
    "open_source": null,
    "arena_votes": 11492,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1399.96,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224461+00:00",
        "confidence": 1.0,
        "raw_name": "longcat-flash-chat",
        "raw_scores": {
          "arena_elo": 1399.96,
          "arena_votes": 11492
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1399.96
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "claude-sonnet-4",
    "canonical_name": "claude-sonnet-4-20250514-thinking-32k",
    "model_name": "claude-sonnet-4-20250514-thinking-32k",
    "aliases": [
      "claude-sonnet-4-20250514",
      "claude-sonnet-4-20250514-thinking-32k"
    ],
    "provider": "Anthropic",
    "context_window": null,
    "open_source": null,
    "arena_votes": 41371,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1394.795,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224474+00:00",
        "confidence": 1.0,
        "raw_name": "claude-sonnet-4-20250514-thinking-32k",
        "raw_scores": {
          "arena_elo": 1399.9,
          "arena_votes": 35984
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224666+00:00",
        "confidence": 1.0,
        "raw_name": "claude-sonnet-4-20250514",
        "raw_scores": {
          "arena_elo": 1389.69,
          "arena_votes": 41371
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1399.9
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-235b-a22b-thinking-2507",
    "canonical_name": "qwen3-235b-a22b-thinking-2507",
    "model_name": "qwen3-235b-a22b-thinking-2507",
    "aliases": [
      "qwen3-235b-a22b-thinking-2507"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 9189,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1398.58,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224498+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-235b-a22b-thinking-2507",
        "raw_scores": {
          "arena_elo": 1398.58,
          "arena_votes": 9189
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1398.58
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "nova-experimental",
    "canonical_name": "amazon-nova-experimental-chat-12-10",
    "model_name": "amazon-nova-experimental-chat-12-10",
    "aliases": [
      "amazon-nova-experimental-chat-12-10"
    ],
    "provider": "Amazon",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3700,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1394.63,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224566+00:00",
        "confidence": 1.0,
        "raw_name": "amazon-nova-experimental-chat-12-10",
        "raw_scores": {
          "arena_elo": 1394.63,
          "arena_votes": 3700
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1394.63
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "hunyuan-vision-15",
    "canonical_name": "hunyuan-vision-1.5-thinking",
    "model_name": "hunyuan-vision-1.5-thinking",
    "aliases": [
      "hunyuan-vision-1.5-thinking"
    ],
    "provider": "Tencent",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2216,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1393.72,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224592+00:00",
        "confidence": 1.0,
        "raw_name": "hunyuan-vision-1.5-thinking",
        "raw_scores": {
          "arena_elo": 1393.72,
          "arena_votes": 2216
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1393.72
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "mai-1-preview",
    "canonical_name": "mai-1-preview",
    "model_name": "mai-1-preview",
    "aliases": [
      "mai-1-preview"
    ],
    "provider": "Microsoft AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 18020,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1392.0,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224604+00:00",
        "confidence": 1.0,
        "raw_name": "mai-1-preview",
        "raw_scores": {
          "arena_elo": 1392.0,
          "arena_votes": 18020
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1392.0
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "step-35-flash",
    "canonical_name": "step-3.5-flash",
    "model_name": "step-3.5-flash",
    "aliases": [
      "step-3.5-flash"
    ],
    "provider": "StepFun",
    "context_window": null,
    "open_source": null,
    "arena_votes": 8214,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1390.95,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224628+00:00",
        "confidence": 1.0,
        "raw_name": "step-3.5-flash",
        "raw_scores": {
          "arena_elo": 1390.95,
          "arena_votes": 8214
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1390.95
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "claude-37-sonnet-20250219-thinking-32k",
    "canonical_name": "claude-3.7-sonnet-20250219-thinking-32k",
    "model_name": "claude-3.7-sonnet-20250219-thinking-32k",
    "aliases": [
      "claude-3.7-sonnet-20250219-thinking-32k"
    ],
    "provider": "Anthropic",
    "context_window": null,
    "open_source": null,
    "arena_votes": 39733,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1388.37,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224696+00:00",
        "confidence": 1.0,
        "raw_name": "claude-3.7-sonnet-20250219-thinking-32k",
        "raw_scores": {
          "arena_elo": 1388.37,
          "arena_votes": 39733
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1388.37
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "hunyuan-t1-20250711",
    "canonical_name": "hunyuan-t1-20250711",
    "model_name": "hunyuan-t1-20250711",
    "aliases": [
      "hunyuan-t1-20250711"
    ],
    "provider": "Tencent",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4767,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1386.69,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224741+00:00",
        "confidence": 1.0,
        "raw_name": "hunyuan-t1-20250711",
        "raw_scores": {
          "arena_elo": 1386.69,
          "arena_votes": 4767
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1386.69
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-coder-480b-a35b-instruct",
    "canonical_name": "qwen3-coder-480b-a35b-instruct",
    "model_name": "qwen3-coder-480b-a35b-instruct",
    "aliases": [
      "qwen3-coder-480b-a35b-instruct"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 26414,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1386.57,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224754+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-coder-480b-a35b-instruct",
        "raw_scores": {
          "arena_elo": 1386.57,
          "arena_votes": 26414
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1386.57
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "minimax-m21-preview",
    "canonical_name": "minimax-m2.1-preview",
    "model_name": "minimax-m2.1-preview",
    "aliases": [
      "minimax-m2.1-preview"
    ],
    "provider": "MiniMax",
    "context_window": null,
    "open_source": null,
    "arena_votes": 17099,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1385.54,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224767+00:00",
        "confidence": 1.0,
        "raw_name": "minimax-m2.1-preview",
        "raw_scores": {
          "arena_elo": 1385.54,
          "arena_votes": 17099
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1385.54
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "mistral-medium-2505",
    "canonical_name": "mistral-medium-2505",
    "model_name": "mistral-medium-2505",
    "aliases": [
      "mistral-medium-2505"
    ],
    "provider": "Mistral",
    "context_window": null,
    "open_source": null,
    "arena_votes": 34390,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1384.6,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224779+00:00",
        "confidence": 1.0,
        "raw_name": "mistral-medium-2505",
        "raw_scores": {
          "arena_elo": 1384.6,
          "arena_votes": 34390
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1384.6
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-30b-a3b-instruct-2507",
    "canonical_name": "qwen3-30b-a3b-instruct-2507",
    "model_name": "qwen3-30b-a3b-instruct-2507",
    "aliases": [
      "qwen3-30b-a3b-instruct-2507"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 23952,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1383.77,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224792+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-30b-a3b-instruct-2507",
        "raw_scores": {
          "arena_elo": 1383.77,
          "arena_votes": 23952
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1383.77
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "hunyuan-turbos-20250416",
    "canonical_name": "hunyuan-turbos-20250416",
    "model_name": "hunyuan-turbos-20250416",
    "aliases": [
      "hunyuan-turbos-20250416"
    ],
    "provider": "Tencent",
    "context_window": null,
    "open_source": null,
    "arena_votes": 11000,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1382.6,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224804+00:00",
        "confidence": 1.0,
        "raw_name": "hunyuan-turbos-20250416",
        "raw_scores": {
          "arena_elo": 1382.6,
          "arena_votes": 11000
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1382.6
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemini-25-flash-lite-preview-09-2025-no-thinking",
    "canonical_name": "gemini-2.5-flash-lite-preview-09-2025-no-thinking",
    "model_name": "gemini-2.5-flash-lite-preview-09-2025-no-thinking",
    "aliases": [
      "gemini-2.5-flash-lite-preview-09-2025-no-thinking"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 46869,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1379.61,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224830+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-2.5-flash-lite-preview-09-2025-no-thinking",
        "raw_scores": {
          "arena_elo": 1379.61,
          "arena_votes": 46869
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1379.61
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "trinity-large",
    "canonical_name": "trinity-large",
    "model_name": "trinity-large",
    "aliases": [
      "trinity-large"
    ],
    "provider": "Arcee AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 1690,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1375.99,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224854+00:00",
        "confidence": 1.0,
        "raw_name": "trinity-large",
        "raw_scores": {
          "arena_elo": 1375.99,
          "arena_votes": 1690
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1375.99
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-235b-a22b",
    "canonical_name": "qwen3-235b-a22b",
    "model_name": "qwen3-235b-a22b",
    "aliases": [
      "qwen3-235b-a22b"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 27026,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1374.79,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224867+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-235b-a22b",
        "raw_scores": {
          "arena_elo": 1374.79,
          "arena_votes": 27026
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1374.79
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemini-25-flash-lite-preview-06-17-thinking",
    "canonical_name": "gemini-2.5-flash-lite-preview-06-17-thinking",
    "model_name": "gemini-2.5-flash-lite-preview-06-17-thinking",
    "aliases": [
      "gemini-2.5-flash-lite-preview-06-17-thinking"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 33681,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1374.71,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.224880+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-2.5-flash-lite-preview-06-17-thinking",
        "raw_scores": {
          "arena_elo": 1374.71,
          "arena_votes": 33681
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1374.71
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-next-80b-a3b-thinking",
    "canonical_name": "qwen3-next-80b-a3b-thinking",
    "model_name": "qwen3-next-80b-a3b-thinking",
    "aliases": [
      "qwen3-next-80b-a3b-thinking"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 13768,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1368.9,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225050+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-next-80b-a3b-thinking",
        "raw_scores": {
          "arena_elo": 1368.9,
          "arena_votes": 13768
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1368.9
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "minimax-m1",
    "canonical_name": "minimax-m1",
    "model_name": "minimax-m1",
    "aliases": [
      "minimax-m1"
    ],
    "provider": "MiniMax",
    "context_window": null,
    "open_source": null,
    "arena_votes": 36573,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1367.36,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225063+00:00",
        "confidence": 1.0,
        "raw_name": "minimax-m1",
        "raw_scores": {
          "arena_elo": 1367.36,
          "arena_votes": 36573
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1367.36
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "amazon-nova-experimental-chat-11-10",
    "canonical_name": "amazon-nova-experimental-chat-11-10",
    "model_name": "amazon-nova-experimental-chat-11-10",
    "aliases": [
      "amazon-nova-experimental-chat-11-10"
    ],
    "provider": "Amazon",
    "context_window": null,
    "open_source": null,
    "arena_votes": 18678,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1365.34,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225075+00:00",
        "confidence": 1.0,
        "raw_name": "amazon-nova-experimental-chat-11-10",
        "raw_scores": {
          "arena_elo": 1365.34,
          "arena_votes": 18678
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1365.34
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemma-3-27b-it",
    "canonical_name": "gemma-3-27b-it",
    "model_name": "gemma-3-27b-it",
    "aliases": [
      "gemma-3-27b-it"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 48462,
    "license_type": "Gemma",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1365.13,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225087+00:00",
        "confidence": 1.0,
        "raw_name": "gemma-3-27b-it",
        "raw_scores": {
          "arena_elo": 1365.13,
          "arena_votes": 48462
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1365.13
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "o3-mini-high",
    "canonical_name": "o3-mini-high",
    "model_name": "o3-mini-high",
    "aliases": [
      "o3-mini-high"
    ],
    "provider": "OpenAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 18584,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1364.04,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225112+00:00",
        "confidence": 1.0,
        "raw_name": "o3-mini-high",
        "raw_scores": {
          "arena_elo": 1364.04,
          "arena_votes": 18584
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1364.04
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "grok-3-mini-beta",
    "canonical_name": "grok-3-mini-beta",
    "model_name": "grok-3-mini-beta",
    "aliases": [
      "grok-3-mini-beta"
    ],
    "provider": "xAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 23619,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1356.8,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225162+00:00",
        "confidence": 1.0,
        "raw_name": "grok-3-mini-beta",
        "raw_scores": {
          "arena_elo": 1356.8,
          "arena_votes": 23619
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1356.8
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "mistral-small-2506",
    "canonical_name": "mistral-small-2506",
    "model_name": "mistral-small-2506",
    "aliases": [
      "mistral-small-2506"
    ],
    "provider": "Mistral",
    "context_window": null,
    "open_source": null,
    "arena_votes": 18240,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1356.06,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225186+00:00",
        "confidence": 1.0,
        "raw_name": "mistral-small-2506",
        "raw_scores": {
          "arena_elo": 1356.06,
          "arena_votes": 18240
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1356.06
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemini-20-flash-lite-preview-02-05",
    "canonical_name": "gemini-2.0-flash-lite-preview-02-05",
    "model_name": "gemini-2.0-flash-lite-preview-02-05",
    "aliases": [
      "gemini-2.0-flash-lite-preview-02-05"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 24951,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1353.32,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225211+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-2.0-flash-lite-preview-02-05",
        "raw_scores": {
          "arena_elo": 1353.32,
          "arena_votes": 24951
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1353.32
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "amazon-nova-experimental-chat-10-20",
    "canonical_name": "amazon-nova-experimental-chat-10-20",
    "model_name": "amazon-nova-experimental-chat-10-20",
    "aliases": [
      "amazon-nova-experimental-chat-10-20"
    ],
    "provider": "Amazon",
    "context_window": null,
    "open_source": null,
    "arena_votes": 11338,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1350.2,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225260+00:00",
        "confidence": 1.0,
        "raw_name": "amazon-nova-experimental-chat-10-20",
        "raw_scores": {
          "arena_elo": 1350.2,
          "arena_votes": 11338
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1350.2
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "hunyuan-turbos-20250226",
    "canonical_name": "hunyuan-turbos-20250226",
    "model_name": "hunyuan-turbos-20250226",
    "aliases": [
      "hunyuan-turbos-20250226"
    ],
    "provider": "Tencent",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2226,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1348.85,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225272+00:00",
        "confidence": 1.0,
        "raw_name": "hunyuan-turbos-20250226",
        "raw_scores": {
          "arena_elo": 1348.85,
          "arena_votes": 2226
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1348.85
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "amazon-nova-experimental-chat-10-09",
    "canonical_name": "amazon-nova-experimental-chat-10-09",
    "model_name": "amazon-nova-experimental-chat-10-09",
    "aliases": [
      "amazon-nova-experimental-chat-10-09"
    ],
    "provider": "Amazon",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2877,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1347.27,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225296+00:00",
        "confidence": 1.0,
        "raw_name": "amazon-nova-experimental-chat-10-09",
        "raw_scores": {
          "arena_elo": 1347.27,
          "arena_votes": 2877
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1347.27
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-nemotron-ultra-253b-v1",
    "canonical_name": "llama-3.1-nemotron-ultra-253b-v1",
    "model_name": "llama-3.1-nemotron-ultra-253b-v1",
    "aliases": [
      "llama-3.1-nemotron-ultra-253b-v1"
    ],
    "provider": "Nvidia",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2546,
    "license_type": "Nvidia Open Model",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1347.27,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225308+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.1-nemotron-ultra-253b-v1",
        "raw_scores": {
          "arena_elo": 1347.27,
          "arena_votes": 2546
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1347.27
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "step-3",
    "canonical_name": "step-3",
    "model_name": "step-3",
    "aliases": [
      "step-3"
    ],
    "provider": "StepFun",
    "context_window": null,
    "open_source": null,
    "arena_votes": 6568,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1346.46,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225358+00:00",
        "confidence": 1.0,
        "raw_name": "step-3",
        "raw_scores": {
          "arena_elo": 1346.46,
          "arena_votes": 6568
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1346.46
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen-plus-0125",
    "canonical_name": "qwen-plus-0125",
    "model_name": "qwen-plus-0125",
    "aliases": [
      "qwen-plus-0125"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 5823,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1346.24,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225370+00:00",
        "confidence": 1.0,
        "raw_name": "qwen-plus-0125",
        "raw_scores": {
          "arena_elo": 1346.24,
          "arena_votes": 5823
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1346.24
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "glm-4-plus-0111",
    "canonical_name": "glm-4-plus-0111",
    "model_name": "glm-4-plus-0111",
    "aliases": [
      "glm-4-plus-0111"
    ],
    "provider": "Zhipu",
    "context_window": null,
    "open_source": null,
    "arena_votes": 5760,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1343.19,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225395+00:00",
        "confidence": 1.0,
        "raw_name": "glm-4-plus-0111",
        "raw_scores": {
          "arena_elo": 1343.19,
          "arena_votes": 5760
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1343.19
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "claude-35-sonnet-20240620",
    "canonical_name": "claude-3.5-sonnet-20240620",
    "model_name": "claude-3.5-sonnet-20240620",
    "aliases": [
      "claude-3.5-sonnet-20240620"
    ],
    "provider": "Anthropic",
    "context_window": null,
    "open_source": null,
    "arena_votes": 82417,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1342.57,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225411+00:00",
        "confidence": 1.0,
        "raw_name": "claude-3.5-sonnet-20240620",
        "raw_scores": {
          "arena_elo": 1342.57,
          "arena_votes": 82417
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1342.57
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemma-3-12b-it",
    "canonical_name": "gemma-3-12b-it",
    "model_name": "gemma-3-12b-it",
    "aliases": [
      "gemma-3-12b-it"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3829,
    "license_type": "Gemma",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1341.62,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225424+00:00",
        "confidence": 1.0,
        "raw_name": "gemma-3-12b-it",
        "raw_scores": {
          "arena_elo": 1341.62,
          "arena_votes": 3829
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1341.62
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "nvidia-llama-33-nemotron-super-49b-v15",
    "canonical_name": "nvidia-llama-3.3-nemotron-super-49b-v1.5",
    "model_name": "nvidia-llama-3.3-nemotron-super-49b-v1.5",
    "aliases": [
      "nvidia-llama-3.3-nemotron-super-49b-v1.5"
    ],
    "provider": "Nvidia",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3402,
    "license_type": "Nvidia Open",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1341.51,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225436+00:00",
        "confidence": 1.0,
        "raw_name": "nvidia-llama-3.3-nemotron-super-49b-v1.5",
        "raw_scores": {
          "arena_elo": 1341.51,
          "arena_votes": 3402
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1341.51
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "hunyuan-turbo-0110",
    "canonical_name": "hunyuan-turbo-0110",
    "model_name": "hunyuan-turbo-0110",
    "aliases": [
      "hunyuan-turbo-0110"
    ],
    "provider": "Tencent",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2295,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1340.48,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225448+00:00",
        "confidence": 1.0,
        "raw_name": "hunyuan-turbo-0110",
        "raw_scores": {
          "arena_elo": 1340.48,
          "arena_votes": 2295
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1340.48
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "nova-2-lite",
    "canonical_name": "nova-2-lite",
    "model_name": "nova-2-lite",
    "aliases": [
      "nova-2-lite"
    ],
    "provider": "Amazon",
    "context_window": null,
    "open_source": null,
    "arena_votes": 12112,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1337.16,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225472+00:00",
        "confidence": 1.0,
        "raw_name": "nova-2-lite",
        "raw_scores": {
          "arena_elo": 1337.16,
          "arena_votes": 12112
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1337.16
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-405b-instruct-bf16",
    "canonical_name": "llama-3.1-405b-instruct-bf16",
    "model_name": "llama-3.1-405b-instruct-bf16",
    "aliases": [
      "llama-3.1-405b-instruct-bf16"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 41392,
    "license_type": "Llama 3.1 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1335.35,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225509+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.1-405b-instruct-bf16",
        "raw_scores": {
          "arena_elo": 1335.35,
          "arena_votes": 41392
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1335.35
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "grok-2-2024-08-13",
    "canonical_name": "grok-2-2024-08-13",
    "model_name": "grok-2-2024-08-13",
    "aliases": [
      "grok-2-2024-08-13"
    ],
    "provider": "xAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 63495,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1335.13,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225540+00:00",
        "confidence": 1.0,
        "raw_name": "grok-2-2024-08-13",
        "raw_scores": {
          "arena_elo": 1335.13,
          "arena_votes": 63495
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1335.13
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gpt-4o-2024-08-06",
    "canonical_name": "gpt-4o-2024-08-06",
    "model_name": "gpt-4o-2024-08-06",
    "aliases": [
      "gpt-4o-2024-08-06"
    ],
    "provider": "OpenAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 45498,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1335.04,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225558+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-4o-2024-08-06",
        "raw_scores": {
          "arena_elo": 1335.04,
          "arena_votes": 45498
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1335.04
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemini-advanced-0514",
    "canonical_name": "gemini-advanced-0514",
    "model_name": "gemini-advanced-0514",
    "aliases": [
      "gemini-advanced-0514"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 50142,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1334.87,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225571+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-advanced-0514",
        "raw_scores": {
          "arena_elo": 1334.87,
          "arena_votes": 50142
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1334.87
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "step-2-16k-exp-202412",
    "canonical_name": "step-2-16k-exp-202412",
    "model_name": "step-2-16k-exp-202412",
    "aliases": [
      "step-2-16k-exp-202412"
    ],
    "provider": "StepFun",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4829,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1334.06,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225583+00:00",
        "confidence": 1.0,
        "raw_name": "step-2-16k-exp-202412",
        "raw_scores": {
          "arena_elo": 1334.06,
          "arena_votes": 4829
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1334.06
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-405b-instruct-fp8",
    "canonical_name": "llama-3.1-405b-instruct-fp8",
    "model_name": "llama-3.1-405b-instruct-fp8",
    "aliases": [
      "llama-3.1-405b-instruct-fp8"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 59655,
    "license_type": "Llama 3.1 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1333.53,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225595+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.1-405b-instruct-fp8",
        "raw_scores": {
          "arena_elo": 1333.53,
          "arena_votes": 59655
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1333.53
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "molmo-2-8b",
    "canonical_name": "molmo-2-8b",
    "model_name": "molmo-2-8b",
    "aliases": [
      "molmo-2-8b"
    ],
    "provider": "AI2",
    "context_window": null,
    "open_source": null,
    "arena_votes": 816,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1329.1,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225621+00:00",
        "confidence": 1.0,
        "raw_name": "molmo-2-8b",
        "raw_scores": {
          "arena_elo": 1329.1,
          "arena_votes": 816
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1329.1
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "yi-lightning",
    "canonical_name": "yi-lightning",
    "model_name": "yi-lightning",
    "aliases": [
      "yi-lightning"
    ],
    "provider": "01 AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 27340,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1328.55,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225633+00:00",
        "confidence": 1.0,
        "raw_name": "yi-lightning",
        "raw_scores": {
          "arena_elo": 1328.55,
          "arena_votes": 27340
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1328.55
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-30b-a3b",
    "canonical_name": "qwen3-30b-a3b",
    "model_name": "qwen3-30b-a3b",
    "aliases": [
      "qwen3-30b-a3b"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 27289,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1328.17,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225646+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-30b-a3b",
        "raw_scores": {
          "arena_elo": 1328.17,
          "arena_votes": 27289
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1328.17
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-33-nemotron-49b-super-v1",
    "canonical_name": "llama-3.3-nemotron-49b-super-v1",
    "model_name": "llama-3.3-nemotron-49b-super-v1",
    "aliases": [
      "llama-3.3-nemotron-49b-super-v1"
    ],
    "provider": "Nvidia",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2230,
    "license_type": "Nvidia",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1327.09,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225670+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.3-nemotron-49b-super-v1",
        "raw_scores": {
          "arena_elo": 1327.09,
          "arena_votes": 2230
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1327.09
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "hunyuan-large-2025-02-10",
    "canonical_name": "hunyuan-large-2025-02-10",
    "model_name": "hunyuan-large-2025-02-10",
    "aliases": [
      "hunyuan-large-2025-02-10"
    ],
    "provider": "Tencent",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3738,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1326.5,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225682+00:00",
        "confidence": 1.0,
        "raw_name": "hunyuan-large-2025-02-10",
        "raw_scores": {
          "arena_elo": 1326.5,
          "arena_votes": 3738
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1326.5
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-v25-1210",
    "canonical_name": "deepseek-v2.5-1210",
    "model_name": "deepseek-v2.5-1210",
    "aliases": [
      "deepseek-v2.5-1210"
    ],
    "provider": "DeepSeek",
    "context_window": null,
    "open_source": null,
    "arena_votes": 6793,
    "license_type": "DeepSeek",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1323.3,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225725+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-v2.5-1210",
        "raw_scores": {
          "arena_elo": 1323.3,
          "arena_votes": 6793
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1323.3
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "step-1o-turbo-202506",
    "canonical_name": "step-1o-turbo-202506",
    "model_name": "step-1o-turbo-202506",
    "aliases": [
      "step-1o-turbo-202506"
    ],
    "provider": "StepFun",
    "context_window": null,
    "open_source": null,
    "arena_votes": 9622,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1321.95,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225775+00:00",
        "confidence": 1.0,
        "raw_name": "step-1o-turbo-202506",
        "raw_scores": {
          "arena_elo": 1321.95,
          "arena_votes": 9622
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1321.95
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-33-70b-instruct",
    "canonical_name": "llama-3.3-70b-instruct",
    "model_name": "llama-3.3-70b-instruct",
    "aliases": [
      "llama-3.3-70b-instruct"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 55456,
    "license_type": "Llama-3.3",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1319.45,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225812+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.3-70b-instruct",
        "raw_scores": {
          "arena_elo": 1319.45,
          "arena_votes": 55456
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1319.45
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "glm-4-plus",
    "canonical_name": "glm-4-plus",
    "model_name": "glm-4-plus",
    "aliases": [
      "glm-4-plus"
    ],
    "provider": "Zhipu AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 26134,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1319.39,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225825+00:00",
        "confidence": 1.0,
        "raw_name": "glm-4-plus",
        "raw_scores": {
          "arena_elo": 1319.39,
          "arena_votes": 26134
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1319.39
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemma-3n-e4b-it",
    "canonical_name": "gemma-3n-e4b-it",
    "model_name": "gemma-3n-e4b-it",
    "aliases": [
      "gemma-3n-e4b-it"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 23197,
    "license_type": "Gemma",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1319.3,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225837+00:00",
        "confidence": 1.0,
        "raw_name": "gemma-3n-e4b-it",
        "raw_scores": {
          "arena_elo": 1319.3,
          "arena_votes": 23197
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1319.3
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen-max-0919",
    "canonical_name": "qwen-max-0919",
    "model_name": "qwen-max-0919",
    "aliases": [
      "qwen-max-0919"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 16479,
    "license_type": "Qwen",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1318.13,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225852+00:00",
        "confidence": 1.0,
        "raw_name": "qwen-max-0919",
        "raw_scores": {
          "arena_elo": 1318.13,
          "arena_votes": 16479
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1318.13
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "nvidia-nemotron-3-nano-30b-a3b-bf16",
    "canonical_name": "nvidia-nemotron-3-nano-30b-a3b-bf16",
    "model_name": "nvidia-nemotron-3-nano-30b-a3b-bf16",
    "aliases": [
      "nvidia-nemotron-3-nano-30b-a3b-bf16"
    ],
    "provider": "Nvidia",
    "context_window": null,
    "open_source": null,
    "arena_votes": 15408,
    "license_type": "NVIDIA Open Model",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1316.95,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225888+00:00",
        "confidence": 1.0,
        "raw_name": "nvidia-nemotron-3-nano-30b-a3b-bf16",
        "raw_scores": {
          "arena_elo": 1316.95,
          "arena_votes": 15408
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1316.95
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen25-plus-1127",
    "canonical_name": "qwen2.5-plus-1127",
    "model_name": "qwen2.5-plus-1127",
    "aliases": [
      "qwen2.5-plus-1127"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 10179,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1315.44,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225901+00:00",
        "confidence": 1.0,
        "raw_name": "qwen2.5-plus-1127",
        "raw_scores": {
          "arena_elo": 1315.44,
          "arena_votes": 10179
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1315.44
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "athene-v2-chat",
    "canonical_name": "athene-v2-chat",
    "model_name": "athene-v2-chat",
    "aliases": [
      "athene-v2-chat"
    ],
    "provider": "NexusFlow",
    "context_window": null,
    "open_source": null,
    "arena_votes": 24746,
    "license_type": "NexusFlow",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1314.5,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225913+00:00",
        "confidence": 1.0,
        "raw_name": "athene-v2-chat",
        "raw_scores": {
          "arena_elo": 1314.5,
          "arena_votes": 24746
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1314.5
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "mistral-large-2407",
    "canonical_name": "mistral-large-2407",
    "model_name": "mistral-large-2407",
    "aliases": [
      "mistral-large-2407"
    ],
    "provider": "Mistral",
    "context_window": null,
    "open_source": null,
    "arena_votes": 45460,
    "license_type": "Mistral Research",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1314.1,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225925+00:00",
        "confidence": 1.0,
        "raw_name": "mistral-large-2407",
        "raw_scores": {
          "arena_elo": 1314.1,
          "arena_votes": 45460
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1314.1
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gpt-4-0125-preview",
    "canonical_name": "gpt-4-0125-preview",
    "model_name": "gpt-4-0125-preview",
    "aliases": [
      "gpt-4-0125-preview"
    ],
    "provider": "OpenAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 93439,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1313.26,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225937+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-4-0125-preview",
        "raw_scores": {
          "arena_elo": 1313.26,
          "arena_votes": 93439
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1313.26
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gpt-4-1106-preview",
    "canonical_name": "gpt-4-1106-preview",
    "model_name": "gpt-4-1106-preview",
    "aliases": [
      "gpt-4-1106-preview"
    ],
    "provider": "OpenAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 100107,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1313.21,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225950+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-4-1106-preview",
        "raw_scores": {
          "arena_elo": 1313.21,
          "arena_votes": 100107
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1313.21
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "hunyuan-standard-2025-02-10",
    "canonical_name": "hunyuan-standard-2025-02-10",
    "model_name": "hunyuan-standard-2025-02-10",
    "aliases": [
      "hunyuan-standard-2025-02-10"
    ],
    "provider": "Tencent",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3905,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1311.62,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225962+00:00",
        "confidence": 1.0,
        "raw_name": "hunyuan-standard-2025-02-10",
        "raw_scores": {
          "arena_elo": 1311.62,
          "arena_votes": 3905
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1311.62
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "mercury",
    "canonical_name": "mercury",
    "model_name": "mercury",
    "aliases": [
      "mercury"
    ],
    "provider": "Inception AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 1887,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1308.83,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225986+00:00",
        "confidence": 1.0,
        "raw_name": "mercury",
        "raw_scores": {
          "arena_elo": 1308.83,
          "arena_votes": 1887
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1308.83
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "grok-2-mini-2024-08-13",
    "canonical_name": "grok-2-mini-2024-08-13",
    "model_name": "grok-2-mini-2024-08-13",
    "aliases": [
      "grok-2-mini-2024-08-13"
    ],
    "provider": "xAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 52574,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1307.99,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.225999+00:00",
        "confidence": 1.0,
        "raw_name": "grok-2-mini-2024-08-13",
        "raw_scores": {
          "arena_elo": 1307.99,
          "arena_votes": 52574
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1307.99
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "athene-70b-0725",
    "canonical_name": "athene-70b-0725",
    "model_name": "athene-70b-0725",
    "aliases": [
      "athene-70b-0725"
    ],
    "provider": "NexusFlow",
    "context_window": null,
    "open_source": null,
    "arena_votes": 19622,
    "license_type": "CC-BY-NC-4.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1306.03,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226023+00:00",
        "confidence": 1.0,
        "raw_name": "athene-70b-0725",
        "raw_scores": {
          "arena_elo": 1306.03,
          "arena_votes": 19622
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1306.03
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "mistral-large-2411",
    "canonical_name": "mistral-large-2411",
    "model_name": "mistral-large-2411",
    "aliases": [
      "mistral-large-2411"
    ],
    "provider": "Mistral",
    "context_window": null,
    "open_source": null,
    "arena_votes": 28081,
    "license_type": "MRL",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1305.16,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226048+00:00",
        "confidence": 1.0,
        "raw_name": "mistral-large-2411",
        "raw_scores": {
          "arena_elo": 1305.16,
          "arena_votes": 28081
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1305.16
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "magistral-medium-2506",
    "canonical_name": "magistral-medium-2506",
    "model_name": "magistral-medium-2506",
    "aliases": [
      "magistral-medium-2506"
    ],
    "provider": "Mistral",
    "context_window": null,
    "open_source": null,
    "arena_votes": 11991,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1304.91,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226060+00:00",
        "confidence": 1.0,
        "raw_name": "magistral-medium-2506",
        "raw_scores": {
          "arena_elo": 1304.91,
          "arena_votes": 11991
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1304.91
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "mistral-small-31-24b-instruct-2503",
    "canonical_name": "mistral-small-3.1-24b-instruct-2503",
    "model_name": "mistral-small-3.1-24b-instruct-2503",
    "aliases": [
      "mistral-small-3.1-24b-instruct-2503"
    ],
    "provider": "Mistral",
    "context_window": null,
    "open_source": null,
    "arena_votes": 33907,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1304.41,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226072+00:00",
        "confidence": 1.0,
        "raw_name": "mistral-small-3.1-24b-instruct-2503",
        "raw_scores": {
          "arena_elo": 1304.41,
          "arena_votes": 33907
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1304.41
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemma-3-4b-it",
    "canonical_name": "gemma-3-4b-it",
    "model_name": "gemma-3-4b-it",
    "aliases": [
      "gemma-3-4b-it"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4177,
    "license_type": "Gemma",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1303.27,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226084+00:00",
        "confidence": 1.0,
        "raw_name": "gemma-3-4b-it",
        "raw_scores": {
          "arena_elo": 1303.27,
          "arena_votes": 4177
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1303.27
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen25-72b-instruct",
    "canonical_name": "qwen2.5-72b-instruct",
    "model_name": "qwen2.5-72b-instruct",
    "aliases": [
      "qwen2.5-72b-instruct"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 39409,
    "license_type": "Qwen",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1302.71,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226097+00:00",
        "confidence": 1.0,
        "raw_name": "qwen2.5-72b-instruct",
        "raw_scores": {
          "arena_elo": 1302.71,
          "arena_votes": 39409
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1302.71
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-nemotron-70b-instruct",
    "canonical_name": "llama-3.1-nemotron-70b-instruct",
    "model_name": "llama-3.1-nemotron-70b-instruct",
    "aliases": [
      "llama-3.1-nemotron-70b-instruct"
    ],
    "provider": "Nvidia",
    "context_window": null,
    "open_source": null,
    "arena_votes": 7136,
    "license_type": "Llama 3.1",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1298.65,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226109+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.1-nemotron-70b-instruct",
        "raw_scores": {
          "arena_elo": 1298.65,
          "arena_votes": 7136
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1298.65
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "hunyuan-large-vision",
    "canonical_name": "hunyuan-large-vision",
    "model_name": "hunyuan-large-vision",
    "aliases": [
      "hunyuan-large-vision"
    ],
    "provider": "Tencent",
    "context_window": null,
    "open_source": null,
    "arena_votes": 5565,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1296.03,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226121+00:00",
        "confidence": 1.0,
        "raw_name": "hunyuan-large-vision",
        "raw_scores": {
          "arena_elo": 1296.03,
          "arena_votes": 5565
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1296.03
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-70b-instruct",
    "canonical_name": "llama-3.1-70b-instruct",
    "model_name": "llama-3.1-70b-instruct",
    "aliases": [
      "llama-3.1-70b-instruct"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 55234,
    "license_type": "Llama 3.1 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1293.51,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226133+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.1-70b-instruct",
        "raw_scores": {
          "arena_elo": 1293.51,
          "arena_votes": 55234
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1293.51
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemma-2-27b-it",
    "canonical_name": "gemma-2-27b-it",
    "model_name": "gemma-2-27b-it",
    "aliases": [
      "gemma-2-27b-it"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 75764,
    "license_type": "Gemma license",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1288.11,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226169+00:00",
        "confidence": 1.0,
        "raw_name": "gemma-2-27b-it",
        "raw_scores": {
          "arena_elo": 1288.11,
          "arena_votes": 75764
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1288.11
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "reka-core-20240904",
    "canonical_name": "reka-core-20240904",
    "model_name": "reka-core-20240904",
    "aliases": [
      "reka-core-20240904"
    ],
    "provider": "Reka AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 7309,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1287.9,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226181+00:00",
        "confidence": 1.0,
        "raw_name": "reka-core-20240904",
        "raw_scores": {
          "arena_elo": 1287.9,
          "arena_votes": 7309
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1287.9
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "ibm-granite-h-small",
    "canonical_name": "ibm-granite-h-small",
    "model_name": "ibm-granite-h-small",
    "aliases": [
      "ibm-granite-h-small"
    ],
    "provider": "IBM",
    "context_window": null,
    "open_source": null,
    "arena_votes": 5622,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1287.14,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226193+00:00",
        "confidence": 1.0,
        "raw_name": "ibm-granite-h-small",
        "raw_scores": {
          "arena_elo": 1287.14,
          "arena_votes": 5622
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1287.14
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gpt-4-0314",
    "canonical_name": "gpt-4-0314",
    "model_name": "gpt-4-0314",
    "aliases": [
      "gpt-4-0314"
    ],
    "provider": "OpenAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 54167,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1287.12,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226205+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-4-0314",
        "raw_scores": {
          "arena_elo": 1287.12,
          "arena_votes": 54167
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1287.12
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-tulu-3-70b",
    "canonical_name": "llama-3.1-tulu-3-70b",
    "model_name": "llama-3.1-tulu-3-70b",
    "aliases": [
      "llama-3.1-tulu-3-70b"
    ],
    "provider": "Ai2",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2846,
    "license_type": "Llama 3.1",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1286.63,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226218+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.1-tulu-3-70b",
        "raw_scores": {
          "arena_elo": 1286.63,
          "arena_votes": 2846
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1286.63
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-nemotron-51b-instruct",
    "canonical_name": "llama-3.1-nemotron-51b-instruct",
    "model_name": "llama-3.1-nemotron-51b-instruct",
    "aliases": [
      "llama-3.1-nemotron-51b-instruct"
    ],
    "provider": "Nvidia",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3749,
    "license_type": "Llama 3.1",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1286.4,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226229+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.1-nemotron-51b-instruct",
        "raw_scores": {
          "arena_elo": 1286.4,
          "arena_votes": 3749
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1286.4
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "claude-3-sonnet-20240229",
    "canonical_name": "claude-3-sonnet-20240229",
    "model_name": "claude-3-sonnet-20240229",
    "aliases": [
      "claude-3-sonnet-20240229"
    ],
    "provider": "Anthropic",
    "context_window": null,
    "open_source": null,
    "arena_votes": 109289,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1281.13,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226267+00:00",
        "confidence": 1.0,
        "raw_name": "claude-3-sonnet-20240229",
        "raw_scores": {
          "arena_elo": 1281.13,
          "arena_votes": 109289
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1281.13
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemma-2-9b-it-simpo",
    "canonical_name": "gemma-2-9b-it-simpo",
    "model_name": "gemma-2-9b-it-simpo",
    "aliases": [
      "gemma-2-9b-it-simpo"
    ],
    "provider": "Princeton",
    "context_window": null,
    "open_source": null,
    "arena_votes": 10069,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1279.47,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226279+00:00",
        "confidence": 1.0,
        "raw_name": "gemma-2-9b-it-simpo",
        "raw_scores": {
          "arena_elo": 1279.47,
          "arena_votes": 10069
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1279.47
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "nemotron-4-340b-instruct",
    "canonical_name": "nemotron-4-340b-instruct",
    "model_name": "nemotron-4-340b-instruct",
    "aliases": [
      "nemotron-4-340b-instruct"
    ],
    "provider": "Nvidia",
    "context_window": null,
    "open_source": null,
    "arena_votes": 19661,
    "license_type": "NVIDIA Open Model",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1277.54,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226292+00:00",
        "confidence": 1.0,
        "raw_name": "nemotron-4-340b-instruct",
        "raw_scores": {
          "arena_elo": 1277.54,
          "arena_votes": 19661
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1277.54
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "command-r-plus-08-2024",
    "canonical_name": "command-r-plus-08-2024",
    "model_name": "command-r-plus-08-2024",
    "aliases": [
      "command-r-plus-08-2024"
    ],
    "provider": "Cohere",
    "context_window": null,
    "open_source": null,
    "arena_votes": 9869,
    "license_type": "CC-BY-NC-4.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1276.54,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226304+00:00",
        "confidence": 1.0,
        "raw_name": "command-r-plus-08-2024",
        "raw_scores": {
          "arena_elo": 1276.54,
          "arena_votes": 9869
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1276.54
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-3-70b-instruct",
    "canonical_name": "llama-3-70b-instruct",
    "model_name": "llama-3-70b-instruct",
    "aliases": [
      "llama-3-70b-instruct"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 156880,
    "license_type": "Llama 3 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1276.07,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226316+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3-70b-instruct",
        "raw_scores": {
          "arena_elo": 1276.07,
          "arena_votes": 156880
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1276.07
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gpt-4-0613",
    "canonical_name": "gpt-4-0613",
    "model_name": "gpt-4-0613",
    "aliases": [
      "gpt-4-0613"
    ],
    "provider": "OpenAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 88721,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1275.26,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226328+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-4-0613",
        "raw_scores": {
          "arena_elo": 1275.26,
          "arena_votes": 88721
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1275.26
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "mistral-small-24b-instruct-2501",
    "canonical_name": "mistral-small-24b-instruct-2501",
    "model_name": "mistral-small-24b-instruct-2501",
    "aliases": [
      "mistral-small-24b-instruct-2501"
    ],
    "provider": "Mistral",
    "context_window": null,
    "open_source": null,
    "arena_votes": 14677,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1273.93,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226340+00:00",
        "confidence": 1.0,
        "raw_name": "mistral-small-24b-instruct-2501",
        "raw_scores": {
          "arena_elo": 1273.93,
          "arena_votes": 14677
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1273.93
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "glm-4-0520",
    "canonical_name": "glm-4-0520",
    "model_name": "glm-4-0520",
    "aliases": [
      "glm-4-0520"
    ],
    "provider": "Zhipu AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 9788,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1273.48,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226352+00:00",
        "confidence": 1.0,
        "raw_name": "glm-4-0520",
        "raw_scores": {
          "arena_elo": 1273.48,
          "arena_votes": 9788
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1273.48
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "reka-flash-20240904",
    "canonical_name": "reka-flash-20240904",
    "model_name": "reka-flash-20240904",
    "aliases": [
      "reka-flash-20240904"
    ],
    "provider": "Reka AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 7537,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1272.25,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226365+00:00",
        "confidence": 1.0,
        "raw_name": "reka-flash-20240904",
        "raw_scores": {
          "arena_elo": 1272.25,
          "arena_votes": 7537
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1272.25
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen25-coder-32b-instruct",
    "canonical_name": "qwen2.5-coder-32b-instruct",
    "model_name": "qwen2.5-coder-32b-instruct",
    "aliases": [
      "qwen2.5-coder-32b-instruct"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 5430,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1270.66,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226377+00:00",
        "confidence": 1.0,
        "raw_name": "qwen2.5-coder-32b-instruct",
        "raw_scores": {
          "arena_elo": 1270.66,
          "arena_votes": 5430
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1270.66
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "c4ai-aya-expanse-32b",
    "canonical_name": "c4ai-aya-expanse-32b",
    "model_name": "c4ai-aya-expanse-32b",
    "aliases": [
      "c4ai-aya-expanse-32b"
    ],
    "provider": "Cohere",
    "context_window": null,
    "open_source": null,
    "arena_votes": 27123,
    "license_type": "CC-BY-NC-4.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1267.12,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226389+00:00",
        "confidence": 1.0,
        "raw_name": "c4ai-aya-expanse-32b",
        "raw_scores": {
          "arena_elo": 1267.12,
          "arena_votes": 27123
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1267.12
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemma-2-9b-it",
    "canonical_name": "gemma-2-9b-it",
    "model_name": "gemma-2-9b-it",
    "aliases": [
      "gemma-2-9b-it"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 54615,
    "license_type": "Gemma license",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1265.53,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226401+00:00",
        "confidence": 1.0,
        "raw_name": "gemma-2-9b-it",
        "raw_scores": {
          "arena_elo": 1265.53,
          "arena_votes": 54615
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1265.53
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "command-r-plus",
    "canonical_name": "command-r-plus",
    "model_name": "command-r-plus",
    "aliases": [
      "command-r-plus"
    ],
    "provider": "Cohere",
    "context_window": null,
    "open_source": null,
    "arena_votes": 77556,
    "license_type": "CC-BY-NC-4.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1262.07,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226425+00:00",
        "confidence": 1.0,
        "raw_name": "command-r-plus",
        "raw_scores": {
          "arena_elo": 1262.07,
          "arena_votes": 77556
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1262.07
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen2-72b-instruct",
    "canonical_name": "qwen2-72b-instruct",
    "model_name": "qwen2-72b-instruct",
    "aliases": [
      "qwen2-72b-instruct"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 37325,
    "license_type": "Qianwen LICENSE",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1261.95,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226437+00:00",
        "confidence": 1.0,
        "raw_name": "qwen2-72b-instruct",
        "raw_scores": {
          "arena_elo": 1261.95,
          "arena_votes": 37325
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1261.95
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "claude-3-haiku-20240307",
    "canonical_name": "claude-3-haiku-20240307",
    "model_name": "claude-3-haiku-20240307",
    "aliases": [
      "claude-3-haiku-20240307"
    ],
    "provider": "Anthropic",
    "context_window": null,
    "open_source": null,
    "arena_votes": 117705,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1261.23,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226450+00:00",
        "confidence": 1.0,
        "raw_name": "claude-3-haiku-20240307",
        "raw_scores": {
          "arena_elo": 1261.23,
          "arena_votes": 117705
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1261.23
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemini-15-flash-8b-001",
    "canonical_name": "gemini-1.5-flash-8b-001",
    "model_name": "gemini-1.5-flash-8b-001",
    "aliases": [
      "gemini-1.5-flash-8b-001"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 35556,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1258.74,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226474+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-1.5-flash-8b-001",
        "raw_scores": {
          "arena_elo": 1258.74,
          "arena_votes": 35556
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1258.74
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "olmo-2-0325-32b-instruct",
    "canonical_name": "olmo-2-0325-32b-instruct",
    "model_name": "olmo-2-0325-32b-instruct",
    "aliases": [
      "olmo-2-0325-32b-instruct"
    ],
    "provider": "Allen AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3335,
    "license_type": "Apache-2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1252.09,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226498+00:00",
        "confidence": 1.0,
        "raw_name": "olmo-2-0325-32b-instruct",
        "raw_scores": {
          "arena_elo": 1252.09,
          "arena_votes": 3335
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1252.09
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "command-r-08-2024",
    "canonical_name": "command-r-08-2024",
    "model_name": "command-r-08-2024",
    "aliases": [
      "command-r-08-2024"
    ],
    "provider": "Cohere",
    "context_window": null,
    "open_source": null,
    "arena_votes": 10141,
    "license_type": "CC-BY-NC-4.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1250.37,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226510+00:00",
        "confidence": 1.0,
        "raw_name": "command-r-08-2024",
        "raw_scores": {
          "arena_elo": 1250.37,
          "arena_votes": 10141
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1250.37
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "mistral-large-2402",
    "canonical_name": "mistral-large-2402",
    "model_name": "mistral-large-2402",
    "aliases": [
      "mistral-large-2402"
    ],
    "provider": "Mistral",
    "context_window": null,
    "open_source": null,
    "arena_votes": 62437,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1242.58,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226547+00:00",
        "confidence": 1.0,
        "raw_name": "mistral-large-2402",
        "raw_scores": {
          "arena_elo": 1242.58,
          "arena_votes": 62437
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1242.58
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "ministral-8b-2410",
    "canonical_name": "ministral-8b-2410",
    "model_name": "ministral-8b-2410",
    "aliases": [
      "ministral-8b-2410"
    ],
    "provider": "Mistral",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4780,
    "license_type": "MRL",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1237.12,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226589+00:00",
        "confidence": 1.0,
        "raw_name": "ministral-8b-2410",
        "raw_scores": {
          "arena_elo": 1237.12,
          "arena_votes": 4780
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1237.12
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemini-pro-dev-api",
    "canonical_name": "gemini-pro-dev-api",
    "model_name": "gemini-pro-dev-api",
    "aliases": [
      "gemini-pro-dev-api"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 18352,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1235.14,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226602+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-pro-dev-api",
        "raw_scores": {
          "arena_elo": 1235.14,
          "arena_votes": 18352
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1235.14
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen15-110b-chat",
    "canonical_name": "qwen1.5-110b-chat",
    "model_name": "qwen1.5-110b-chat",
    "aliases": [
      "qwen1.5-110b-chat"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 26191,
    "license_type": "Qianwen LICENSE",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1234.12,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226614+00:00",
        "confidence": 1.0,
        "raw_name": "qwen1.5-110b-chat",
        "raw_scores": {
          "arena_elo": 1234.12,
          "arena_votes": 26191
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1234.12
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "hunyuan-standard-256k",
    "canonical_name": "hunyuan-standard-256k",
    "model_name": "hunyuan-standard-256k",
    "aliases": [
      "hunyuan-standard-256k"
    ],
    "provider": "Tencent",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2729,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1233.43,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226627+00:00",
        "confidence": 1.0,
        "raw_name": "hunyuan-standard-256k",
        "raw_scores": {
          "arena_elo": 1233.43,
          "arena_votes": 2729
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1233.43
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "reka-flash-21b-20240226-online",
    "canonical_name": "reka-flash-21b-20240226-online",
    "model_name": "reka-flash-21b-20240226-online",
    "aliases": [
      "reka-flash-21b-20240226-online"
    ],
    "provider": "Reka AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 15451,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1233.43,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226639+00:00",
        "confidence": 1.0,
        "raw_name": "reka-flash-21b-20240226-online",
        "raw_scores": {
          "arena_elo": 1233.43,
          "arena_votes": 15451
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1233.43
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen15-72b-chat",
    "canonical_name": "qwen1.5-72b-chat",
    "model_name": "qwen1.5-72b-chat",
    "aliases": [
      "qwen1.5-72b-chat"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 39296,
    "license_type": "Qianwen LICENSE",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1233.31,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226651+00:00",
        "confidence": 1.0,
        "raw_name": "qwen1.5-72b-chat",
        "raw_scores": {
          "arena_elo": 1233.31,
          "arena_votes": 39296
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1233.31
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "mixtral-8x22b-instruct-v01",
    "canonical_name": "mixtral-8x22b-instruct-v0.1",
    "model_name": "mixtral-8x22b-instruct-v0.1",
    "aliases": [
      "mixtral-8x22b-instruct-v0.1"
    ],
    "provider": "Mistral",
    "context_window": null,
    "open_source": null,
    "arena_votes": 51417,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1229.67,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226664+00:00",
        "confidence": 1.0,
        "raw_name": "mixtral-8x22b-instruct-v0.1",
        "raw_scores": {
          "arena_elo": 1229.67,
          "arena_votes": 51417
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1229.67
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "reka-flash-21b-20240226",
    "canonical_name": "reka-flash-21b-20240226",
    "model_name": "reka-flash-21b-20240226",
    "aliases": [
      "reka-flash-21b-20240226"
    ],
    "provider": "Reka AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 24806,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1226.66,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226689+00:00",
        "confidence": 1.0,
        "raw_name": "reka-flash-21b-20240226",
        "raw_scores": {
          "arena_elo": 1226.66,
          "arena_votes": 24806
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1226.66
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gpt-35-turbo-0125",
    "canonical_name": "gpt-3.5-turbo-0125",
    "model_name": "gpt-3.5-turbo-0125",
    "aliases": [
      "gpt-3.5-turbo-0125"
    ],
    "provider": "OpenAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 66191,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1224.17,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226702+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-3.5-turbo-0125",
        "raw_scores": {
          "arena_elo": 1224.17,
          "arena_votes": 66191
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1224.17
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-3-8b-instruct",
    "canonical_name": "llama-3-8b-instruct",
    "model_name": "llama-3-8b-instruct",
    "aliases": [
      "llama-3-8b-instruct"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 104636,
    "license_type": "Llama 3 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1223.25,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226714+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3-8b-instruct",
        "raw_scores": {
          "arena_elo": 1223.25,
          "arena_votes": 104636
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1223.25
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "c4ai-aya-expanse-8b",
    "canonical_name": "c4ai-aya-expanse-8b",
    "model_name": "c4ai-aya-expanse-8b",
    "aliases": [
      "c4ai-aya-expanse-8b"
    ],
    "provider": "Cohere",
    "context_window": null,
    "open_source": null,
    "arena_votes": 9827,
    "license_type": "CC-BY-NC-4.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1223.08,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226739+00:00",
        "confidence": 1.0,
        "raw_name": "c4ai-aya-expanse-8b",
        "raw_scores": {
          "arena_elo": 1223.08,
          "arena_votes": 9827
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1223.08
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemini-pro",
    "canonical_name": "gemini-pro",
    "model_name": "gemini-pro",
    "aliases": [
      "gemini-pro"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 6390,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1221.87,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226752+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-pro",
        "raw_scores": {
          "arena_elo": 1221.87,
          "arena_votes": 6390
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1221.87
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-tulu-3-8b",
    "canonical_name": "llama-3.1-tulu-3-8b",
    "model_name": "llama-3.1-tulu-3-8b",
    "aliases": [
      "llama-3.1-tulu-3-8b"
    ],
    "provider": "Ai2",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2895,
    "license_type": "Llama 3.1",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1220.63,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226764+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.1-tulu-3-8b",
        "raw_scores": {
          "arena_elo": 1220.63,
          "arena_votes": 2895
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1220.63
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "yi-15-34b-chat",
    "canonical_name": "yi-1.5-34b-chat",
    "model_name": "yi-1.5-34b-chat",
    "aliases": [
      "yi-1.5-34b-chat"
    ],
    "provider": "01 AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 24142,
    "license_type": "Apache-2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1213.46,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226776+00:00",
        "confidence": 1.0,
        "raw_name": "yi-1.5-34b-chat",
        "raw_scores": {
          "arena_elo": 1213.46,
          "arena_votes": 24142
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1213.46
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "zephyr-orpo-141b-a35b-v01",
    "canonical_name": "zephyr-orpo-141b-A35b-v0.1",
    "model_name": "zephyr-orpo-141b-A35b-v0.1",
    "aliases": [
      "zephyr-orpo-141b-A35b-v0.1"
    ],
    "provider": "HuggingFace",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4653,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1212.92,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226788+00:00",
        "confidence": 1.0,
        "raw_name": "zephyr-orpo-141b-A35b-v0.1",
        "raw_scores": {
          "arena_elo": 1212.92,
          "arena_votes": 4653
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1212.92
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-8b-instruct",
    "canonical_name": "llama-3.1-8b-instruct",
    "model_name": "llama-3.1-8b-instruct",
    "aliases": [
      "llama-3.1-8b-instruct"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 49605,
    "license_type": "Llama 3.1 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1211.53,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226800+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.1-8b-instruct",
        "raw_scores": {
          "arena_elo": 1211.53,
          "arena_votes": 49605
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1211.53
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "granite-31-8b-instruct",
    "canonical_name": "granite-3.1-8b-instruct",
    "model_name": "granite-3.1-8b-instruct",
    "aliases": [
      "granite-3.1-8b-instruct"
    ],
    "provider": "IBM",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3092,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1208.71,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226812+00:00",
        "confidence": 1.0,
        "raw_name": "granite-3.1-8b-instruct",
        "raw_scores": {
          "arena_elo": 1208.71,
          "arena_votes": 3092
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1208.71
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen15-32b-chat",
    "canonical_name": "qwen1.5-32b-chat",
    "model_name": "qwen1.5-32b-chat",
    "aliases": [
      "qwen1.5-32b-chat"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 21744,
    "license_type": "Qianwen LICENSE",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1204.05,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226824+00:00",
        "confidence": 1.0,
        "raw_name": "qwen1.5-32b-chat",
        "raw_scores": {
          "arena_elo": 1204.05,
          "arena_votes": 21744
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1204.05
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gpt-35-turbo-1106",
    "canonical_name": "gpt-3.5-turbo-1106",
    "model_name": "gpt-3.5-turbo-1106",
    "aliases": [
      "gpt-3.5-turbo-1106"
    ],
    "provider": "OpenAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 16616,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1202.62,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226837+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-3.5-turbo-1106",
        "raw_scores": {
          "arena_elo": 1202.62,
          "arena_votes": 16616
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1202.62
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemma-2-2b-it",
    "canonical_name": "gemma-2-2b-it",
    "model_name": "gemma-2-2b-it",
    "aliases": [
      "gemma-2-2b-it"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 46618,
    "license_type": "Gemma license",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1198.74,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226849+00:00",
        "confidence": 1.0,
        "raw_name": "gemma-2-2b-it",
        "raw_scores": {
          "arena_elo": 1198.74,
          "arena_votes": 46618
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1198.74
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "phi-3-medium-4k-instruct",
    "canonical_name": "phi-3-medium-4k-instruct",
    "model_name": "phi-3-medium-4k-instruct",
    "aliases": [
      "phi-3-medium-4k-instruct"
    ],
    "provider": "Microsoft",
    "context_window": null,
    "open_source": null,
    "arena_votes": 25055,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1198.12,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226861+00:00",
        "confidence": 1.0,
        "raw_name": "phi-3-medium-4k-instruct",
        "raw_scores": {
          "arena_elo": 1198.12,
          "arena_votes": 25055
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1198.12
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "mixtral-8x7b-instruct-v01",
    "canonical_name": "mixtral-8x7b-instruct-v0.1",
    "model_name": "mixtral-8x7b-instruct-v0.1",
    "aliases": [
      "mixtral-8x7b-instruct-v0.1"
    ],
    "provider": "Mistral",
    "context_window": null,
    "open_source": null,
    "arena_votes": 73505,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1197.31,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226873+00:00",
        "confidence": 1.0,
        "raw_name": "mixtral-8x7b-instruct-v0.1",
        "raw_scores": {
          "arena_elo": 1197.31,
          "arena_votes": 73505
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1197.31
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "dbrx-instruct-preview",
    "canonical_name": "dbrx-instruct-preview",
    "model_name": "dbrx-instruct-preview",
    "aliases": [
      "dbrx-instruct-preview"
    ],
    "provider": "Databricks",
    "context_window": null,
    "open_source": null,
    "arena_votes": 32196,
    "license_type": "DBRX LICENSE",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1195.12,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226885+00:00",
        "confidence": 1.0,
        "raw_name": "dbrx-instruct-preview",
        "raw_scores": {
          "arena_elo": 1195.12,
          "arena_votes": 32196
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1195.12
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "internlm2_5-20b-chat",
    "canonical_name": "internlm2_5-20b-chat",
    "model_name": "internlm2_5-20b-chat",
    "aliases": [
      "internlm2_5-20b-chat"
    ],
    "provider": "InternLM",
    "context_window": null,
    "open_source": null,
    "arena_votes": 9902,
    "license_type": "Other",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1191.38,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226897+00:00",
        "confidence": 1.0,
        "raw_name": "internlm2_5-20b-chat",
        "raw_scores": {
          "arena_elo": 1191.38,
          "arena_votes": 9902
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1191.38
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen15-14b-chat",
    "canonical_name": "qwen1.5-14b-chat",
    "model_name": "qwen1.5-14b-chat",
    "aliases": [
      "qwen1.5-14b-chat"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 17841,
    "license_type": "Qianwen LICENSE",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1190.99,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226909+00:00",
        "confidence": 1.0,
        "raw_name": "qwen1.5-14b-chat",
        "raw_scores": {
          "arena_elo": 1190.99,
          "arena_votes": 17841
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1190.99
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "wizardlm-70b",
    "canonical_name": "wizardlm-70b",
    "model_name": "wizardlm-70b",
    "aliases": [
      "wizardlm-70b"
    ],
    "provider": "Microsoft",
    "context_window": null,
    "open_source": null,
    "arena_votes": 8214,
    "license_type": "Llama 2 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1184.82,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226921+00:00",
        "confidence": 1.0,
        "raw_name": "wizardlm-70b",
        "raw_scores": {
          "arena_elo": 1184.82,
          "arena_votes": 8214
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1184.82
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-llm-67b-chat",
    "canonical_name": "deepseek-llm-67b-chat",
    "model_name": "deepseek-llm-67b-chat",
    "aliases": [
      "deepseek-llm-67b-chat"
    ],
    "provider": "DeepSeek",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4933,
    "license_type": "DeepSeek License",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1184.55,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226933+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-llm-67b-chat",
        "raw_scores": {
          "arena_elo": 1184.55,
          "arena_votes": 4933
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1184.55
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "yi-34b-chat",
    "canonical_name": "yi-34b-chat",
    "model_name": "yi-34b-chat",
    "aliases": [
      "yi-34b-chat"
    ],
    "provider": "01 AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 15483,
    "license_type": "Yi License",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1183.9,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226946+00:00",
        "confidence": 1.0,
        "raw_name": "yi-34b-chat",
        "raw_scores": {
          "arena_elo": 1183.9,
          "arena_votes": 15483
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1183.9
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "openchat-35-0106",
    "canonical_name": "openchat-3.5-0106",
    "model_name": "openchat-3.5-0106",
    "aliases": [
      "openchat-3.5-0106"
    ],
    "provider": "OpenChat",
    "context_window": null,
    "open_source": null,
    "arena_votes": 12636,
    "license_type": "Apache-2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1182.46,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226958+00:00",
        "confidence": 1.0,
        "raw_name": "openchat-3.5-0106",
        "raw_scores": {
          "arena_elo": 1182.46,
          "arena_votes": 12636
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1182.46
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "granite-30-8b-instruct",
    "canonical_name": "granite-3.0-8b-instruct",
    "model_name": "granite-3.0-8b-instruct",
    "aliases": [
      "granite-3.0-8b-instruct"
    ],
    "provider": "IBM",
    "context_window": null,
    "open_source": null,
    "arena_votes": 6643,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1182.1,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226983+00:00",
        "confidence": 1.0,
        "raw_name": "granite-3.0-8b-instruct",
        "raw_scores": {
          "arena_elo": 1182.1,
          "arena_votes": 6643
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1182.1
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemma-11-7b-it",
    "canonical_name": "gemma-1.1-7b-it",
    "model_name": "gemma-1.1-7b-it",
    "aliases": [
      "gemma-1.1-7b-it"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 23893,
    "license_type": "Gemma license",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1180.25,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.226995+00:00",
        "confidence": 1.0,
        "raw_name": "gemma-1.1-7b-it",
        "raw_scores": {
          "arena_elo": 1180.25,
          "arena_votes": 23893
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1180.25
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "snowflake-arctic-instruct",
    "canonical_name": "snowflake-arctic-instruct",
    "model_name": "snowflake-arctic-instruct",
    "aliases": [
      "snowflake-arctic-instruct"
    ],
    "provider": "Snowflake",
    "context_window": null,
    "open_source": null,
    "arena_votes": 32836,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1179.65,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227007+00:00",
        "confidence": 1.0,
        "raw_name": "snowflake-arctic-instruct",
        "raw_scores": {
          "arena_elo": 1179.65,
          "arena_votes": 32836
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1179.65
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "granite-31-2b-instruct",
    "canonical_name": "granite-3.1-2b-instruct",
    "model_name": "granite-3.1-2b-instruct",
    "aliases": [
      "granite-3.1-2b-instruct"
    ],
    "provider": "IBM",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3191,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1179.44,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227019+00:00",
        "confidence": 1.0,
        "raw_name": "granite-3.1-2b-instruct",
        "raw_scores": {
          "arena_elo": 1179.44,
          "arena_votes": 3191
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1179.44
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "tulu-2-dpo-70b",
    "canonical_name": "tulu-2-dpo-70b",
    "model_name": "tulu-2-dpo-70b",
    "aliases": [
      "tulu-2-dpo-70b"
    ],
    "provider": "AllenAI/UW",
    "context_window": null,
    "open_source": null,
    "arena_votes": 6534,
    "license_type": "AI2 ImpACT Low-risk",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1178.18,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227032+00:00",
        "confidence": 1.0,
        "raw_name": "tulu-2-dpo-70b",
        "raw_scores": {
          "arena_elo": 1178.18,
          "arena_votes": 6534
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1178.18
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "openhermes-25-mistral-7b",
    "canonical_name": "openhermes-2.5-mistral-7b",
    "model_name": "openhermes-2.5-mistral-7b",
    "aliases": [
      "openhermes-2.5-mistral-7b"
    ],
    "provider": "NousResearch",
    "context_window": null,
    "open_source": null,
    "arena_votes": 5006,
    "license_type": "Apache-2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1175.32,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227044+00:00",
        "confidence": 1.0,
        "raw_name": "openhermes-2.5-mistral-7b",
        "raw_scores": {
          "arena_elo": 1175.32,
          "arena_votes": 5006
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1175.32
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "vicuna-33b",
    "canonical_name": "vicuna-33b",
    "model_name": "vicuna-33b",
    "aliases": [
      "vicuna-33b"
    ],
    "provider": "LMSYS",
    "context_window": null,
    "open_source": null,
    "arena_votes": 22479,
    "license_type": "Non-commercial",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1172.96,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227056+00:00",
        "confidence": 1.0,
        "raw_name": "vicuna-33b",
        "raw_scores": {
          "arena_elo": 1172.96,
          "arena_votes": 22479
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1172.96
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "starling-lm-7b-beta",
    "canonical_name": "starling-lm-7b-beta",
    "model_name": "starling-lm-7b-beta",
    "aliases": [
      "starling-lm-7b-beta"
    ],
    "provider": "Nexusflow",
    "context_window": null,
    "open_source": null,
    "arena_votes": 16057,
    "license_type": "Apache-2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1171.73,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227069+00:00",
        "confidence": 1.0,
        "raw_name": "starling-lm-7b-beta",
        "raw_scores": {
          "arena_elo": 1171.73,
          "arena_votes": 16057
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1171.73
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "phi-3-small-8k-instruct",
    "canonical_name": "phi-3-small-8k-instruct",
    "model_name": "phi-3-small-8k-instruct",
    "aliases": [
      "phi-3-small-8k-instruct"
    ],
    "provider": "Microsoft",
    "context_window": null,
    "open_source": null,
    "arena_votes": 17763,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1171.32,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227081+00:00",
        "confidence": 1.0,
        "raw_name": "phi-3-small-8k-instruct",
        "raw_scores": {
          "arena_elo": 1171.32,
          "arena_votes": 17763
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1171.32
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-2-70b-chat",
    "canonical_name": "llama-2-70b-chat",
    "model_name": "llama-2-70b-chat",
    "aliases": [
      "llama-2-70b-chat"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 38491,
    "license_type": "Llama 2 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1170.95,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227093+00:00",
        "confidence": 1.0,
        "raw_name": "llama-2-70b-chat",
        "raw_scores": {
          "arena_elo": 1170.95,
          "arena_votes": 38491
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1170.95
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "starling-lm-7b-alpha",
    "canonical_name": "starling-lm-7b-alpha",
    "model_name": "starling-lm-7b-alpha",
    "aliases": [
      "starling-lm-7b-alpha"
    ],
    "provider": "UC Berkeley",
    "context_window": null,
    "open_source": null,
    "arena_votes": 10224,
    "license_type": "CC-BY-NC-4.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1167.68,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227105+00:00",
        "confidence": 1.0,
        "raw_name": "starling-lm-7b-alpha",
        "raw_scores": {
          "arena_elo": 1167.68,
          "arena_votes": 10224
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1167.68
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-32-3b-instruct",
    "canonical_name": "llama-3.2-3b-instruct",
    "model_name": "llama-3.2-3b-instruct",
    "aliases": [
      "llama-3.2-3b-instruct"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 7936,
    "license_type": "Llama 3.2",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1166.75,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227118+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.2-3b-instruct",
        "raw_scores": {
          "arena_elo": 1166.75,
          "arena_votes": 7936
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1166.75
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "nous-hermes-2-mixtral-8x7b-dpo",
    "canonical_name": "nous-hermes-2-mixtral-8x7b-dpo",
    "model_name": "nous-hermes-2-mixtral-8x7b-dpo",
    "aliases": [
      "nous-hermes-2-mixtral-8x7b-dpo"
    ],
    "provider": "NousResearch",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3776,
    "license_type": "Apache-2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1164.82,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227130+00:00",
        "confidence": 1.0,
        "raw_name": "nous-hermes-2-mixtral-8x7b-dpo",
        "raw_scores": {
          "arena_elo": 1164.82,
          "arena_votes": 3776
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1164.82
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "granite-30-2b-instruct",
    "canonical_name": "granite-3.0-2b-instruct",
    "model_name": "granite-3.0-2b-instruct",
    "aliases": [
      "granite-3.0-2b-instruct"
    ],
    "provider": "IBM",
    "context_window": null,
    "open_source": null,
    "arena_votes": 6837,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1156.11,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227155+00:00",
        "confidence": 1.0,
        "raw_name": "granite-3.0-2b-instruct",
        "raw_scores": {
          "arena_elo": 1156.11,
          "arena_votes": 6837
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1156.11
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama2-70b-steerlm-chat",
    "canonical_name": "llama2-70b-steerlm-chat",
    "model_name": "llama2-70b-steerlm-chat",
    "aliases": [
      "llama2-70b-steerlm-chat"
    ],
    "provider": "Nvidia",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3584,
    "license_type": "Llama 2 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1155.48,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227167+00:00",
        "confidence": 1.0,
        "raw_name": "llama2-70b-steerlm-chat",
        "raw_scores": {
          "arena_elo": 1155.48,
          "arena_votes": 3584
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1155.48
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "solar-107b-instruct-v10",
    "canonical_name": "solar-10.7b-instruct-v1.0",
    "model_name": "solar-10.7b-instruct-v1.0",
    "aliases": [
      "solar-10.7b-instruct-v1.0"
    ],
    "provider": "Upstage AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4155,
    "license_type": "CC-BY-NC-4.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1152.53,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227179+00:00",
        "confidence": 1.0,
        "raw_name": "solar-10.7b-instruct-v1.0",
        "raw_scores": {
          "arena_elo": 1152.53,
          "arena_votes": 4155
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1152.53
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "dolphin-221-mistral-7b",
    "canonical_name": "dolphin-2.2.1-mistral-7b",
    "model_name": "dolphin-2.2.1-mistral-7b",
    "aliases": [
      "dolphin-2.2.1-mistral-7b"
    ],
    "provider": "Cognitive Computations",
    "context_window": null,
    "open_source": null,
    "arena_votes": 1679,
    "license_type": "Apache-2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1152.13,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227192+00:00",
        "confidence": 1.0,
        "raw_name": "dolphin-2.2.1-mistral-7b",
        "raw_scores": {
          "arena_elo": 1152.13,
          "arena_votes": 1679
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1152.13
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "mpt-30b-chat",
    "canonical_name": "mpt-30b-chat",
    "model_name": "mpt-30b-chat",
    "aliases": [
      "mpt-30b-chat"
    ],
    "provider": "MosaicML",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2571,
    "license_type": "CC-BY-NC-SA-4.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1150.28,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227204+00:00",
        "confidence": 1.0,
        "raw_name": "mpt-30b-chat",
        "raw_scores": {
          "arena_elo": 1150.28,
          "arena_votes": 2571
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1150.28
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "mistral-7b-instruct-v02",
    "canonical_name": "mistral-7b-instruct-v0.2",
    "model_name": "mistral-7b-instruct-v0.2",
    "aliases": [
      "mistral-7b-instruct-v0.2"
    ],
    "provider": "Mistral",
    "context_window": null,
    "open_source": null,
    "arena_votes": 19402,
    "license_type": "Apache-2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1149.78,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227216+00:00",
        "confidence": 1.0,
        "raw_name": "mistral-7b-instruct-v0.2",
        "raw_scores": {
          "arena_elo": 1149.78,
          "arena_votes": 19402
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1149.78
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "wizardlm-13b",
    "canonical_name": "wizardlm-13b",
    "model_name": "wizardlm-13b",
    "aliases": [
      "wizardlm-13b"
    ],
    "provider": "Microsoft",
    "context_window": null,
    "open_source": null,
    "arena_votes": 7046,
    "license_type": "Llama 2 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1149.3,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227228+00:00",
        "confidence": 1.0,
        "raw_name": "wizardlm-13b",
        "raw_scores": {
          "arena_elo": 1149.3,
          "arena_votes": 7046
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1149.3
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "falcon-180b-chat",
    "canonical_name": "falcon-180b-chat",
    "model_name": "falcon-180b-chat",
    "aliases": [
      "falcon-180b-chat"
    ],
    "provider": "TII",
    "context_window": null,
    "open_source": null,
    "arena_votes": 1295,
    "license_type": "Falcon-180B TII License",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1147.16,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227241+00:00",
        "confidence": 1.0,
        "raw_name": "falcon-180b-chat",
        "raw_scores": {
          "arena_elo": 1147.16,
          "arena_votes": 1295
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1147.16
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen15-7b-chat",
    "canonical_name": "qwen1.5-7b-chat",
    "model_name": "qwen1.5-7b-chat",
    "aliases": [
      "qwen1.5-7b-chat"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4735,
    "license_type": "Qianwen LICENSE",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1144.02,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227253+00:00",
        "confidence": 1.0,
        "raw_name": "qwen1.5-7b-chat",
        "raw_scores": {
          "arena_elo": 1144.02,
          "arena_votes": 4735
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1144.02
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "phi-3-mini-4k-instruct-june-2024",
    "canonical_name": "phi-3-mini-4k-instruct-june-2024",
    "model_name": "phi-3-mini-4k-instruct-june-2024",
    "aliases": [
      "phi-3-mini-4k-instruct-june-2024"
    ],
    "provider": "Microsoft",
    "context_window": null,
    "open_source": null,
    "arena_votes": 12296,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1143.16,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227265+00:00",
        "confidence": 1.0,
        "raw_name": "phi-3-mini-4k-instruct-june-2024",
        "raw_scores": {
          "arena_elo": 1143.16,
          "arena_votes": 12296
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1143.16
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-2-13b-chat",
    "canonical_name": "llama-2-13b-chat",
    "model_name": "llama-2-13b-chat",
    "aliases": [
      "llama-2-13b-chat"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 19171,
    "license_type": "Llama 2 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1141.61,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227277+00:00",
        "confidence": 1.0,
        "raw_name": "llama-2-13b-chat",
        "raw_scores": {
          "arena_elo": 1141.61,
          "arena_votes": 19171
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1141.61
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "vicuna-13b",
    "canonical_name": "vicuna-13b",
    "model_name": "vicuna-13b",
    "aliases": [
      "vicuna-13b"
    ],
    "provider": "LMSYS",
    "context_window": null,
    "open_source": null,
    "arena_votes": 19366,
    "license_type": "Llama 2 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1141.06,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227290+00:00",
        "confidence": 1.0,
        "raw_name": "vicuna-13b",
        "raw_scores": {
          "arena_elo": 1141.06,
          "arena_votes": 19366
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1141.06
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen-14b-chat",
    "canonical_name": "qwen-14b-chat",
    "model_name": "qwen-14b-chat",
    "aliases": [
      "qwen-14b-chat"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4964,
    "license_type": "Qianwen LICENSE",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1138.71,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227302+00:00",
        "confidence": 1.0,
        "raw_name": "qwen-14b-chat",
        "raw_scores": {
          "arena_elo": 1138.71,
          "arena_votes": 4964
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1138.71
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "codellama-34b-instruct",
    "canonical_name": "codellama-34b-instruct",
    "model_name": "codellama-34b-instruct",
    "aliases": [
      "codellama-34b-instruct"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 7363,
    "license_type": "Llama 2 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1136.73,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227327+00:00",
        "confidence": 1.0,
        "raw_name": "codellama-34b-instruct",
        "raw_scores": {
          "arena_elo": 1136.73,
          "arena_votes": 7363
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1136.73
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemma-7b-it",
    "canonical_name": "gemma-7b-it",
    "model_name": "gemma-7b-it",
    "aliases": [
      "gemma-7b-it"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 8925,
    "license_type": "Gemma license",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1136.04,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227339+00:00",
        "confidence": 1.0,
        "raw_name": "gemma-7b-it",
        "raw_scores": {
          "arena_elo": 1136.04,
          "arena_votes": 8925
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1136.04
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "zephyr-7b-beta",
    "canonical_name": "zephyr-7b-beta",
    "model_name": "zephyr-7b-beta",
    "aliases": [
      "zephyr-7b-beta"
    ],
    "provider": "HuggingFace",
    "context_window": null,
    "open_source": null,
    "arena_votes": 11116,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1131.22,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227351+00:00",
        "confidence": 1.0,
        "raw_name": "zephyr-7b-beta",
        "raw_scores": {
          "arena_elo": 1131.22,
          "arena_votes": 11116
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1131.22
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "phi-3-mini-128k-instruct",
    "canonical_name": "phi-3-mini-128k-instruct",
    "model_name": "phi-3-mini-128k-instruct",
    "aliases": [
      "phi-3-mini-128k-instruct"
    ],
    "provider": "Microsoft",
    "context_window": null,
    "open_source": null,
    "arena_votes": 20691,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1129.34,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227363+00:00",
        "confidence": 1.0,
        "raw_name": "phi-3-mini-128k-instruct",
        "raw_scores": {
          "arena_elo": 1129.34,
          "arena_votes": 20691
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1129.34
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "phi-3-mini-4k-instruct",
    "canonical_name": "phi-3-mini-4k-instruct",
    "model_name": "phi-3-mini-4k-instruct",
    "aliases": [
      "phi-3-mini-4k-instruct"
    ],
    "provider": "Microsoft",
    "context_window": null,
    "open_source": null,
    "arena_votes": 20115,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1128.5,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227375+00:00",
        "confidence": 1.0,
        "raw_name": "phi-3-mini-4k-instruct",
        "raw_scores": {
          "arena_elo": 1128.5,
          "arena_votes": 20115
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1128.5
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "guanaco-33b",
    "canonical_name": "guanaco-33b",
    "model_name": "guanaco-33b",
    "aliases": [
      "guanaco-33b"
    ],
    "provider": "UW",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2921,
    "license_type": "Non-commercial",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1127.45,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227387+00:00",
        "confidence": 1.0,
        "raw_name": "guanaco-33b",
        "raw_scores": {
          "arena_elo": 1127.45,
          "arena_votes": 2921
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1127.45
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "zephyr-7b-alpha",
    "canonical_name": "zephyr-7b-alpha",
    "model_name": "zephyr-7b-alpha",
    "aliases": [
      "zephyr-7b-alpha"
    ],
    "provider": "HuggingFace",
    "context_window": null,
    "open_source": null,
    "arena_votes": 1785,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1127.05,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227400+00:00",
        "confidence": 1.0,
        "raw_name": "zephyr-7b-alpha",
        "raw_scores": {
          "arena_elo": 1127.05,
          "arena_votes": 1785
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1127.05
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "stripedhyena-nous-7b",
    "canonical_name": "stripedhyena-nous-7b",
    "model_name": "stripedhyena-nous-7b",
    "aliases": [
      "stripedhyena-nous-7b"
    ],
    "provider": "Together AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 5184,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1121.1,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227412+00:00",
        "confidence": 1.0,
        "raw_name": "stripedhyena-nous-7b",
        "raw_scores": {
          "arena_elo": 1121.1,
          "arena_votes": 5184
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1121.1
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "codellama-70b-instruct",
    "canonical_name": "codellama-70b-instruct",
    "model_name": "codellama-70b-instruct",
    "aliases": [
      "codellama-70b-instruct"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 1143,
    "license_type": "Llama 2 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1119.1,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227424+00:00",
        "confidence": 1.0,
        "raw_name": "codellama-70b-instruct",
        "raw_scores": {
          "arena_elo": 1119.1,
          "arena_votes": 1143
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1119.1
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "vicuna-7b",
    "canonical_name": "vicuna-7b",
    "model_name": "vicuna-7b",
    "aliases": [
      "vicuna-7b"
    ],
    "provider": "LMSYS",
    "context_window": null,
    "open_source": null,
    "arena_votes": 6923,
    "license_type": "Llama 2 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1114.77,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227436+00:00",
        "confidence": 1.0,
        "raw_name": "vicuna-7b",
        "raw_scores": {
          "arena_elo": 1114.77,
          "arena_votes": 6923
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1114.77
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "smollm2-17b-instruct",
    "canonical_name": "smollm2-1.7b-instruct",
    "model_name": "smollm2-1.7b-instruct",
    "aliases": [
      "smollm2-1.7b-instruct"
    ],
    "provider": "HuggingFace",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2201,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1114.44,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227448+00:00",
        "confidence": 1.0,
        "raw_name": "smollm2-1.7b-instruct",
        "raw_scores": {
          "arena_elo": 1114.44,
          "arena_votes": 2201
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1114.44
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemma-11-2b-it",
    "canonical_name": "gemma-1.1-2b-it",
    "model_name": "gemma-1.1-2b-it",
    "aliases": [
      "gemma-1.1-2b-it"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 10853,
    "license_type": "Gemma license",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1114.19,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227460+00:00",
        "confidence": 1.0,
        "raw_name": "gemma-1.1-2b-it",
        "raw_scores": {
          "arena_elo": 1114.19,
          "arena_votes": 10853
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1114.19
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-32-1b-instruct",
    "canonical_name": "llama-3.2-1b-instruct",
    "model_name": "llama-3.2-1b-instruct",
    "aliases": [
      "llama-3.2-1b-instruct"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 8045,
    "license_type": "Llama 3.2",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1111.33,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227472+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.2-1b-instruct",
        "raw_scores": {
          "arena_elo": 1111.33,
          "arena_votes": 8045
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1111.33
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "mistral-7b-instruct",
    "canonical_name": "mistral-7b-instruct",
    "model_name": "mistral-7b-instruct",
    "aliases": [
      "mistral-7b-instruct"
    ],
    "provider": "Mistral",
    "context_window": null,
    "open_source": null,
    "arena_votes": 8977,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1109.78,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227485+00:00",
        "confidence": 1.0,
        "raw_name": "mistral-7b-instruct",
        "raw_scores": {
          "arena_elo": 1109.78,
          "arena_votes": 8977
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1109.78
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-2-7b-chat",
    "canonical_name": "llama-2-7b-chat",
    "model_name": "llama-2-7b-chat",
    "aliases": [
      "llama-2-7b-chat"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 14148,
    "license_type": "Llama 2 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1108.29,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227497+00:00",
        "confidence": 1.0,
        "raw_name": "llama-2-7b-chat",
        "raw_scores": {
          "arena_elo": 1108.29,
          "arena_votes": 14148
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1108.29
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gemma-2b-it",
    "canonical_name": "gemma-2b-it",
    "model_name": "gemma-2b-it",
    "aliases": [
      "gemma-2b-it"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4779,
    "license_type": "Gemma license",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1091.68,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227509+00:00",
        "confidence": 1.0,
        "raw_name": "gemma-2b-it",
        "raw_scores": {
          "arena_elo": 1091.68,
          "arena_votes": 4779
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1091.68
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "qwen15-4b-chat",
    "canonical_name": "qwen1.5-4b-chat",
    "model_name": "qwen1.5-4b-chat",
    "aliases": [
      "qwen1.5-4b-chat"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 7598,
    "license_type": "Qianwen LICENSE",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1090.27,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227540+00:00",
        "confidence": 1.0,
        "raw_name": "qwen1.5-4b-chat",
        "raw_scores": {
          "arena_elo": 1090.27,
          "arena_votes": 7598
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1090.27
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "olmo-7b-instruct",
    "canonical_name": "olmo-7b-instruct",
    "model_name": "olmo-7b-instruct",
    "aliases": [
      "olmo-7b-instruct"
    ],
    "provider": "Allen AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 6329,
    "license_type": "Apache-2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1074.72,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227561+00:00",
        "confidence": 1.0,
        "raw_name": "olmo-7b-instruct",
        "raw_scores": {
          "arena_elo": 1074.72,
          "arena_votes": 6329
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1074.72
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "koala-13b",
    "canonical_name": "koala-13b",
    "model_name": "koala-13b",
    "aliases": [
      "koala-13b"
    ],
    "provider": "UC Berkeley",
    "context_window": null,
    "open_source": null,
    "arena_votes": 6964,
    "license_type": "Non-commercial",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1070.54,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227575+00:00",
        "confidence": 1.0,
        "raw_name": "koala-13b",
        "raw_scores": {
          "arena_elo": 1070.54,
          "arena_votes": 6964
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1070.54
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "alpaca-13b",
    "canonical_name": "alpaca-13b",
    "model_name": "alpaca-13b",
    "aliases": [
      "alpaca-13b"
    ],
    "provider": "Stanford",
    "context_window": null,
    "open_source": null,
    "arena_votes": 5745,
    "license_type": "Non-commercial",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1067.52,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227587+00:00",
        "confidence": 1.0,
        "raw_name": "alpaca-13b",
        "raw_scores": {
          "arena_elo": 1067.52,
          "arena_votes": 5745
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1067.52
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "gpt4all-13b-snoozy",
    "canonical_name": "gpt4all-13b-snoozy",
    "model_name": "gpt4all-13b-snoozy",
    "aliases": [
      "gpt4all-13b-snoozy"
    ],
    "provider": "Nomic AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 1743,
    "license_type": "Non-commercial",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1066.06,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227599+00:00",
        "confidence": 1.0,
        "raw_name": "gpt4all-13b-snoozy",
        "raw_scores": {
          "arena_elo": 1066.06,
          "arena_votes": 1743
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1066.06
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "mpt-7b-chat",
    "canonical_name": "mpt-7b-chat",
    "model_name": "mpt-7b-chat",
    "aliases": [
      "mpt-7b-chat"
    ],
    "provider": "MosaicML",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3925,
    "license_type": "CC-BY-NC-SA-4.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1061.94,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227614+00:00",
        "confidence": 1.0,
        "raw_name": "mpt-7b-chat",
        "raw_scores": {
          "arena_elo": 1061.94,
          "arena_votes": 3925
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1061.94
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "chatglm3-6b",
    "canonical_name": "chatglm3-6b",
    "model_name": "chatglm3-6b",
    "aliases": [
      "chatglm3-6b"
    ],
    "provider": "Tsinghua",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4658,
    "license_type": "Apache-2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1056.17,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227626+00:00",
        "confidence": 1.0,
        "raw_name": "chatglm3-6b",
        "raw_scores": {
          "arena_elo": 1056.17,
          "arena_votes": 4658
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1056.17
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "rwkv-4-raven-14b",
    "canonical_name": "RWKV-4-Raven-14B",
    "model_name": "RWKV-4-Raven-14B",
    "aliases": [
      "RWKV-4-Raven-14B"
    ],
    "provider": "RWKV",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4845,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1041.4,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227639+00:00",
        "confidence": 1.0,
        "raw_name": "RWKV-4-Raven-14B",
        "raw_scores": {
          "arena_elo": 1041.4,
          "arena_votes": 4845
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1041.4
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "chatglm2-6b",
    "canonical_name": "chatglm2-6b",
    "model_name": "chatglm2-6b",
    "aliases": [
      "chatglm2-6b"
    ],
    "provider": "Tsinghua",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2657,
    "license_type": "Apache-2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1024.3,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227651+00:00",
        "confidence": 1.0,
        "raw_name": "chatglm2-6b",
        "raw_scores": {
          "arena_elo": 1024.3,
          "arena_votes": 2657
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1024.3
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "oasst-pythia-12b",
    "canonical_name": "oasst-pythia-12b",
    "model_name": "oasst-pythia-12b",
    "aliases": [
      "oasst-pythia-12b"
    ],
    "provider": "OpenAssistant",
    "context_window": null,
    "open_source": null,
    "arena_votes": 6311,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1022.21,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227663+00:00",
        "confidence": 1.0,
        "raw_name": "oasst-pythia-12b",
        "raw_scores": {
          "arena_elo": 1022.21,
          "arena_votes": 6311
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1022.21
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "chatglm-6b",
    "canonical_name": "chatglm-6b",
    "model_name": "chatglm-6b",
    "aliases": [
      "chatglm-6b"
    ],
    "provider": "Tsinghua",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4914,
    "license_type": "Non-commercial",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 995.679,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227675+00:00",
        "confidence": 1.0,
        "raw_name": "chatglm-6b",
        "raw_scores": {
          "arena_elo": 995.679,
          "arena_votes": 4914
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 995.679
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "fastchat-t5-3b",
    "canonical_name": "fastchat-t5-3b",
    "model_name": "fastchat-t5-3b",
    "aliases": [
      "fastchat-t5-3b"
    ],
    "provider": "LMSYS",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4203,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 991.39,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227687+00:00",
        "confidence": 1.0,
        "raw_name": "fastchat-t5-3b",
        "raw_scores": {
          "arena_elo": 991.39,
          "arena_votes": 4203
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 991.39
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "dolly-v2-12b",
    "canonical_name": "dolly-v2-12b",
    "model_name": "dolly-v2-12b",
    "aliases": [
      "dolly-v2-12b"
    ],
    "provider": "Databricks",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3412,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 980.169,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227699+00:00",
        "confidence": 1.0,
        "raw_name": "dolly-v2-12b",
        "raw_scores": {
          "arena_elo": 980.169,
          "arena_votes": 3412
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 980.169
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "llama-13b",
    "canonical_name": "llama-13b",
    "model_name": "llama-13b",
    "aliases": [
      "llama-13b"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2391,
    "license_type": "Non-commercial",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 972.227,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227711+00:00",
        "confidence": 1.0,
        "raw_name": "llama-13b",
        "raw_scores": {
          "arena_elo": 972.227,
          "arena_votes": 2391
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 972.227
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  },
  {
    "model_id": null,
    "model_slug": "stablelm-tuned-alpha-7b",
    "canonical_name": "stablelm-tuned-alpha-7b",
    "model_name": "stablelm-tuned-alpha-7b",
    "aliases": [
      "stablelm-tuned-alpha-7b"
    ],
    "provider": "Stability AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3287,
    "license_type": "CC-BY-NC-SA-4.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 952.696,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-26T11:25:03.227723+00:00",
        "confidence": 1.0,
        "raw_name": "stablelm-tuned-alpha-7b",
        "raw_scores": {
          "arena_elo": 952.696,
          "arena_votes": 3287
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 952.696
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-26"
  }
]