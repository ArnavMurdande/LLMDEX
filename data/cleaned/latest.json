[
  {
    "model_id": null,
    "model_slug": "gpt-oss-20b",
    "canonical_name": "gpt-oss-20B (high)",
    "model_name": "gpt-oss-20B (high)",
    "aliases": [
      "gpt-oss-20B (high)",
      "gpt-oss-20B (low)",
      "gpt-oss-20b"
    ],
    "provider": "OpenAI",
    "context_window": 131072,
    "open_source": true,
    "arena_votes": 10759,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 22.63,
    "coding_score": 16.45,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1317.07,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.1,
    "latency_seconds": 0.46,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 310.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 653.44,
    "terminalbench_hard": 0.0755,
    "tau2": 0.5525,
    "lcr": 30.85,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 7.45,
    "gpqa": 64.95,
    "scicode": 34.2,
    "ifbench": 61.45,
    "aime25": 75.8,
    "critpt": 0.7,
    "mmmu_pro": null,
    "livecodebench": 71.45,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.259829+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-oss-20B (high)",
        "raw_scores": {
          "intelligence_score": 24.47,
          "coding_score": 18.53,
          "blended_cost_per_1m": 0.1,
          "latency_seconds": 0.47,
          "tokens_per_second": 313.0,
          "context_window": 131072,
          "gdpval": 697.9209399384639,
          "terminalbench_hard": 0.106,
          "tau2": 0.602,
          "lcr": 30.7,
          "hle": 9.8,
          "gpqa": 68.8,
          "scicode": 34.4,
          "ifbench": 65.1,
          "aime25": 89.3,
          "critpt": 1.4,
          "livecodebench": 77.7
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.260013+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-oss-20B (low)",
        "raw_scores": {
          "intelligence_score": 20.79,
          "coding_score": 14.37,
          "blended_cost_per_1m": 0.1,
          "latency_seconds": 0.45,
          "tokens_per_second": 307.0,
          "context_window": 131072,
          "gdpval": 608.9590334901852,
          "terminalbench_hard": 0.045,
          "tau2": 0.503,
          "lcr": 31.0,
          "hle": 5.1,
          "gpqa": 61.1,
          "scicode": 34.0,
          "ifbench": 57.8,
          "aime25": 62.3,
          "critpt": 0.0,
          "livecodebench": 65.2
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126917+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-oss-20b",
        "raw_scores": {
          "arena_elo": 1317.07,
          "arena_votes": 10759
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 24.47,
        "coding_score": 18.53,
        "gdpval": 697.9209399384639,
        "terminalbench_hard": 0.106,
        "tau2": 0.602,
        "lcr": 30.7,
        "hle": 9.8,
        "gpqa": 68.8,
        "scicode": 34.4,
        "ifbench": 65.1,
        "aime25": 89.3,
        "critpt": 1.4,
        "livecodebench": 77.7
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1317.07
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gpt-oss-120b",
    "canonical_name": "gpt-oss-120B (high)",
    "model_name": "gpt-oss-120B (high)",
    "aliases": [
      "gpt-oss-120B (high)",
      "gpt-oss-120B (low)",
      "gpt-oss-120b"
    ],
    "provider": "OpenAI",
    "context_window": 131072,
    "open_source": true,
    "arena_votes": 30761,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 28.55,
    "coding_score": 22.075,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1353.97,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.26,
    "latency_seconds": 0.45,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 340.5,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 922.1654,
    "terminalbench_hard": 0.144,
    "tau2": 0.554,
    "lcr": 47.2,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 11.85,
    "gpqa": 72.7,
    "scicode": 37.45,
    "ifbench": 63.65,
    "aime25": 80.05,
    "critpt": 0.55,
    "mmmu_pro": null,
    "livecodebench": 79.25,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.259913+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-oss-120B (high)",
        "raw_scores": {
          "intelligence_score": 33.25,
          "coding_score": 28.62,
          "blended_cost_per_1m": 0.26,
          "latency_seconds": 0.48,
          "tokens_per_second": 335.0,
          "context_window": 131072,
          "gdpval": 972.8137194140797,
          "terminalbench_hard": 0.235,
          "tau2": 0.658,
          "lcr": 50.7,
          "hle": 18.5,
          "gpqa": 78.2,
          "scicode": 38.9,
          "ifbench": 69.0,
          "aime25": 93.4,
          "critpt": 1.1,
          "livecodebench": 87.8
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.259966+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-oss-120B (low)",
        "raw_scores": {
          "intelligence_score": 23.85,
          "coding_score": 15.53,
          "blended_cost_per_1m": 0.26,
          "latency_seconds": 0.42,
          "tokens_per_second": 346.0,
          "context_window": 131072,
          "gdpval": 871.5171067420872,
          "terminalbench_hard": 0.053,
          "tau2": 0.45,
          "lcr": 43.7,
          "hle": 5.2,
          "gpqa": 67.2,
          "scicode": 36.0,
          "ifbench": 58.3,
          "aime25": 66.7,
          "critpt": 0.0,
          "livecodebench": 70.7
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126232+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-oss-120b",
        "raw_scores": {
          "arena_elo": 1353.97,
          "arena_votes": 30761
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 33.25,
        "coding_score": 28.62,
        "gdpval": 972.8137194140797,
        "terminalbench_hard": 0.235,
        "tau2": 0.658,
        "lcr": 50.7,
        "hle": 18.5,
        "gpqa": 78.2,
        "scicode": 38.9,
        "ifbench": 69.0,
        "aime25": 93.4,
        "critpt": 1.1,
        "livecodebench": 87.8
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1353.97
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "grok-1",
    "canonical_name": "Grok-1",
    "model_name": "Grok-1",
    "aliases": [
      "Grok-1"
    ],
    "provider": "xAI",
    "context_window": 8192,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 11.6902,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.260039+00:00",
        "confidence": 0.65,
        "raw_name": "Grok-1",
        "raw_scores": {
          "intelligence_score": 11.690189040378796,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 8192
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 11.690189040378796
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gpt-5-nano",
    "canonical_name": "GPT-5 nano (high)",
    "model_name": "GPT-5 nano (high)",
    "aliases": [
      "GPT-5 nano (high)",
      "GPT-5 nano (medium)",
      "GPT-5 nano (minimal)",
      "gpt-5-nano-high"
    ],
    "provider": "OpenAI",
    "context_window": 400000,
    "open_source": null,
    "arena_votes": 8355,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 22.0067,
    "coding_score": 19.1267,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1338.1,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.14,
    "latency_seconds": 59.61,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 132.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 602.6519,
    "terminalbench_hard": 0.121,
    "tau2": 0.3087,
    "lcr": 33.9,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 6.6333,
    "gpqa": 59.1333,
    "scicode": 33.1667,
    "ifbench": 55.3333,
    "aime25": 63.1,
    "critpt": 0.0,
    "mmmu_pro": 50.3333,
    "livecodebench": 67.4,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.260089+00:00",
        "confidence": 1.0,
        "raw_name": "GPT-5 nano (high)",
        "raw_scores": {
          "intelligence_score": 26.69,
          "coding_score": 20.27,
          "blended_cost_per_1m": 0.14,
          "latency_seconds": 125.37,
          "tokens_per_second": 134.0,
          "context_window": 400000,
          "gdpval": 801.648883489908,
          "terminalbench_hard": 0.121,
          "tau2": 0.365,
          "lcr": 41.7,
          "hle": 8.2,
          "gpqa": 67.6,
          "scicode": 36.6,
          "ifbench": 67.6,
          "aime25": 83.7,
          "critpt": 0.0,
          "mmmu_pro": 61.0,
          "livecodebench": 78.9
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.268238+00:00",
        "confidence": 1.0,
        "raw_name": "GPT-5 nano (minimal)",
        "raw_scores": {
          "intelligence_score": 13.65,
          "coding_score": 14.23,
          "blended_cost_per_1m": 0.14,
          "latency_seconds": 0.67,
          "tokens_per_second": 132.0,
          "context_window": 400000,
          "gdpval": 356.6771695858463,
          "terminalbench_hard": 0.068,
          "tau2": 0.257,
          "lcr": 20.0,
          "hle": 4.1,
          "gpqa": 42.8,
          "scicode": 29.1,
          "ifbench": 32.5,
          "aime25": 27.3,
          "critpt": 0.0,
          "mmmu_pro": 31.8,
          "livecodebench": 47.0
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.269143+00:00",
        "confidence": 1.0,
        "raw_name": "GPT-5 nano (medium)",
        "raw_scores": {
          "intelligence_score": 25.68,
          "coding_score": 22.88,
          "blended_cost_per_1m": 0.14,
          "latency_seconds": 52.79,
          "tokens_per_second": 130.0,
          "context_window": 400000,
          "gdpval": 649.6297647878148,
          "terminalbench_hard": 0.174,
          "tau2": 0.304,
          "lcr": 40.0,
          "hle": 7.6,
          "gpqa": 67.0,
          "scicode": 33.8,
          "ifbench": 65.9,
          "aime25": 78.3,
          "critpt": 0.0,
          "mmmu_pro": 58.2,
          "livecodebench": 76.3
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126520+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-5-nano-high",
        "raw_scores": {
          "arena_elo": 1338.1,
          "arena_votes": 8355
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 26.69,
        "coding_score": 20.27,
        "gdpval": 801.648883489908,
        "terminalbench_hard": 0.121,
        "tau2": 0.365,
        "lcr": 41.7,
        "hle": 8.2,
        "gpqa": 67.6,
        "scicode": 36.6,
        "ifbench": 67.6,
        "aime25": 83.7,
        "critpt": 0.0,
        "mmmu_pro": 61.0,
        "livecodebench": 78.9
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1338.1
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gpt-52",
    "canonical_name": "GPT-5.2 (xhigh)",
    "model_name": "GPT-5.2 (xhigh)",
    "aliases": [
      "GPT-5.2 (Non-reasoning)",
      "GPT-5.2 (medium)",
      "GPT-5.2 (xhigh)",
      "gpt-5.2",
      "gpt-5.2-chat-latest-20260210",
      "gpt-5.2-high"
    ],
    "provider": "OpenAI",
    "context_window": 400000,
    "open_source": null,
    "arena_votes": 18534,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 44.5551,
    "coding_score": 43.0994,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1452.34,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 4.81,
    "latency_seconds": 19.255,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 44.5,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 1380.5609,
    "terminalbench_hard": 0.4133,
    "tau2": 0.7019,
    "lcr": 59.5054,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 23.6799,
    "gpqa": 83.4939,
    "scicode": 46.6724,
    "ifbench": 63.8158,
    "aime25": 84.5842,
    "critpt": 7.1591,
    "mmmu_pro": 70.7162,
    "livecodebench": 82.8498,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.260136+00:00",
        "confidence": 1.0,
        "raw_name": "GPT-5.2 (xhigh)",
        "raw_scores": {
          "intelligence_score": 51.24,
          "coding_score": 48.67,
          "blended_cost_per_1m": 4.81,
          "latency_seconds": 38.51,
          "tokens_per_second": 89.0,
          "context_window": 400000,
          "gdpval": 1462.1404149522382,
          "terminalbench_hard": 0.47,
          "tau2": 0.848,
          "lcr": 72.7,
          "hle": 35.4,
          "gpqa": 90.3,
          "scicode": 52.1,
          "ifbench": 75.4,
          "aime25": 99.0,
          "critpt": 11.6,
          "livecodebench": 88.9
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.260361+00:00",
        "confidence": 1.0,
        "raw_name": "GPT-5.2 (medium)",
        "raw_scores": {
          "intelligence_score": 46.58,
          "coding_score": 44.18,
          "blended_cost_per_1m": 4.81,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 400000,
          "gdpval": 1418.0029763915531,
          "terminalbench_hard": 0.432,
          "tau2": 0.743,
          "lcr": 63.3,
          "hle": 24.9,
          "gpqa": 86.4,
          "scicode": 46.2,
          "ifbench": 65.2,
          "aime25": 96.7,
          "critpt": 7.9,
          "mmmu_pro": 74.6,
          "livecodebench": 89.4
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.260405+00:00",
        "confidence": 0.79,
        "raw_name": "GPT-5.2 (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 33.53,
          "coding_score": 34.68,
          "context_window": 400000,
          "gdpval": 1229.9005497004919,
          "terminalbench_hard": 0.318,
          "tau2": 0.465,
          "lcr": 38.0,
          "hle": 7.3,
          "gpqa": 71.2,
          "scicode": 40.4,
          "ifbench": 47.4,
          "aime25": 51.0,
          "critpt": 0.6,
          "mmmu_pro": 65.8,
          "livecodebench": 66.9
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.124562+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-5.2-chat-latest-20260210",
        "raw_scores": {
          "arena_elo": 1479.91,
          "arena_votes": 2771
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.124904+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-5.2-high",
        "raw_scores": {
          "arena_elo": 1440.19,
          "arena_votes": 18534
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.124930+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-5.2",
        "raw_scores": {
          "arena_elo": 1436.92,
          "arena_votes": 15345
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 51.24,
        "coding_score": 48.67,
        "gdpval": 1462.1404149522382,
        "terminalbench_hard": 0.47,
        "tau2": 0.848,
        "lcr": 72.7,
        "hle": 35.4,
        "gpqa": 90.3,
        "scicode": 52.1,
        "ifbench": 75.4,
        "aime25": 99.0,
        "critpt": 11.6,
        "livecodebench": 88.9,
        "mmmu_pro": 74.6
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1479.91
      }
    },
    "confidence_score": 0.965,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gpt-5-mini",
    "canonical_name": "GPT-5 mini (high)",
    "model_name": "GPT-5 mini (high)",
    "aliases": [
      "GPT-5 mini (high)",
      "GPT-5 mini (medium)",
      "GPT-5 mini (minimal)",
      "gpt-5-mini-high"
    ],
    "provider": "OpenAI",
    "context_window": 400000,
    "open_source": null,
    "arena_votes": 26945,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 33.5,
    "coding_score": 30.0167,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1390.44,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.69,
    "latency_seconds": 44.9633,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 71.6667,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 913.9501,
    "terminalbench_hard": 0.255,
    "tau2": 0.5713,
    "lcr": 56.5667,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 13.1,
    "gpqa": 77.2667,
    "scicode": 39.0333,
    "ifbench": 64.0667,
    "aime25": 74.1333,
    "critpt": 0.4667,
    "mmmu_pro": 65.7667,
    "livecodebench": 69.1667,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.260195+00:00",
        "confidence": 1.0,
        "raw_name": "GPT-5 mini (high)",
        "raw_scores": {
          "intelligence_score": 41.03,
          "coding_score": 35.3,
          "blended_cost_per_1m": 0.69,
          "latency_seconds": 101.89,
          "tokens_per_second": 75.0,
          "context_window": 400000,
          "gdpval": 1193.3971840483464,
          "terminalbench_hard": 0.333,
          "tau2": 0.684,
          "lcr": 68.0,
          "hle": 19.7,
          "gpqa": 82.8,
          "scicode": 39.2,
          "ifbench": 75.4,
          "aime25": 90.7,
          "critpt": 0.0,
          "mmmu_pro": 70.1,
          "livecodebench": 83.8
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.268740+00:00",
        "confidence": 1.0,
        "raw_name": "GPT-5 mini (minimal)",
        "raw_scores": {
          "intelligence_score": 20.66,
          "coding_score": 21.9,
          "blended_cost_per_1m": 0.69,
          "latency_seconds": 0.77,
          "tokens_per_second": 69.0,
          "context_window": 400000,
          "gdpval": 529.2773011742238,
          "terminalbench_hard": 0.144,
          "tau2": 0.319,
          "lcr": 35.7,
          "hle": 5.0,
          "gpqa": 68.7,
          "scicode": 36.9,
          "ifbench": 45.6,
          "aime25": 46.7,
          "critpt": 0.0,
          "mmmu_pro": 58.4,
          "livecodebench": 54.5
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.269187+00:00",
        "confidence": 1.0,
        "raw_name": "GPT-5 mini (medium)",
        "raw_scores": {
          "intelligence_score": 38.81,
          "coding_score": 32.85,
          "blended_cost_per_1m": 0.69,
          "latency_seconds": 32.23,
          "tokens_per_second": 71.0,
          "context_window": 400000,
          "gdpval": 1019.1758307888824,
          "terminalbench_hard": 0.288,
          "tau2": 0.711,
          "lcr": 66.0,
          "hle": 14.6,
          "gpqa": 80.3,
          "scicode": 41.0,
          "ifbench": 71.2,
          "aime25": 85.0,
          "critpt": 1.4,
          "mmmu_pro": 68.8,
          "livecodebench": 69.2
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125645+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-5-mini-high",
        "raw_scores": {
          "arena_elo": 1390.44,
          "arena_votes": 26945
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 41.03,
        "coding_score": 35.3,
        "gdpval": 1193.3971840483464,
        "terminalbench_hard": 0.333,
        "tau2": 0.684,
        "lcr": 68.0,
        "hle": 19.7,
        "gpqa": 82.8,
        "scicode": 39.2,
        "ifbench": 75.4,
        "aime25": 90.7,
        "critpt": 0.0,
        "mmmu_pro": 70.1,
        "livecodebench": 83.8
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1390.44
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "o3",
    "canonical_name": "o3",
    "model_name": "o3",
    "aliases": [
      "o3",
      "o3-2025-04-16"
    ],
    "provider": "OpenAI",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 60958,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 38.33,
    "coding_score": 38.4,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1432.59,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.5,
    "latency_seconds": 14.57,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 137.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 747.8712,
    "terminalbench_hard": 0.371,
    "tau2": 0.807,
    "lcr": 69.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 20.0,
    "gpqa": 82.7,
    "scicode": 41.0,
    "ifbench": 71.4,
    "aime25": 88.3,
    "critpt": 1.1,
    "mmmu_pro": 70.1,
    "livecodebench": 80.8,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.260265+00:00",
        "confidence": 1.0,
        "raw_name": "o3",
        "raw_scores": {
          "intelligence_score": 38.33,
          "coding_score": 38.4,
          "blended_cost_per_1m": 3.5,
          "latency_seconds": 14.57,
          "tokens_per_second": 137.0,
          "context_window": 200000,
          "gdpval": 747.8712490632478,
          "terminalbench_hard": 0.371,
          "tau2": 0.807,
          "lcr": 69.3,
          "hle": 20.0,
          "gpqa": 82.7,
          "scicode": 41.0,
          "ifbench": 71.4,
          "aime25": 88.3,
          "critpt": 1.1,
          "mmmu_pro": 70.1,
          "livecodebench": 80.8
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.124982+00:00",
        "confidence": 1.0,
        "raw_name": "o3-2025-04-16",
        "raw_scores": {
          "arena_elo": 1432.59,
          "arena_votes": 60958
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 38.33,
        "coding_score": 38.4,
        "gdpval": 747.8712490632478,
        "terminalbench_hard": 0.371,
        "tau2": 0.807,
        "lcr": 69.3,
        "hle": 20.0,
        "gpqa": 82.7,
        "scicode": 41.0,
        "ifbench": 71.4,
        "aime25": 88.3,
        "critpt": 1.1,
        "mmmu_pro": 70.1,
        "livecodebench": 80.8
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1432.59
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gpt-51-codex-mini",
    "canonical_name": "GPT-5.1 Codex mini (high)",
    "model_name": "GPT-5.1 Codex mini (high)",
    "aliases": [
      "GPT-5.1 Codex mini (high)"
    ],
    "provider": "OpenAI",
    "context_window": 400000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 38.54,
    "coding_score": 36.42,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.69,
    "latency_seconds": 10.18,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 162.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 1033.5992,
    "terminalbench_hard": 0.333,
    "tau2": 0.629,
    "lcr": 62.7,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 16.9,
    "gpqa": 81.3,
    "scicode": 42.6,
    "ifbench": 67.9,
    "aime25": 91.7,
    "critpt": 0.0,
    "mmmu_pro": 69.0,
    "livecodebench": 83.6,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.260316+00:00",
        "confidence": 1.0,
        "raw_name": "GPT-5.1 Codex mini (high)",
        "raw_scores": {
          "intelligence_score": 38.54,
          "coding_score": 36.42,
          "blended_cost_per_1m": 0.69,
          "latency_seconds": 10.18,
          "tokens_per_second": 162.0,
          "context_window": 400000,
          "gdpval": 1033.5992192938484,
          "terminalbench_hard": 0.333,
          "tau2": 0.629,
          "lcr": 62.7,
          "hle": 16.9,
          "gpqa": 81.3,
          "scicode": 42.6,
          "ifbench": 67.9,
          "aime25": 91.7,
          "critpt": 0.0,
          "mmmu_pro": 69.0,
          "livecodebench": 83.6
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 38.54,
        "coding_score": 36.42,
        "gdpval": 1033.5992192938484,
        "terminalbench_hard": 0.333,
        "tau2": 0.629,
        "lcr": 62.7,
        "hle": 16.9,
        "gpqa": 81.3,
        "scicode": 42.6,
        "ifbench": 67.9,
        "aime25": 91.7,
        "critpt": 0.0,
        "mmmu_pro": 69.0,
        "livecodebench": 83.6
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gpt-52-codex",
    "canonical_name": "GPT-5.2 Codex (xhigh)",
    "model_name": "GPT-5.2 Codex (xhigh)",
    "aliases": [
      "GPT-5.2 Codex (xhigh)"
    ],
    "provider": "OpenAI",
    "context_window": 400000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 48.98,
    "coding_score": 42.96,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 4.81,
    "latency_seconds": 20.78,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 95.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 1285.4495,
    "terminalbench_hard": 0.371,
    "tau2": 0.921,
    "lcr": 75.7,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 33.5,
    "gpqa": 89.9,
    "scicode": 54.6,
    "ifbench": 77.6,
    "aime25": null,
    "critpt": 8.7,
    "mmmu_pro": 76.3,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.260446+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "GPT-5.2 Codex (xhigh)",
        "raw_scores": {
          "intelligence_score": 48.98,
          "coding_score": 42.96,
          "blended_cost_per_1m": 4.81,
          "latency_seconds": 20.78,
          "tokens_per_second": 95.0,
          "context_window": 400000,
          "gdpval": 1285.4495421454399,
          "terminalbench_hard": 0.371,
          "tau2": 0.921,
          "lcr": 75.7,
          "hle": 33.5,
          "gpqa": 89.9,
          "scicode": 54.6,
          "ifbench": 77.6,
          "critpt": 8.7,
          "mmmu_pro": 76.3
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 48.98,
        "coding_score": 42.96,
        "gdpval": 1285.4495421454399,
        "terminalbench_hard": 0.371,
        "tau2": 0.921,
        "lcr": 75.7,
        "hle": 33.5,
        "gpqa": 89.9,
        "scicode": 54.6,
        "ifbench": 77.6,
        "critpt": 8.7,
        "mmmu_pro": 76.3
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-33-instruct-70b",
    "canonical_name": "Llama 3.3 Instruct 70B",
    "model_name": "Llama 3.3 Instruct 70B",
    "aliases": [
      "Llama 3.3 Instruct 70B"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "LLAMA 3.3 COMMUNITY LICENSE AGREEMENT",
    "creator": null,
    "intelligence_score": 14.23,
    "coding_score": 10.7,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 467.2945,
    "terminalbench_hard": 0.03,
    "tau2": 0.266,
    "lcr": 15.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.0,
    "gpqa": 49.8,
    "scicode": 26.0,
    "ifbench": 47.1,
    "aime25": 7.7,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 28.8,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.260487+00:00",
        "confidence": 0.79,
        "raw_name": "Llama 3.3 Instruct 70B",
        "raw_scores": {
          "intelligence_score": 14.23,
          "coding_score": 10.7,
          "context_window": 128000,
          "gdpval": 467.2944824244753,
          "terminalbench_hard": 0.03,
          "tau2": 0.266,
          "lcr": 15.0,
          "hle": 4.0,
          "gpqa": 49.8,
          "scicode": 26.0,
          "ifbench": 47.1,
          "aime25": 7.7,
          "critpt": 0.0,
          "livecodebench": 28.8
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.23,
        "coding_score": 10.7,
        "gdpval": 467.2944824244753,
        "terminalbench_hard": 0.03,
        "tau2": 0.266,
        "lcr": 15.0,
        "hle": 4.0,
        "gpqa": 49.8,
        "scicode": 26.0,
        "ifbench": 47.1,
        "aime25": 7.7,
        "critpt": 0.0,
        "livecodebench": 28.8
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-instruct-405b",
    "canonical_name": "Llama 3.1 Instruct 405B",
    "model_name": "Llama 3.1 Instruct 405B",
    "aliases": [
      "Llama 3.1 Instruct 405B"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT",
    "creator": null,
    "intelligence_score": 14.2,
    "coding_score": 14.5,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 317.5502,
    "terminalbench_hard": 0.068,
    "tau2": 0.19,
    "lcr": 24.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.2,
    "gpqa": 51.5,
    "scicode": 29.9,
    "ifbench": 39.0,
    "aime25": 3.0,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 30.5,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.260528+00:00",
        "confidence": 0.79,
        "raw_name": "Llama 3.1 Instruct 405B",
        "raw_scores": {
          "intelligence_score": 14.2,
          "coding_score": 14.5,
          "context_window": 128000,
          "gdpval": 317.55018682026093,
          "terminalbench_hard": 0.068,
          "tau2": 0.19,
          "lcr": 24.3,
          "hle": 4.2,
          "gpqa": 51.5,
          "scicode": 29.9,
          "ifbench": 39.0,
          "aime25": 3.0,
          "critpt": 0.0,
          "livecodebench": 30.5
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.2,
        "coding_score": 14.5,
        "gdpval": 317.55018682026093,
        "terminalbench_hard": 0.068,
        "tau2": 0.19,
        "lcr": 24.3,
        "hle": 4.2,
        "gpqa": 51.5,
        "scicode": 29.9,
        "ifbench": 39.0,
        "aime25": 3.0,
        "critpt": 0.0,
        "livecodebench": 30.5
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-32-instruct-90b",
    "canonical_name": "Llama 3.2 Instruct 90B (Vision)",
    "model_name": "Llama 3.2 Instruct 90B (Vision)",
    "aliases": [
      "Llama 3.2 Instruct 90B (Vision)"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "LLAMA 3.2 COMMUNITY LICENSE AGREEMENT",
    "creator": null,
    "intelligence_score": 11.9013,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.9,
    "gpqa": 43.2,
    "scicode": 24.0,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": 39.5,
    "livecodebench": 21.4,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.260559+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 3.2 Instruct 90B (Vision)",
        "raw_scores": {
          "intelligence_score": 11.90129896307905,
          "context_window": 128000,
          "hle": 4.9,
          "gpqa": 43.2,
          "scicode": 24.0,
          "mmmu_pro": 39.5,
          "livecodebench": 21.4
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 11.90129896307905,
        "hle": 4.9,
        "gpqa": 43.2,
        "scicode": 24.0,
        "mmmu_pro": 39.5,
        "livecodebench": 21.4
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-32-instruct-11b",
    "canonical_name": "Llama 3.2 Instruct 11B (Vision)",
    "model_name": "Llama 3.2 Instruct 11B (Vision)",
    "aliases": [
      "Llama 3.2 Instruct 11B (Vision)"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "LLAMA 3.2 COMMUNITY LICENSE AGREEMENT",
    "creator": null,
    "intelligence_score": 8.77,
    "coding_score": 4.25,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": 0.008,
    "tau2": 0.146,
    "lcr": 11.7,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.2,
    "gpqa": 22.1,
    "scicode": 11.2,
    "ifbench": 30.4,
    "aime25": 1.7,
    "critpt": 0.0,
    "mmmu_pro": 29.3,
    "livecodebench": 11.0,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.260598+00:00",
        "confidence": 0.79,
        "raw_name": "Llama 3.2 Instruct 11B (Vision)",
        "raw_scores": {
          "intelligence_score": 8.77,
          "coding_score": 4.25,
          "context_window": 128000,
          "terminalbench_hard": 0.008,
          "tau2": 0.146,
          "lcr": 11.7,
          "hle": 5.2,
          "gpqa": 22.1,
          "scicode": 11.2,
          "ifbench": 30.4,
          "aime25": 1.7,
          "critpt": 0.0,
          "mmmu_pro": 29.3,
          "livecodebench": 11.0
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.77,
        "coding_score": 4.25,
        "terminalbench_hard": 0.008,
        "tau2": 0.146,
        "lcr": 11.7,
        "hle": 5.2,
        "gpqa": 22.1,
        "scicode": 11.2,
        "ifbench": 30.4,
        "aime25": 1.7,
        "critpt": 0.0,
        "mmmu_pro": 29.3,
        "livecodebench": 11.0
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-4-scout",
    "canonical_name": "Llama 4 Scout",
    "model_name": "Llama 4 Scout",
    "aliases": [
      "Llama 4 Scout",
      "llama-4-scout-17b-16e-instruct"
    ],
    "provider": "Meta",
    "context_window": 10000000,
    "open_source": true,
    "arena_votes": 31053,
    "license_type": "LLAMA 4 COMMUNITY LICENSE AGREEMENT",
    "creator": null,
    "intelligence_score": 13.48,
    "coding_score": 6.68,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1322.53,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.29,
    "latency_seconds": 0.47,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 158.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 346.4824,
    "terminalbench_hard": 0.015,
    "tau2": 0.155,
    "lcr": 25.8,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.3,
    "gpqa": 58.7,
    "scicode": 17.0,
    "ifbench": 39.5,
    "aime25": 14.0,
    "critpt": 0.0,
    "mmmu_pro": 52.9,
    "livecodebench": 29.9,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.260644+00:00",
        "confidence": 1.0,
        "raw_name": "Llama 4 Scout",
        "raw_scores": {
          "intelligence_score": 13.48,
          "coding_score": 6.68,
          "blended_cost_per_1m": 0.29,
          "latency_seconds": 0.47,
          "tokens_per_second": 158.0,
          "context_window": 10000000,
          "gdpval": 346.48238155190825,
          "terminalbench_hard": 0.015,
          "tau2": 0.155,
          "lcr": 25.8,
          "hle": 4.3,
          "gpqa": 58.7,
          "scicode": 17.0,
          "ifbench": 39.5,
          "aime25": 14.0,
          "critpt": 0.0,
          "mmmu_pro": 52.9,
          "livecodebench": 29.9
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126791+00:00",
        "confidence": 1.0,
        "raw_name": "llama-4-scout-17b-16e-instruct",
        "raw_scores": {
          "arena_elo": 1322.53,
          "arena_votes": 31053
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.48,
        "coding_score": 6.68,
        "gdpval": 346.48238155190825,
        "terminalbench_hard": 0.015,
        "tau2": 0.155,
        "lcr": 25.8,
        "hle": 4.3,
        "gpqa": 58.7,
        "scicode": 17.0,
        "ifbench": 39.5,
        "aime25": 14.0,
        "critpt": 0.0,
        "mmmu_pro": 52.9,
        "livecodebench": 29.9
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1322.53
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-4-maverick",
    "canonical_name": "Llama 4 Maverick",
    "model_name": "Llama 4 Maverick",
    "aliases": [
      "Llama 4 Maverick",
      "llama-4-maverick-17b-128e-instruct"
    ],
    "provider": "Meta",
    "context_window": 1000000,
    "open_source": true,
    "arena_votes": 40931,
    "license_type": "LLAMA 4 COMMUNITY LICENSE AGREEMENT",
    "creator": null,
    "intelligence_score": 18.3,
    "coding_score": 15.58,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1327.73,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.46,
    "latency_seconds": 0.51,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 115.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 491.8213,
    "terminalbench_hard": 0.068,
    "tau2": 0.178,
    "lcr": 46.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.8,
    "gpqa": 67.1,
    "scicode": 33.1,
    "ifbench": 43.0,
    "aime25": 19.3,
    "critpt": 0.0,
    "mmmu_pro": 62.1,
    "livecodebench": 39.7,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.260689+00:00",
        "confidence": 1.0,
        "raw_name": "Llama 4 Maverick",
        "raw_scores": {
          "intelligence_score": 18.3,
          "coding_score": 15.58,
          "blended_cost_per_1m": 0.46,
          "latency_seconds": 0.51,
          "tokens_per_second": 115.0,
          "context_window": 1000000,
          "gdpval": 491.8213188811111,
          "terminalbench_hard": 0.068,
          "tau2": 0.178,
          "lcr": 46.0,
          "hle": 4.8,
          "gpqa": 67.1,
          "scicode": 33.1,
          "ifbench": 43.0,
          "aime25": 19.3,
          "critpt": 0.0,
          "mmmu_pro": 62.1,
          "livecodebench": 39.7
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126697+00:00",
        "confidence": 1.0,
        "raw_name": "llama-4-maverick-17b-128e-instruct",
        "raw_scores": {
          "arena_elo": 1327.73,
          "arena_votes": 40931
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 18.3,
        "coding_score": 15.58,
        "gdpval": 491.8213188811111,
        "terminalbench_hard": 0.068,
        "tau2": 0.178,
        "lcr": 46.0,
        "hle": 4.8,
        "gpqa": 67.1,
        "scicode": 33.1,
        "ifbench": 43.0,
        "aime25": 19.3,
        "critpt": 0.0,
        "mmmu_pro": 62.1,
        "livecodebench": 39.7
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1327.73
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemini-25-pro",
    "canonical_name": "Gemini 2.5 Pro",
    "model_name": "Gemini 2.5 Pro",
    "aliases": [
      "Gemini 2.5 Pro",
      "gemini-2.5-pro"
    ],
    "provider": "Google",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": 96594,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 34.45,
    "coding_score": 31.95,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1449.26,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.44,
    "latency_seconds": 38.05,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 153.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 930.623,
    "terminalbench_hard": 0.265,
    "tau2": 0.541,
    "lcr": 66.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 21.1,
    "gpqa": 84.4,
    "scicode": 42.8,
    "ifbench": 48.7,
    "aime25": 87.7,
    "critpt": 2.6,
    "mmmu_pro": 74.9,
    "livecodebench": 80.1,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.260736+00:00",
        "confidence": 1.0,
        "raw_name": "Gemini 2.5 Pro",
        "raw_scores": {
          "intelligence_score": 34.45,
          "coding_score": 31.95,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 38.05,
          "tokens_per_second": 153.0,
          "context_window": 1000000,
          "gdpval": 930.623008696432,
          "terminalbench_hard": 0.265,
          "tau2": 0.541,
          "lcr": 66.0,
          "hle": 21.1,
          "gpqa": 84.4,
          "scicode": 42.8,
          "ifbench": 48.7,
          "aime25": 87.7,
          "critpt": 2.6,
          "mmmu_pro": 74.9,
          "livecodebench": 80.1
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.124806+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-2.5-pro",
        "raw_scores": {
          "arena_elo": 1449.26,
          "arena_votes": 96594
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 34.45,
        "coding_score": 31.95,
        "gdpval": 930.623008696432,
        "terminalbench_hard": 0.265,
        "tau2": 0.541,
        "lcr": 66.0,
        "hle": 21.1,
        "gpqa": 84.4,
        "scicode": 42.8,
        "ifbench": 48.7,
        "aime25": 87.7,
        "critpt": 2.6,
        "mmmu_pro": 74.9,
        "livecodebench": 80.1
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1449.26
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemma-3-4b-instruct",
    "canonical_name": "Gemma 3 4B Instruct",
    "model_name": "Gemma 3 4B Instruct",
    "aliases": [
      "Gemma 3 4B Instruct"
    ],
    "provider": "Google",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Gemma license",
    "creator": null,
    "intelligence_score": 6.31,
    "coding_score": 2.94,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 327.157,
    "terminalbench_hard": 0.008,
    "tau2": 0.05,
    "lcr": 5.7,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.2,
    "gpqa": 29.1,
    "scicode": 7.3,
    "ifbench": 28.3,
    "aime25": 12.7,
    "critpt": 0.0,
    "mmmu_pro": 29.9,
    "livecodebench": 11.2,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.260776+00:00",
        "confidence": 0.79,
        "raw_name": "Gemma 3 4B Instruct",
        "raw_scores": {
          "intelligence_score": 6.31,
          "coding_score": 2.94,
          "context_window": 128000,
          "gdpval": 327.1570257650019,
          "terminalbench_hard": 0.008,
          "tau2": 0.05,
          "lcr": 5.7,
          "hle": 5.2,
          "gpqa": 29.1,
          "scicode": 7.3,
          "ifbench": 28.3,
          "aime25": 12.7,
          "critpt": 0.0,
          "mmmu_pro": 29.9,
          "livecodebench": 11.2
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 6.31,
        "coding_score": 2.94,
        "gdpval": 327.1570257650019,
        "terminalbench_hard": 0.008,
        "tau2": 0.05,
        "lcr": 5.7,
        "hle": 5.2,
        "gpqa": 29.1,
        "scicode": 7.3,
        "ifbench": 28.3,
        "aime25": 12.7,
        "critpt": 0.0,
        "mmmu_pro": 29.9,
        "livecodebench": 11.2
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemma-3-27b-instruct",
    "canonical_name": "Gemma 3 27B Instruct",
    "model_name": "Gemma 3 27B Instruct",
    "aliases": [
      "Gemma 3 27B Instruct"
    ],
    "provider": "Google",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Gemma license",
    "creator": null,
    "intelligence_score": 10.19,
    "coding_score": 9.59,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 362.9185,
    "terminalbench_hard": 0.038,
    "tau2": 0.105,
    "lcr": 5.7,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.7,
    "gpqa": 42.8,
    "scicode": 21.2,
    "ifbench": 31.8,
    "aime25": 20.7,
    "critpt": 0.0,
    "mmmu_pro": 48.0,
    "livecodebench": 13.7,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.260817+00:00",
        "confidence": 0.79,
        "raw_name": "Gemma 3 27B Instruct",
        "raw_scores": {
          "intelligence_score": 10.19,
          "coding_score": 9.59,
          "context_window": 128000,
          "gdpval": 362.91846238312473,
          "terminalbench_hard": 0.038,
          "tau2": 0.105,
          "lcr": 5.7,
          "hle": 4.7,
          "gpqa": 42.8,
          "scicode": 21.2,
          "ifbench": 31.8,
          "aime25": 20.7,
          "critpt": 0.0,
          "mmmu_pro": 48.0,
          "livecodebench": 13.7
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.19,
        "coding_score": 9.59,
        "gdpval": 362.91846238312473,
        "terminalbench_hard": 0.038,
        "tau2": 0.105,
        "lcr": 5.7,
        "hle": 4.7,
        "gpqa": 42.8,
        "scicode": 21.2,
        "ifbench": 31.8,
        "aime25": 20.7,
        "critpt": 0.0,
        "mmmu_pro": 48.0,
        "livecodebench": 13.7
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemini-25-flash-lite-preview",
    "canonical_name": "Gemini 2.5 Flash-Lite Preview (Sep '25) (Reasoning)",
    "model_name": "Gemini 2.5 Flash-Lite Preview (Sep '25) (Reasoning)",
    "aliases": [
      "Gemini 2.5 Flash-Lite Preview (Sep '25) (Non-reasoning)",
      "Gemini 2.5 Flash-Lite Preview (Sep '25) (Reasoning)"
    ],
    "provider": "Google",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 20.5,
    "coding_score": 16.345,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 465.3087,
    "terminalbench_hard": 0.1025,
    "tau2": 0.3055,
    "lcr": 53.5,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.6,
    "gpqa": 68.0,
    "scicode": 28.6,
    "ifbench": 47.2,
    "aime25": 57.7,
    "critpt": 0.0,
    "mmmu_pro": 64.2,
    "livecodebench": 66.45,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.260857+00:00",
        "confidence": 0.79,
        "raw_name": "Gemini 2.5 Flash-Lite Preview (Sep '25) (Reasoning)",
        "raw_scores": {
          "intelligence_score": 21.6,
          "coding_score": 18.15,
          "context_window": 1000000,
          "gdpval": 486.90640028099506,
          "terminalbench_hard": 0.129,
          "tau2": 0.307,
          "lcr": 59.0,
          "hle": 6.6,
          "gpqa": 70.9,
          "scicode": 28.7,
          "ifbench": 52.6,
          "aime25": 68.7,
          "critpt": 0.0,
          "mmmu_pro": 65.0,
          "livecodebench": 68.8
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.261095+00:00",
        "confidence": 0.79,
        "raw_name": "Gemini 2.5 Flash-Lite Preview (Sep '25) (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 19.4,
          "coding_score": 14.54,
          "context_window": 1000000,
          "gdpval": 443.7109197319369,
          "terminalbench_hard": 0.076,
          "tau2": 0.304,
          "lcr": 48.0,
          "hle": 4.6,
          "gpqa": 65.1,
          "scicode": 28.5,
          "ifbench": 41.8,
          "aime25": 46.7,
          "critpt": 0.0,
          "mmmu_pro": 63.4,
          "livecodebench": 64.1
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 21.6,
        "coding_score": 18.15,
        "gdpval": 486.90640028099506,
        "terminalbench_hard": 0.129,
        "tau2": 0.307,
        "lcr": 59.0,
        "hle": 6.6,
        "gpqa": 70.9,
        "scicode": 28.7,
        "ifbench": 52.6,
        "aime25": 68.7,
        "critpt": 0.0,
        "mmmu_pro": 65.0,
        "livecodebench": 68.8
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemma-3-12b-instruct",
    "canonical_name": "Gemma 3 12B Instruct",
    "model_name": "Gemma 3 12B Instruct",
    "aliases": [
      "Gemma 3 12B Instruct"
    ],
    "provider": "Google",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Gemma license",
    "creator": null,
    "intelligence_score": 8.79,
    "coding_score": 6.29,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 361.3164,
    "terminalbench_hard": 0.008,
    "tau2": 0.108,
    "lcr": 6.7,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.8,
    "gpqa": 34.9,
    "scicode": 17.4,
    "ifbench": 36.7,
    "aime25": 18.3,
    "critpt": 0.0,
    "mmmu_pro": 37.5,
    "livecodebench": 13.7,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.260897+00:00",
        "confidence": 0.79,
        "raw_name": "Gemma 3 12B Instruct",
        "raw_scores": {
          "intelligence_score": 8.79,
          "coding_score": 6.29,
          "context_window": 128000,
          "gdpval": 361.3163714432842,
          "terminalbench_hard": 0.008,
          "tau2": 0.108,
          "lcr": 6.7,
          "hle": 4.8,
          "gpqa": 34.9,
          "scicode": 17.4,
          "ifbench": 36.7,
          "aime25": 18.3,
          "critpt": 0.0,
          "mmmu_pro": 37.5,
          "livecodebench": 13.7
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.79,
        "coding_score": 6.29,
        "gdpval": 361.3163714432842,
        "terminalbench_hard": 0.008,
        "tau2": 0.108,
        "lcr": 6.7,
        "hle": 4.8,
        "gpqa": 34.9,
        "scicode": 17.4,
        "ifbench": 36.7,
        "aime25": 18.3,
        "critpt": 0.0,
        "mmmu_pro": 37.5,
        "livecodebench": 13.7
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemma-3-1b-instruct",
    "canonical_name": "Gemma 3 1B Instruct",
    "model_name": "Gemma 3 1B Instruct",
    "aliases": [
      "Gemma 3 1B Instruct"
    ],
    "provider": "Google",
    "context_window": 32000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Gemma license",
    "creator": null,
    "intelligence_score": 5.37,
    "coding_score": 0.23,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": 0.0,
    "tau2": 0.105,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.2,
    "gpqa": 23.7,
    "scicode": 0.7,
    "ifbench": 19.9,
    "aime25": 3.3,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 1.7,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.260933+00:00",
        "confidence": 0.79,
        "raw_name": "Gemma 3 1B Instruct",
        "raw_scores": {
          "intelligence_score": 5.37,
          "coding_score": 0.23,
          "context_window": 32000,
          "terminalbench_hard": 0.0,
          "tau2": 0.105,
          "lcr": 0.0,
          "hle": 5.2,
          "gpqa": 23.7,
          "scicode": 0.7,
          "ifbench": 19.9,
          "aime25": 3.3,
          "critpt": 0.0,
          "livecodebench": 1.7
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 5.37,
        "coding_score": 0.23,
        "terminalbench_hard": 0.0,
        "tau2": 0.105,
        "lcr": 0.0,
        "hle": 5.2,
        "gpqa": 23.7,
        "scicode": 0.7,
        "ifbench": 19.9,
        "aime25": 3.3,
        "critpt": 0.0,
        "livecodebench": 1.7
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemini-3-flash-preview",
    "canonical_name": "Gemini 3 Flash Preview (Reasoning)",
    "model_name": "Gemini 3 Flash Preview (Reasoning)",
    "aliases": [
      "Gemini 3 Flash Preview (Non-reasoning)",
      "Gemini 3 Flash Preview (Reasoning)"
    ],
    "provider": "Google",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 40.75,
    "coding_score": 40.23,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 1157.0114,
    "terminalbench_hard": 0.352,
    "tau2": 0.6185,
    "lcr": 57.15,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 24.4,
    "gpqa": 85.5,
    "scicode": 50.25,
    "ifbench": 66.55,
    "aime25": 76.35,
    "critpt": 5.0,
    "mmmu_pro": 79.25,
    "livecodebench": 85.25,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.260974+00:00",
        "confidence": 0.79,
        "raw_name": "Gemini 3 Flash Preview (Reasoning)",
        "raw_scores": {
          "intelligence_score": 46.4,
          "coding_score": 42.62,
          "context_window": 1000000,
          "gdpval": 1191.2633766321467,
          "terminalbench_hard": 0.386,
          "tau2": 0.804,
          "lcr": 66.3,
          "hle": 34.7,
          "gpqa": 89.8,
          "scicode": 50.6,
          "ifbench": 78.0,
          "aime25": 97.0,
          "critpt": 8.6,
          "mmmu_pro": 79.9,
          "livecodebench": 90.8
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.261055+00:00",
        "confidence": 0.79,
        "raw_name": "Gemini 3 Flash Preview (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 35.1,
          "coding_score": 37.84,
          "context_window": 1000000,
          "gdpval": 1122.7594138574727,
          "terminalbench_hard": 0.318,
          "tau2": 0.433,
          "lcr": 48.0,
          "hle": 14.1,
          "gpqa": 81.2,
          "scicode": 49.9,
          "ifbench": 55.1,
          "aime25": 55.7,
          "critpt": 1.4,
          "mmmu_pro": 78.6,
          "livecodebench": 79.7
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 46.4,
        "coding_score": 42.62,
        "gdpval": 1191.2633766321467,
        "terminalbench_hard": 0.386,
        "tau2": 0.804,
        "lcr": 66.3,
        "hle": 34.7,
        "gpqa": 89.8,
        "scicode": 50.6,
        "ifbench": 78.0,
        "aime25": 97.0,
        "critpt": 8.6,
        "mmmu_pro": 79.9,
        "livecodebench": 90.8
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemma-3n-e4b-instruct",
    "canonical_name": "Gemma 3n E4B Instruct",
    "model_name": "Gemma 3n E4B Instruct",
    "aliases": [
      "Gemma 3n E4B Instruct"
    ],
    "provider": "Google",
    "context_window": 32000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Gemma license",
    "creator": null,
    "intelligence_score": 6.3,
    "coding_score": 4.22,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 303.0899,
    "terminalbench_hard": 0.023,
    "tau2": 0.05,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.4,
    "gpqa": 29.6,
    "scicode": 8.1,
    "ifbench": 27.9,
    "aime25": 14.3,
    "critpt": 0.0,
    "mmmu_pro": 26.2,
    "livecodebench": 14.6,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.261014+00:00",
        "confidence": 0.79,
        "raw_name": "Gemma 3n E4B Instruct",
        "raw_scores": {
          "intelligence_score": 6.3,
          "coding_score": 4.22,
          "context_window": 32000,
          "gdpval": 303.0899110013331,
          "terminalbench_hard": 0.023,
          "tau2": 0.05,
          "lcr": 0.0,
          "hle": 4.4,
          "gpqa": 29.6,
          "scicode": 8.1,
          "ifbench": 27.9,
          "aime25": 14.3,
          "critpt": 0.0,
          "mmmu_pro": 26.2,
          "livecodebench": 14.6
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 6.3,
        "coding_score": 4.22,
        "gdpval": 303.0899110013331,
        "terminalbench_hard": 0.023,
        "tau2": 0.05,
        "lcr": 0.0,
        "hle": 4.4,
        "gpqa": 29.6,
        "scicode": 8.1,
        "ifbench": 27.9,
        "aime25": 14.3,
        "critpt": 0.0,
        "mmmu_pro": 26.2,
        "livecodebench": 14.6
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemma-3-270m",
    "canonical_name": "Gemma 3 270M",
    "model_name": "Gemma 3 270M",
    "aliases": [
      "Gemma 3 270M"
    ],
    "provider": "Google",
    "context_window": 32000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Gemma",
    "creator": null,
    "intelligence_score": 7.48,
    "coding_score": 0.0,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": 0.0,
    "tau2": 0.091,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.2,
    "gpqa": 22.4,
    "scicode": 0.0,
    "ifbench": 12.1,
    "aime25": 2.3,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 0.3,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.261133+00:00",
        "confidence": 1.0,
        "raw_name": "Gemma 3 270M",
        "raw_scores": {
          "intelligence_score": 7.48,
          "coding_score": 0.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32000,
          "terminalbench_hard": 0.0,
          "tau2": 0.091,
          "lcr": 0.0,
          "hle": 4.2,
          "gpqa": 22.4,
          "scicode": 0.0,
          "ifbench": 12.1,
          "aime25": 2.3,
          "critpt": 0.0,
          "livecodebench": 0.3
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 7.48,
        "coding_score": 0.0,
        "terminalbench_hard": 0.0,
        "tau2": 0.091,
        "lcr": 0.0,
        "hle": 4.2,
        "gpqa": 22.4,
        "scicode": 0.0,
        "ifbench": 12.1,
        "aime25": 2.3,
        "critpt": 0.0,
        "livecodebench": 0.3
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemma-3n-e2b-instruct",
    "canonical_name": "Gemma 3n E2B Instruct",
    "model_name": "Gemma 3n E2B Instruct",
    "aliases": [
      "Gemma 3n E2B Instruct"
    ],
    "provider": "Google",
    "context_window": 32000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Gemma license",
    "creator": null,
    "intelligence_score": 4.72,
    "coding_score": 2.24,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": 0.008,
    "tau2": 0.0,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.0,
    "gpqa": 22.9,
    "scicode": 5.2,
    "ifbench": 22.0,
    "aime25": 10.3,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 9.5,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.261169+00:00",
        "confidence": 0.79,
        "raw_name": "Gemma 3n E2B Instruct",
        "raw_scores": {
          "intelligence_score": 4.72,
          "coding_score": 2.24,
          "context_window": 32000,
          "terminalbench_hard": 0.008,
          "tau2": 0.0,
          "lcr": 0.0,
          "hle": 4.0,
          "gpqa": 22.9,
          "scicode": 5.2,
          "ifbench": 22.0,
          "aime25": 10.3,
          "critpt": 0.0,
          "livecodebench": 9.5
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 4.72,
        "coding_score": 2.24,
        "terminalbench_hard": 0.008,
        "tau2": 0.0,
        "lcr": 0.0,
        "hle": 4.0,
        "gpqa": 22.9,
        "scicode": 5.2,
        "ifbench": 22.0,
        "aime25": 10.3,
        "critpt": 0.0,
        "livecodebench": 9.5
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemini-3-pro",
    "canonical_name": "Gemini 3 Pro Preview (low)",
    "model_name": "Gemini 3 Pro Preview (low)",
    "aliases": [
      "Gemini 3 Pro Preview (high)",
      "Gemini 3 Pro Preview (low)",
      "gemini-3-pro"
    ],
    "provider": "Google",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": 37602,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 44.765,
    "coding_score": 42.925,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1485.54,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 4.5,
    "latency_seconds": 17.51,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 140.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 1188.2301,
    "terminalbench_hard": 0.379,
    "tau2": 0.776,
    "lcr": 69.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 32.4,
    "gpqa": 89.75,
    "scicode": 53.0,
    "ifbench": 60.05,
    "aime25": 91.2,
    "critpt": 4.55,
    "mmmu_pro": 80.2,
    "livecodebench": 88.7,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.261212+00:00",
        "confidence": 1.0,
        "raw_name": "Gemini 3 Pro Preview (low)",
        "raw_scores": {
          "intelligence_score": 41.09,
          "coding_score": 39.36,
          "blended_cost_per_1m": 4.5,
          "latency_seconds": 4.43,
          "tokens_per_second": 145.0,
          "context_window": 1000000,
          "gdpval": 1175.1366487465157,
          "terminalbench_hard": 0.341,
          "tau2": 0.681,
          "lcr": 67.3,
          "hle": 27.6,
          "gpqa": 88.7,
          "scicode": 49.9,
          "ifbench": 49.7,
          "aime25": 86.7,
          "critpt": 0.0,
          "livecodebench": 85.7
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.269978+00:00",
        "confidence": 1.0,
        "raw_name": "Gemini 3 Pro Preview (high)",
        "raw_scores": {
          "intelligence_score": 48.44,
          "coding_score": 46.49,
          "blended_cost_per_1m": 4.5,
          "latency_seconds": 30.59,
          "tokens_per_second": 135.0,
          "context_window": 1000000,
          "gdpval": 1201.3235057371494,
          "terminalbench_hard": 0.417,
          "tau2": 0.871,
          "lcr": 70.7,
          "hle": 37.2,
          "gpqa": 90.8,
          "scicode": 56.1,
          "ifbench": 70.4,
          "aime25": 95.7,
          "critpt": 9.1,
          "mmmu_pro": 80.2,
          "livecodebench": 91.7
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.124547+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-3-pro",
        "raw_scores": {
          "arena_elo": 1485.54,
          "arena_votes": 37602
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 41.09,
        "coding_score": 39.36,
        "gdpval": 1175.1366487465157,
        "terminalbench_hard": 0.341,
        "tau2": 0.681,
        "lcr": 67.3,
        "hle": 27.6,
        "gpqa": 88.7,
        "scicode": 49.9,
        "ifbench": 49.7,
        "aime25": 86.7,
        "critpt": 0.0,
        "livecodebench": 85.7,
        "mmmu_pro": 80.2
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1485.54
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemini-31-pro-preview",
    "canonical_name": "Gemini 3.1 Pro Preview",
    "model_name": "Gemini 3.1 Pro Preview",
    "aliases": [
      "Gemini 3.1 Pro Preview",
      "gemini-3.1-pro-preview"
    ],
    "provider": "Google",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": 4059,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 57.05,
    "coding_score": 55.5,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1500.39,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 4.5,
    "latency_seconds": 29.19,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 109.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 1309.6078,
    "terminalbench_hard": 0.538,
    "tau2": 0.956,
    "lcr": 72.7,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 44.7,
    "gpqa": 94.1,
    "scicode": 58.9,
    "ifbench": 77.1,
    "aime25": null,
    "critpt": 17.7,
    "mmmu_pro": 82.4,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.261261+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "Gemini 3.1 Pro Preview",
        "raw_scores": {
          "intelligence_score": 57.05,
          "coding_score": 55.5,
          "blended_cost_per_1m": 4.5,
          "latency_seconds": 29.19,
          "tokens_per_second": 109.0,
          "context_window": 1000000,
          "gdpval": 1309.607764439464,
          "terminalbench_hard": 0.538,
          "tau2": 0.956,
          "lcr": 72.7,
          "hle": 44.7,
          "gpqa": 94.1,
          "scicode": 58.9,
          "ifbench": 77.1,
          "critpt": 17.7,
          "mmmu_pro": 82.4
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.124531+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-3.1-pro-preview",
        "raw_scores": {
          "arena_elo": 1500.39,
          "arena_votes": 4059
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 57.05,
        "coding_score": 55.5,
        "gdpval": 1309.607764439464,
        "terminalbench_hard": 0.538,
        "tau2": 0.956,
        "lcr": 72.7,
        "hle": 44.7,
        "gpqa": 94.1,
        "scicode": 58.9,
        "ifbench": 77.1,
        "critpt": 17.7,
        "mmmu_pro": 82.4
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1500.39
      }
    },
    "confidence_score": 0.93,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "claude-sonnet-46",
    "canonical_name": "Claude Sonnet 4.6 (Adaptive Reasoning, Max Effort)",
    "model_name": "Claude Sonnet 4.6 (Adaptive Reasoning, Max Effort)",
    "aliases": [
      "Claude Sonnet 4.6 (Adaptive Reasoning, Max Effort)",
      "Claude Sonnet 4.6 (Non-reasoning, High Effort)",
      "Claude Sonnet 4.6 (Non-reasoning, Low Effort)",
      "claude-sonnet-4.6"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 3294,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 45.6938,
    "coding_score": 46.4136,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1456.89,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 6.0,
    "latency_seconds": 0.71,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 56.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 1529.1325,
    "terminalbench_hard": 0.4673,
    "tau2": 0.7812,
    "lcr": 62.0102,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 17.3,
    "gpqa": 82.1074,
    "scicode": 45.7551,
    "ifbench": 46.312,
    "aime25": null,
    "critpt": 1.562,
    "mmmu_pro": 70.8551,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.261299+00:00",
        "confidence": 0.65,
        "raw_name": "Claude Sonnet 4.6 (Adaptive Reasoning, Max Effort)",
        "raw_scores": {
          "intelligence_score": 51.27,
          "coding_score": 50.94,
          "context_window": 200000,
          "gdpval": 1632.6648495109562,
          "terminalbench_hard": 0.53,
          "tau2": 0.757,
          "lcr": 70.7,
          "hle": 30.0,
          "gpqa": 87.5,
          "scicode": 46.8,
          "ifbench": 56.6,
          "critpt": 3.1,
          "mmmu_pro": 73.3
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.261408+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "Claude Sonnet 4.6 (Non-reasoning, Low Effort)",
        "raw_scores": {
          "intelligence_score": 42.51,
          "coding_score": 42.98,
          "blended_cost_per_1m": 6.0,
          "latency_seconds": 0.71,
          "tokens_per_second": 56.0,
          "context_window": 200000,
          "gdpval": 1432.6037331248876,
          "terminalbench_hard": 0.424,
          "tau2": 0.789,
          "lcr": 58.7,
          "hle": 10.8,
          "gpqa": 79.7,
          "scicode": 44.1,
          "ifbench": 42.4,
          "critpt": 0.9,
          "mmmu_pro": 69.2
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.261482+00:00",
        "confidence": 0.65,
        "raw_name": "Claude Sonnet 4.6 (Non-reasoning, High Effort)",
        "raw_scores": {
          "intelligence_score": 44.33,
          "coding_score": 46.43,
          "context_window": 200000,
          "gdpval": 1553.3150150350505,
          "terminalbench_hard": 0.462,
          "tau2": 0.795,
          "lcr": 57.7,
          "hle": 13.2,
          "gpqa": 79.9,
          "scicode": 46.9,
          "ifbench": 41.2,
          "critpt": 0.9,
          "mmmu_pro": 70.6
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.124702+00:00",
        "confidence": 1.0,
        "raw_name": "claude-sonnet-4.6",
        "raw_scores": {
          "arena_elo": 1456.89,
          "arena_votes": 3294
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 51.27,
        "coding_score": 50.94,
        "gdpval": 1632.6648495109562,
        "terminalbench_hard": 0.53,
        "tau2": 0.757,
        "lcr": 70.7,
        "hle": 30.0,
        "gpqa": 87.5,
        "scicode": 46.8,
        "ifbench": 56.6,
        "critpt": 3.1,
        "mmmu_pro": 73.3
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1456.89
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "claude-opus-46",
    "canonical_name": "Claude Opus 4.6 (Non-reasoning, High Effort)",
    "model_name": "Claude Opus 4.6 (Non-reasoning, High Effort)",
    "aliases": [
      "Claude Opus 4.6 (Adaptive Reasoning, Max Effort)",
      "Claude Opus 4.6 (Non-reasoning, High Effort)",
      "claude-opus-4.6",
      "claude-opus-4.6-thinking"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 6774,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 49.71,
    "coding_score": 47.825,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1504.04,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 1592.5148,
    "terminalbench_hard": 0.4735,
    "tau2": 0.8845,
    "lcr": 64.5,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 27.65,
    "gpqa": 86.8,
    "scicode": 48.8,
    "ifbench": 48.85,
    "aime25": null,
    "critpt": 7.7,
    "mmmu_pro": 73.95,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.261336+00:00",
        "confidence": 0.65,
        "raw_name": "Claude Opus 4.6 (Non-reasoning, High Effort)",
        "raw_scores": {
          "intelligence_score": 46.39,
          "coding_score": 47.56,
          "context_window": 200000,
          "gdpval": 1578.6121034600746,
          "terminalbench_hard": 0.485,
          "tau2": 0.848,
          "lcr": 58.3,
          "hle": 18.6,
          "gpqa": 84.0,
          "scicode": 45.7,
          "ifbench": 44.6,
          "critpt": 2.8,
          "mmmu_pro": 72.5
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.261370+00:00",
        "confidence": 0.65,
        "raw_name": "Claude Opus 4.6 (Adaptive Reasoning, Max Effort)",
        "raw_scores": {
          "intelligence_score": 53.03,
          "coding_score": 48.09,
          "context_window": 200000,
          "gdpval": 1606.4175944685169,
          "terminalbench_hard": 0.462,
          "tau2": 0.921,
          "lcr": 70.7,
          "hle": 36.7,
          "gpqa": 89.6,
          "scicode": 51.9,
          "ifbench": 53.1,
          "critpt": 12.6,
          "mmmu_pro": 75.4
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.124456+00:00",
        "confidence": 1.0,
        "raw_name": "claude-opus-4.6",
        "raw_scores": {
          "arena_elo": 1504.2,
          "arena_votes": 6774
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.124508+00:00",
        "confidence": 1.0,
        "raw_name": "claude-opus-4.6-thinking",
        "raw_scores": {
          "arena_elo": 1503.88,
          "arena_votes": 5934
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 46.39,
        "coding_score": 47.56,
        "gdpval": 1578.6121034600746,
        "terminalbench_hard": 0.485,
        "tau2": 0.848,
        "lcr": 58.3,
        "hle": 18.6,
        "gpqa": 84.0,
        "scicode": 45.7,
        "ifbench": 44.6,
        "critpt": 2.8,
        "mmmu_pro": 72.5
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1504.2
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "claude-45-haiku",
    "canonical_name": "Claude 4.5 Haiku (Non-reasoning)",
    "model_name": "Claude 4.5 Haiku (Non-reasoning)",
    "aliases": [
      "Claude 4.5 Haiku (Non-reasoning)",
      "Claude 4.5 Haiku (Reasoning)",
      "claude-haiku-4.5-20251001"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 46678,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 34.025,
    "coding_score": 31.125,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1404.9,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 1167.1762,
    "terminalbench_hard": 0.273,
    "tau2": 0.436,
    "lcr": 57.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 7.0,
    "gpqa": 65.9,
    "scicode": 38.85,
    "ifbench": 48.15,
    "aime25": 61.35,
    "critpt": 0.0,
    "mmmu_pro": 56.7,
    "livecodebench": 56.3,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.261448+00:00",
        "confidence": 0.79,
        "raw_name": "Claude 4.5 Haiku (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 31.03,
          "coding_score": 29.64,
          "context_window": 200000,
          "gdpval": 1166.4908586115118,
          "terminalbench_hard": 0.273,
          "tau2": 0.325,
          "lcr": 43.7,
          "hle": 4.3,
          "gpqa": 64.6,
          "scicode": 34.4,
          "ifbench": 42.0,
          "aime25": 39.0,
          "critpt": 0.0,
          "mmmu_pro": 55.1,
          "livecodebench": 51.1
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.261523+00:00",
        "confidence": 0.79,
        "raw_name": "Claude 4.5 Haiku (Reasoning)",
        "raw_scores": {
          "intelligence_score": 37.02,
          "coding_score": 32.61,
          "context_window": 200000,
          "gdpval": 1167.8615896169708,
          "terminalbench_hard": 0.273,
          "tau2": 0.547,
          "lcr": 70.3,
          "hle": 9.7,
          "gpqa": 67.2,
          "scicode": 43.3,
          "ifbench": 54.3,
          "aime25": 83.7,
          "critpt": 0.0,
          "mmmu_pro": 58.3,
          "livecodebench": 61.5
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125420+00:00",
        "confidence": 1.0,
        "raw_name": "claude-haiku-4.5-20251001",
        "raw_scores": {
          "arena_elo": 1404.9,
          "arena_votes": 46678
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 31.03,
        "coding_score": 29.64,
        "gdpval": 1166.4908586115118,
        "terminalbench_hard": 0.273,
        "tau2": 0.325,
        "lcr": 43.7,
        "hle": 4.3,
        "gpqa": 64.6,
        "scicode": 34.4,
        "ifbench": 42.0,
        "aime25": 39.0,
        "critpt": 0.0,
        "mmmu_pro": 55.1,
        "livecodebench": 51.1
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1404.9
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "magistral-small-12",
    "canonical_name": "Magistral Small 1.2",
    "model_name": "Magistral Small 1.2",
    "aliases": [
      "Magistral Small 1.2"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 18.11,
    "coding_score": 14.76,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.75,
    "latency_seconds": 0.33,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 213.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 725.4557,
    "terminalbench_hard": 0.045,
    "tau2": 0.278,
    "lcr": 16.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 6.1,
    "gpqa": 66.3,
    "scicode": 35.2,
    "ifbench": 44.4,
    "aime25": 80.3,
    "critpt": 0.3,
    "mmmu_pro": 55.5,
    "livecodebench": 72.3,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.261568+00:00",
        "confidence": 1.0,
        "raw_name": "Magistral Small 1.2",
        "raw_scores": {
          "intelligence_score": 18.11,
          "coding_score": 14.76,
          "blended_cost_per_1m": 0.75,
          "latency_seconds": 0.33,
          "tokens_per_second": 213.0,
          "context_window": 128000,
          "gdpval": 725.4557239261692,
          "terminalbench_hard": 0.045,
          "tau2": 0.278,
          "lcr": 16.3,
          "hle": 6.1,
          "gpqa": 66.3,
          "scicode": 35.2,
          "ifbench": 44.4,
          "aime25": 80.3,
          "critpt": 0.3,
          "mmmu_pro": 55.5,
          "livecodebench": 72.3
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 18.11,
        "coding_score": 14.76,
        "gdpval": 725.4557239261692,
        "terminalbench_hard": 0.045,
        "tau2": 0.278,
        "lcr": 16.3,
        "hle": 6.1,
        "gpqa": 66.3,
        "scicode": 35.2,
        "ifbench": 44.4,
        "aime25": 80.3,
        "critpt": 0.3,
        "mmmu_pro": 55.5,
        "livecodebench": 72.3
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "magistral-medium-12",
    "canonical_name": "Magistral Medium 1.2",
    "model_name": "Magistral Medium 1.2",
    "aliases": [
      "Magistral Medium 1.2"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 27.04,
    "coding_score": 21.66,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 2.75,
    "latency_seconds": 0.51,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 29.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 673.4666,
    "terminalbench_hard": 0.129,
    "tau2": 0.52,
    "lcr": 51.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 9.6,
    "gpqa": 73.9,
    "scicode": 39.2,
    "ifbench": 43.0,
    "aime25": 82.0,
    "critpt": 0.3,
    "mmmu_pro": 59.7,
    "livecodebench": 75.0,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.261613+00:00",
        "confidence": 1.0,
        "raw_name": "Magistral Medium 1.2",
        "raw_scores": {
          "intelligence_score": 27.04,
          "coding_score": 21.66,
          "blended_cost_per_1m": 2.75,
          "latency_seconds": 0.51,
          "tokens_per_second": 29.0,
          "context_window": 128000,
          "gdpval": 673.4665570609145,
          "terminalbench_hard": 0.129,
          "tau2": 0.52,
          "lcr": 51.3,
          "hle": 9.6,
          "gpqa": 73.9,
          "scicode": 39.2,
          "ifbench": 43.0,
          "aime25": 82.0,
          "critpt": 0.3,
          "mmmu_pro": 59.7,
          "livecodebench": 75.0
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 27.04,
        "coding_score": 21.66,
        "gdpval": 673.4665570609145,
        "terminalbench_hard": 0.129,
        "tau2": 0.52,
        "lcr": 51.3,
        "hle": 9.6,
        "gpqa": 73.9,
        "scicode": 39.2,
        "ifbench": 43.0,
        "aime25": 82.0,
        "critpt": 0.3,
        "mmmu_pro": 59.7,
        "livecodebench": 75.0
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "ministral-3-3b",
    "canonical_name": "Ministral 3 3B",
    "model_name": "Ministral 3 3B",
    "aliases": [
      "Ministral 3 3B"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 11.24,
    "coding_score": 4.78,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.1,
    "latency_seconds": 0.26,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 296.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 548.9871,
    "terminalbench_hard": 0.0,
    "tau2": 0.249,
    "lcr": 11.7,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.3,
    "gpqa": 35.8,
    "scicode": 14.4,
    "ifbench": 26.8,
    "aime25": 22.0,
    "critpt": 0.0,
    "mmmu_pro": 38.1,
    "livecodebench": 24.7,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.261656+00:00",
        "confidence": 1.0,
        "raw_name": "Ministral 3 3B",
        "raw_scores": {
          "intelligence_score": 11.24,
          "coding_score": 4.78,
          "blended_cost_per_1m": 0.1,
          "latency_seconds": 0.26,
          "tokens_per_second": 296.0,
          "context_window": 256000,
          "gdpval": 548.98713223079,
          "terminalbench_hard": 0.0,
          "tau2": 0.249,
          "lcr": 11.7,
          "hle": 5.3,
          "gpqa": 35.8,
          "scicode": 14.4,
          "ifbench": 26.8,
          "aime25": 22.0,
          "critpt": 0.0,
          "mmmu_pro": 38.1,
          "livecodebench": 24.7
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 11.24,
        "coding_score": 4.78,
        "gdpval": 548.98713223079,
        "terminalbench_hard": 0.0,
        "tau2": 0.249,
        "lcr": 11.7,
        "hle": 5.3,
        "gpqa": 35.8,
        "scicode": 14.4,
        "ifbench": 26.8,
        "aime25": 22.0,
        "critpt": 0.0,
        "mmmu_pro": 38.1,
        "livecodebench": 24.7
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "mistral-large-3",
    "canonical_name": "Mistral Large 3",
    "model_name": "Mistral Large 3",
    "aliases": [
      "Mistral Large 3",
      "mistral-large-3"
    ],
    "provider": "Mistral",
    "context_window": 256000,
    "open_source": true,
    "arena_votes": 26461,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 22.72,
    "coding_score": 22.68,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1414.34,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.75,
    "latency_seconds": 0.5,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 56.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 894.0459,
    "terminalbench_hard": 0.159,
    "tau2": 0.246,
    "lcr": 34.7,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.1,
    "gpqa": 68.0,
    "scicode": 36.2,
    "ifbench": 36.2,
    "aime25": 38.0,
    "critpt": 0.0,
    "mmmu_pro": 55.7,
    "livecodebench": 46.5,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.261700+00:00",
        "confidence": 1.0,
        "raw_name": "Mistral Large 3",
        "raw_scores": {
          "intelligence_score": 22.72,
          "coding_score": 22.68,
          "blended_cost_per_1m": 0.75,
          "latency_seconds": 0.5,
          "tokens_per_second": 56.0,
          "context_window": 256000,
          "gdpval": 894.0458604667072,
          "terminalbench_hard": 0.159,
          "tau2": 0.246,
          "lcr": 34.7,
          "hle": 4.1,
          "gpqa": 68.0,
          "scicode": 36.2,
          "ifbench": 36.2,
          "aime25": 38.0,
          "critpt": 0.0,
          "mmmu_pro": 55.7,
          "livecodebench": 46.5
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125310+00:00",
        "confidence": 1.0,
        "raw_name": "mistral-large-3",
        "raw_scores": {
          "arena_elo": 1414.34,
          "arena_votes": 26461
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 22.72,
        "coding_score": 22.68,
        "gdpval": 894.0458604667072,
        "terminalbench_hard": 0.159,
        "tau2": 0.246,
        "lcr": 34.7,
        "hle": 4.1,
        "gpqa": 68.0,
        "scicode": 36.2,
        "ifbench": 36.2,
        "aime25": 38.0,
        "critpt": 0.0,
        "mmmu_pro": 55.7,
        "livecodebench": 46.5
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1414.34
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "devstral-small-2",
    "canonical_name": "Devstral Small 2",
    "model_name": "Devstral Small 2",
    "aliases": [
      "Devstral Small 2"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 19.33,
    "coding_score": 20.72,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.37,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 200.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 867.1765,
    "terminalbench_hard": 0.167,
    "tau2": 0.234,
    "lcr": 24.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 3.4,
    "gpqa": 53.2,
    "scicode": 28.8,
    "ifbench": 31.2,
    "aime25": 34.3,
    "critpt": 0.0,
    "mmmu_pro": 44.6,
    "livecodebench": 34.8,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.261743+00:00",
        "confidence": 1.0,
        "raw_name": "Devstral Small 2",
        "raw_scores": {
          "intelligence_score": 19.33,
          "coding_score": 20.72,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.37,
          "tokens_per_second": 200.0,
          "context_window": 256000,
          "gdpval": 867.1764645422761,
          "terminalbench_hard": 0.167,
          "tau2": 0.234,
          "lcr": 24.0,
          "hle": 3.4,
          "gpqa": 53.2,
          "scicode": 28.8,
          "ifbench": 31.2,
          "aime25": 34.3,
          "critpt": 0.0,
          "mmmu_pro": 44.6,
          "livecodebench": 34.8
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.33,
        "coding_score": 20.72,
        "gdpval": 867.1764645422761,
        "terminalbench_hard": 0.167,
        "tau2": 0.234,
        "lcr": 24.0,
        "hle": 3.4,
        "gpqa": 53.2,
        "scicode": 28.8,
        "ifbench": 31.2,
        "aime25": 34.3,
        "critpt": 0.0,
        "mmmu_pro": 44.6,
        "livecodebench": 34.8
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "devstral-2",
    "canonical_name": "Devstral 2",
    "model_name": "Devstral 2",
    "aliases": [
      "Devstral 2"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": false,
    "arena_votes": null,
    "license_type": "Modified MIT License",
    "creator": null,
    "intelligence_score": 22.0,
    "coding_score": 23.66,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.39,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 76.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 902.7165,
    "terminalbench_hard": 0.189,
    "tau2": 0.249,
    "lcr": 30.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 3.6,
    "gpqa": 59.4,
    "scicode": 33.1,
    "ifbench": 38.1,
    "aime25": 36.7,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 44.8,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.261785+00:00",
        "confidence": 1.0,
        "raw_name": "Devstral 2",
        "raw_scores": {
          "intelligence_score": 22.0,
          "coding_score": 23.66,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.39,
          "tokens_per_second": 76.0,
          "context_window": 256000,
          "gdpval": 902.7165259671074,
          "terminalbench_hard": 0.189,
          "tau2": 0.249,
          "lcr": 30.0,
          "hle": 3.6,
          "gpqa": 59.4,
          "scicode": 33.1,
          "ifbench": 38.1,
          "aime25": 36.7,
          "critpt": 0.0,
          "livecodebench": 44.8
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 22.0,
        "coding_score": 23.66,
        "gdpval": 902.7165259671074,
        "terminalbench_hard": 0.189,
        "tau2": 0.249,
        "lcr": 30.0,
        "hle": 3.6,
        "gpqa": 59.4,
        "scicode": 33.1,
        "ifbench": 38.1,
        "aime25": 36.7,
        "critpt": 0.0,
        "livecodebench": 44.8
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "mistral-small-32",
    "canonical_name": "Mistral Small 3.2",
    "model_name": "Mistral Small 3.2",
    "aliases": [
      "Mistral Small 3.2"
    ],
    "provider": "Mistral AI",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 15.03,
    "coding_score": 13.34,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.15,
    "latency_seconds": 0.31,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 118.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 359.3453,
    "terminalbench_hard": 0.068,
    "tau2": 0.295,
    "lcr": 17.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.3,
    "gpqa": 50.5,
    "scicode": 26.4,
    "ifbench": 33.5,
    "aime25": 27.0,
    "critpt": 0.0,
    "mmmu_pro": 48.0,
    "livecodebench": 27.5,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.261829+00:00",
        "confidence": 1.0,
        "raw_name": "Mistral Small 3.2",
        "raw_scores": {
          "intelligence_score": 15.03,
          "coding_score": 13.34,
          "blended_cost_per_1m": 0.15,
          "latency_seconds": 0.31,
          "tokens_per_second": 118.0,
          "context_window": 128000,
          "gdpval": 359.34525862943815,
          "terminalbench_hard": 0.068,
          "tau2": 0.295,
          "lcr": 17.3,
          "hle": 4.3,
          "gpqa": 50.5,
          "scicode": 26.4,
          "ifbench": 33.5,
          "aime25": 27.0,
          "critpt": 0.0,
          "mmmu_pro": 48.0,
          "livecodebench": 27.5
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.03,
        "coding_score": 13.34,
        "gdpval": 359.34525862943815,
        "terminalbench_hard": 0.068,
        "tau2": 0.295,
        "lcr": 17.3,
        "hle": 4.3,
        "gpqa": 50.5,
        "scicode": 26.4,
        "ifbench": 33.5,
        "aime25": 27.0,
        "critpt": 0.0,
        "mmmu_pro": 48.0,
        "livecodebench": 27.5
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "ministral-3-14b",
    "canonical_name": "Ministral 3 14B",
    "model_name": "Ministral 3 14B",
    "aliases": [
      "Ministral 3 14B"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 15.96,
    "coding_score": 10.9,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.2,
    "latency_seconds": 0.29,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 124.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 703.5105,
    "terminalbench_hard": 0.045,
    "tau2": 0.272,
    "lcr": 22.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.6,
    "gpqa": 57.2,
    "scicode": 23.6,
    "ifbench": 32.0,
    "aime25": 30.0,
    "critpt": 0.0,
    "mmmu_pro": 49.8,
    "livecodebench": 35.1,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.261872+00:00",
        "confidence": 1.0,
        "raw_name": "Ministral 3 14B",
        "raw_scores": {
          "intelligence_score": 15.96,
          "coding_score": 10.9,
          "blended_cost_per_1m": 0.2,
          "latency_seconds": 0.29,
          "tokens_per_second": 124.0,
          "context_window": 256000,
          "gdpval": 703.510499244125,
          "terminalbench_hard": 0.045,
          "tau2": 0.272,
          "lcr": 22.0,
          "hle": 4.6,
          "gpqa": 57.2,
          "scicode": 23.6,
          "ifbench": 32.0,
          "aime25": 30.0,
          "critpt": 0.0,
          "mmmu_pro": 49.8,
          "livecodebench": 35.1
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.96,
        "coding_score": 10.9,
        "gdpval": 703.510499244125,
        "terminalbench_hard": 0.045,
        "tau2": 0.272,
        "lcr": 22.0,
        "hle": 4.6,
        "gpqa": 57.2,
        "scicode": 23.6,
        "ifbench": 32.0,
        "aime25": 30.0,
        "critpt": 0.0,
        "mmmu_pro": 49.8,
        "livecodebench": 35.1
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "mistral-medium-31",
    "canonical_name": "Mistral Medium 3.1",
    "model_name": "Mistral Medium 3.1",
    "aliases": [
      "Mistral Medium 3.1"
    ],
    "provider": "Mistral AI",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 21.13,
    "coding_score": 18.34,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.8,
    "latency_seconds": 0.37,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 105.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 828.4784,
    "terminalbench_hard": 0.106,
    "tau2": 0.406,
    "lcr": 19.7,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.4,
    "gpqa": 58.8,
    "scicode": 33.8,
    "ifbench": 39.8,
    "aime25": 38.3,
    "critpt": 0.0,
    "mmmu_pro": 54.2,
    "livecodebench": 40.6,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.261915+00:00",
        "confidence": 1.0,
        "raw_name": "Mistral Medium 3.1",
        "raw_scores": {
          "intelligence_score": 21.13,
          "coding_score": 18.34,
          "blended_cost_per_1m": 0.8,
          "latency_seconds": 0.37,
          "tokens_per_second": 105.0,
          "context_window": 128000,
          "gdpval": 828.4783919391759,
          "terminalbench_hard": 0.106,
          "tau2": 0.406,
          "lcr": 19.7,
          "hle": 4.4,
          "gpqa": 58.8,
          "scicode": 33.8,
          "ifbench": 39.8,
          "aime25": 38.3,
          "critpt": 0.0,
          "mmmu_pro": 54.2,
          "livecodebench": 40.6
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 21.13,
        "coding_score": 18.34,
        "gdpval": 828.4783919391759,
        "terminalbench_hard": 0.106,
        "tau2": 0.406,
        "lcr": 19.7,
        "hle": 4.4,
        "gpqa": 58.8,
        "scicode": 33.8,
        "ifbench": 39.8,
        "aime25": 38.3,
        "critpt": 0.0,
        "mmmu_pro": 54.2,
        "livecodebench": 40.6
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "ministral-3-8b",
    "canonical_name": "Ministral 3 8B",
    "model_name": "Ministral 3 8B",
    "aliases": [
      "Ministral 3 8B"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 14.64,
    "coding_score": 9.97,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.15,
    "latency_seconds": 0.28,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 177.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 697.8624,
    "terminalbench_hard": 0.045,
    "tau2": 0.266,
    "lcr": 24.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.3,
    "gpqa": 47.1,
    "scicode": 20.8,
    "ifbench": 29.1,
    "aime25": 31.7,
    "critpt": 0.0,
    "mmmu_pro": 46.0,
    "livecodebench": 30.3,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.261959+00:00",
        "confidence": 1.0,
        "raw_name": "Ministral 3 8B",
        "raw_scores": {
          "intelligence_score": 14.64,
          "coding_score": 9.97,
          "blended_cost_per_1m": 0.15,
          "latency_seconds": 0.28,
          "tokens_per_second": 177.0,
          "context_window": 256000,
          "gdpval": 697.8623878313061,
          "terminalbench_hard": 0.045,
          "tau2": 0.266,
          "lcr": 24.0,
          "hle": 4.3,
          "gpqa": 47.1,
          "scicode": 20.8,
          "ifbench": 29.1,
          "aime25": 31.7,
          "critpt": 0.0,
          "mmmu_pro": 46.0,
          "livecodebench": 30.3
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.64,
        "coding_score": 9.97,
        "gdpval": 697.8623878313061,
        "terminalbench_hard": 0.045,
        "tau2": 0.266,
        "lcr": 24.0,
        "hle": 4.3,
        "gpqa": 47.1,
        "scicode": 20.8,
        "ifbench": 29.1,
        "aime25": 31.7,
        "critpt": 0.0,
        "mmmu_pro": 46.0,
        "livecodebench": 30.3
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-r1-distill-llama-70b",
    "canonical_name": "DeepSeek R1 Distill Llama 70B",
    "model_name": "DeepSeek R1 Distill Llama 70B",
    "aliases": [
      "DeepSeek R1 Distill Llama 70B"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "LLAMA 3.3 COMMUNITY LICENSE AGREEMENT",
    "creator": null,
    "intelligence_score": 15.9502,
    "coding_score": 11.43,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.88,
    "latency_seconds": 0.81,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 57.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": 0.015,
    "tau2": 0.219,
    "lcr": 11.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 6.1,
    "gpqa": 40.2,
    "scicode": 31.2,
    "ifbench": 27.6,
    "aime25": 53.7,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 26.6,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.261999+00:00",
        "confidence": 1.0,
        "raw_name": "DeepSeek R1 Distill Llama 70B",
        "raw_scores": {
          "intelligence_score": 15.950177423585206,
          "coding_score": 11.43,
          "blended_cost_per_1m": 0.88,
          "latency_seconds": 0.81,
          "tokens_per_second": 57.0,
          "context_window": 128000,
          "terminalbench_hard": 0.015,
          "tau2": 0.219,
          "lcr": 11.0,
          "hle": 6.1,
          "gpqa": 40.2,
          "scicode": 31.2,
          "ifbench": 27.6,
          "aime25": 53.7,
          "critpt": 0.0,
          "livecodebench": 26.6
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.950177423585206,
        "coding_score": 11.43,
        "terminalbench_hard": 0.015,
        "tau2": 0.219,
        "lcr": 11.0,
        "hle": 6.1,
        "gpqa": 40.2,
        "scicode": 31.2,
        "ifbench": 27.6,
        "aime25": 53.7,
        "critpt": 0.0,
        "livecodebench": 26.6
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-r1",
    "canonical_name": "DeepSeek R1 0528 (May '25)",
    "model_name": "DeepSeek R1 0528 (May '25)",
    "aliases": [
      "DeepSeek R1 (Jan '25)",
      "DeepSeek R1 0528 (May '25)",
      "deepseek-r1",
      "deepseek-r1-0528"
    ],
    "provider": "DeepSeek",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": 19177,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": 22.9,
    "coding_score": 19.99,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1408.395,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 517.1857,
    "terminalbench_hard": 0.11,
    "tau2": 0.2395,
    "lcr": 53.5,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 12.1,
    "gpqa": 76.05,
    "scicode": 38.0,
    "ifbench": 39.3,
    "aime25": 72.0,
    "critpt": 1.0,
    "mmmu_pro": null,
    "livecodebench": 69.35,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.262038+00:00",
        "confidence": 0.79,
        "raw_name": "DeepSeek R1 0528 (May '25)",
        "raw_scores": {
          "intelligence_score": 27.01,
          "coding_score": 24.03,
          "context_window": 128000,
          "gdpval": 720.8131561371974,
          "terminalbench_hard": 0.159,
          "tau2": 0.365,
          "lcr": 54.7,
          "hle": 14.9,
          "gpqa": 81.3,
          "scicode": 40.3,
          "ifbench": 39.6,
          "aime25": 76.0,
          "critpt": 1.4,
          "livecodebench": 77.0
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.272462+00:00",
        "confidence": 0.79,
        "raw_name": "DeepSeek R1 (Jan '25)",
        "raw_scores": {
          "intelligence_score": 18.79,
          "coding_score": 15.95,
          "context_window": 128000,
          "gdpval": 313.5581981776156,
          "terminalbench_hard": 0.061,
          "tau2": 0.114,
          "lcr": 52.3,
          "hle": 9.3,
          "gpqa": 70.8,
          "scicode": 35.7,
          "ifbench": 39.0,
          "aime25": 68.0,
          "critpt": 0.6,
          "livecodebench": 61.7
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125177+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-r1-0528",
        "raw_scores": {
          "arena_elo": 1419.1,
          "arena_votes": 19177
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125552+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-r1",
        "raw_scores": {
          "arena_elo": 1397.69,
          "arena_votes": 18537
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 27.01,
        "coding_score": 24.03,
        "gdpval": 720.8131561371974,
        "terminalbench_hard": 0.159,
        "tau2": 0.365,
        "lcr": 54.7,
        "hle": 14.9,
        "gpqa": 81.3,
        "scicode": 40.3,
        "ifbench": 39.6,
        "aime25": 76.0,
        "critpt": 1.4,
        "livecodebench": 77.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1419.1
      }
    },
    "confidence_score": 0.895,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-v32",
    "canonical_name": "DeepSeek V3.2 (Non-reasoning)",
    "model_name": "DeepSeek V3.2 (Non-reasoning)",
    "aliases": [
      "DeepSeek V3.2 (Non-reasoning)",
      "DeepSeek V3.2 (Reasoning)",
      "deepseek-v3.2",
      "deepseek-v3.2-thinking"
    ],
    "provider": "DeepSeek",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": 30091,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": 36.835,
    "coding_score": 35.65,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1419.75,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 1040.7036,
    "terminalbench_hard": 0.341,
    "tau2": 0.8475,
    "lcr": 52.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 16.35,
    "gpqa": 79.55,
    "scicode": 38.8,
    "ifbench": 54.85,
    "aime25": 75.5,
    "critpt": 1.9,
    "mmmu_pro": null,
    "livecodebench": 72.75,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.262077+00:00",
        "confidence": 0.79,
        "raw_name": "DeepSeek V3.2 (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 32.06,
          "coding_score": 34.6,
          "context_window": 128000,
          "gdpval": 888.0769172475143,
          "terminalbench_hard": 0.326,
          "tau2": 0.789,
          "lcr": 39.0,
          "hle": 10.5,
          "gpqa": 75.1,
          "scicode": 38.7,
          "ifbench": 49.0,
          "aime25": 59.0,
          "critpt": 0.9,
          "livecodebench": 59.3
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.262117+00:00",
        "confidence": 0.79,
        "raw_name": "DeepSeek V3.2 (Reasoning)",
        "raw_scores": {
          "intelligence_score": 41.61,
          "coding_score": 36.7,
          "context_window": 128000,
          "gdpval": 1193.330210992916,
          "terminalbench_hard": 0.356,
          "tau2": 0.906,
          "lcr": 65.0,
          "hle": 22.2,
          "gpqa": 84.0,
          "scicode": 38.9,
          "ifbench": 60.7,
          "aime25": 92.0,
          "critpt": 2.9,
          "livecodebench": 86.2
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125152+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-v3.2-thinking",
        "raw_scores": {
          "arena_elo": 1420.12,
          "arena_votes": 25060
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125164+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-v3.2",
        "raw_scores": {
          "arena_elo": 1419.38,
          "arena_votes": 30091
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 32.06,
        "coding_score": 34.6,
        "gdpval": 888.0769172475143,
        "terminalbench_hard": 0.326,
        "tau2": 0.789,
        "lcr": 39.0,
        "hle": 10.5,
        "gpqa": 75.1,
        "scicode": 38.7,
        "ifbench": 49.0,
        "aime25": 59.0,
        "critpt": 0.9,
        "livecodebench": 59.3
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1420.12
      }
    },
    "confidence_score": 0.895,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-v32-speciale",
    "canonical_name": "DeepSeek V3.2 Speciale",
    "model_name": "DeepSeek V3.2 Speciale",
    "aliases": [
      "DeepSeek V3.2 Exp (Non-reasoning)",
      "DeepSeek V3.2 Exp (Reasoning)",
      "DeepSeek V3.2 Speciale",
      "deepseek-v3.2-exp",
      "deepseek-v3.2-exp-thinking"
    ],
    "provider": "DeepSeek",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": 11683,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": 31.9578,
    "coding_score": 34.0564,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1423.435,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 845.5203,
    "terminalbench_hard": 0.3067,
    "tau2": 0.2076,
    "lcr": 57.2791,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 16.9752,
    "gpqa": 80.7616,
    "scicode": 40.8155,
    "ifbench": 54.5302,
    "aime25": 82.0023,
    "critpt": 3.7256,
    "mmmu_pro": null,
    "livecodebench": 75.8516,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.262159+00:00",
        "confidence": 1.0,
        "raw_name": "DeepSeek V3.2 Speciale",
        "raw_scores": {
          "intelligence_score": 34.07946327638502,
          "coding_score": 37.89,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000,
          "gdpval": 500.0,
          "terminalbench_hard": 0.348,
          "tau2": 0.0,
          "lcr": 59.3,
          "hle": 26.1,
          "gpqa": 87.1,
          "scicode": 44.0,
          "ifbench": 63.9,
          "aime25": 96.7,
          "critpt": 7.4,
          "livecodebench": 89.6
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.272502+00:00",
        "confidence": 0.79,
        "raw_name": "DeepSeek V3.2 Exp (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 28.33,
          "coding_score": 29.98,
          "context_window": 128000,
          "gdpval": 1101.238279564431,
          "terminalbench_hard": 0.25,
          "tau2": 0.339,
          "lcr": 43.0,
          "hle": 8.6,
          "gpqa": 73.8,
          "scicode": 39.9,
          "ifbench": 43.1,
          "aime25": 57.7,
          "critpt": 1.4,
          "livecodebench": 55.4
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.272703+00:00",
        "confidence": 0.79,
        "raw_name": "DeepSeek V3.2 Exp (Reasoning)",
        "raw_scores": {
          "intelligence_score": 32.9,
          "coding_score": 33.28,
          "context_window": 128000,
          "gdpval": 1027.1699514320856,
          "terminalbench_hard": 0.311,
          "tau2": 0.339,
          "lcr": 69.0,
          "hle": 13.8,
          "gpqa": 79.7,
          "scicode": 37.7,
          "ifbench": 54.1,
          "aime25": 87.7,
          "critpt": 1.4,
          "livecodebench": 78.9
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125099+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-v3.2-exp",
        "raw_scores": {
          "arena_elo": 1423.62,
          "arena_votes": 11683
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125112+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-v3.2-exp-thinking",
        "raw_scores": {
          "arena_elo": 1423.25,
          "arena_votes": 8944
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 34.07946327638502,
        "coding_score": 37.89,
        "gdpval": 500.0,
        "terminalbench_hard": 0.348,
        "tau2": 0.0,
        "lcr": 59.3,
        "hle": 26.1,
        "gpqa": 87.1,
        "scicode": 44.0,
        "ifbench": 63.9,
        "aime25": 96.7,
        "critpt": 7.4,
        "livecodebench": 89.6
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1423.62
      }
    },
    "confidence_score": 0.916,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-r1-0528-qwen3-8b",
    "canonical_name": "DeepSeek R1 0528 Qwen3 8B",
    "model_name": "DeepSeek R1 0528 Qwen3 8B",
    "aliases": [
      "DeepSeek R1 0528 Qwen3 8B"
    ],
    "provider": "Alibaba",
    "context_window": 32768,
    "open_source": true,
    "arena_votes": null,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": 16.4307,
    "coding_score": 7.8,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": 0.015,
    "tau2": 0.0,
    "lcr": 13.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.6,
    "gpqa": 61.2,
    "scicode": 20.4,
    "ifbench": 19.9,
    "aime25": 63.7,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 51.3,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.262199+00:00",
        "confidence": 1.0,
        "raw_name": "DeepSeek R1 0528 Qwen3 8B",
        "raw_scores": {
          "intelligence_score": 16.43067398648048,
          "coding_score": 7.8,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32768,
          "terminalbench_hard": 0.015,
          "tau2": 0.0,
          "lcr": 13.0,
          "hle": 5.6,
          "gpqa": 61.2,
          "scicode": 20.4,
          "ifbench": 19.9,
          "aime25": 63.7,
          "critpt": 0.0,
          "livecodebench": 51.3
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 16.43067398648048,
        "coding_score": 7.8,
        "terminalbench_hard": 0.015,
        "tau2": 0.0,
        "lcr": 13.0,
        "hle": 5.6,
        "gpqa": 61.2,
        "scicode": 20.4,
        "ifbench": 19.9,
        "aime25": 63.7,
        "critpt": 0.0,
        "livecodebench": 51.3
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "r1-1776",
    "canonical_name": "R1 1776",
    "model_name": "R1 1776",
    "aliases": [
      "R1 1776"
    ],
    "provider": "DeepSeek",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": 11.9893,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.262221+00:00",
        "confidence": 0.65,
        "raw_name": "R1 1776",
        "raw_scores": {
          "intelligence_score": 11.989331081091219,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 11.989331081091219
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "falcon-h1r-7b",
    "canonical_name": "Falcon-H1R-7B",
    "model_name": "Falcon-H1R-7B",
    "aliases": [
      "Falcon-H1R-7B"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 15.84,
    "coding_score": 9.81,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 428.279,
    "terminalbench_hard": 0.023,
    "tau2": 0.278,
    "lcr": 8.7,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 10.8,
    "gpqa": 66.1,
    "scicode": 24.9,
    "ifbench": 54.4,
    "aime25": 80.0,
    "critpt": 0.3,
    "mmmu_pro": null,
    "livecodebench": 72.4,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.262277+00:00",
        "confidence": 1.0,
        "raw_name": "Falcon-H1R-7B",
        "raw_scores": {
          "intelligence_score": 15.84,
          "coding_score": 9.81,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 256000,
          "gdpval": 428.2790074242391,
          "terminalbench_hard": 0.023,
          "tau2": 0.278,
          "lcr": 8.7,
          "hle": 10.8,
          "gpqa": 66.1,
          "scicode": 24.9,
          "ifbench": 54.4,
          "aime25": 80.0,
          "critpt": 0.3,
          "livecodebench": 72.4
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.84,
        "coding_score": 9.81,
        "gdpval": 428.2790074242391,
        "terminalbench_hard": 0.023,
        "tau2": 0.278,
        "lcr": 8.7,
        "hle": 10.8,
        "gpqa": 66.1,
        "scicode": 24.9,
        "ifbench": 54.4,
        "aime25": 80.0,
        "critpt": 0.3,
        "livecodebench": 72.4
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "grok-41-fast",
    "canonical_name": "Grok 4.1 Fast (Reasoning)",
    "model_name": "Grok 4.1 Fast (Reasoning)",
    "aliases": [
      "Grok 4.1 Fast (Non-reasoning)",
      "Grok 4.1 Fast (Reasoning)",
      "grok-4.1-fast-reasoning"
    ],
    "provider": "xAI",
    "context_window": 2000000,
    "open_source": null,
    "arena_votes": 30487,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 31.04,
    "coding_score": 25.185,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1430.74,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 934.7023,
    "terminalbench_hard": 0.193,
    "tau2": 0.785,
    "lcr": 45.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 11.3,
    "gpqa": 74.5,
    "scicode": 36.9,
    "ifbench": 44.6,
    "aime25": 61.8,
    "critpt": 1.45,
    "mmmu_pro": 55.85,
    "livecodebench": 61.05,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.262325+00:00",
        "confidence": 0.79,
        "raw_name": "Grok 4.1 Fast (Reasoning)",
        "raw_scores": {
          "intelligence_score": 38.54,
          "coding_score": 30.9,
          "context_window": 2000000,
          "gdpval": 1043.4312061609066,
          "terminalbench_hard": 0.242,
          "tau2": 0.933,
          "lcr": 68.0,
          "hle": 17.6,
          "gpqa": 85.3,
          "scicode": 44.2,
          "ifbench": 52.7,
          "aime25": 89.3,
          "critpt": 2.9,
          "mmmu_pro": 63.3,
          "livecodebench": 82.2
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.262412+00:00",
        "confidence": 0.79,
        "raw_name": "Grok 4.1 Fast (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 23.54,
          "coding_score": 19.47,
          "context_window": 2000000,
          "gdpval": 825.9734886477772,
          "terminalbench_hard": 0.144,
          "tau2": 0.637,
          "lcr": 22.0,
          "hle": 5.0,
          "gpqa": 63.7,
          "scicode": 29.6,
          "ifbench": 36.5,
          "aime25": 34.3,
          "critpt": 0.0,
          "mmmu_pro": 48.4,
          "livecodebench": 39.9
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125016+00:00",
        "confidence": 1.0,
        "raw_name": "grok-4.1-fast-reasoning",
        "raw_scores": {
          "arena_elo": 1430.74,
          "arena_votes": 30487
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 38.54,
        "coding_score": 30.9,
        "gdpval": 1043.4312061609066,
        "terminalbench_hard": 0.242,
        "tau2": 0.933,
        "lcr": 68.0,
        "hle": 17.6,
        "gpqa": 85.3,
        "scicode": 44.2,
        "ifbench": 52.7,
        "aime25": 89.3,
        "critpt": 2.9,
        "mmmu_pro": 63.3,
        "livecodebench": 82.2
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1430.74
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "grok-3-mini",
    "canonical_name": "Grok 3 mini Reasoning (high)",
    "model_name": "Grok 3 mini Reasoning (high)",
    "aliases": [
      "Grok 3 mini Reasoning (high)",
      "grok-3-mini-high"
    ],
    "provider": "xAI",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": 17412,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 32.02,
    "coding_score": 25.16,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1362.86,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.35,
    "latency_seconds": 0.76,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 195.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 477.9495,
    "terminalbench_hard": 0.174,
    "tau2": 0.904,
    "lcr": 50.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 11.1,
    "gpqa": 79.1,
    "scicode": 40.6,
    "ifbench": 45.9,
    "aime25": 84.7,
    "critpt": 0.6,
    "mmmu_pro": null,
    "livecodebench": 69.6,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.262370+00:00",
        "confidence": 1.0,
        "raw_name": "Grok 3 mini Reasoning (high)",
        "raw_scores": {
          "intelligence_score": 32.02,
          "coding_score": 25.16,
          "blended_cost_per_1m": 0.35,
          "latency_seconds": 0.76,
          "tokens_per_second": 195.0,
          "context_window": 1000000,
          "gdpval": 477.9494708105153,
          "terminalbench_hard": 0.174,
          "tau2": 0.904,
          "lcr": 50.3,
          "hle": 11.1,
          "gpqa": 79.1,
          "scicode": 40.6,
          "ifbench": 45.9,
          "aime25": 84.7,
          "critpt": 0.6,
          "livecodebench": 69.6
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126157+00:00",
        "confidence": 1.0,
        "raw_name": "grok-3-mini-high",
        "raw_scores": {
          "arena_elo": 1362.86,
          "arena_votes": 17412
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 32.02,
        "coding_score": 25.16,
        "gdpval": 477.9494708105153,
        "terminalbench_hard": 0.174,
        "tau2": 0.904,
        "lcr": 50.3,
        "hle": 11.1,
        "gpqa": 79.1,
        "scicode": 40.6,
        "ifbench": 45.9,
        "aime25": 84.7,
        "critpt": 0.6,
        "livecodebench": 69.6
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1362.86
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "grok-4",
    "canonical_name": "Grok 4",
    "model_name": "Grok 4",
    "aliases": [
      "Grok 4",
      "grok-4-0709"
    ],
    "provider": "xAI",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": 41759,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 41.43,
    "coding_score": 40.49,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1409.44,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 6.0,
    "latency_seconds": 15.77,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 43.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 987.2631,
    "terminalbench_hard": 0.379,
    "tau2": 0.749,
    "lcr": 68.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 23.9,
    "gpqa": 87.7,
    "scicode": 45.7,
    "ifbench": 53.7,
    "aime25": 92.7,
    "critpt": 2.0,
    "mmmu_pro": 68.8,
    "livecodebench": 81.9,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.262456+00:00",
        "confidence": 1.0,
        "raw_name": "Grok 4",
        "raw_scores": {
          "intelligence_score": 41.43,
          "coding_score": 40.49,
          "blended_cost_per_1m": 6.0,
          "latency_seconds": 15.77,
          "tokens_per_second": 43.0,
          "context_window": 256000,
          "gdpval": 987.2630883874588,
          "terminalbench_hard": 0.379,
          "tau2": 0.749,
          "lcr": 68.0,
          "hle": 23.9,
          "gpqa": 87.7,
          "scicode": 45.7,
          "ifbench": 53.7,
          "aime25": 92.7,
          "critpt": 2.0,
          "mmmu_pro": 68.8,
          "livecodebench": 81.9
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125402+00:00",
        "confidence": 1.0,
        "raw_name": "grok-4-0709",
        "raw_scores": {
          "arena_elo": 1409.44,
          "arena_votes": 41759
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 41.43,
        "coding_score": 40.49,
        "gdpval": 987.2630883874588,
        "terminalbench_hard": 0.379,
        "tau2": 0.749,
        "lcr": 68.0,
        "hle": 23.9,
        "gpqa": 87.7,
        "scicode": 45.7,
        "ifbench": 53.7,
        "aime25": 92.7,
        "critpt": 2.0,
        "mmmu_pro": 68.8,
        "livecodebench": 81.9
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1409.44
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "grok-voice-agent",
    "canonical_name": "Grok Voice Agent",
    "model_name": "Grok Voice Agent",
    "aliases": [
      "Grok Voice Agent"
    ],
    "provider": "xAI",
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.262475+00:00",
        "confidence": 0.5800000000000001,
        "raw_name": "Grok Voice Agent",
        "raw_scores": {
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32000
        }
      }
    ],
    "benchmark_breakdown": {},
    "confidence_score": 0.58,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "grok-code-fast-1",
    "canonical_name": "Grok Code Fast 1",
    "model_name": "Grok Code Fast 1",
    "aliases": [
      "Grok Code Fast 1"
    ],
    "provider": "xAI",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 28.67,
    "coding_score": 23.69,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.53,
    "latency_seconds": 7.06,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 384.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 781.3448,
    "terminalbench_hard": 0.174,
    "tau2": 0.757,
    "lcr": 48.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 7.5,
    "gpqa": 72.7,
    "scicode": 36.2,
    "ifbench": 41.4,
    "aime25": 43.3,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 65.7,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.262516+00:00",
        "confidence": 1.0,
        "raw_name": "Grok Code Fast 1",
        "raw_scores": {
          "intelligence_score": 28.67,
          "coding_score": 23.69,
          "blended_cost_per_1m": 0.53,
          "latency_seconds": 7.06,
          "tokens_per_second": 384.0,
          "context_window": 256000,
          "gdpval": 781.3448378510266,
          "terminalbench_hard": 0.174,
          "tau2": 0.757,
          "lcr": 48.3,
          "hle": 7.5,
          "gpqa": 72.7,
          "scicode": 36.2,
          "ifbench": 41.4,
          "aime25": 43.3,
          "critpt": 0.0,
          "livecodebench": 65.7
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 28.67,
        "coding_score": 23.69,
        "gdpval": 781.3448378510266,
        "terminalbench_hard": 0.174,
        "tau2": 0.757,
        "lcr": 48.3,
        "hle": 7.5,
        "gpqa": 72.7,
        "scicode": 36.2,
        "ifbench": 41.4,
        "aime25": 43.3,
        "critpt": 0.0,
        "livecodebench": 65.7
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "nova-micro",
    "canonical_name": "Nova Micro",
    "model_name": "Nova Micro",
    "aliases": [
      "Nova Micro",
      "amazon-nova-micro-v1.0"
    ],
    "provider": "Amazon",
    "context_window": 130000,
    "open_source": null,
    "arena_votes": 19355,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 10.25,
    "coding_score": 4.14,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1240.99,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.06,
    "latency_seconds": 0.35,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 419.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 399.6494,
    "terminalbench_hard": 0.015,
    "tau2": 0.14,
    "lcr": 9.7,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.7,
    "gpqa": 35.8,
    "scicode": 9.4,
    "ifbench": 29.4,
    "aime25": 6.0,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 14.0,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.262559+00:00",
        "confidence": 1.0,
        "raw_name": "Nova Micro",
        "raw_scores": {
          "intelligence_score": 10.25,
          "coding_score": 4.14,
          "blended_cost_per_1m": 0.06,
          "latency_seconds": 0.35,
          "tokens_per_second": 419.0,
          "context_window": 130000,
          "gdpval": 399.6493701344966,
          "terminalbench_hard": 0.015,
          "tau2": 0.14,
          "lcr": 9.7,
          "hle": 4.7,
          "gpqa": 35.8,
          "scicode": 9.4,
          "ifbench": 29.4,
          "aime25": 6.0,
          "critpt": 0.0,
          "livecodebench": 14.0
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127613+00:00",
        "confidence": 1.0,
        "raw_name": "amazon-nova-micro-v1.0",
        "raw_scores": {
          "arena_elo": 1240.99,
          "arena_votes": 19355
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.25,
        "coding_score": 4.14,
        "gdpval": 399.6493701344966,
        "terminalbench_hard": 0.015,
        "tau2": 0.14,
        "lcr": 9.7,
        "hle": 4.7,
        "gpqa": 35.8,
        "scicode": 9.4,
        "ifbench": 29.4,
        "aime25": 6.0,
        "critpt": 0.0,
        "livecodebench": 14.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1240.99
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "nova-20-lite",
    "canonical_name": "Nova 2.0 Lite (Non-reasoning)",
    "model_name": "Nova 2.0 Lite (Non-reasoning)",
    "aliases": [
      "Nova 2.0 Lite (Non-reasoning)",
      "Nova 2.0 Lite (low)",
      "Nova 2.0 Lite (medium)"
    ],
    "provider": "Amazon",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 24.3944,
    "coding_score": 16.9959,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.85,
    "latency_seconds": 11.41,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 230.5,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 571.6251,
    "terminalbench_hard": 0.0952,
    "tau2": 0.7046,
    "lcr": 44.5459,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.4373,
    "gpqa": 69.619,
    "scicode": 31.9211,
    "ifbench": 57.9552,
    "aime25": 58.0728,
    "critpt": 0.0,
    "mmmu_pro": 57.0645,
    "livecodebench": 50.3706,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.262601+00:00",
        "confidence": 0.79,
        "raw_name": "Nova 2.0 Lite (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 17.95,
          "coding_score": 12.53,
          "context_window": 1000000,
          "gdpval": 441.1295127050306,
          "terminalbench_hard": 0.068,
          "tau2": 0.62,
          "lcr": 17.7,
          "hle": 3.0,
          "gpqa": 60.3,
          "scicode": 24.0,
          "ifbench": 40.5,
          "aime25": 33.7,
          "critpt": 0.0,
          "mmmu_pro": 49.0,
          "livecodebench": 34.6
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.262857+00:00",
        "confidence": 1.0,
        "raw_name": "Nova 2.0 Lite (low)",
        "raw_scores": {
          "intelligence_score": 24.23,
          "coding_score": 13.64,
          "blended_cost_per_1m": 0.85,
          "latency_seconds": 5.41,
          "tokens_per_second": 219.0,
          "context_window": 1000000,
          "gdpval": 556.0573420305453,
          "terminalbench_hard": 0.038,
          "tau2": 0.719,
          "lcr": 52.0,
          "hle": 4.2,
          "gpqa": 69.8,
          "scicode": 33.3,
          "ifbench": 61.2,
          "aime25": 46.7,
          "critpt": 0.0,
          "mmmu_pro": 58.0,
          "livecodebench": 46.9
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.262989+00:00",
        "confidence": 1.0,
        "raw_name": "Nova 2.0 Lite (medium)",
        "raw_scores": {
          "intelligence_score": 29.65,
          "coding_score": 23.88,
          "blended_cost_per_1m": 0.85,
          "latency_seconds": 17.41,
          "tokens_per_second": 242.0,
          "context_window": 1000000,
          "gdpval": 690.2842753291834,
          "terminalbench_hard": 0.174,
          "tau2": 0.757,
          "lcr": 58.3,
          "hle": 8.6,
          "gpqa": 76.8,
          "scicode": 36.8,
          "ifbench": 68.5,
          "aime25": 88.7,
          "critpt": 0.0,
          "mmmu_pro": 62.5,
          "livecodebench": 66.3
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 17.95,
        "coding_score": 12.53,
        "gdpval": 441.1295127050306,
        "terminalbench_hard": 0.068,
        "tau2": 0.62,
        "lcr": 17.7,
        "hle": 3.0,
        "gpqa": 60.3,
        "scicode": 24.0,
        "ifbench": 40.5,
        "aime25": 33.7,
        "critpt": 0.0,
        "mmmu_pro": 49.0,
        "livecodebench": 34.6
      }
    },
    "confidence_score": 0.93,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "nova-20-pro-preview",
    "canonical_name": "Nova 2.0 Pro Preview (Non-reasoning)",
    "model_name": "Nova 2.0 Pro Preview (Non-reasoning)",
    "aliases": [
      "Nova 2.0 Pro Preview (Non-reasoning)",
      "Nova 2.0 Pro Preview (low)",
      "Nova 2.0 Pro Preview (medium)"
    ],
    "provider": "Amazon",
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 30.6734,
    "coding_score": 25.4792,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.44,
    "latency_seconds": 16.06,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 131.5,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 710.5462,
    "terminalbench_hard": 0.1964,
    "tau2": 0.8597,
    "lcr": 49.5903,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 6.1864,
    "gpqa": 73.0624,
    "scicode": 37.1323,
    "ifbench": 71.5699,
    "aime25": 63.2806,
    "critpt": 0.0,
    "mmmu_pro": 63.6,
    "livecodebench": 62.4254,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.262640+00:00",
        "confidence": 0.79,
        "raw_name": "Nova 2.0 Pro Preview (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 22.91,
          "coding_score": 20.49,
          "context_window": 256000,
          "gdpval": 389.3630470221425,
          "terminalbench_hard": 0.167,
          "tau2": 0.716,
          "lcr": 28.3,
          "hle": 4.0,
          "gpqa": 63.6,
          "scicode": 28.1,
          "ifbench": 52.0,
          "aime25": 30.7,
          "critpt": 0.0,
          "livecodebench": 47.3
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.262687+00:00",
        "confidence": 1.0,
        "raw_name": "Nova 2.0 Pro Preview (medium)",
        "raw_scores": {
          "intelligence_score": 35.62,
          "coding_score": 30.4,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 19.8,
          "tokens_per_second": 131.0,
          "context_window": 256000,
          "gdpval": 980.3540319613992,
          "terminalbench_hard": 0.242,
          "tau2": 0.927,
          "lcr": 54.3,
          "hle": 8.9,
          "gpqa": 78.5,
          "scicode": 42.7,
          "ifbench": 79.0,
          "aime25": 89.0,
          "critpt": 0.0,
          "mmmu_pro": 64.5,
          "livecodebench": 73.0
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.262941+00:00",
        "confidence": 1.0,
        "raw_name": "Nova 2.0 Pro Preview (low)",
        "raw_scores": {
          "intelligence_score": 31.86,
          "coding_score": 24.5,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 12.32,
          "tokens_per_second": 132.0,
          "context_window": 256000,
          "gdpval": 694.4729716506291,
          "terminalbench_hard": 0.174,
          "tau2": 0.906,
          "lcr": 61.7,
          "hle": 5.2,
          "gpqa": 75.1,
          "scicode": 38.7,
          "ifbench": 79.6,
          "aime25": 63.3,
          "critpt": 0.0,
          "mmmu_pro": 62.7,
          "livecodebench": 63.8
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 22.91,
        "coding_score": 20.49,
        "gdpval": 389.3630470221425,
        "terminalbench_hard": 0.167,
        "tau2": 0.716,
        "lcr": 28.3,
        "hle": 4.0,
        "gpqa": 63.6,
        "scicode": 28.1,
        "ifbench": 52.0,
        "aime25": 30.7,
        "critpt": 0.0,
        "livecodebench": 47.3,
        "mmmu_pro": 64.5
      }
    },
    "confidence_score": 0.93,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "nova-20-omni",
    "canonical_name": "Nova 2.0 Omni (medium)",
    "model_name": "Nova 2.0 Omni (medium)",
    "aliases": [
      "Nova 2.0 Omni (Non-reasoning)",
      "Nova 2.0 Omni (low)",
      "Nova 2.0 Omni (medium)"
    ],
    "provider": "Amazon",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 23.0094,
    "coding_score": 14.3346,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.85,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 548.5328,
    "terminalbench_hard": 0.049,
    "tau2": 0.6578,
    "lcr": 43.8412,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.9753,
    "gpqa": 68.009,
    "scicode": 33.1688,
    "ifbench": 57.5158,
    "aime25": 62.6989,
    "critpt": 0.0,
    "mmmu_pro": 57.7495,
    "livecodebench": 53.5108,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.262731+00:00",
        "confidence": 1.0,
        "raw_name": "Nova 2.0 Omni (medium)",
        "raw_scores": {
          "intelligence_score": 27.93,
          "coding_score": 15.11,
          "blended_cost_per_1m": 0.85,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000,
          "gdpval": 817.2660312720545,
          "terminalbench_hard": 0.045,
          "tau2": 0.804,
          "lcr": 53.7,
          "hle": 6.8,
          "gpqa": 76.0,
          "scicode": 36.2,
          "ifbench": 66.2,
          "aime25": 89.7,
          "critpt": 0.0,
          "mmmu_pro": 61.9,
          "livecodebench": 66.0
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.262774+00:00",
        "confidence": 1.0,
        "raw_name": "Nova 2.0 Omni (low)",
        "raw_scores": {
          "intelligence_score": 23.16,
          "coding_score": 13.95,
          "blended_cost_per_1m": 0.85,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000,
          "gdpval": 419.82052283671396,
          "terminalbench_hard": 0.038,
          "tau2": 0.678,
          "lcr": 51.0,
          "hle": 4.0,
          "gpqa": 69.9,
          "scicode": 34.3,
          "ifbench": 61.8,
          "aime25": 56.0,
          "critpt": 0.0,
          "mmmu_pro": 59.8,
          "livecodebench": 59.2
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.262814+00:00",
        "confidence": 0.79,
        "raw_name": "Nova 2.0 Omni (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 16.59,
          "coding_score": 13.84,
          "context_window": 1000000,
          "gdpval": 371.2911641056936,
          "terminalbench_hard": 0.068,
          "tau2": 0.447,
          "lcr": 22.3,
          "hle": 3.9,
          "gpqa": 55.5,
          "scicode": 27.9,
          "ifbench": 41.1,
          "aime25": 37.0,
          "critpt": 0.0,
          "mmmu_pro": 49.9,
          "livecodebench": 30.5
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 27.93,
        "coding_score": 15.11,
        "gdpval": 817.2660312720545,
        "terminalbench_hard": 0.045,
        "tau2": 0.804,
        "lcr": 53.7,
        "hle": 6.8,
        "gpqa": 76.0,
        "scicode": 36.2,
        "ifbench": 66.2,
        "aime25": 89.7,
        "critpt": 0.0,
        "mmmu_pro": 61.9,
        "livecodebench": 66.0
      }
    },
    "confidence_score": 0.93,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "nova-premier",
    "canonical_name": "Nova Premier",
    "model_name": "Nova Premier",
    "aliases": [
      "Nova Premier"
    ],
    "provider": "Amazon",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 18.87,
    "coding_score": 13.84,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 5.0,
    "latency_seconds": 0.8,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 79.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 564.0432,
    "terminalbench_hard": 0.068,
    "tau2": 0.383,
    "lcr": 30.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.7,
    "gpqa": 56.9,
    "scicode": 27.9,
    "ifbench": 36.2,
    "aime25": 17.3,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 31.7,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.262898+00:00",
        "confidence": 1.0,
        "raw_name": "Nova Premier",
        "raw_scores": {
          "intelligence_score": 18.87,
          "coding_score": 13.84,
          "blended_cost_per_1m": 5.0,
          "latency_seconds": 0.8,
          "tokens_per_second": 79.0,
          "context_window": 1000000,
          "gdpval": 564.0432471606757,
          "terminalbench_hard": 0.068,
          "tau2": 0.383,
          "lcr": 30.0,
          "hle": 4.7,
          "gpqa": 56.9,
          "scicode": 27.9,
          "ifbench": 36.2,
          "aime25": 17.3,
          "critpt": 0.0,
          "livecodebench": 31.7
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 18.87,
        "coding_score": 13.84,
        "gdpval": 564.0432471606757,
        "terminalbench_hard": 0.068,
        "tau2": 0.383,
        "lcr": 30.0,
        "hle": 4.7,
        "gpqa": 56.9,
        "scicode": 27.9,
        "ifbench": 36.2,
        "aime25": 17.3,
        "critpt": 0.0,
        "livecodebench": 31.7
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "phi-4",
    "canonical_name": "Phi-4",
    "model_name": "Phi-4",
    "aliases": [
      "Phi-4",
      "phi-4"
    ],
    "provider": "Microsoft",
    "context_window": 16000,
    "open_source": true,
    "arena_votes": 24126,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": 10.47,
    "coding_score": 11.21,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1256.2,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.22,
    "latency_seconds": 0.98,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 7.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": 0.038,
    "tau2": 0.0,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.1,
    "gpqa": 57.5,
    "scicode": 26.0,
    "ifbench": 23.5,
    "aime25": 18.0,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 23.1,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.263030+00:00",
        "confidence": 1.0,
        "raw_name": "Phi-4",
        "raw_scores": {
          "intelligence_score": 10.47,
          "coding_score": 11.21,
          "blended_cost_per_1m": 0.22,
          "latency_seconds": 0.98,
          "tokens_per_second": 7.0,
          "context_window": 16000,
          "terminalbench_hard": 0.038,
          "tau2": 0.0,
          "lcr": 0.0,
          "hle": 4.1,
          "gpqa": 57.5,
          "scicode": 26.0,
          "ifbench": 23.5,
          "aime25": 18.0,
          "critpt": 0.0,
          "livecodebench": 23.1
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127563+00:00",
        "confidence": 1.0,
        "raw_name": "phi-4",
        "raw_scores": {
          "arena_elo": 1256.2,
          "arena_votes": 24126
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.47,
        "coding_score": 11.21,
        "terminalbench_hard": 0.038,
        "tau2": 0.0,
        "lcr": 0.0,
        "hle": 4.1,
        "gpqa": 57.5,
        "scicode": 26.0,
        "ifbench": 23.5,
        "aime25": 18.0,
        "critpt": 0.0,
        "livecodebench": 23.1
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1256.2
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "phi-4-mini-instruct",
    "canonical_name": "Phi-4 Mini Instruct",
    "model_name": "Phi-4 Mini Instruct",
    "aliases": [
      "Phi-4 Mini Instruct"
    ],
    "provider": "Microsoft",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": 8.31,
    "coding_score": 3.59,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 289.8889,
    "terminalbench_hard": 0.0,
    "tau2": 0.082,
    "lcr": 13.7,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.2,
    "gpqa": 33.1,
    "scicode": 10.8,
    "ifbench": 21.1,
    "aime25": 6.7,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 12.6,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.263069+00:00",
        "confidence": 0.79,
        "raw_name": "Phi-4 Mini Instruct",
        "raw_scores": {
          "intelligence_score": 8.31,
          "coding_score": 3.59,
          "context_window": 128000,
          "gdpval": 289.8888965772336,
          "terminalbench_hard": 0.0,
          "tau2": 0.082,
          "lcr": 13.7,
          "hle": 4.2,
          "gpqa": 33.1,
          "scicode": 10.8,
          "ifbench": 21.1,
          "aime25": 6.7,
          "critpt": 0.0,
          "livecodebench": 12.6
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.31,
        "coding_score": 3.59,
        "gdpval": 289.8888965772336,
        "terminalbench_hard": 0.0,
        "tau2": 0.082,
        "lcr": 13.7,
        "hle": 4.2,
        "gpqa": 33.1,
        "scicode": 10.8,
        "ifbench": 21.1,
        "aime25": 6.7,
        "critpt": 0.0,
        "livecodebench": 12.6
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "phi-4-multimodal-instruct",
    "canonical_name": "Phi-4 Multimodal Instruct",
    "model_name": "Phi-4 Multimodal Instruct",
    "aliases": [
      "Phi-4 Multimodal Instruct"
    ],
    "provider": "Microsoft",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": 10.0404,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.4,
    "gpqa": 31.5,
    "scicode": 11.0,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": 14.5,
    "livecodebench": 13.1,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.263102+00:00",
        "confidence": 0.65,
        "raw_name": "Phi-4 Multimodal Instruct",
        "raw_scores": {
          "intelligence_score": 10.04043714573622,
          "context_window": 128000,
          "hle": 4.4,
          "gpqa": 31.5,
          "scicode": 11.0,
          "mmmu_pro": 14.5,
          "livecodebench": 13.1
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.04043714573622,
        "hle": 4.4,
        "gpqa": 31.5,
        "scicode": 11.0,
        "mmmu_pro": 14.5,
        "livecodebench": 13.1
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "lfm25-vl-16b",
    "canonical_name": "LFM2.5-VL-1.6B",
    "model_name": "LFM2.5-VL-1.6B",
    "aliases": [
      "LFM2.5-VL-1.6B"
    ],
    "provider": null,
    "context_window": 32000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "lfm 1.0",
    "creator": null,
    "intelligence_score": 6.06,
    "coding_score": 1.0,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 294.3984,
    "terminalbench_hard": 0.0,
    "tau2": 0.085,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.1,
    "gpqa": 28.9,
    "scicode": 3.0,
    "ifbench": 33.1,
    "aime25": null,
    "critpt": 0.0,
    "mmmu_pro": 26.5,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.263138+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "LFM2.5-VL-1.6B",
        "raw_scores": {
          "intelligence_score": 6.06,
          "coding_score": 1.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32000,
          "gdpval": 294.39842383507425,
          "terminalbench_hard": 0.0,
          "tau2": 0.085,
          "lcr": 0.0,
          "hle": 5.1,
          "gpqa": 28.9,
          "scicode": 3.0,
          "ifbench": 33.1,
          "critpt": 0.0,
          "mmmu_pro": 26.5
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 6.06,
        "coding_score": 1.0,
        "gdpval": 294.39842383507425,
        "terminalbench_hard": 0.0,
        "tau2": 0.085,
        "lcr": 0.0,
        "hle": 5.1,
        "gpqa": 28.9,
        "scicode": 3.0,
        "ifbench": 33.1,
        "critpt": 0.0,
        "mmmu_pro": 26.5
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "lfm2-26b",
    "canonical_name": "LFM2 2.6B",
    "model_name": "LFM2 2.6B",
    "aliases": [
      "LFM2 2.6B"
    ],
    "provider": null,
    "context_window": 32768,
    "open_source": true,
    "arena_votes": null,
    "license_type": "lfm 1.0",
    "creator": null,
    "intelligence_score": 7.86,
    "coding_score": 1.35,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 306.4225,
    "terminalbench_hard": 0.008,
    "tau2": 0.135,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.2,
    "gpqa": 30.6,
    "scicode": 2.5,
    "ifbench": 19.5,
    "aime25": 8.3,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 8.1,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.263180+00:00",
        "confidence": 1.0,
        "raw_name": "LFM2 2.6B",
        "raw_scores": {
          "intelligence_score": 7.86,
          "coding_score": 1.35,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32768,
          "gdpval": 306.42246994631637,
          "terminalbench_hard": 0.008,
          "tau2": 0.135,
          "lcr": 0.0,
          "hle": 5.2,
          "gpqa": 30.6,
          "scicode": 2.5,
          "ifbench": 19.5,
          "aime25": 8.3,
          "critpt": 0.0,
          "livecodebench": 8.1
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 7.86,
        "coding_score": 1.35,
        "gdpval": 306.42246994631637,
        "terminalbench_hard": 0.008,
        "tau2": 0.135,
        "lcr": 0.0,
        "hle": 5.2,
        "gpqa": 30.6,
        "scicode": 2.5,
        "ifbench": 19.5,
        "aime25": 8.3,
        "critpt": 0.0,
        "livecodebench": 8.1
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "lfm2-8b-a1b",
    "canonical_name": "LFM2 8B A1B",
    "model_name": "LFM2 8B A1B",
    "aliases": [
      "LFM2 8B A1B"
    ],
    "provider": null,
    "context_window": 32768,
    "open_source": true,
    "arena_votes": null,
    "license_type": "lfm 1.0",
    "creator": null,
    "intelligence_score": 6.85,
    "coding_score": 2.28,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 331.849,
    "terminalbench_hard": 0.0,
    "tau2": 0.105,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.9,
    "gpqa": 34.4,
    "scicode": 6.8,
    "ifbench": 26.3,
    "aime25": 25.3,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 15.1,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.263222+00:00",
        "confidence": 1.0,
        "raw_name": "LFM2 8B A1B",
        "raw_scores": {
          "intelligence_score": 6.85,
          "coding_score": 2.28,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32768,
          "gdpval": 331.84902287269256,
          "terminalbench_hard": 0.0,
          "tau2": 0.105,
          "lcr": 0.0,
          "hle": 4.9,
          "gpqa": 34.4,
          "scicode": 6.8,
          "ifbench": 26.3,
          "aime25": 25.3,
          "critpt": 0.0,
          "livecodebench": 15.1
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 6.85,
        "coding_score": 2.28,
        "gdpval": 331.84902287269256,
        "terminalbench_hard": 0.0,
        "tau2": 0.105,
        "lcr": 0.0,
        "hle": 4.9,
        "gpqa": 34.4,
        "scicode": 6.8,
        "ifbench": 26.3,
        "aime25": 25.3,
        "critpt": 0.0,
        "livecodebench": 15.1
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "lfm25-12b-thinking",
    "canonical_name": "LFM2.5-1.2B-Thinking",
    "model_name": "LFM2.5-1.2B-Thinking",
    "aliases": [
      "LFM2.5-1.2B-Thinking"
    ],
    "provider": null,
    "context_window": 32000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "lfm 1.0",
    "creator": null,
    "intelligence_score": 8.12,
    "coding_score": 1.39,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 323.2348,
    "terminalbench_hard": 0.0,
    "tau2": 0.196,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 6.1,
    "gpqa": 33.9,
    "scicode": 4.2,
    "ifbench": 41.8,
    "aime25": null,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.263269+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "LFM2.5-1.2B-Thinking",
        "raw_scores": {
          "intelligence_score": 8.12,
          "coding_score": 1.39,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32000,
          "gdpval": 323.23483108195444,
          "terminalbench_hard": 0.0,
          "tau2": 0.196,
          "lcr": 0.0,
          "hle": 6.1,
          "gpqa": 33.9,
          "scicode": 4.2,
          "ifbench": 41.8,
          "critpt": 0.0
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.12,
        "coding_score": 1.39,
        "gdpval": 323.23483108195444,
        "terminalbench_hard": 0.0,
        "tau2": 0.196,
        "lcr": 0.0,
        "hle": 6.1,
        "gpqa": 33.9,
        "scicode": 4.2,
        "ifbench": 41.8,
        "critpt": 0.0
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "lfm25-12b-instruct",
    "canonical_name": "LFM2.5-1.2B-Instruct",
    "model_name": "LFM2.5-1.2B-Instruct",
    "aliases": [
      "LFM2.5-1.2B-Instruct"
    ],
    "provider": null,
    "context_window": 32000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "lfm 1.0",
    "creator": null,
    "intelligence_score": 7.95,
    "coding_score": 0.77,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 330.2291,
    "terminalbench_hard": 0.0,
    "tau2": 0.108,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 6.8,
    "gpqa": 32.6,
    "scicode": 2.3,
    "ifbench": 43.8,
    "aime25": null,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.263309+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "LFM2.5-1.2B-Instruct",
        "raw_scores": {
          "intelligence_score": 7.95,
          "coding_score": 0.77,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32000,
          "gdpval": 330.2291010608569,
          "terminalbench_hard": 0.0,
          "tau2": 0.108,
          "lcr": 0.0,
          "hle": 6.8,
          "gpqa": 32.6,
          "scicode": 2.3,
          "ifbench": 43.8,
          "critpt": 0.0
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 7.95,
        "coding_score": 0.77,
        "gdpval": 330.2291010608569,
        "terminalbench_hard": 0.0,
        "tau2": 0.108,
        "lcr": 0.0,
        "hle": 6.8,
        "gpqa": 32.6,
        "scicode": 2.3,
        "ifbench": 43.8,
        "critpt": 0.0
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "solar-open-100b",
    "canonical_name": "Solar Open 100B (Reasoning)",
    "model_name": "Solar Open 100B (Reasoning)",
    "aliases": [
      "Solar Open 100B (Reasoning)"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 21.6,
    "coding_score": 10.47,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 713.9439,
    "terminalbench_hard": 0.023,
    "tau2": 0.482,
    "lcr": 36.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 9.2,
    "gpqa": 65.7,
    "scicode": 26.9,
    "ifbench": 57.7,
    "aime25": null,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.263343+00:00",
        "confidence": 0.65,
        "raw_name": "Solar Open 100B (Reasoning)",
        "raw_scores": {
          "intelligence_score": 21.6,
          "coding_score": 10.47,
          "context_window": 128000,
          "gdpval": 713.9439395204645,
          "terminalbench_hard": 0.023,
          "tau2": 0.482,
          "lcr": 36.0,
          "hle": 9.2,
          "gpqa": 65.7,
          "scicode": 26.9,
          "ifbench": 57.7,
          "critpt": 0.0
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 21.6,
        "coding_score": 10.47,
        "gdpval": 713.9439395204645,
        "terminalbench_hard": 0.023,
        "tau2": 0.482,
        "lcr": 36.0,
        "hle": 9.2,
        "gpqa": 65.7,
        "scicode": 26.9,
        "ifbench": 57.7,
        "critpt": 0.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "solar-pro-2",
    "canonical_name": "Solar Pro 2 (Reasoning)",
    "model_name": "Solar Pro 2 (Reasoning)",
    "aliases": [
      "Solar Pro 2 (Non-reasoning)",
      "Solar Pro 2 (Preview) (Non-reasoning)",
      "Solar Pro 2 (Preview) (Reasoning)",
      "Solar Pro 2 (Reasoning)"
    ],
    "provider": null,
    "context_window": 65536,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 15.6617,
    "coding_score": 11.69,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 506.3094,
    "terminalbench_hard": 0.0375,
    "tau2": 0.3,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.1066,
    "gpqa": 59.5562,
    "scicode": 24.9271,
    "ifbench": 35.4,
    "aime25": 45.65,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 47.6441,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.263382+00:00",
        "confidence": 0.79,
        "raw_name": "Solar Pro 2 (Reasoning)",
        "raw_scores": {
          "intelligence_score": 14.93,
          "coding_score": 12.09,
          "context_window": 65536,
          "gdpval": 509.5455553631705,
          "terminalbench_hard": 0.03,
          "tau2": 0.281,
          "lcr": 0.0,
          "hle": 7.0,
          "gpqa": 68.7,
          "scicode": 30.2,
          "ifbench": 37.1,
          "aime25": 61.3,
          "critpt": 0.0,
          "livecodebench": 61.6
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.263420+00:00",
        "confidence": 0.79,
        "raw_name": "Solar Pro 2 (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 13.53,
          "coding_score": 11.29,
          "context_window": 65536,
          "gdpval": 503.07325446690083,
          "terminalbench_hard": 0.045,
          "tau2": 0.319,
          "lcr": 0.0,
          "hle": 3.8,
          "gpqa": 56.1,
          "scicode": 24.8,
          "ifbench": 33.7,
          "aime25": 30.0,
          "critpt": 0.0,
          "livecodebench": 42.4
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.273359+00:00",
        "confidence": 0.65,
        "raw_name": "Solar Pro 2 (Preview) (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 15.99411151166208,
          "context_window": 64000,
          "hle": 3.8,
          "gpqa": 54.4,
          "scicode": 27.2,
          "livecodebench": 38.5
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.273387+00:00",
        "confidence": 0.65,
        "raw_name": "Solar Pro 2 (Preview) (Reasoning)",
        "raw_scores": {
          "intelligence_score": 18.80930200641581,
          "context_window": 64000,
          "hle": 5.7,
          "gpqa": 57.8,
          "scicode": 16.4,
          "livecodebench": 46.2
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.93,
        "coding_score": 12.09,
        "gdpval": 509.5455553631705,
        "terminalbench_hard": 0.03,
        "tau2": 0.281,
        "lcr": 0.0,
        "hle": 7.0,
        "gpqa": 68.7,
        "scicode": 30.2,
        "ifbench": 37.1,
        "aime25": 61.3,
        "critpt": 0.0,
        "livecodebench": 61.6
      }
    },
    "confidence_score": 0.72,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "minimax-m25",
    "canonical_name": "MiniMax-M2.5",
    "model_name": "MiniMax-M2.5",
    "aliases": [
      "MiniMax-M2.5",
      "minimax-m2.5"
    ],
    "provider": "MiniMax",
    "context_window": 204800,
    "open_source": true,
    "arena_votes": 5380,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": 41.97,
    "coding_score": 37.43,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1397.69,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.53,
    "latency_seconds": 3.48,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 54.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 1209.1598,
    "terminalbench_hard": 0.348,
    "tau2": 0.953,
    "lcr": 66.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 19.1,
    "gpqa": 84.8,
    "scicode": 42.6,
    "ifbench": 71.6,
    "aime25": null,
    "critpt": 1.1,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.263457+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "MiniMax-M2.5",
        "raw_scores": {
          "intelligence_score": 41.97,
          "coding_score": 37.43,
          "blended_cost_per_1m": 0.53,
          "latency_seconds": 3.48,
          "tokens_per_second": 54.0,
          "context_window": 204800,
          "gdpval": 1209.1598153413106,
          "terminalbench_hard": 0.348,
          "tau2": 0.953,
          "lcr": 66.0,
          "hle": 19.1,
          "gpqa": 84.8,
          "scicode": 42.6,
          "ifbench": 71.6,
          "critpt": 1.1
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125539+00:00",
        "confidence": 1.0,
        "raw_name": "minimax-m2.5",
        "raw_scores": {
          "arena_elo": 1397.69,
          "arena_votes": 5380
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 41.97,
        "coding_score": 37.43,
        "gdpval": 1209.1598153413106,
        "terminalbench_hard": 0.348,
        "tau2": 0.953,
        "lcr": 66.0,
        "hle": 19.1,
        "gpqa": 84.8,
        "scicode": 42.6,
        "ifbench": 71.6,
        "critpt": 1.1
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1397.69
      }
    },
    "confidence_score": 0.93,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-nemotron-instruct-70b",
    "canonical_name": "Llama 3.1 Nemotron Instruct 70B",
    "model_name": "Llama 3.1 Nemotron Instruct 70B",
    "aliases": [
      "Llama 3.1 Nemotron Instruct 70B"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT",
    "creator": null,
    "intelligence_score": 13.42,
    "coding_score": 10.78,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 406.0468,
    "terminalbench_hard": 0.045,
    "tau2": 0.231,
    "lcr": 7.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.6,
    "gpqa": 46.5,
    "scicode": 23.3,
    "ifbench": 30.7,
    "aime25": 11.0,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 16.9,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.263496+00:00",
        "confidence": 0.79,
        "raw_name": "Llama 3.1 Nemotron Instruct 70B",
        "raw_scores": {
          "intelligence_score": 13.42,
          "coding_score": 10.78,
          "context_window": 128000,
          "gdpval": 406.04680820092995,
          "terminalbench_hard": 0.045,
          "tau2": 0.231,
          "lcr": 7.0,
          "hle": 4.6,
          "gpqa": 46.5,
          "scicode": 23.3,
          "ifbench": 30.7,
          "aime25": 11.0,
          "critpt": 0.0,
          "livecodebench": 16.9
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.42,
        "coding_score": 10.78,
        "gdpval": 406.04680820092995,
        "terminalbench_hard": 0.045,
        "tau2": 0.231,
        "lcr": 7.0,
        "hle": 4.6,
        "gpqa": 46.5,
        "scicode": 23.3,
        "ifbench": 30.7,
        "aime25": 11.0,
        "critpt": 0.0,
        "livecodebench": 16.9
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "nvidia-nemotron-nano-12b-v2-vl",
    "canonical_name": "NVIDIA Nemotron Nano 12B v2 VL (Non-reasoning)",
    "model_name": "NVIDIA Nemotron Nano 12B v2 VL (Non-reasoning)",
    "aliases": [
      "NVIDIA Nemotron Nano 12B v2 VL (Non-reasoning)",
      "NVIDIA Nemotron Nano 12B v2 VL (Reasoning)"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Nvidia Open Model License",
    "creator": null,
    "intelligence_score": 12.445,
    "coding_score": 8.805,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 373.515,
    "terminalbench_hard": 0.0225,
    "tau2": 0.203,
    "lcr": 28.5,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.9,
    "gpqa": 50.55,
    "scicode": 21.9,
    "ifbench": 28.9,
    "aime25": 50.85,
    "critpt": 0.0,
    "mmmu_pro": 48.7,
    "livecodebench": 51.95,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.263535+00:00",
        "confidence": 0.79,
        "raw_name": "NVIDIA Nemotron Nano 12B v2 VL (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 10.11,
          "coding_score": 5.86,
          "context_window": 128000,
          "gdpval": 352.3149451476975,
          "terminalbench_hard": 0.0,
          "tau2": 0.193,
          "lcr": 17.0,
          "hle": 4.5,
          "gpqa": 43.9,
          "scicode": 17.6,
          "ifbench": 25.9,
          "aime25": 26.7,
          "critpt": 0.0,
          "mmmu_pro": 44.5,
          "livecodebench": 34.5
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.263810+00:00",
        "confidence": 0.79,
        "raw_name": "NVIDIA Nemotron Nano 12B v2 VL (Reasoning)",
        "raw_scores": {
          "intelligence_score": 14.78,
          "coding_score": 11.75,
          "context_window": 128000,
          "gdpval": 394.71505170057776,
          "terminalbench_hard": 0.045,
          "tau2": 0.213,
          "lcr": 40.0,
          "hle": 5.3,
          "gpqa": 57.2,
          "scicode": 26.2,
          "ifbench": 31.9,
          "aime25": 75.0,
          "critpt": 0.0,
          "mmmu_pro": 52.9,
          "livecodebench": 69.4
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.11,
        "coding_score": 5.86,
        "gdpval": 352.3149451476975,
        "terminalbench_hard": 0.0,
        "tau2": 0.193,
        "lcr": 17.0,
        "hle": 4.5,
        "gpqa": 43.9,
        "scicode": 17.6,
        "ifbench": 25.9,
        "aime25": 26.7,
        "critpt": 0.0,
        "mmmu_pro": 44.5,
        "livecodebench": 34.5
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "nvidia-nemotron-nano-9b-v2",
    "canonical_name": "NVIDIA Nemotron Nano 9B V2 (Reasoning)",
    "model_name": "NVIDIA Nemotron Nano 9B V2 (Reasoning)",
    "aliases": [
      "NVIDIA Nemotron Nano 9B V2 (Non-reasoning)",
      "NVIDIA Nemotron Nano 9B V2 (Reasoning)"
    ],
    "provider": null,
    "context_window": 131072,
    "open_source": true,
    "arena_votes": null,
    "license_type": "NVIDIA Open Model License Agreement",
    "creator": null,
    "intelligence_score": 13.93,
    "coding_score": 7.915,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 438.1945,
    "terminalbench_hard": 0.0115,
    "tau2": 0.2265,
    "lcr": 21.85,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.3,
    "gpqa": 56.35,
    "scicode": 21.45,
    "ifbench": 27.35,
    "aime25": 66.0,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 71.25,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.263574+00:00",
        "confidence": 0.79,
        "raw_name": "NVIDIA Nemotron Nano 9B V2 (Reasoning)",
        "raw_scores": {
          "intelligence_score": 14.76,
          "coding_score": 8.34,
          "context_window": 131072,
          "gdpval": 497.12243839989435,
          "terminalbench_hard": 0.015,
          "tau2": 0.219,
          "lcr": 21.0,
          "hle": 4.6,
          "gpqa": 57.0,
          "scicode": 22.0,
          "ifbench": 27.6,
          "aime25": 69.7,
          "critpt": 0.0,
          "livecodebench": 72.4
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.263769+00:00",
        "confidence": 0.79,
        "raw_name": "NVIDIA Nemotron Nano 9B V2 (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 13.1,
          "coding_score": 7.49,
          "context_window": 131072,
          "gdpval": 379.26655321665646,
          "terminalbench_hard": 0.008,
          "tau2": 0.234,
          "lcr": 22.7,
          "hle": 4.0,
          "gpqa": 55.7,
          "scicode": 20.9,
          "ifbench": 27.1,
          "aime25": 62.3,
          "critpt": 0.0,
          "livecodebench": 70.1
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.76,
        "coding_score": 8.34,
        "gdpval": 497.12243839989435,
        "terminalbench_hard": 0.015,
        "tau2": 0.219,
        "lcr": 21.0,
        "hle": 4.6,
        "gpqa": 57.0,
        "scicode": 22.0,
        "ifbench": 27.6,
        "aime25": 69.7,
        "critpt": 0.0,
        "livecodebench": 72.4
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "nvidia-nemotron-3-nano-30b-a3b",
    "canonical_name": "NVIDIA Nemotron 3 Nano 30B A3B (Reasoning)",
    "model_name": "NVIDIA Nemotron 3 Nano 30B A3B (Reasoning)",
    "aliases": [
      "NVIDIA Nemotron 3 Nano 30B A3B (Non-reasoning)",
      "NVIDIA Nemotron 3 Nano 30B A3B (Reasoning)"
    ],
    "provider": null,
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 18.8,
    "coding_score": 17.365,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 511.4449,
    "terminalbench_hard": 0.1285,
    "tau2": 0.3315,
    "lcr": 20.2,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 7.4,
    "gpqa": 57.8,
    "scicode": 26.3,
    "ifbench": 54.3,
    "aime25": 52.15,
    "critpt": 0.45,
    "mmmu_pro": null,
    "livecodebench": 55.05,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.263613+00:00",
        "confidence": 0.79,
        "raw_name": "NVIDIA Nemotron 3 Nano 30B A3B (Reasoning)",
        "raw_scores": {
          "intelligence_score": 24.26,
          "coding_score": 18.97,
          "context_window": 1000000,
          "gdpval": 618.4052469638573,
          "terminalbench_hard": 0.136,
          "tau2": 0.409,
          "lcr": 33.7,
          "hle": 10.2,
          "gpqa": 75.7,
          "scicode": 29.6,
          "ifbench": 71.1,
          "aime25": 91.0,
          "critpt": 0.9,
          "livecodebench": 74.1
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.263691+00:00",
        "confidence": 0.79,
        "raw_name": "NVIDIA Nemotron 3 Nano 30B A3B (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 13.34,
          "coding_score": 15.76,
          "context_window": 1000000,
          "gdpval": 404.48451633260936,
          "terminalbench_hard": 0.121,
          "tau2": 0.254,
          "lcr": 6.7,
          "hle": 4.6,
          "gpqa": 39.9,
          "scicode": 23.0,
          "ifbench": 37.5,
          "aime25": 13.3,
          "critpt": 0.0,
          "livecodebench": 36.0
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 24.26,
        "coding_score": 18.97,
        "gdpval": 618.4052469638573,
        "terminalbench_hard": 0.136,
        "tau2": 0.409,
        "lcr": 33.7,
        "hle": 10.2,
        "gpqa": 75.7,
        "scicode": 29.6,
        "ifbench": 71.1,
        "aime25": 91.0,
        "critpt": 0.9,
        "livecodebench": 74.1
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-33-nemotron-super-49b-v1",
    "canonical_name": "Llama 3.3 Nemotron Super 49B v1 (Reasoning)",
    "model_name": "Llama 3.3 Nemotron Super 49B v1 (Reasoning)",
    "aliases": [
      "Llama 3.3 Nemotron Super 49B v1 (Non-reasoning)",
      "Llama 3.3 Nemotron Super 49B v1 (Reasoning)"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "NVIDIA Open Model License Agreement",
    "creator": null,
    "intelligence_score": 16.4192,
    "coding_score": 8.525,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": 0.0,
    "tau2": null,
    "lcr": 14.15,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.0,
    "gpqa": 58.0,
    "scicode": 25.55,
    "ifbench": 38.8,
    "aime25": 31.2,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 27.85,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.263651+00:00",
        "confidence": 0.79,
        "raw_name": "Llama 3.3 Nemotron Super 49B v1 (Reasoning)",
        "raw_scores": {
          "intelligence_score": 18.49174710104611,
          "coding_score": 9.41,
          "context_window": 128000,
          "terminalbench_hard": 0.0,
          "lcr": 17.0,
          "hle": 6.5,
          "gpqa": 64.3,
          "scicode": 28.2,
          "ifbench": 38.1,
          "aime25": 54.7,
          "livecodebench": 27.7
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.263960+00:00",
        "confidence": 0.79,
        "raw_name": "Llama 3.3 Nemotron Super 49B v1 (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 14.34668262331532,
          "coding_score": 7.64,
          "context_window": 128000,
          "terminalbench_hard": 0.0,
          "lcr": 11.3,
          "hle": 3.5,
          "gpqa": 51.7,
          "scicode": 22.9,
          "ifbench": 39.5,
          "aime25": 7.7,
          "critpt": 0.0,
          "livecodebench": 28.0
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 18.49174710104611,
        "coding_score": 9.41,
        "terminalbench_hard": 0.0,
        "lcr": 17.0,
        "hle": 6.5,
        "gpqa": 64.3,
        "scicode": 28.2,
        "ifbench": 38.1,
        "aime25": 54.7,
        "livecodebench": 27.7,
        "critpt": 0.0
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-nemotron-super-49b-v15",
    "canonical_name": "Llama Nemotron Super 49B v1.5 (Non-reasoning)",
    "model_name": "Llama Nemotron Super 49B v1.5 (Non-reasoning)",
    "aliases": [
      "Llama Nemotron Super 49B v1.5 (Non-reasoning)",
      "Llama Nemotron Super 49B v1.5 (Reasoning)"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "NVIDIA Open Model License Agreement",
    "creator": null,
    "intelligence_score": 16.565,
    "coding_score": 12.81,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 434.1009,
    "terminalbench_hard": 0.0455,
    "tau2": 0.266,
    "lcr": 28.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.55,
    "gpqa": 61.45,
    "scicode": 29.3,
    "ifbench": 34.95,
    "aime25": 42.35,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 51.35,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.263731+00:00",
        "confidence": 0.79,
        "raw_name": "Llama Nemotron Super 49B v1.5 (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 14.51,
          "coding_score": 10.47,
          "context_window": 128000,
          "gdpval": 443.57338806260896,
          "terminalbench_hard": 0.038,
          "tau2": 0.251,
          "lcr": 22.0,
          "hle": 4.3,
          "gpqa": 48.1,
          "scicode": 23.8,
          "ifbench": 32.9,
          "aime25": 8.0,
          "critpt": 0.0,
          "livecodebench": 29.0
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.263924+00:00",
        "confidence": 0.79,
        "raw_name": "Llama Nemotron Super 49B v1.5 (Reasoning)",
        "raw_scores": {
          "intelligence_score": 18.62,
          "coding_score": 15.15,
          "context_window": 128000,
          "gdpval": 424.62846148863105,
          "terminalbench_hard": 0.053,
          "tau2": 0.281,
          "lcr": 34.0,
          "hle": 6.8,
          "gpqa": 74.8,
          "scicode": 34.8,
          "ifbench": 37.0,
          "aime25": 76.7,
          "critpt": 0.0,
          "livecodebench": 73.7
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.51,
        "coding_score": 10.47,
        "gdpval": 443.57338806260896,
        "terminalbench_hard": 0.038,
        "tau2": 0.251,
        "lcr": 22.0,
        "hle": 4.3,
        "gpqa": 48.1,
        "scicode": 23.8,
        "ifbench": 32.9,
        "aime25": 8.0,
        "critpt": 0.0,
        "livecodebench": 29.0
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-nemotron-nano-4b-v11",
    "canonical_name": "Llama 3.1 Nemotron Nano 4B v1.1 (Reasoning)",
    "model_name": "Llama 3.1 Nemotron Nano 4B v1.1 (Reasoning)",
    "aliases": [
      "Llama 3.1 Nemotron Nano 4B v1.1 (Reasoning)"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "NVIDIA Open Model License Agreement",
    "creator": null,
    "intelligence_score": 14.4337,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": 0.117,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.1,
    "gpqa": 40.8,
    "scicode": 10.1,
    "ifbench": 25.5,
    "aime25": 50.0,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 49.3,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.263844+00:00",
        "confidence": 0.72,
        "raw_name": "Llama 3.1 Nemotron Nano 4B v1.1 (Reasoning)",
        "raw_scores": {
          "intelligence_score": 14.433728654243223,
          "context_window": 128000,
          "tau2": 0.117,
          "lcr": 0.0,
          "hle": 5.1,
          "gpqa": 40.8,
          "scicode": 10.1,
          "ifbench": 25.5,
          "aime25": 50.0,
          "livecodebench": 49.3
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.433728654243223,
        "tau2": 0.117,
        "lcr": 0.0,
        "hle": 5.1,
        "gpqa": 40.8,
        "scicode": 10.1,
        "ifbench": 25.5,
        "aime25": 50.0,
        "livecodebench": 49.3
      }
    },
    "confidence_score": 0.72,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-nemotron-ultra-253b-v1",
    "canonical_name": "Llama 3.1 Nemotron Ultra 253B v1 (Reasoning)",
    "model_name": "Llama 3.1 Nemotron Ultra 253B v1 (Reasoning)",
    "aliases": [
      "Llama 3.1 Nemotron Ultra 253B v1 (Reasoning)",
      "llama-3.1-nemotron-ultra-253b-v1"
    ],
    "provider": "Nvidia",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": 2546,
    "license_type": "NVIDIA Open Model License Agreement",
    "creator": null,
    "intelligence_score": 15.02,
    "coding_score": 13.09,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1347.28,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 293.134,
    "terminalbench_hard": 0.023,
    "tau2": 0.114,
    "lcr": 7.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 8.1,
    "gpqa": 72.8,
    "scicode": 34.7,
    "ifbench": 38.2,
    "aime25": 63.7,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 64.1,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.263885+00:00",
        "confidence": 0.79,
        "raw_name": "Llama 3.1 Nemotron Ultra 253B v1 (Reasoning)",
        "raw_scores": {
          "intelligence_score": 15.02,
          "coding_score": 13.09,
          "context_window": 128000,
          "gdpval": 293.1340094677996,
          "terminalbench_hard": 0.023,
          "tau2": 0.114,
          "lcr": 7.3,
          "hle": 8.1,
          "gpqa": 72.8,
          "scicode": 34.7,
          "ifbench": 38.2,
          "aime25": 63.7,
          "critpt": 0.0,
          "livecodebench": 64.1
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126347+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.1-nemotron-ultra-253b-v1",
        "raw_scores": {
          "arena_elo": 1347.28,
          "arena_votes": 2546
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.02,
        "coding_score": 13.09,
        "gdpval": 293.1340094677996,
        "terminalbench_hard": 0.023,
        "tau2": 0.114,
        "lcr": 7.3,
        "hle": 8.1,
        "gpqa": 72.8,
        "scicode": 34.7,
        "ifbench": 38.2,
        "aime25": 63.7,
        "critpt": 0.0,
        "livecodebench": 64.1
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1347.28
      }
    },
    "confidence_score": 0.895,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "kimi-k25",
    "canonical_name": "Kimi K2.5 (Reasoning)",
    "model_name": "Kimi K2.5 (Reasoning)",
    "aliases": [
      "Kimi K2.5 (Non-reasoning)",
      "Kimi K2.5 (Reasoning)",
      "kimi-k2.5-thinking"
    ],
    "provider": "Moonshot",
    "context_window": 256000,
    "open_source": true,
    "arena_votes": 10440,
    "license_type": "Modified MIT License",
    "creator": null,
    "intelligence_score": 41.955,
    "coding_score": 32.685,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1451.34,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 1278.6651,
    "terminalbench_hard": 0.2685,
    "tau2": 0.886,
    "lcr": 62.15,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 20.85,
    "gpqa": 83.4,
    "scicode": 44.3,
    "ifbench": 56.95,
    "aime25": null,
    "critpt": 1.85,
    "mmmu_pro": 74.25,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.263997+00:00",
        "confidence": 0.65,
        "raw_name": "Kimi K2.5 (Reasoning)",
        "raw_scores": {
          "intelligence_score": 46.73,
          "coding_score": 39.55,
          "context_window": 256000,
          "gdpval": 1279.368731275364,
          "terminalbench_hard": 0.348,
          "tau2": 0.959,
          "lcr": 65.3,
          "hle": 29.4,
          "gpqa": 87.9,
          "scicode": 49.0,
          "ifbench": 70.2,
          "critpt": 3.1,
          "mmmu_pro": 75.4
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.264032+00:00",
        "confidence": 0.65,
        "raw_name": "Kimi K2.5 (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 37.18,
          "coding_score": 25.82,
          "context_window": 256000,
          "gdpval": 1277.9615198361619,
          "terminalbench_hard": 0.189,
          "tau2": 0.813,
          "lcr": 59.0,
          "hle": 12.3,
          "gpqa": 78.9,
          "scicode": 39.6,
          "ifbench": 43.7,
          "critpt": 0.6,
          "mmmu_pro": 73.1
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.124743+00:00",
        "confidence": 1.0,
        "raw_name": "kimi-k2.5-thinking",
        "raw_scores": {
          "arena_elo": 1451.34,
          "arena_votes": 10440
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 46.73,
        "coding_score": 39.55,
        "gdpval": 1279.368731275364,
        "terminalbench_hard": 0.348,
        "tau2": 0.959,
        "lcr": 65.3,
        "hle": 29.4,
        "gpqa": 87.9,
        "scicode": 49.0,
        "ifbench": 70.2,
        "critpt": 3.1,
        "mmmu_pro": 75.4
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1451.34
      }
    },
    "confidence_score": 0.7667,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "kimi-linear-48b-a3b-instruct",
    "canonical_name": "Kimi Linear 48B A3B Instruct",
    "model_name": "Kimi Linear 48B A3B Instruct",
    "aliases": [
      "Kimi Linear 48B A3B Instruct"
    ],
    "provider": "Moonshot",
    "context_window": 1000000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": 14.4146,
    "coding_score": 14.21,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": 0.114,
    "tau2": 0.0,
    "lcr": 25.7,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 2.7,
    "gpqa": 41.2,
    "scicode": 19.9,
    "ifbench": 28.1,
    "aime25": 36.3,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 37.8,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.264071+00:00",
        "confidence": 1.0,
        "raw_name": "Kimi Linear 48B A3B Instruct",
        "raw_scores": {
          "intelligence_score": 14.414576519674707,
          "coding_score": 14.21,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000,
          "terminalbench_hard": 0.114,
          "tau2": 0.0,
          "lcr": 25.7,
          "hle": 2.7,
          "gpqa": 41.2,
          "scicode": 19.9,
          "ifbench": 28.1,
          "aime25": 36.3,
          "livecodebench": 37.8
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.414576519674707,
        "coding_score": 14.21,
        "terminalbench_hard": 0.114,
        "tau2": 0.0,
        "lcr": 25.7,
        "hle": 2.7,
        "gpqa": 41.2,
        "scicode": 19.9,
        "ifbench": 28.1,
        "aime25": 36.3,
        "livecodebench": 37.8
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "step3-vl-10b",
    "canonical_name": "Step3 VL 10B",
    "model_name": "Step3 VL 10B",
    "aliases": [
      "Step3 VL 10B"
    ],
    "provider": null,
    "context_window": 65536,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 15.44,
    "coding_score": 13.91,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 323.45,
    "terminalbench_hard": 0.053,
    "tau2": 0.161,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 10.2,
    "gpqa": 69.0,
    "scicode": 31.1,
    "ifbench": 50.2,
    "aime25": null,
    "critpt": 0.0,
    "mmmu_pro": 64.0,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.264108+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "Step3 VL 10B",
        "raw_scores": {
          "intelligence_score": 15.44,
          "coding_score": 13.91,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 65536,
          "gdpval": 323.44999676103885,
          "terminalbench_hard": 0.053,
          "tau2": 0.161,
          "lcr": 0.0,
          "hle": 10.2,
          "gpqa": 69.0,
          "scicode": 31.1,
          "ifbench": 50.2,
          "critpt": 0.0,
          "mmmu_pro": 64.0
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.44,
        "coding_score": 13.91,
        "gdpval": 323.44999676103885,
        "terminalbench_hard": 0.053,
        "tau2": 0.161,
        "lcr": 0.0,
        "hle": 10.2,
        "gpqa": 69.0,
        "scicode": 31.1,
        "ifbench": 50.2,
        "critpt": 0.0,
        "mmmu_pro": 64.0
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "olmo-3-7b-instruct",
    "canonical_name": "Olmo 3 7B Instruct",
    "model_name": "Olmo 3 7B Instruct",
    "aliases": [
      "Olmo 3 7B Instruct"
    ],
    "provider": null,
    "context_window": 65536,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 8.14,
    "coding_score": 3.43,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 347.9036,
    "terminalbench_hard": 0.0,
    "tau2": 0.126,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.8,
    "gpqa": 40.0,
    "scicode": 10.3,
    "ifbench": 32.8,
    "aime25": 41.3,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 26.6,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.264145+00:00",
        "confidence": 0.79,
        "raw_name": "Olmo 3 7B Instruct",
        "raw_scores": {
          "intelligence_score": 8.14,
          "coding_score": 3.43,
          "context_window": 65536,
          "gdpval": 347.9036010954658,
          "terminalbench_hard": 0.0,
          "tau2": 0.126,
          "lcr": 0.0,
          "hle": 5.8,
          "gpqa": 40.0,
          "scicode": 10.3,
          "ifbench": 32.8,
          "aime25": 41.3,
          "critpt": 0.0,
          "livecodebench": 26.6
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.14,
        "coding_score": 3.43,
        "gdpval": 347.9036010954658,
        "terminalbench_hard": 0.0,
        "tau2": 0.126,
        "lcr": 0.0,
        "hle": 5.8,
        "gpqa": 40.0,
        "scicode": 10.3,
        "ifbench": 32.8,
        "aime25": 41.3,
        "critpt": 0.0,
        "livecodebench": 26.6
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "molmo-7b-d",
    "canonical_name": "Molmo 7B-D",
    "model_name": "Molmo 7B-D",
    "aliases": [
      "Molmo 7B-D"
    ],
    "provider": null,
    "context_window": 4096,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 9.2476,
    "coding_score": 1.2,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": 0.0,
    "tau2": 0.0,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.1,
    "gpqa": 24.0,
    "scicode": 3.6,
    "ifbench": 19.7,
    "aime25": 0.0,
    "critpt": null,
    "mmmu_pro": 24.5,
    "livecodebench": 3.9,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.264185+00:00",
        "confidence": 1.0,
        "raw_name": "Molmo 7B-D",
        "raw_scores": {
          "intelligence_score": 9.247608272030813,
          "coding_score": 1.2,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 4096,
          "terminalbench_hard": 0.0,
          "tau2": 0.0,
          "lcr": 0.0,
          "hle": 5.1,
          "gpqa": 24.0,
          "scicode": 3.6,
          "ifbench": 19.7,
          "aime25": 0.0,
          "mmmu_pro": 24.5,
          "livecodebench": 3.9
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.247608272030813,
        "coding_score": 1.2,
        "terminalbench_hard": 0.0,
        "tau2": 0.0,
        "lcr": 0.0,
        "hle": 5.1,
        "gpqa": 24.0,
        "scicode": 3.6,
        "ifbench": 19.7,
        "aime25": 0.0,
        "mmmu_pro": 24.5,
        "livecodebench": 3.9
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "molmo2-8b",
    "canonical_name": "Molmo2-8B",
    "model_name": "Molmo2-8B",
    "aliases": [
      "Molmo2-8B"
    ],
    "provider": null,
    "context_window": 36864,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": 4.44,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.47,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 114.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 500.0,
    "terminalbench_hard": 0.0,
    "tau2": 0.0,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.4,
    "gpqa": 42.5,
    "scicode": 13.3,
    "ifbench": 26.9,
    "aime25": null,
    "critpt": 0.0,
    "mmmu_pro": 37.5,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.264219+00:00",
        "confidence": 0.79,
        "raw_name": "Molmo2-8B",
        "raw_scores": {
          "coding_score": 4.44,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.47,
          "tokens_per_second": 114.0,
          "context_window": 36864,
          "gdpval": 500.0,
          "terminalbench_hard": 0.0,
          "tau2": 0.0,
          "lcr": 0.0,
          "hle": 4.4,
          "gpqa": 42.5,
          "scicode": 13.3,
          "ifbench": 26.9,
          "critpt": 0.0,
          "mmmu_pro": 37.5
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "coding_score": 4.44,
        "gdpval": 500.0,
        "terminalbench_hard": 0.0,
        "tau2": 0.0,
        "lcr": 0.0,
        "hle": 4.4,
        "gpqa": 42.5,
        "scicode": 13.3,
        "ifbench": 26.9,
        "critpt": 0.0,
        "mmmu_pro": 37.5
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "olmo-31-32b-instruct",
    "canonical_name": "Olmo 3.1 32B Instruct",
    "model_name": "Olmo 3.1 32B Instruct",
    "aliases": [
      "Olmo 3.1 32B Instruct",
      "olmo-3.1-32b-instruct"
    ],
    "provider": "Allen AI",
    "context_window": 65536,
    "open_source": true,
    "arena_votes": 12248,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 12.01,
    "coding_score": 5.56,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1330.5,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.3,
    "latency_seconds": 0.24,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 43.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 413.5021,
    "terminalbench_hard": 0.0,
    "tau2": 0.213,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.9,
    "gpqa": 53.9,
    "scicode": 16.7,
    "ifbench": 39.2,
    "aime25": null,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.264264+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "Olmo 3.1 32B Instruct",
        "raw_scores": {
          "intelligence_score": 12.01,
          "coding_score": 5.56,
          "blended_cost_per_1m": 0.3,
          "latency_seconds": 0.24,
          "tokens_per_second": 43.0,
          "context_window": 65536,
          "gdpval": 413.50214592966574,
          "terminalbench_hard": 0.0,
          "tau2": 0.213,
          "lcr": 0.0,
          "hle": 4.9,
          "gpqa": 53.9,
          "scicode": 16.7,
          "ifbench": 39.2,
          "critpt": 0.0
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126646+00:00",
        "confidence": 1.0,
        "raw_name": "olmo-3.1-32b-instruct",
        "raw_scores": {
          "arena_elo": 1330.5,
          "arena_votes": 12248
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.01,
        "coding_score": 5.56,
        "gdpval": 413.50214592966574,
        "terminalbench_hard": 0.0,
        "tau2": 0.213,
        "lcr": 0.0,
        "hle": 4.9,
        "gpqa": 53.9,
        "scicode": 16.7,
        "ifbench": 39.2,
        "critpt": 0.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1330.5
      }
    },
    "confidence_score": 0.93,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "olmo-31-32b-think",
    "canonical_name": "Olmo 3.1 32B Think",
    "model_name": "Olmo 3.1 32B Think",
    "aliases": [
      "Olmo 3.1 32B Think",
      "olmo-3.1-32b-think"
    ],
    "provider": "Allen AI",
    "context_window": 65500,
    "open_source": true,
    "arena_votes": 8435,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 14.24,
    "coding_score": 9.76,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1284.98,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.71,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 59.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": 0.0,
    "tau2": 0.0,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 6.0,
    "gpqa": 59.1,
    "scicode": 29.3,
    "ifbench": 66.0,
    "aime25": 77.3,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 69.5,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.264307+00:00",
        "confidence": 1.0,
        "raw_name": "Olmo 3.1 32B Think",
        "raw_scores": {
          "intelligence_score": 14.24,
          "coding_score": 9.76,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.71,
          "tokens_per_second": 59.0,
          "context_window": 65500,
          "terminalbench_hard": 0.0,
          "tau2": 0.0,
          "lcr": 0.0,
          "hle": 6.0,
          "gpqa": 59.1,
          "scicode": 29.3,
          "ifbench": 66.0,
          "aime25": 77.3,
          "critpt": 0.0,
          "livecodebench": 69.5
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127322+00:00",
        "confidence": 1.0,
        "raw_name": "olmo-3.1-32b-think",
        "raw_scores": {
          "arena_elo": 1284.98,
          "arena_votes": 8435
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.24,
        "coding_score": 9.76,
        "terminalbench_hard": 0.0,
        "tau2": 0.0,
        "lcr": 0.0,
        "hle": 6.0,
        "gpqa": 59.1,
        "scicode": 29.3,
        "ifbench": 66.0,
        "aime25": 77.3,
        "critpt": 0.0,
        "livecodebench": 69.5
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1284.98
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "olmo-3-7b-think",
    "canonical_name": "Olmo 3 7B Think",
    "model_name": "Olmo 3 7B Think",
    "aliases": [
      "Olmo 3 7B Think"
    ],
    "provider": null,
    "context_window": 65536,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 9.46,
    "coding_score": 7.57,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.14,
    "latency_seconds": 0.6,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 171.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": 0.008,
    "tau2": 0.0,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.7,
    "gpqa": 51.6,
    "scicode": 21.2,
    "ifbench": 41.5,
    "aime25": 70.7,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 61.7,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.264348+00:00",
        "confidence": 1.0,
        "raw_name": "Olmo 3 7B Think",
        "raw_scores": {
          "intelligence_score": 9.46,
          "coding_score": 7.57,
          "blended_cost_per_1m": 0.14,
          "latency_seconds": 0.6,
          "tokens_per_second": 171.0,
          "context_window": 65536,
          "terminalbench_hard": 0.008,
          "tau2": 0.0,
          "lcr": 0.0,
          "hle": 5.7,
          "gpqa": 51.6,
          "scicode": 21.2,
          "ifbench": 41.5,
          "aime25": 70.7,
          "critpt": 0.0,
          "livecodebench": 61.7
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.46,
        "coding_score": 7.57,
        "terminalbench_hard": 0.008,
        "tau2": 0.0,
        "lcr": 0.0,
        "hle": 5.7,
        "gpqa": 51.6,
        "scicode": 21.2,
        "ifbench": 41.5,
        "aime25": 70.7,
        "critpt": 0.0,
        "livecodebench": 61.7
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "granite-40-350m",
    "canonical_name": "Granite 4.0 350M",
    "model_name": "Granite 4.0 350M",
    "aliases": [
      "Granite 4.0 350M"
    ],
    "provider": null,
    "context_window": 32768,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 6.62,
    "coding_score": 0.31,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 344.2329,
    "terminalbench_hard": 0.0,
    "tau2": 0.132,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.7,
    "gpqa": 26.1,
    "scicode": 0.9,
    "ifbench": 15.9,
    "aime25": 0.0,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 2.4,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.264388+00:00",
        "confidence": 1.0,
        "raw_name": "Granite 4.0 350M",
        "raw_scores": {
          "intelligence_score": 6.62,
          "coding_score": 0.31,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32768,
          "gdpval": 344.2329302529844,
          "terminalbench_hard": 0.0,
          "tau2": 0.132,
          "lcr": 0.0,
          "hle": 5.7,
          "gpqa": 26.1,
          "scicode": 0.9,
          "ifbench": 15.9,
          "aime25": 0.0,
          "critpt": 0.0,
          "livecodebench": 2.4
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 6.62,
        "coding_score": 0.31,
        "gdpval": 344.2329302529844,
        "terminalbench_hard": 0.0,
        "tau2": 0.132,
        "lcr": 0.0,
        "hle": 5.7,
        "gpqa": 26.1,
        "scicode": 0.9,
        "ifbench": 15.9,
        "aime25": 0.0,
        "critpt": 0.0,
        "livecodebench": 2.4
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "granite-40-h-1b",
    "canonical_name": "Granite 4.0 H 1B",
    "model_name": "Granite 4.0 H 1B",
    "aliases": [
      "Granite 4.0 H 1B"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 7.96,
    "coding_score": 2.74,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 342.5671,
    "terminalbench_hard": 0.0,
    "tau2": 0.196,
    "lcr": 6.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.0,
    "gpqa": 26.3,
    "scicode": 8.2,
    "ifbench": 26.2,
    "aime25": 6.3,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 11.5,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.264430+00:00",
        "confidence": 1.0,
        "raw_name": "Granite 4.0 H 1B",
        "raw_scores": {
          "intelligence_score": 7.96,
          "coding_score": 2.74,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000,
          "gdpval": 342.5670778151739,
          "terminalbench_hard": 0.0,
          "tau2": 0.196,
          "lcr": 6.3,
          "hle": 5.0,
          "gpqa": 26.3,
          "scicode": 8.2,
          "ifbench": 26.2,
          "aime25": 6.3,
          "critpt": 0.0,
          "livecodebench": 11.5
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 7.96,
        "coding_score": 2.74,
        "gdpval": 342.5670778151739,
        "terminalbench_hard": 0.0,
        "tau2": 0.196,
        "lcr": 6.3,
        "hle": 5.0,
        "gpqa": 26.3,
        "scicode": 8.2,
        "ifbench": 26.2,
        "aime25": 6.3,
        "critpt": 0.0,
        "livecodebench": 11.5
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "granite-40-h-350m",
    "canonical_name": "Granite 4.0 H 350M",
    "model_name": "Granite 4.0 H 350M",
    "aliases": [
      "Granite 4.0 H 350M"
    ],
    "provider": null,
    "context_window": 32768,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 5.31,
    "coding_score": 0.58,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 379.4054,
    "terminalbench_hard": 0.0,
    "tau2": 0.146,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 6.4,
    "gpqa": 25.7,
    "scicode": 1.7,
    "ifbench": 17.6,
    "aime25": 1.3,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 1.9,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.264471+00:00",
        "confidence": 1.0,
        "raw_name": "Granite 4.0 H 350M",
        "raw_scores": {
          "intelligence_score": 5.31,
          "coding_score": 0.58,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32768,
          "gdpval": 379.4054047079794,
          "terminalbench_hard": 0.0,
          "tau2": 0.146,
          "lcr": 0.0,
          "hle": 6.4,
          "gpqa": 25.7,
          "scicode": 1.7,
          "ifbench": 17.6,
          "aime25": 1.3,
          "critpt": 0.0,
          "livecodebench": 1.9
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 5.31,
        "coding_score": 0.58,
        "gdpval": 379.4054047079794,
        "terminalbench_hard": 0.0,
        "tau2": 0.146,
        "lcr": 0.0,
        "hle": 6.4,
        "gpqa": 25.7,
        "scicode": 1.7,
        "ifbench": 17.6,
        "aime25": 1.3,
        "critpt": 0.0,
        "livecodebench": 1.9
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "granite-40-1b",
    "canonical_name": "Granite 4.0 1B",
    "model_name": "Granite 4.0 1B",
    "aliases": [
      "Granite 4.0 1B"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 7.27,
    "coding_score": 2.89,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 332.2685,
    "terminalbench_hard": 0.0,
    "tau2": 0.228,
    "lcr": 4.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.1,
    "gpqa": 28.1,
    "scicode": 8.7,
    "ifbench": 20.5,
    "aime25": 6.3,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 4.7,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.264512+00:00",
        "confidence": 1.0,
        "raw_name": "Granite 4.0 1B",
        "raw_scores": {
          "intelligence_score": 7.27,
          "coding_score": 2.89,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000,
          "gdpval": 332.2684510639747,
          "terminalbench_hard": 0.0,
          "tau2": 0.228,
          "lcr": 4.0,
          "hle": 5.1,
          "gpqa": 28.1,
          "scicode": 8.7,
          "ifbench": 20.5,
          "aime25": 6.3,
          "critpt": 0.0,
          "livecodebench": 4.7
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 7.27,
        "coding_score": 2.89,
        "gdpval": 332.2684510639747,
        "terminalbench_hard": 0.0,
        "tau2": 0.228,
        "lcr": 4.0,
        "hle": 5.1,
        "gpqa": 28.1,
        "scicode": 8.7,
        "ifbench": 20.5,
        "aime25": 6.3,
        "critpt": 0.0,
        "livecodebench": 4.7
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "granite-40-h-small",
    "canonical_name": "Granite 4.0 H Small",
    "model_name": "Granite 4.0 H Small",
    "aliases": [
      "Granite 4.0 H Small"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 10.79,
    "coding_score": 8.5,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.11,
    "latency_seconds": 8.78,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 408.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 404.0405,
    "terminalbench_hard": 0.023,
    "tau2": 0.173,
    "lcr": 9.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 3.7,
    "gpqa": 41.6,
    "scicode": 20.9,
    "ifbench": 31.5,
    "aime25": 13.7,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 25.1,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.264553+00:00",
        "confidence": 1.0,
        "raw_name": "Granite 4.0 H Small",
        "raw_scores": {
          "intelligence_score": 10.79,
          "coding_score": 8.5,
          "blended_cost_per_1m": 0.11,
          "latency_seconds": 8.78,
          "tokens_per_second": 408.0,
          "context_window": 128000,
          "gdpval": 404.0405020909311,
          "terminalbench_hard": 0.023,
          "tau2": 0.173,
          "lcr": 9.0,
          "hle": 3.7,
          "gpqa": 41.6,
          "scicode": 20.9,
          "ifbench": 31.5,
          "aime25": 13.7,
          "critpt": 0.0,
          "livecodebench": 25.1
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.79,
        "coding_score": 8.5,
        "gdpval": 404.0405020909311,
        "terminalbench_hard": 0.023,
        "tau2": 0.173,
        "lcr": 9.0,
        "hle": 3.7,
        "gpqa": 41.6,
        "scicode": 20.9,
        "ifbench": 31.5,
        "aime25": 13.7,
        "critpt": 0.0,
        "livecodebench": 25.1
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "granite-40-micro",
    "canonical_name": "Granite 4.0 Micro",
    "model_name": "Granite 4.0 Micro",
    "aliases": [
      "Granite 4.0 Micro"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 7.66,
    "coding_score": 4.98,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 361.0886,
    "terminalbench_hard": 0.015,
    "tau2": 0.126,
    "lcr": 4.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.1,
    "gpqa": 33.6,
    "scicode": 11.9,
    "ifbench": 24.8,
    "aime25": 6.0,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 18.0,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.264597+00:00",
        "confidence": 1.0,
        "raw_name": "Granite 4.0 Micro",
        "raw_scores": {
          "intelligence_score": 7.66,
          "coding_score": 4.98,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000,
          "gdpval": 361.0886156807659,
          "terminalbench_hard": 0.015,
          "tau2": 0.126,
          "lcr": 4.0,
          "hle": 5.1,
          "gpqa": 33.6,
          "scicode": 11.9,
          "ifbench": 24.8,
          "aime25": 6.0,
          "critpt": 0.0,
          "livecodebench": 18.0
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 7.66,
        "coding_score": 4.98,
        "gdpval": 361.0886156807659,
        "terminalbench_hard": 0.015,
        "tau2": 0.126,
        "lcr": 4.0,
        "hle": 5.1,
        "gpqa": 33.6,
        "scicode": 11.9,
        "ifbench": 24.8,
        "aime25": 6.0,
        "critpt": 0.0,
        "livecodebench": 18.0
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "mercury-2",
    "canonical_name": "Mercury 2",
    "model_name": "Mercury 2",
    "aliases": [
      "Mercury 2"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 32.83,
    "coding_score": 30.56,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.38,
    "latency_seconds": 12.74,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 1196.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 984.2036,
    "terminalbench_hard": 0.265,
    "tau2": 0.708,
    "lcr": 36.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 15.5,
    "gpqa": 77.0,
    "scicode": 38.7,
    "ifbench": 69.8,
    "aime25": null,
    "critpt": 0.8,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.264634+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "Mercury 2",
        "raw_scores": {
          "intelligence_score": 32.83,
          "coding_score": 30.56,
          "blended_cost_per_1m": 0.38,
          "latency_seconds": 12.74,
          "tokens_per_second": 1196.0,
          "context_window": 128000,
          "gdpval": 984.2036412843768,
          "terminalbench_hard": 0.265,
          "tau2": 0.708,
          "lcr": 36.3,
          "hle": 15.5,
          "gpqa": 77.0,
          "scicode": 38.7,
          "ifbench": 69.8,
          "critpt": 0.8
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 32.83,
        "coding_score": 30.56,
        "gdpval": 984.2036412843768,
        "terminalbench_hard": 0.265,
        "tau2": 0.708,
        "lcr": 36.3,
        "hle": 15.5,
        "gpqa": 77.0,
        "scicode": 38.7,
        "ifbench": 69.8,
        "critpt": 0.8
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "reka-flash-3",
    "canonical_name": "Reka Flash 3",
    "model_name": "Reka Flash 3",
    "aliases": [
      "Reka Flash 3"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 9.5,
    "coding_score": 8.91,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.35,
    "latency_seconds": 1.33,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 48.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": 0.0,
    "tau2": 0.0,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.1,
    "gpqa": 52.9,
    "scicode": 26.7,
    "ifbench": 30.4,
    "aime25": 33.7,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 43.5,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.264673+00:00",
        "confidence": 1.0,
        "raw_name": "Reka Flash 3",
        "raw_scores": {
          "intelligence_score": 9.5,
          "coding_score": 8.91,
          "blended_cost_per_1m": 0.35,
          "latency_seconds": 1.33,
          "tokens_per_second": 48.0,
          "context_window": 128000,
          "terminalbench_hard": 0.0,
          "tau2": 0.0,
          "lcr": 0.0,
          "hle": 5.1,
          "gpqa": 52.9,
          "scicode": 26.7,
          "ifbench": 30.4,
          "aime25": 33.7,
          "critpt": 0.0,
          "livecodebench": 43.5
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.5,
        "coding_score": 8.91,
        "terminalbench_hard": 0.0,
        "tau2": 0.0,
        "lcr": 0.0,
        "hle": 5.1,
        "gpqa": 52.9,
        "scicode": 26.7,
        "ifbench": 30.4,
        "aime25": 33.7,
        "critpt": 0.0,
        "livecodebench": 43.5
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "hermes-4---llama-31-405b",
    "canonical_name": "Hermes 4 - Llama-3.1 405B (Non-reasoning)",
    "model_name": "Hermes 4 - Llama-3.1 405B (Non-reasoning)",
    "aliases": [
      "Hermes 4 - Llama-3.1 405B (Non-reasoning)",
      "Hermes 4 - Llama-3.1 405B (Reasoning)"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT",
    "creator": null,
    "intelligence_score": 18.085,
    "coding_score": 17.045,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 593.1294,
    "terminalbench_hard": 0.106,
    "tau2": 0.244,
    "lcr": 20.35,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 7.25,
    "gpqa": 63.15,
    "scicode": 29.9,
    "ifbench": 33.75,
    "aime25": 42.5,
    "critpt": 0.15,
    "mmmu_pro": null,
    "livecodebench": 61.6,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.264712+00:00",
        "confidence": 0.79,
        "raw_name": "Hermes 4 - Llama-3.1 405B (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 17.61,
          "coding_score": 18.1,
          "context_window": 128000,
          "gdpval": 560.5445115607312,
          "terminalbench_hard": 0.098,
          "tau2": 0.266,
          "lcr": 20.0,
          "hle": 4.2,
          "gpqa": 53.6,
          "scicode": 34.6,
          "ifbench": 34.8,
          "aime25": 15.3,
          "critpt": 0.0,
          "livecodebench": 54.6
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.264790+00:00",
        "confidence": 0.79,
        "raw_name": "Hermes 4 - Llama-3.1 405B (Reasoning)",
        "raw_scores": {
          "intelligence_score": 18.56,
          "coding_score": 15.99,
          "context_window": 128000,
          "gdpval": 625.714209951592,
          "terminalbench_hard": 0.114,
          "tau2": 0.222,
          "lcr": 20.7,
          "hle": 10.3,
          "gpqa": 72.7,
          "scicode": 25.2,
          "ifbench": 32.7,
          "aime25": 69.7,
          "critpt": 0.3,
          "livecodebench": 68.6
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 17.61,
        "coding_score": 18.1,
        "gdpval": 560.5445115607312,
        "terminalbench_hard": 0.098,
        "tau2": 0.266,
        "lcr": 20.0,
        "hle": 4.2,
        "gpqa": 53.6,
        "scicode": 34.6,
        "ifbench": 34.8,
        "aime25": 15.3,
        "critpt": 0.0,
        "livecodebench": 54.6
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "hermes-4---llama-31-70b",
    "canonical_name": "Hermes 4 - Llama-3.1 70B (Reasoning)",
    "model_name": "Hermes 4 - Llama-3.1 70B (Reasoning)",
    "aliases": [
      "Hermes 4 - Llama-3.1 70B (Non-reasoning)",
      "Hermes 4 - Llama-3.1 70B (Reasoning)"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT",
    "creator": null,
    "intelligence_score": 14.235,
    "coding_score": 11.815,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 586.8093,
    "terminalbench_hard": 0.0225,
    "tau2": 0.2205,
    "lcr": 4.35,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.75,
    "gpqa": 59.5,
    "scicode": 30.9,
    "ifbench": 30.15,
    "aime25": 40.0,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 46.1,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.264751+00:00",
        "confidence": 0.79,
        "raw_name": "Hermes 4 - Llama-3.1 70B (Reasoning)",
        "raw_scores": {
          "intelligence_score": 16.02,
          "coding_score": 14.41,
          "context_window": 128000,
          "gdpval": 591.7302483727656,
          "terminalbench_hard": 0.045,
          "tau2": 0.225,
          "lcr": 6.7,
          "hle": 7.9,
          "gpqa": 69.9,
          "scicode": 34.1,
          "ifbench": 31.3,
          "aime25": 68.7,
          "critpt": 0.0,
          "livecodebench": 65.3
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.264856+00:00",
        "confidence": 0.79,
        "raw_name": "Hermes 4 - Llama-3.1 70B (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 12.45,
          "coding_score": 9.22,
          "context_window": 128000,
          "gdpval": 581.8884304312953,
          "terminalbench_hard": 0.0,
          "tau2": 0.216,
          "lcr": 2.0,
          "hle": 3.6,
          "gpqa": 49.1,
          "scicode": 27.7,
          "ifbench": 29.0,
          "aime25": 11.3,
          "critpt": 0.0,
          "livecodebench": 26.9
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 16.02,
        "coding_score": 14.41,
        "gdpval": 591.7302483727656,
        "terminalbench_hard": 0.045,
        "tau2": 0.225,
        "lcr": 6.7,
        "hle": 7.9,
        "gpqa": 69.9,
        "scicode": 34.1,
        "ifbench": 31.3,
        "aime25": 68.7,
        "critpt": 0.0,
        "livecodebench": 65.3
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "deephermes-3---mistral-24b-preview",
    "canonical_name": "DeepHermes 3 - Mistral 24B Preview (Non-reasoning)",
    "model_name": "DeepHermes 3 - Mistral 24B Preview (Non-reasoning)",
    "aliases": [
      "DeepHermes 3 - Mistral 24B Preview (Non-reasoning)"
    ],
    "provider": "Mistral AI",
    "context_window": 32000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 10.8883,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 3.9,
    "gpqa": 38.2,
    "scicode": 22.8,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 19.5,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.264818+00:00",
        "confidence": 0.65,
        "raw_name": "DeepHermes 3 - Mistral 24B Preview (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 10.888270503865678,
          "context_window": 32000,
          "hle": 3.9,
          "gpqa": 38.2,
          "scicode": 22.8,
          "livecodebench": 19.5
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.888270503865678,
        "hle": 3.9,
        "gpqa": 38.2,
        "scicode": 22.8,
        "livecodebench": 19.5
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "deephermes-3---llama-31-8b-preview",
    "canonical_name": "DeepHermes 3 - Llama-3.1 8B Preview (Non-reasoning)",
    "model_name": "DeepHermes 3 - Llama-3.1 8B Preview (Non-reasoning)",
    "aliases": [
      "DeepHermes 3 - Llama-3.1 8B Preview (Non-reasoning)"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT",
    "creator": null,
    "intelligence_score": 7.5781,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.3,
    "gpqa": 27.0,
    "scicode": 9.1,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 8.5,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.264884+00:00",
        "confidence": 0.65,
        "raw_name": "DeepHermes 3 - Llama-3.1 8B Preview (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 7.578083680871105,
          "context_window": 128000,
          "hle": 4.3,
          "gpqa": 27.0,
          "scicode": 9.1,
          "livecodebench": 8.5
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 7.578083680871105,
        "hle": 4.3,
        "gpqa": 27.0,
        "scicode": 9.1,
        "livecodebench": 8.5
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "exaone-40-32b",
    "canonical_name": "EXAONE 4.0 32B (Reasoning)",
    "model_name": "EXAONE 4.0 32B (Reasoning)",
    "aliases": [
      "EXAONE 4.0 32B (Non-reasoning)",
      "EXAONE 4.0 32B (Reasoning)"
    ],
    "provider": null,
    "context_window": 131000,
    "open_source": false,
    "arena_votes": null,
    "license_type": "EXAONE AI Model License Agreement 1.2 - NC",
    "creator": null,
    "intelligence_score": 14.095,
    "coding_score": 11.7,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 479.0597,
    "terminalbench_hard": 0.0265,
    "tau2": 0.107,
    "lcr": 11.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 7.7,
    "gpqa": 68.35,
    "scicode": 29.8,
    "ifbench": 34.9,
    "aime25": 59.65,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 60.95,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.264924+00:00",
        "confidence": 0.79,
        "raw_name": "EXAONE 4.0 32B (Reasoning)",
        "raw_scores": {
          "intelligence_score": 16.65,
          "coding_score": 13.98,
          "context_window": 131000,
          "gdpval": 561.6015125184587,
          "terminalbench_hard": 0.038,
          "tau2": 0.173,
          "lcr": 14.0,
          "hle": 10.5,
          "gpqa": 73.9,
          "scicode": 34.4,
          "ifbench": 36.3,
          "aime25": 80.0,
          "critpt": 0.0,
          "livecodebench": 74.7
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.264965+00:00",
        "confidence": 0.79,
        "raw_name": "EXAONE 4.0 32B (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 11.54,
          "coding_score": 9.42,
          "context_window": 131000,
          "gdpval": 396.51790878894576,
          "terminalbench_hard": 0.015,
          "tau2": 0.041,
          "lcr": 8.0,
          "hle": 4.9,
          "gpqa": 62.8,
          "scicode": 25.2,
          "ifbench": 33.5,
          "aime25": 39.3,
          "critpt": 0.0,
          "livecodebench": 47.2
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 16.65,
        "coding_score": 13.98,
        "gdpval": 561.6015125184587,
        "terminalbench_hard": 0.038,
        "tau2": 0.173,
        "lcr": 14.0,
        "hle": 10.5,
        "gpqa": 73.9,
        "scicode": 34.4,
        "ifbench": 36.3,
        "aime25": 80.0,
        "critpt": 0.0,
        "livecodebench": 74.7
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "exaone-40-12b",
    "canonical_name": "Exaone 4.0 1.2B (Non-reasoning)",
    "model_name": "Exaone 4.0 1.2B (Non-reasoning)",
    "aliases": [
      "Exaone 4.0 1.2B (Non-reasoning)",
      "Exaone 4.0 1.2B (Reasoning)"
    ],
    "provider": null,
    "context_window": 64000,
    "open_source": false,
    "arena_votes": null,
    "license_type": "EXAONE AI Model License Agreement 1.2 - NC",
    "creator": null,
    "intelligence_score": 8.165,
    "coding_score": 2.78,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 368.5111,
    "terminalbench_hard": 0.0,
    "tau2": 0.1845,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.8,
    "gpqa": 46.95,
    "scicode": 8.35,
    "ifbench": 24.15,
    "aime25": 37.15,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 40.45,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.265004+00:00",
        "confidence": 0.79,
        "raw_name": "Exaone 4.0 1.2B (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 8.07,
          "coding_score": 2.47,
          "context_window": 64000,
          "gdpval": 368.85963568852355,
          "terminalbench_hard": 0.0,
          "tau2": 0.205,
          "lcr": 0.0,
          "hle": 5.8,
          "gpqa": 42.4,
          "scicode": 7.4,
          "ifbench": 25.3,
          "aime25": 24.0,
          "critpt": 0.0,
          "livecodebench": 29.3
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.265043+00:00",
        "confidence": 0.79,
        "raw_name": "Exaone 4.0 1.2B (Reasoning)",
        "raw_scores": {
          "intelligence_score": 8.26,
          "coding_score": 3.09,
          "context_window": 64000,
          "gdpval": 368.16254520271445,
          "terminalbench_hard": 0.0,
          "tau2": 0.164,
          "lcr": 0.0,
          "hle": 5.8,
          "gpqa": 51.5,
          "scicode": 9.3,
          "ifbench": 23.0,
          "aime25": 50.3,
          "critpt": 0.0,
          "livecodebench": 51.6
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.07,
        "coding_score": 2.47,
        "gdpval": 368.85963568852355,
        "terminalbench_hard": 0.0,
        "tau2": 0.205,
        "lcr": 0.0,
        "hle": 5.8,
        "gpqa": 42.4,
        "scicode": 7.4,
        "ifbench": 25.3,
        "aime25": 24.0,
        "critpt": 0.0,
        "livecodebench": 29.3
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "k-exaone",
    "canonical_name": "K-EXAONE (Non-reasoning)",
    "model_name": "K-EXAONE (Non-reasoning)",
    "aliases": [
      "K-EXAONE (Non-reasoning)",
      "K-EXAONE (Reasoning)"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "K Exaone",
    "creator": null,
    "intelligence_score": 27.7909,
    "coding_score": 20.5929,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 849.6258,
    "terminalbench_hard": 0.1512,
    "tau2": 0.6705,
    "lcr": 51.5517,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 9.4285,
    "gpqa": 74.104,
    "scicode": 31.4993,
    "ifbench": 52.7318,
    "aime25": 68.2232,
    "critpt": 0.5755,
    "mmmu_pro": null,
    "livecodebench": 76.8,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.265081+00:00",
        "confidence": 0.72,
        "raw_name": "K-EXAONE (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 23.03,
          "coding_score": 13.53,
          "context_window": 256000,
          "gdpval": 820.1978952946506,
          "terminalbench_hard": 0.068,
          "tau2": 0.591,
          "lcr": 47.0,
          "hle": 5.4,
          "gpqa": 69.5,
          "scicode": 27.0,
          "ifbench": 39.6,
          "aime25": 44.0,
          "critpt": 0.0
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.265120+00:00",
        "confidence": 0.79,
        "raw_name": "K-EXAONE (Reasoning)",
        "raw_scores": {
          "intelligence_score": 32.13,
          "coding_score": 27.03,
          "context_window": 256000,
          "gdpval": 876.4461632374728,
          "terminalbench_hard": 0.227,
          "tau2": 0.743,
          "lcr": 55.7,
          "hle": 13.1,
          "gpqa": 78.3,
          "scicode": 35.6,
          "ifbench": 64.7,
          "aime25": 90.3,
          "critpt": 1.1,
          "livecodebench": 76.8
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 23.03,
        "coding_score": 13.53,
        "gdpval": 820.1978952946506,
        "terminalbench_hard": 0.068,
        "tau2": 0.591,
        "lcr": 47.0,
        "hle": 5.4,
        "gpqa": 69.5,
        "scicode": 27.0,
        "ifbench": 39.6,
        "aime25": 44.0,
        "critpt": 0.0,
        "livecodebench": 76.8
      }
    },
    "confidence_score": 0.755,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "mimo-v2-flash",
    "canonical_name": "MiMo-V2-Flash (Non-reasoning)",
    "model_name": "MiMo-V2-Flash (Non-reasoning)",
    "aliases": [
      "MiMo-V2-Flash (Feb 2026)",
      "MiMo-V2-Flash (Non-reasoning)",
      "MiMo-V2-Flash (Reasoning)",
      "mimo-v2-flash (non-thinking)",
      "mimo-v2-flash (thinking)"
    ],
    "provider": "Xiaomi",
    "context_window": 256000,
    "open_source": true,
    "arena_votes": 19001,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": 37.198,
    "coding_score": 30.4527,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1388.15,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.15,
    "latency_seconds": 1.25,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 166.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 1078.6875,
    "terminalbench_hard": 0.2838,
    "tau2": 0.9081,
    "lcr": 53.1947,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 16.4709,
    "gpqa": 78.0607,
    "scicode": 34.6414,
    "ifbench": 59.0111,
    "aime25": 82.0,
    "critpt": 2.4143,
    "mmmu_pro": null,
    "livecodebench": 63.5,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.265158+00:00",
        "confidence": 0.79,
        "raw_name": "MiMo-V2-Flash (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 30.56,
          "coding_score": 25.81,
          "context_window": 256000,
          "gdpval": 1091.7705172357842,
          "terminalbench_hard": 0.258,
          "tau2": 0.839,
          "lcr": 31.3,
          "hle": 8.0,
          "gpqa": 65.6,
          "scicode": 25.9,
          "ifbench": 39.9,
          "aime25": 67.7,
          "critpt": 0.0,
          "livecodebench": 40.2
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.265194+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "MiMo-V2-Flash (Feb 2026)",
        "raw_scores": {
          "intelligence_score": 41.42,
          "coding_score": 33.48,
          "blended_cost_per_1m": 0.15,
          "latency_seconds": 1.25,
          "tokens_per_second": 166.0,
          "context_window": 256000,
          "gdpval": 1036.1949578243912,
          "terminalbench_hard": 0.311,
          "tau2": 0.933,
          "lcr": 64.3,
          "hle": 20.0,
          "gpqa": 83.5,
          "scicode": 38.3,
          "ifbench": 71.8,
          "critpt": 2.9
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.273998+00:00",
        "confidence": 0.79,
        "raw_name": "MiMo-V2-Flash (Reasoning)",
        "raw_scores": {
          "intelligence_score": 39.24,
          "coding_score": 31.8,
          "context_window": 256000,
          "gdpval": 1111.862229738039,
          "terminalbench_hard": 0.28,
          "tau2": 0.95,
          "lcr": 63.0,
          "hle": 21.1,
          "gpqa": 84.6,
          "scicode": 39.4,
          "ifbench": 64.2,
          "aime25": 96.3,
          "critpt": 4.3,
          "livecodebench": 86.8
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125684+00:00",
        "confidence": 1.0,
        "raw_name": "mimo-v2-flash (non-thinking)",
        "raw_scores": {
          "arena_elo": 1389.49,
          "arena_votes": 19001
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125743+00:00",
        "confidence": 1.0,
        "raw_name": "mimo-v2-flash (thinking)",
        "raw_scores": {
          "arena_elo": 1386.81,
          "arena_votes": 10867
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 30.56,
        "coding_score": 25.81,
        "gdpval": 1091.7705172357842,
        "terminalbench_hard": 0.258,
        "tau2": 0.839,
        "lcr": 31.3,
        "hle": 8.0,
        "gpqa": 65.6,
        "scicode": 25.9,
        "ifbench": 39.9,
        "aime25": 67.7,
        "critpt": 0.0,
        "livecodebench": 40.2
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1389.49
      }
    },
    "confidence_score": 0.888,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "ernie-45-300b-a47b",
    "canonical_name": "ERNIE 4.5 300B A47B",
    "model_name": "ERNIE 4.5 300B A47B",
    "aliases": [
      "ERNIE 4.5 300B A47B"
    ],
    "provider": null,
    "context_window": 131072,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 14.94,
    "coding_score": 14.53,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.48,
    "latency_seconds": 1.98,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 18.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": 0.061,
    "tau2": 0.0,
    "lcr": 2.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 3.5,
    "gpqa": 81.1,
    "scicode": 31.5,
    "ifbench": 39.1,
    "aime25": 41.3,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 46.7,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.265234+00:00",
        "confidence": 1.0,
        "raw_name": "ERNIE 4.5 300B A47B",
        "raw_scores": {
          "intelligence_score": 14.94,
          "coding_score": 14.53,
          "blended_cost_per_1m": 0.48,
          "latency_seconds": 1.98,
          "tokens_per_second": 18.0,
          "context_window": 131072,
          "terminalbench_hard": 0.061,
          "tau2": 0.0,
          "lcr": 2.3,
          "hle": 3.5,
          "gpqa": 81.1,
          "scicode": 31.5,
          "ifbench": 39.1,
          "aime25": 41.3,
          "critpt": 0.0,
          "livecodebench": 46.7
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.94,
        "coding_score": 14.53,
        "terminalbench_hard": 0.061,
        "tau2": 0.0,
        "lcr": 2.3,
        "hle": 3.5,
        "gpqa": 81.1,
        "scicode": 31.5,
        "ifbench": 39.1,
        "aime25": 41.3,
        "critpt": 0.0,
        "livecodebench": 46.7
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "ernie-50-thinking-preview",
    "canonical_name": "ERNIE 5.0 Thinking Preview",
    "model_name": "ERNIE 5.0 Thinking Preview",
    "aliases": [
      "ERNIE 5.0 Thinking Preview"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 29.12,
    "coding_score": 29.17,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 829.8288,
    "terminalbench_hard": 0.25,
    "tau2": 0.839,
    "lcr": 6.7,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 12.7,
    "gpqa": 77.7,
    "scicode": 37.5,
    "ifbench": 41.4,
    "aime25": 85.0,
    "critpt": 1.4,
    "mmmu_pro": 64.6,
    "livecodebench": 81.2,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.265296+00:00",
        "confidence": 1.0,
        "raw_name": "ERNIE 5.0 Thinking Preview",
        "raw_scores": {
          "intelligence_score": 29.12,
          "coding_score": 29.17,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000,
          "gdpval": 829.8288294864831,
          "terminalbench_hard": 0.25,
          "tau2": 0.839,
          "lcr": 6.7,
          "hle": 12.7,
          "gpqa": 77.7,
          "scicode": 37.5,
          "ifbench": 41.4,
          "aime25": 85.0,
          "critpt": 1.4,
          "mmmu_pro": 64.6,
          "livecodebench": 81.2
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 29.12,
        "coding_score": 29.17,
        "gdpval": 829.8288294864831,
        "terminalbench_hard": 0.25,
        "tau2": 0.839,
        "lcr": 6.7,
        "hle": 12.7,
        "gpqa": 77.7,
        "scicode": 37.5,
        "ifbench": 41.4,
        "aime25": 85.0,
        "critpt": 1.4,
        "mmmu_pro": 64.6,
        "livecodebench": 81.2
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "cogito-v21",
    "canonical_name": "Cogito v2.1 (Reasoning)",
    "model_name": "Cogito v2.1 (Reasoning)",
    "aliases": [
      "Cogito v2.1 (Reasoning)"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": 24.77,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": 0.167,
    "tau2": null,
    "lcr": 21.7,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 11.0,
    "gpqa": 76.8,
    "scicode": 41.0,
    "ifbench": 46.3,
    "aime25": 72.7,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 68.8,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.265330+00:00",
        "confidence": 0.72,
        "raw_name": "Cogito v2.1 (Reasoning)",
        "raw_scores": {
          "coding_score": 24.77,
          "context_window": 128000,
          "terminalbench_hard": 0.167,
          "lcr": 21.7,
          "hle": 11.0,
          "gpqa": 76.8,
          "scicode": 41.0,
          "ifbench": 46.3,
          "aime25": 72.7,
          "critpt": 0.0,
          "livecodebench": 68.8
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "coding_score": 24.77,
        "terminalbench_hard": 0.167,
        "lcr": 21.7,
        "hle": 11.0,
        "gpqa": 76.8,
        "scicode": 41.0,
        "ifbench": 46.3,
        "aime25": 72.7,
        "critpt": 0.0,
        "livecodebench": 68.8
      }
    },
    "confidence_score": 0.72,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-65b",
    "canonical_name": "Llama 65B",
    "model_name": "Llama 65B",
    "aliases": [
      "Llama 65B"
    ],
    "provider": "Meta",
    "context_window": 2048,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 4.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.265352+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 65B",
        "raw_scores": {
          "intelligence_score": 4.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 2048
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 4.0
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "kat-coder-pro-v1",
    "canonical_name": "KAT-Coder-Pro V1",
    "model_name": "KAT-Coder-Pro V1",
    "aliases": [
      "KAT-Coder-Pro V1"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 36.11,
    "coding_score": 18.25,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.53,
    "latency_seconds": 2.14,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 58.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 848.0408,
    "terminalbench_hard": 0.091,
    "tau2": 0.886,
    "lcr": 74.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 33.4,
    "gpqa": 76.4,
    "scicode": 36.6,
    "ifbench": 68.4,
    "aime25": 94.7,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 74.7,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.265395+00:00",
        "confidence": 1.0,
        "raw_name": "KAT-Coder-Pro V1",
        "raw_scores": {
          "intelligence_score": 36.11,
          "coding_score": 18.25,
          "blended_cost_per_1m": 0.53,
          "latency_seconds": 2.14,
          "tokens_per_second": 58.0,
          "context_window": 256000,
          "gdpval": 848.0407804175372,
          "terminalbench_hard": 0.091,
          "tau2": 0.886,
          "lcr": 74.0,
          "hle": 33.4,
          "gpqa": 76.4,
          "scicode": 36.6,
          "ifbench": 68.4,
          "aime25": 94.7,
          "critpt": 0.0,
          "livecodebench": 74.7
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 36.11,
        "coding_score": 18.25,
        "gdpval": 848.0407804175372,
        "terminalbench_hard": 0.091,
        "tau2": 0.886,
        "lcr": 74.0,
        "hle": 33.4,
        "gpqa": 76.4,
        "scicode": 36.6,
        "ifbench": 68.4,
        "aime25": 94.7,
        "critpt": 0.0,
        "livecodebench": 74.7
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "intellect-3",
    "canonical_name": "INTELLECT-3",
    "model_name": "INTELLECT-3",
    "aliases": [
      "INTELLECT-3",
      "intellect-3"
    ],
    "provider": "Prime Intellect",
    "context_window": 131100,
    "open_source": true,
    "arena_votes": 5290,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": 22.14,
    "coding_score": 19.1,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1356.11,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.42,
    "latency_seconds": 0.82,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 63.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 804.3718,
    "terminalbench_hard": 0.091,
    "tau2": 0.266,
    "lcr": 32.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 12.1,
    "gpqa": 76.1,
    "scicode": 39.1,
    "ifbench": 34.0,
    "aime25": 88.0,
    "critpt": 0.3,
    "mmmu_pro": null,
    "livecodebench": 77.7,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.265437+00:00",
        "confidence": 1.0,
        "raw_name": "INTELLECT-3",
        "raw_scores": {
          "intelligence_score": 22.14,
          "coding_score": 19.1,
          "blended_cost_per_1m": 0.42,
          "latency_seconds": 0.82,
          "tokens_per_second": 63.0,
          "context_window": 131100,
          "gdpval": 804.3718233706356,
          "terminalbench_hard": 0.091,
          "tau2": 0.266,
          "lcr": 32.3,
          "hle": 12.1,
          "gpqa": 76.1,
          "scicode": 39.1,
          "ifbench": 34.0,
          "aime25": 88.0,
          "critpt": 0.3,
          "livecodebench": 77.7
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126207+00:00",
        "confidence": 1.0,
        "raw_name": "intellect-3",
        "raw_scores": {
          "arena_elo": 1356.11,
          "arena_votes": 5290
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 22.14,
        "coding_score": 19.1,
        "gdpval": 804.3718233706356,
        "terminalbench_hard": 0.091,
        "tau2": 0.266,
        "lcr": 32.3,
        "hle": 12.1,
        "gpqa": 76.1,
        "scicode": 39.1,
        "ifbench": 34.0,
        "aime25": 88.0,
        "critpt": 0.3,
        "livecodebench": 77.7
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1356.11
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "motif-2-127b-reasoning",
    "canonical_name": "Motif-2-12.7B-Reasoning",
    "model_name": "Motif-2-12.7B-Reasoning",
    "aliases": [
      "Motif-2-12.7B-Reasoning"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 19.1,
    "coding_score": 11.94,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 542.4747,
    "terminalbench_hard": 0.038,
    "tau2": 0.465,
    "lcr": 13.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 8.2,
    "gpqa": 69.5,
    "scicode": 28.2,
    "ifbench": 57.0,
    "aime25": 80.3,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 65.1,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.265475+00:00",
        "confidence": 0.79,
        "raw_name": "Motif-2-12.7B-Reasoning",
        "raw_scores": {
          "intelligence_score": 19.1,
          "coding_score": 11.94,
          "context_window": 128000,
          "gdpval": 542.4747025763876,
          "terminalbench_hard": 0.038,
          "tau2": 0.465,
          "lcr": 13.0,
          "hle": 8.2,
          "gpqa": 69.5,
          "scicode": 28.2,
          "ifbench": 57.0,
          "aime25": 80.3,
          "critpt": 0.0,
          "livecodebench": 65.1
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.1,
        "coding_score": 11.94,
        "gdpval": 542.4747025763876,
        "terminalbench_hard": 0.038,
        "tau2": 0.465,
        "lcr": 13.0,
        "hle": 8.2,
        "gpqa": 69.5,
        "scicode": 28.2,
        "ifbench": 57.0,
        "aime25": 80.3,
        "critpt": 0.0,
        "livecodebench": 65.1
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "k2-think-v2",
    "canonical_name": "K2 Think V2",
    "model_name": "K2 Think V2",
    "aliases": [
      "K2 Think V2"
    ],
    "provider": null,
    "context_window": 262144,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 24.52,
    "coding_score": 15.54,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 659.6844,
    "terminalbench_hard": 0.068,
    "tau2": 0.254,
    "lcr": 52.7,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 9.5,
    "gpqa": 71.3,
    "scicode": 33.0,
    "ifbench": 62.8,
    "aime25": null,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.265510+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "K2 Think V2",
        "raw_scores": {
          "intelligence_score": 24.52,
          "coding_score": 15.54,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 262144,
          "gdpval": 659.6843818818754,
          "terminalbench_hard": 0.068,
          "tau2": 0.254,
          "lcr": 52.7,
          "hle": 9.5,
          "gpqa": 71.3,
          "scicode": 33.0,
          "ifbench": 62.8,
          "critpt": 0.0
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 24.52,
        "coding_score": 15.54,
        "gdpval": 659.6843818818754,
        "terminalbench_hard": 0.068,
        "tau2": 0.254,
        "lcr": 52.7,
        "hle": 9.5,
        "gpqa": 71.3,
        "scicode": 33.0,
        "ifbench": 62.8,
        "critpt": 0.0
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "k2-v2",
    "canonical_name": "K2-V2 (medium)",
    "model_name": "K2-V2 (medium)",
    "aliases": [
      "K2-V2 (high)",
      "K2-V2 (low)",
      "K2-V2 (medium)"
    ],
    "provider": null,
    "context_window": 512000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 17.9367,
    "coding_score": 13.5133,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 554.9293,
    "terminalbench_hard": 0.0753,
    "tau2": 0.245,
    "lcr": 26.7667,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 6.0333,
    "gpqa": 60.6667,
    "scicode": 25.3667,
    "ifbench": 52.0667,
    "aime25": 59.4333,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 54.2667,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.265550+00:00",
        "confidence": 1.0,
        "raw_name": "K2-V2 (medium)",
        "raw_scores": {
          "intelligence_score": 18.7,
          "coding_score": 13.97,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 512000,
          "gdpval": 629.1345727913064,
          "terminalbench_hard": 0.083,
          "tau2": 0.249,
          "lcr": 28.0,
          "hle": 4.4,
          "gpqa": 59.8,
          "scicode": 25.2,
          "ifbench": 55.1,
          "aime25": 64.7,
          "critpt": 0.0,
          "livecodebench": 54.1
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.265591+00:00",
        "confidence": 1.0,
        "raw_name": "K2-V2 (low)",
        "raw_scores": {
          "intelligence_score": 14.44,
          "coding_score": 10.48,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 512000,
          "gdpval": 421.92258675185917,
          "terminalbench_hard": 0.045,
          "tau2": 0.208,
          "lcr": 19.0,
          "hle": 3.9,
          "gpqa": 54.1,
          "scicode": 22.3,
          "ifbench": 41.0,
          "aime25": 35.3,
          "critpt": 0.0,
          "livecodebench": 39.3
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.265650+00:00",
        "confidence": 1.0,
        "raw_name": "K2-V2 (high)",
        "raw_scores": {
          "intelligence_score": 20.67,
          "coding_score": 16.09,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 512000,
          "gdpval": 613.7307940592383,
          "terminalbench_hard": 0.098,
          "tau2": 0.278,
          "lcr": 33.3,
          "hle": 9.8,
          "gpqa": 68.1,
          "scicode": 28.6,
          "ifbench": 60.1,
          "aime25": 78.3,
          "critpt": 0.0,
          "livecodebench": 69.4
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 18.7,
        "coding_score": 13.97,
        "gdpval": 629.1345727913064,
        "terminalbench_hard": 0.083,
        "tau2": 0.249,
        "lcr": 28.0,
        "hle": 4.4,
        "gpqa": 59.8,
        "scicode": 25.2,
        "ifbench": 55.1,
        "aime25": 64.7,
        "critpt": 0.0,
        "livecodebench": 54.1
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "midm-k-25-pro",
    "canonical_name": "Mi:dm K 2.5 Pro",
    "model_name": "Mi:dm K 2.5 Pro",
    "aliases": [
      "Mi:dm K 2.5 Pro"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 23.03,
    "coding_score": 12.57,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 694.3372,
    "terminalbench_hard": 0.023,
    "tau2": 0.865,
    "lcr": 9.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 7.7,
    "gpqa": 70.1,
    "scicode": 33.2,
    "ifbench": 49.3,
    "aime25": 76.7,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 65.6,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.265693+00:00",
        "confidence": 1.0,
        "raw_name": "Mi:dm K 2.5 Pro",
        "raw_scores": {
          "intelligence_score": 23.03,
          "coding_score": 12.57,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000,
          "gdpval": 694.337185642587,
          "terminalbench_hard": 0.023,
          "tau2": 0.865,
          "lcr": 9.0,
          "hle": 7.7,
          "gpqa": 70.1,
          "scicode": 33.2,
          "ifbench": 49.3,
          "aime25": 76.7,
          "critpt": 0.0,
          "livecodebench": 65.6
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 23.03,
        "coding_score": 12.57,
        "gdpval": 694.337185642587,
        "terminalbench_hard": 0.023,
        "tau2": 0.865,
        "lcr": 9.0,
        "hle": 7.7,
        "gpqa": 70.1,
        "scicode": 33.2,
        "ifbench": 49.3,
        "aime25": 76.7,
        "critpt": 0.0,
        "livecodebench": 65.6
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "midm-k-25-pro-preview",
    "canonical_name": "Mi:dm K 2.5 Pro Preview",
    "model_name": "Mi:dm K 2.5 Pro Preview",
    "aliases": [
      "Mi:dm K 2.5 Pro Preview"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": null,
    "coding_score": 11.94,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": 0.03,
    "tau2": 0.494,
    "lcr": 11.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 8.8,
    "gpqa": 72.2,
    "scicode": 29.7,
    "ifbench": 45.6,
    "aime25": 78.7,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 57.6,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.265730+00:00",
        "confidence": 0.9300000000000002,
        "raw_name": "Mi:dm K 2.5 Pro Preview",
        "raw_scores": {
          "coding_score": 11.94,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000,
          "terminalbench_hard": 0.03,
          "tau2": 0.494,
          "lcr": 11.0,
          "hle": 8.8,
          "gpqa": 72.2,
          "scicode": 29.7,
          "ifbench": 45.6,
          "aime25": 78.7,
          "critpt": 0.0,
          "livecodebench": 57.6
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "coding_score": 11.94,
        "terminalbench_hard": 0.03,
        "tau2": 0.494,
        "lcr": 11.0,
        "hle": 8.8,
        "gpqa": 72.2,
        "scicode": 29.7,
        "ifbench": 45.6,
        "aime25": 78.7,
        "critpt": 0.0,
        "livecodebench": 57.6
      }
    },
    "confidence_score": 0.93,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "hyperclova-x-seed-think",
    "canonical_name": "HyperCLOVA X SEED Think (32B)",
    "model_name": "HyperCLOVA X SEED Think (32B)",
    "aliases": [
      "HyperCLOVA X SEED Think (32B)"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 23.72,
    "coding_score": 17.53,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 737.6885,
    "terminalbench_hard": 0.121,
    "tau2": 0.874,
    "lcr": 11.7,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.5,
    "gpqa": 61.5,
    "scicode": 28.4,
    "ifbench": 37.9,
    "aime25": 59.0,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 62.9,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.265769+00:00",
        "confidence": 1.0,
        "raw_name": "HyperCLOVA X SEED Think (32B)",
        "raw_scores": {
          "intelligence_score": 23.72,
          "coding_score": 17.53,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000,
          "gdpval": 737.6885087171511,
          "terminalbench_hard": 0.121,
          "tau2": 0.874,
          "lcr": 11.7,
          "hle": 5.5,
          "gpqa": 61.5,
          "scicode": 28.4,
          "ifbench": 37.9,
          "aime25": 59.0,
          "critpt": 0.0,
          "livecodebench": 62.9
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 23.72,
        "coding_score": 17.53,
        "gdpval": 737.6885087171511,
        "terminalbench_hard": 0.121,
        "tau2": 0.874,
        "lcr": 11.7,
        "hle": 5.5,
        "gpqa": 61.5,
        "scicode": 28.4,
        "ifbench": 37.9,
        "aime25": 59.0,
        "critpt": 0.0,
        "livecodebench": 62.9
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "tri-21b-think",
    "canonical_name": "Tri-21B-Think",
    "model_name": "Tri-21B-Think",
    "aliases": [
      "Tri-21B-Think"
    ],
    "provider": null,
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 18.62,
    "coding_score": 6.29,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 429.9409,
    "terminalbench_hard": 0.008,
    "tau2": 0.81,
    "lcr": 11.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 6.1,
    "gpqa": 60.1,
    "scicode": 17.4,
    "ifbench": 54.6,
    "aime25": null,
    "critpt": 0.3,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.265805+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "Tri-21B-Think",
        "raw_scores": {
          "intelligence_score": 18.62,
          "coding_score": 6.29,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32000,
          "gdpval": 429.9408924811171,
          "terminalbench_hard": 0.008,
          "tau2": 0.81,
          "lcr": 11.0,
          "hle": 6.1,
          "gpqa": 60.1,
          "scicode": 17.4,
          "ifbench": 54.6,
          "critpt": 0.3
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 18.62,
        "coding_score": 6.29,
        "gdpval": 429.9408924811171,
        "terminalbench_hard": 0.008,
        "tau2": 0.81,
        "lcr": 11.0,
        "hle": 6.1,
        "gpqa": 60.1,
        "scicode": 17.4,
        "ifbench": 54.6,
        "critpt": 0.3
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "tri-21b-think-preview",
    "canonical_name": "Tri-21B-think Preview",
    "model_name": "Tri-21B-think Preview",
    "aliases": [
      "Tri-21B-think Preview"
    ],
    "provider": null,
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 20.46,
    "coding_score": 7.44,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 337.0179,
    "terminalbench_hard": 0.023,
    "tau2": 0.933,
    "lcr": 14.7,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.7,
    "gpqa": 53.8,
    "scicode": 17.8,
    "ifbench": 47.1,
    "aime25": null,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.265839+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "Tri-21B-think Preview",
        "raw_scores": {
          "intelligence_score": 20.46,
          "coding_score": 7.44,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32000,
          "gdpval": 337.0179335195246,
          "terminalbench_hard": 0.023,
          "tau2": 0.933,
          "lcr": 14.7,
          "hle": 5.7,
          "gpqa": 53.8,
          "scicode": 17.8,
          "ifbench": 47.1,
          "critpt": 0.0
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 20.46,
        "coding_score": 7.44,
        "gdpval": 337.0179335195246,
        "terminalbench_hard": 0.023,
        "tau2": 0.933,
        "lcr": 14.7,
        "hle": 5.7,
        "gpqa": 53.8,
        "scicode": 17.8,
        "ifbench": 47.1,
        "critpt": 0.0
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "glm-5",
    "canonical_name": "GLM-5 (Reasoning)",
    "model_name": "GLM-5 (Reasoning)",
    "aliases": [
      "GLM-5 (Non-reasoning)",
      "GLM-5 (Reasoning)",
      "glm-5"
    ],
    "provider": "Z.ai",
    "context_window": 200000,
    "open_source": true,
    "arena_votes": 5826,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": 45.06,
    "coding_score": 41.605,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1453.05,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 1373.8437,
    "terminalbench_hard": 0.413,
    "tau2": 0.978,
    "lcr": 50.15,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 17.2,
    "gpqa": 74.3,
    "scicode": 42.25,
    "ifbench": 63.75,
    "aime25": null,
    "critpt": 1.0,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.265871+00:00",
        "confidence": 0.65,
        "raw_name": "GLM-5 (Reasoning)",
        "raw_scores": {
          "intelligence_score": 49.64,
          "coding_score": 44.18,
          "context_window": 200000,
          "gdpval": 1410.564682935448,
          "terminalbench_hard": 0.432,
          "tau2": 0.982,
          "lcr": 63.3,
          "hle": 27.2,
          "gpqa": 82.0,
          "scicode": 46.2,
          "ifbench": 72.3,
          "critpt": 2.0
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.265947+00:00",
        "confidence": 0.65,
        "raw_name": "GLM-5 (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 40.48,
          "coding_score": 39.03,
          "context_window": 200000,
          "gdpval": 1337.1227126639594,
          "terminalbench_hard": 0.394,
          "tau2": 0.974,
          "lcr": 37.0,
          "hle": 7.2,
          "gpqa": 66.6,
          "scicode": 38.3,
          "ifbench": 55.2,
          "critpt": 0.0
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.124716+00:00",
        "confidence": 1.0,
        "raw_name": "glm-5",
        "raw_scores": {
          "arena_elo": 1453.05,
          "arena_votes": 5826
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 49.64,
        "coding_score": 44.18,
        "gdpval": 1410.564682935448,
        "terminalbench_hard": 0.432,
        "tau2": 0.982,
        "lcr": 63.3,
        "hle": 27.2,
        "gpqa": 82.0,
        "scicode": 46.2,
        "ifbench": 72.3,
        "critpt": 2.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1453.05
      }
    },
    "confidence_score": 0.7667,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "glm-46v",
    "canonical_name": "GLM-4.6V (Reasoning)",
    "model_name": "GLM-4.6V (Reasoning)",
    "aliases": [
      "GLM-4.6V (Non-reasoning)",
      "GLM-4.6V (Reasoning)",
      "glm-4.6v"
    ],
    "provider": "Z.ai",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": 2785,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": 20.275,
    "coding_score": 15.415,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1377.78,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 693.6182,
    "terminalbench_hard": 0.087,
    "tau2": 0.3115,
    "lcr": 26.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 6.3,
    "gpqa": 64.25,
    "scicode": 28.8,
    "ifbench": 29.0,
    "aime25": 55.8,
    "critpt": 0.0,
    "mmmu_pro": 45.4,
    "livecodebench": 28.55,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.265912+00:00",
        "confidence": 0.79,
        "raw_name": "GLM-4.6V (Reasoning)",
        "raw_scores": {
          "intelligence_score": 23.46,
          "coding_score": 19.74,
          "context_window": 128000,
          "gdpval": 651.2217048899735,
          "terminalbench_hard": 0.144,
          "tau2": 0.316,
          "lcr": 40.3,
          "hle": 8.9,
          "gpqa": 71.9,
          "scicode": 30.4,
          "ifbench": 30.1,
          "aime25": 85.3,
          "critpt": 0.0,
          "mmmu_pro": 48.6,
          "livecodebench": 16.0
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.265987+00:00",
        "confidence": 0.79,
        "raw_name": "GLM-4.6V (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 17.09,
          "coding_score": 11.09,
          "context_window": 128000,
          "gdpval": 736.0146026271243,
          "terminalbench_hard": 0.03,
          "tau2": 0.307,
          "lcr": 12.3,
          "hle": 3.7,
          "gpqa": 56.6,
          "scicode": 27.2,
          "ifbench": 27.9,
          "aime25": 26.3,
          "critpt": 0.0,
          "mmmu_pro": 42.2,
          "livecodebench": 41.1
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125970+00:00",
        "confidence": 1.0,
        "raw_name": "glm-4.6v",
        "raw_scores": {
          "arena_elo": 1377.78,
          "arena_votes": 2785
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 23.46,
        "coding_score": 19.74,
        "gdpval": 651.2217048899735,
        "terminalbench_hard": 0.144,
        "tau2": 0.316,
        "lcr": 40.3,
        "hle": 8.9,
        "gpqa": 71.9,
        "scicode": 30.4,
        "ifbench": 30.1,
        "aime25": 85.3,
        "critpt": 0.0,
        "mmmu_pro": 48.6,
        "livecodebench": 16.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1377.78
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "glm-47-flash",
    "canonical_name": "GLM-4.7-Flash (Non-reasoning)",
    "model_name": "GLM-4.7-Flash (Non-reasoning)",
    "aliases": [
      "GLM-4.7-Flash (Non-reasoning)",
      "GLM-4.7-Flash (Reasoning)",
      "glm-4.7-flash"
    ],
    "provider": "Z.ai",
    "context_window": 200000,
    "open_source": true,
    "arena_votes": 9956,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": 25.795,
    "coding_score": 18.44,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1364.55,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 857.8579,
    "terminalbench_hard": 0.129,
    "tau2": 0.953,
    "lcr": 24.85,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 6.0,
    "gpqa": 51.65,
    "scicode": 29.6,
    "ifbench": 53.55,
    "aime25": null,
    "critpt": 0.15,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.266020+00:00",
        "confidence": 0.65,
        "raw_name": "GLM-4.7-Flash (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 21.47,
          "coding_score": 11.01,
          "context_window": 200000,
          "gdpval": 839.2183137261031,
          "terminalbench_hard": 0.038,
          "tau2": 0.918,
          "lcr": 14.7,
          "hle": 4.9,
          "gpqa": 45.2,
          "scicode": 25.5,
          "ifbench": 46.3,
          "critpt": 0.0
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.266052+00:00",
        "confidence": 0.65,
        "raw_name": "GLM-4.7-Flash (Reasoning)",
        "raw_scores": {
          "intelligence_score": 30.12,
          "coding_score": 25.87,
          "context_window": 200000,
          "gdpval": 876.4975687208821,
          "terminalbench_hard": 0.22,
          "tau2": 0.988,
          "lcr": 35.0,
          "hle": 7.1,
          "gpqa": 58.1,
          "scicode": 33.7,
          "ifbench": 60.8,
          "critpt": 0.3
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126132+00:00",
        "confidence": 1.0,
        "raw_name": "glm-4.7-flash",
        "raw_scores": {
          "arena_elo": 1364.55,
          "arena_votes": 9956
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 21.47,
        "coding_score": 11.01,
        "gdpval": 839.2183137261031,
        "terminalbench_hard": 0.038,
        "tau2": 0.918,
        "lcr": 14.7,
        "hle": 4.9,
        "gpqa": 45.2,
        "scicode": 25.5,
        "ifbench": 46.3,
        "critpt": 0.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1364.55
      }
    },
    "confidence_score": 0.7667,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "command-a",
    "canonical_name": "Command A",
    "model_name": "Command A",
    "aliases": [
      "Command A",
      "command-a-03-2025"
    ],
    "provider": "Cohere",
    "context_window": 256000,
    "open_source": false,
    "arena_votes": 57102,
    "license_type": "CC-BY-NC 4.0 License with Acceptable Use Addendum",
    "creator": null,
    "intelligence_score": 13.44,
    "coding_score": 9.88,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1353.08,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 4.38,
    "latency_seconds": 0.33,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 54.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 336.2227,
    "terminalbench_hard": 0.008,
    "tau2": 0.152,
    "lcr": 18.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.6,
    "gpqa": 52.7,
    "scicode": 28.1,
    "ifbench": 36.5,
    "aime25": 13.0,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 28.7,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.266094+00:00",
        "confidence": 1.0,
        "raw_name": "Command A",
        "raw_scores": {
          "intelligence_score": 13.44,
          "coding_score": 9.88,
          "blended_cost_per_1m": 4.38,
          "latency_seconds": 0.33,
          "tokens_per_second": 54.0,
          "context_window": 256000,
          "gdpval": 336.22272741632503,
          "terminalbench_hard": 0.008,
          "tau2": 0.152,
          "lcr": 18.0,
          "hle": 4.6,
          "gpqa": 52.7,
          "scicode": 28.1,
          "ifbench": 36.5,
          "aime25": 13.0,
          "critpt": 0.0,
          "livecodebench": 28.7
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126285+00:00",
        "confidence": 1.0,
        "raw_name": "command-a-03-2025",
        "raw_scores": {
          "arena_elo": 1353.08,
          "arena_votes": 57102
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.44,
        "coding_score": 9.88,
        "gdpval": 336.22272741632503,
        "terminalbench_hard": 0.008,
        "tau2": 0.152,
        "lcr": 18.0,
        "hle": 4.6,
        "gpqa": 52.7,
        "scicode": 28.1,
        "ifbench": 36.5,
        "aime25": 13.0,
        "critpt": 0.0,
        "livecodebench": 28.7
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1353.08
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "tiny-aya-global",
    "canonical_name": "Tiny Aya Global",
    "model_name": "Tiny Aya Global",
    "aliases": [
      "Tiny Aya Global"
    ],
    "provider": null,
    "context_window": 8192,
    "open_source": null,
    "arena_votes": null,
    "license_type": "Cc By Nc 4.0",
    "creator": null,
    "intelligence_score": 4.72,
    "coding_score": 1.2,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": 0.0,
    "tau2": 0.0,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.2,
    "gpqa": 30.5,
    "scicode": 3.6,
    "ifbench": 20.1,
    "aime25": null,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.266125+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "Tiny Aya Global",
        "raw_scores": {
          "intelligence_score": 4.72,
          "coding_score": 1.2,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 8192,
          "terminalbench_hard": 0.0,
          "tau2": 0.0,
          "lcr": 0.0,
          "hle": 5.2,
          "gpqa": 30.5,
          "scicode": 3.6,
          "ifbench": 20.1,
          "critpt": 0.0
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 4.72,
        "coding_score": 1.2,
        "terminalbench_hard": 0.0,
        "tau2": 0.0,
        "lcr": 0.0,
        "hle": 5.2,
        "gpqa": 30.5,
        "scicode": 3.6,
        "ifbench": 20.1,
        "critpt": 0.0
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "apriel-v16-15b-thinker",
    "canonical_name": "Apriel-v1.6-15B-Thinker",
    "model_name": "Apriel-v1.6-15B-Thinker",
    "aliases": [
      "Apriel-v1.6-15B-Thinker"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": 27.51,
    "coding_score": 22.02,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.24,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 101.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 613.9002,
    "terminalbench_hard": 0.144,
    "tau2": 0.693,
    "lcr": 50.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 9.8,
    "gpqa": 73.3,
    "scicode": 37.3,
    "ifbench": 69.1,
    "aime25": 88.0,
    "critpt": 0.3,
    "mmmu_pro": null,
    "livecodebench": 80.7,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.266168+00:00",
        "confidence": 1.0,
        "raw_name": "Apriel-v1.6-15B-Thinker",
        "raw_scores": {
          "intelligence_score": 27.51,
          "coding_score": 22.02,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.24,
          "tokens_per_second": 101.0,
          "context_window": 128000,
          "gdpval": 613.9001742677217,
          "terminalbench_hard": 0.144,
          "tau2": 0.693,
          "lcr": 50.3,
          "hle": 9.8,
          "gpqa": 73.3,
          "scicode": 37.3,
          "ifbench": 69.1,
          "aime25": 88.0,
          "critpt": 0.3,
          "livecodebench": 80.7
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 27.51,
        "coding_score": 22.02,
        "gdpval": 613.9001742677217,
        "terminalbench_hard": 0.144,
        "tau2": 0.693,
        "lcr": 50.3,
        "hle": 9.8,
        "gpqa": 73.3,
        "scicode": 37.3,
        "ifbench": 69.1,
        "aime25": 88.0,
        "critpt": 0.3,
        "livecodebench": 80.7
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "jamba-reasoning-3b",
    "canonical_name": "Jamba Reasoning 3B",
    "model_name": "Jamba Reasoning 3B",
    "aliases": [
      "Jamba Reasoning 3B"
    ],
    "provider": null,
    "context_window": 262000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 10.33,
    "coding_score": 2.47,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 318.9795,
    "terminalbench_hard": 0.008,
    "tau2": 0.158,
    "lcr": 7.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.6,
    "gpqa": 33.3,
    "scicode": 5.9,
    "ifbench": 52.4,
    "aime25": 10.7,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 21.0,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.266209+00:00",
        "confidence": 1.0,
        "raw_name": "Jamba Reasoning 3B",
        "raw_scores": {
          "intelligence_score": 10.33,
          "coding_score": 2.47,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 262000,
          "gdpval": 318.9794612836961,
          "terminalbench_hard": 0.008,
          "tau2": 0.158,
          "lcr": 7.0,
          "hle": 4.6,
          "gpqa": 33.3,
          "scicode": 5.9,
          "ifbench": 52.4,
          "aime25": 10.7,
          "critpt": 0.0,
          "livecodebench": 21.0
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.33,
        "coding_score": 2.47,
        "gdpval": 318.9794612836961,
        "terminalbench_hard": 0.008,
        "tau2": 0.158,
        "lcr": 7.0,
        "hle": 4.6,
        "gpqa": 33.3,
        "scicode": 5.9,
        "ifbench": 52.4,
        "aime25": 10.7,
        "critpt": 0.0,
        "livecodebench": 21.0
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "jamba-17-large",
    "canonical_name": "Jamba 1.7 Large",
    "model_name": "Jamba 1.7 Large",
    "aliases": [
      "Jamba 1.7 Large"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Jamba Open Model License Agreement",
    "creator": null,
    "intelligence_score": 9.27,
    "coding_score": 7.77,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.5,
    "latency_seconds": 0.74,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 51.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 350.5816,
    "terminalbench_hard": 0.023,
    "tau2": 0.135,
    "lcr": 17.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 3.8,
    "gpqa": 39.0,
    "scicode": 18.8,
    "ifbench": 35.2,
    "aime25": 2.3,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 18.1,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.266266+00:00",
        "confidence": 1.0,
        "raw_name": "Jamba 1.7 Large",
        "raw_scores": {
          "intelligence_score": 9.27,
          "coding_score": 7.77,
          "blended_cost_per_1m": 3.5,
          "latency_seconds": 0.74,
          "tokens_per_second": 51.0,
          "context_window": 256000,
          "gdpval": 350.5816140803545,
          "terminalbench_hard": 0.023,
          "tau2": 0.135,
          "lcr": 17.3,
          "hle": 3.8,
          "gpqa": 39.0,
          "scicode": 18.8,
          "ifbench": 35.2,
          "aime25": 2.3,
          "critpt": 0.0,
          "livecodebench": 18.1
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.27,
        "coding_score": 7.77,
        "gdpval": 350.5816140803545,
        "terminalbench_hard": 0.023,
        "tau2": 0.135,
        "lcr": 17.3,
        "hle": 3.8,
        "gpqa": 39.0,
        "scicode": 18.8,
        "ifbench": 35.2,
        "aime25": 2.3,
        "critpt": 0.0,
        "livecodebench": 18.1
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "jamba-17-mini",
    "canonical_name": "Jamba 1.7 Mini",
    "model_name": "Jamba 1.7 Mini",
    "aliases": [
      "Jamba 1.7 Mini"
    ],
    "provider": null,
    "context_window": 258000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Jamba Open Model License Agreement",
    "creator": null,
    "intelligence_score": 7.33,
    "coding_score": 3.09,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.25,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 351.2532,
    "terminalbench_hard": 0.0,
    "tau2": 0.126,
    "lcr": 12.7,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.5,
    "gpqa": 32.2,
    "scicode": 9.3,
    "ifbench": 31.4,
    "aime25": 0.3,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 6.1,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.266310+00:00",
        "confidence": 1.0,
        "raw_name": "Jamba 1.7 Mini",
        "raw_scores": {
          "intelligence_score": 7.33,
          "coding_score": 3.09,
          "blended_cost_per_1m": 0.25,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 258000,
          "gdpval": 351.2532228748671,
          "terminalbench_hard": 0.0,
          "tau2": 0.126,
          "lcr": 12.7,
          "hle": 4.5,
          "gpqa": 32.2,
          "scicode": 9.3,
          "ifbench": 31.4,
          "aime25": 0.3,
          "critpt": 0.0,
          "livecodebench": 6.1
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 7.33,
        "coding_score": 3.09,
        "gdpval": 351.2532228748671,
        "terminalbench_hard": 0.0,
        "tau2": 0.126,
        "lcr": 12.7,
        "hle": 4.5,
        "gpqa": 32.2,
        "scicode": 9.3,
        "ifbench": 31.4,
        "aime25": 0.3,
        "critpt": 0.0,
        "livecodebench": 6.1
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen35-397b",
    "canonical_name": "Qwen3.5 397B A17B (Non-reasoning)",
    "model_name": "Qwen3.5 397B A17B (Non-reasoning)",
    "aliases": [
      "Qwen3.5 397B A17B (Non-reasoning)",
      "Qwen3.5 397B A17B (Reasoning)",
      "qwen3.5-397b-a17b"
    ],
    "provider": "Alibaba",
    "context_window": 262144,
    "open_source": true,
    "arena_votes": 4318,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 42.465,
    "coding_score": 39.355,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1449.75,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 1231.7966,
    "terminalbench_hard": 0.3825,
    "tau2": 0.8975,
    "lcr": 61.85,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 23.05,
    "gpqa": 87.7,
    "scicode": 41.55,
    "ifbench": 65.2,
    "aime25": null,
    "critpt": 1.3,
    "mmmu_pro": 52.7,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.266345+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3.5 397B A17B (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 39.93,
          "coding_score": 37.43,
          "context_window": 262144,
          "gdpval": 1253.7486925465391,
          "terminalbench_hard": 0.356,
          "tau2": 0.839,
          "lcr": 58.0,
          "hle": 18.8,
          "gpqa": 86.1,
          "scicode": 41.1,
          "ifbench": 51.6,
          "critpt": 0.9,
          "mmmu_pro": 52.7
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.266612+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3.5 397B A17B (Reasoning)",
        "raw_scores": {
          "intelligence_score": 45.0,
          "coding_score": 41.28,
          "context_window": 262144,
          "gdpval": 1209.8445930903338,
          "terminalbench_hard": 0.409,
          "tau2": 0.956,
          "lcr": 65.7,
          "hle": 27.3,
          "gpqa": 89.3,
          "scicode": 42.0,
          "ifbench": 78.8,
          "critpt": 1.7
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.124775+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3.5-397b-a17b",
        "raw_scores": {
          "arena_elo": 1449.75,
          "arena_votes": 4318
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 39.93,
        "coding_score": 37.43,
        "gdpval": 1253.7486925465391,
        "terminalbench_hard": 0.356,
        "tau2": 0.839,
        "lcr": 58.0,
        "hle": 18.8,
        "gpqa": 86.1,
        "scicode": 41.1,
        "ifbench": 51.6,
        "critpt": 0.9,
        "mmmu_pro": 52.7
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1449.75
      }
    },
    "confidence_score": 0.7667,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-next-80b-a3b",
    "canonical_name": "Qwen3 Next 80B A3B (Reasoning)",
    "model_name": "Qwen3 Next 80B A3B (Reasoning)",
    "aliases": [
      "Qwen3 Next 80B A3B (Reasoning)"
    ],
    "provider": "Alibaba",
    "context_window": 262144,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 26.49,
    "coding_score": 19.49,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 768.3116,
    "terminalbench_hard": 0.098,
    "tau2": 0.415,
    "lcr": 60.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 11.7,
    "gpqa": 75.9,
    "scicode": 38.8,
    "ifbench": 60.7,
    "aime25": 84.3,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 78.4,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.266384+00:00",
        "confidence": 0.79,
        "raw_name": "Qwen3 Next 80B A3B (Reasoning)",
        "raw_scores": {
          "intelligence_score": 26.49,
          "coding_score": 19.49,
          "context_window": 262144,
          "gdpval": 768.3116326432962,
          "terminalbench_hard": 0.098,
          "tau2": 0.415,
          "lcr": 60.3,
          "hle": 11.7,
          "gpqa": 75.9,
          "scicode": 38.8,
          "ifbench": 60.7,
          "aime25": 84.3,
          "critpt": 0.0,
          "livecodebench": 78.4
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 26.49,
        "coding_score": 19.49,
        "gdpval": 768.3116326432962,
        "terminalbench_hard": 0.098,
        "tau2": 0.415,
        "lcr": 60.3,
        "hle": 11.7,
        "gpqa": 75.9,
        "scicode": 38.8,
        "ifbench": 60.7,
        "aime25": 84.3,
        "critpt": 0.0,
        "livecodebench": 78.4
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-vl-8b-instruct",
    "canonical_name": "Qwen3 VL 8B Instruct",
    "model_name": "Qwen3 VL 8B Instruct",
    "aliases": [
      "Qwen3 VL 8B Instruct"
    ],
    "provider": "Alibaba",
    "context_window": 256000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 14.25,
    "coding_score": 7.3,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 726.4153,
    "terminalbench_hard": 0.023,
    "tau2": 0.292,
    "lcr": 15.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 2.9,
    "gpqa": 42.7,
    "scicode": 17.4,
    "ifbench": 32.3,
    "aime25": 27.3,
    "critpt": 0.0,
    "mmmu_pro": 47.3,
    "livecodebench": 33.2,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.266424+00:00",
        "confidence": 0.79,
        "raw_name": "Qwen3 VL 8B Instruct",
        "raw_scores": {
          "intelligence_score": 14.25,
          "coding_score": 7.3,
          "context_window": 256000,
          "gdpval": 726.4153195934122,
          "terminalbench_hard": 0.023,
          "tau2": 0.292,
          "lcr": 15.3,
          "hle": 2.9,
          "gpqa": 42.7,
          "scicode": 17.4,
          "ifbench": 32.3,
          "aime25": 27.3,
          "critpt": 0.0,
          "mmmu_pro": 47.3,
          "livecodebench": 33.2
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.25,
        "coding_score": 7.3,
        "gdpval": 726.4153195934122,
        "terminalbench_hard": 0.023,
        "tau2": 0.292,
        "lcr": 15.3,
        "hle": 2.9,
        "gpqa": 42.7,
        "scicode": 17.4,
        "ifbench": 32.3,
        "aime25": 27.3,
        "critpt": 0.0,
        "mmmu_pro": 47.3,
        "livecodebench": 33.2
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-omni-30b-a3b-instruct",
    "canonical_name": "Qwen3 Omni 30B A3B Instruct",
    "model_name": "Qwen3 Omni 30B A3B Instruct",
    "aliases": [
      "Qwen3 Omni 30B A3B Instruct"
    ],
    "provider": "Alibaba",
    "context_window": 65536,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 10.68,
    "coding_score": 7.22,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 356.6,
    "terminalbench_hard": 0.015,
    "tau2": 0.164,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.1,
    "gpqa": 62.0,
    "scicode": 18.6,
    "ifbench": 31.2,
    "aime25": 52.3,
    "critpt": 0.0,
    "mmmu_pro": 55.5,
    "livecodebench": 42.2,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.266462+00:00",
        "confidence": 0.79,
        "raw_name": "Qwen3 Omni 30B A3B Instruct",
        "raw_scores": {
          "intelligence_score": 10.68,
          "coding_score": 7.22,
          "context_window": 65536,
          "gdpval": 356.59996607862456,
          "terminalbench_hard": 0.015,
          "tau2": 0.164,
          "lcr": 0.0,
          "hle": 5.1,
          "gpqa": 62.0,
          "scicode": 18.6,
          "ifbench": 31.2,
          "aime25": 52.3,
          "critpt": 0.0,
          "mmmu_pro": 55.5,
          "livecodebench": 42.2
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.68,
        "coding_score": 7.22,
        "gdpval": 356.59996607862456,
        "terminalbench_hard": 0.015,
        "tau2": 0.164,
        "lcr": 0.0,
        "hle": 5.1,
        "gpqa": 62.0,
        "scicode": 18.6,
        "ifbench": 31.2,
        "aime25": 52.3,
        "critpt": 0.0,
        "mmmu_pro": 55.5,
        "livecodebench": 42.2
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-coder-480b-a35b-instruct",
    "canonical_name": "Qwen3 Coder 480B A35B Instruct",
    "model_name": "Qwen3 Coder 480B A35B Instruct",
    "aliases": [
      "Qwen3 Coder 480B A35B Instruct",
      "qwen3-coder-480b-a35b-instruct"
    ],
    "provider": "Alibaba",
    "context_window": 262144,
    "open_source": true,
    "arena_votes": 26409,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 24.65,
    "coding_score": 24.59,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1386.58,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 557.1192,
    "terminalbench_hard": 0.189,
    "tau2": 0.436,
    "lcr": 42.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.4,
    "gpqa": 61.8,
    "scicode": 35.9,
    "ifbench": 40.5,
    "aime25": 39.3,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 58.5,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.266500+00:00",
        "confidence": 0.79,
        "raw_name": "Qwen3 Coder 480B A35B Instruct",
        "raw_scores": {
          "intelligence_score": 24.65,
          "coding_score": 24.59,
          "context_window": 262144,
          "gdpval": 557.1192081392261,
          "terminalbench_hard": 0.189,
          "tau2": 0.436,
          "lcr": 42.3,
          "hle": 4.4,
          "gpqa": 61.8,
          "scicode": 35.9,
          "ifbench": 40.5,
          "aime25": 39.3,
          "critpt": 0.0,
          "livecodebench": 58.5
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125768+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-coder-480b-a35b-instruct",
        "raw_scores": {
          "arena_elo": 1386.58,
          "arena_votes": 26409
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 24.65,
        "coding_score": 24.59,
        "gdpval": 557.1192081392261,
        "terminalbench_hard": 0.189,
        "tau2": 0.436,
        "lcr": 42.3,
        "hle": 4.4,
        "gpqa": 61.8,
        "scicode": 35.9,
        "ifbench": 40.5,
        "aime25": 39.3,
        "critpt": 0.0,
        "livecodebench": 58.5
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1386.58
      }
    },
    "confidence_score": 0.895,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-235b-a22b-2507-instruct",
    "canonical_name": "Qwen3 235B A22B 2507 Instruct",
    "model_name": "Qwen3 235B A22B 2507 Instruct",
    "aliases": [
      "Qwen3 235B A22B 2507 Instruct"
    ],
    "provider": "Alibaba",
    "context_window": 256000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 24.66,
    "coding_score": 22.1,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 817.4699,
    "terminalbench_hard": 0.152,
    "tau2": 0.333,
    "lcr": 31.2,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 10.6,
    "gpqa": 75.3,
    "scicode": 36.0,
    "ifbench": 46.1,
    "aime25": 71.7,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 52.4,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.266539+00:00",
        "confidence": 0.79,
        "raw_name": "Qwen3 235B A22B 2507 Instruct",
        "raw_scores": {
          "intelligence_score": 24.66,
          "coding_score": 22.1,
          "context_window": 256000,
          "gdpval": 817.4699477215904,
          "terminalbench_hard": 0.152,
          "tau2": 0.333,
          "lcr": 31.2,
          "hle": 10.6,
          "gpqa": 75.3,
          "scicode": 36.0,
          "ifbench": 46.1,
          "aime25": 71.7,
          "critpt": 0.0,
          "livecodebench": 52.4
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 24.66,
        "coding_score": 22.1,
        "gdpval": 817.4699477215904,
        "terminalbench_hard": 0.152,
        "tau2": 0.333,
        "lcr": 31.2,
        "hle": 10.6,
        "gpqa": 75.3,
        "scicode": 36.0,
        "ifbench": 46.1,
        "aime25": 71.7,
        "critpt": 0.0,
        "livecodebench": 52.4
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-06b",
    "canonical_name": "Qwen3 0.6B (Non-reasoning)",
    "model_name": "Qwen3 0.6B (Non-reasoning)",
    "aliases": [
      "Qwen3 0.6B (Non-reasoning)",
      "Qwen3 0.6B (Reasoning)"
    ],
    "provider": "Alibaba",
    "context_window": 32000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 6.01,
    "coding_score": 1.14,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 359.7635,
    "terminalbench_hard": 0.0,
    "tau2": 0.1785,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.45,
    "gpqa": 23.5,
    "scicode": 3.45,
    "ifbench": 22.6,
    "aime25": 14.15,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 9.7,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.266579+00:00",
        "confidence": 0.79,
        "raw_name": "Qwen3 0.6B (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 5.59,
          "coding_score": 1.35,
          "context_window": 32000,
          "gdpval": 338.362713127246,
          "terminalbench_hard": 0.0,
          "tau2": 0.146,
          "lcr": 0.0,
          "hle": 5.2,
          "gpqa": 23.1,
          "scicode": 4.1,
          "ifbench": 21.9,
          "aime25": 10.3,
          "critpt": 0.0,
          "livecodebench": 7.3
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.266824+00:00",
        "confidence": 0.79,
        "raw_name": "Qwen3 0.6B (Reasoning)",
        "raw_scores": {
          "intelligence_score": 6.43,
          "coding_score": 0.93,
          "context_window": 32000,
          "gdpval": 381.16424952360467,
          "terminalbench_hard": 0.0,
          "tau2": 0.211,
          "lcr": 0.0,
          "hle": 5.7,
          "gpqa": 23.9,
          "scicode": 2.8,
          "ifbench": 23.3,
          "aime25": 18.0,
          "critpt": 0.0,
          "livecodebench": 12.1
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 5.59,
        "coding_score": 1.35,
        "gdpval": 338.362713127246,
        "terminalbench_hard": 0.0,
        "tau2": 0.146,
        "lcr": 0.0,
        "hle": 5.2,
        "gpqa": 23.1,
        "scicode": 4.1,
        "ifbench": 21.9,
        "aime25": 10.3,
        "critpt": 0.0,
        "livecodebench": 7.3
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-next-80b",
    "canonical_name": "Qwen3 Next 80B A3B Instruct",
    "model_name": "Qwen3 Next 80B A3B Instruct",
    "aliases": [
      "Qwen3 Next 80B A3B Instruct",
      "qwen3-next-80b-a3b-instruct"
    ],
    "provider": "Alibaba",
    "context_window": 262144,
    "open_source": true,
    "arena_votes": 22675,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 20.08,
    "coding_score": 15.27,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1401.62,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 667.7147,
    "terminalbench_hard": 0.076,
    "tau2": 0.216,
    "lcr": 51.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 7.3,
    "gpqa": 73.8,
    "scicode": 30.7,
    "ifbench": 39.7,
    "aime25": 66.3,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 68.4,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.266651+00:00",
        "confidence": 0.79,
        "raw_name": "Qwen3 Next 80B A3B Instruct",
        "raw_scores": {
          "intelligence_score": 20.08,
          "coding_score": 15.27,
          "context_window": 262144,
          "gdpval": 667.7146901785043,
          "terminalbench_hard": 0.076,
          "tau2": 0.216,
          "lcr": 51.3,
          "hle": 7.3,
          "gpqa": 73.8,
          "scicode": 30.7,
          "ifbench": 39.7,
          "aime25": 66.3,
          "critpt": 0.0,
          "livecodebench": 68.4
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125486+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-next-80b-a3b-instruct",
        "raw_scores": {
          "arena_elo": 1401.62,
          "arena_votes": 22675
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 20.08,
        "coding_score": 15.27,
        "gdpval": 667.7146901785043,
        "terminalbench_hard": 0.076,
        "tau2": 0.216,
        "lcr": 51.3,
        "hle": 7.3,
        "gpqa": 73.8,
        "scicode": 30.7,
        "ifbench": 39.7,
        "aime25": 66.3,
        "critpt": 0.0,
        "livecodebench": 68.4
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1401.62
      }
    },
    "confidence_score": 0.895,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-17b",
    "canonical_name": "Qwen3 1.7B (Non-reasoning)",
    "model_name": "Qwen3 1.7B (Non-reasoning)",
    "aliases": [
      "Qwen3 1.7B (Non-reasoning)",
      "Qwen3 1.7B (Reasoning)"
    ],
    "provider": "Alibaba",
    "context_window": 32000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 7.33,
    "coding_score": 1.87,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 325.3027,
    "terminalbench_hard": 0.0,
    "tau2": 0.238,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.0,
    "gpqa": 31.95,
    "scicode": 5.6,
    "ifbench": 24.0,
    "aime25": 23.0,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 21.7,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.266689+00:00",
        "confidence": 0.79,
        "raw_name": "Qwen3 1.7B (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 6.78,
          "coding_score": 2.31,
          "context_window": 32000,
          "gdpval": 315.5462918955766,
          "terminalbench_hard": 0.0,
          "tau2": 0.216,
          "lcr": 0.0,
          "hle": 5.2,
          "gpqa": 28.3,
          "scicode": 6.9,
          "ifbench": 21.1,
          "aime25": 7.3,
          "critpt": 0.0,
          "livecodebench": 12.6
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.266786+00:00",
        "confidence": 0.79,
        "raw_name": "Qwen3 1.7B (Reasoning)",
        "raw_scores": {
          "intelligence_score": 7.88,
          "coding_score": 1.43,
          "context_window": 32000,
          "gdpval": 335.0590797951072,
          "terminalbench_hard": 0.0,
          "tau2": 0.26,
          "lcr": 0.0,
          "hle": 4.8,
          "gpqa": 35.6,
          "scicode": 4.3,
          "ifbench": 26.9,
          "aime25": 38.7,
          "critpt": 0.0,
          "livecodebench": 30.8
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 6.78,
        "coding_score": 2.31,
        "gdpval": 315.5462918955766,
        "terminalbench_hard": 0.0,
        "tau2": 0.216,
        "lcr": 0.0,
        "hle": 5.2,
        "gpqa": 28.3,
        "scicode": 6.9,
        "ifbench": 21.1,
        "aime25": 7.3,
        "critpt": 0.0,
        "livecodebench": 12.6
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-4b-2507-instruct",
    "canonical_name": "Qwen3 4B 2507 Instruct",
    "model_name": "Qwen3 4B 2507 Instruct",
    "aliases": [
      "Qwen3 4B 2507 Instruct"
    ],
    "provider": "Alibaba",
    "context_window": 262144,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 13.19,
    "coding_score": 9.05,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 368.0325,
    "terminalbench_hard": 0.045,
    "tau2": 0.266,
    "lcr": 7.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.7,
    "gpqa": 51.7,
    "scicode": 18.1,
    "ifbench": 33.5,
    "aime25": 52.3,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 37.7,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.266727+00:00",
        "confidence": 0.79,
        "raw_name": "Qwen3 4B 2507 Instruct",
        "raw_scores": {
          "intelligence_score": 13.19,
          "coding_score": 9.05,
          "context_window": 262144,
          "gdpval": 368.0324515211296,
          "terminalbench_hard": 0.045,
          "tau2": 0.266,
          "lcr": 7.3,
          "hle": 4.7,
          "gpqa": 51.7,
          "scicode": 18.1,
          "ifbench": 33.5,
          "aime25": 52.3,
          "critpt": 0.0,
          "livecodebench": 37.7
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.19,
        "coding_score": 9.05,
        "gdpval": 368.0324515211296,
        "terminalbench_hard": 0.045,
        "tau2": 0.266,
        "lcr": 7.3,
        "hle": 4.7,
        "gpqa": 51.7,
        "scicode": 18.1,
        "ifbench": 33.5,
        "aime25": 52.3,
        "critpt": 0.0,
        "livecodebench": 37.7
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen-chat-14b",
    "canonical_name": "Qwen Chat 14B",
    "model_name": "Qwen Chat 14B",
    "aliases": [
      "Qwen Chat 14B"
    ],
    "provider": "Alibaba",
    "context_window": 8192,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 7.4139,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.266748+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen Chat 14B",
        "raw_scores": {
          "intelligence_score": 7.413887665229345,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 8192
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 7.413887665229345
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-235b-a22b-2507",
    "canonical_name": "Qwen3 235B A22B 2507 (Reasoning)",
    "model_name": "Qwen3 235B A22B 2507 (Reasoning)",
    "aliases": [
      "Qwen3 235B A22B 2507 (Reasoning)"
    ],
    "provider": "Alibaba",
    "context_window": 256000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 29.46,
    "coding_score": 23.21,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 847.1243,
    "terminalbench_hard": 0.136,
    "tau2": 0.532,
    "lcr": 67.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 15.0,
    "gpqa": 79.0,
    "scicode": 42.4,
    "ifbench": 51.2,
    "aime25": 91.0,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 78.8,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.266862+00:00",
        "confidence": 0.79,
        "raw_name": "Qwen3 235B A22B 2507 (Reasoning)",
        "raw_scores": {
          "intelligence_score": 29.46,
          "coding_score": 23.21,
          "context_window": 256000,
          "gdpval": 847.124333048346,
          "terminalbench_hard": 0.136,
          "tau2": 0.532,
          "lcr": 67.0,
          "hle": 15.0,
          "gpqa": 79.0,
          "scicode": 42.4,
          "ifbench": 51.2,
          "aime25": 91.0,
          "critpt": 0.0,
          "livecodebench": 78.8
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 29.46,
        "coding_score": 23.21,
        "gdpval": 847.124333048346,
        "terminalbench_hard": 0.136,
        "tau2": 0.532,
        "lcr": 67.0,
        "hle": 15.0,
        "gpqa": 79.0,
        "scicode": 42.4,
        "ifbench": 51.2,
        "aime25": 91.0,
        "critpt": 0.0,
        "livecodebench": 78.8
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-vl-4b-instruct",
    "canonical_name": "Qwen3 VL 4B Instruct",
    "model_name": "Qwen3 VL 4B Instruct",
    "aliases": [
      "Qwen3 VL 4B Instruct"
    ],
    "provider": "Alibaba",
    "context_window": 256000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 9.5,
    "coding_score": 4.55,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 408.4439,
    "terminalbench_hard": 0.0,
    "tau2": 0.234,
    "lcr": 13.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 3.7,
    "gpqa": 37.1,
    "scicode": 13.7,
    "ifbench": 31.8,
    "aime25": 37.0,
    "critpt": 0.0,
    "mmmu_pro": 43.9,
    "livecodebench": 29.0,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.266902+00:00",
        "confidence": 0.79,
        "raw_name": "Qwen3 VL 4B Instruct",
        "raw_scores": {
          "intelligence_score": 9.5,
          "coding_score": 4.55,
          "context_window": 256000,
          "gdpval": 408.44385248753065,
          "terminalbench_hard": 0.0,
          "tau2": 0.234,
          "lcr": 13.0,
          "hle": 3.7,
          "gpqa": 37.1,
          "scicode": 13.7,
          "ifbench": 31.8,
          "aime25": 37.0,
          "critpt": 0.0,
          "mmmu_pro": 43.9,
          "livecodebench": 29.0
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.5,
        "coding_score": 4.55,
        "gdpval": 408.44385248753065,
        "terminalbench_hard": 0.0,
        "tau2": 0.234,
        "lcr": 13.0,
        "hle": 3.7,
        "gpqa": 37.1,
        "scicode": 13.7,
        "ifbench": 31.8,
        "aime25": 37.0,
        "critpt": 0.0,
        "mmmu_pro": 43.9,
        "livecodebench": 29.0
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-vl-4b",
    "canonical_name": "Qwen3 VL 4B (Reasoning)",
    "model_name": "Qwen3 VL 4B (Reasoning)",
    "aliases": [
      "Qwen3 VL 4B (Reasoning)"
    ],
    "provider": "Alibaba",
    "context_window": 256000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 13.74,
    "coding_score": 6.72,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 775.5468,
    "terminalbench_hard": 0.015,
    "tau2": 0.155,
    "lcr": 21.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.4,
    "gpqa": 49.4,
    "scicode": 17.1,
    "ifbench": 36.6,
    "aime25": 25.7,
    "critpt": 0.0,
    "mmmu_pro": 52.0,
    "livecodebench": 32.0,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.266946+00:00",
        "confidence": 0.79,
        "raw_name": "Qwen3 VL 4B (Reasoning)",
        "raw_scores": {
          "intelligence_score": 13.74,
          "coding_score": 6.72,
          "context_window": 256000,
          "gdpval": 775.5467734090345,
          "terminalbench_hard": 0.015,
          "tau2": 0.155,
          "lcr": 21.3,
          "hle": 4.4,
          "gpqa": 49.4,
          "scicode": 17.1,
          "ifbench": 36.6,
          "aime25": 25.7,
          "critpt": 0.0,
          "mmmu_pro": 52.0,
          "livecodebench": 32.0
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.74,
        "coding_score": 6.72,
        "gdpval": 775.5467734090345,
        "terminalbench_hard": 0.015,
        "tau2": 0.155,
        "lcr": 21.3,
        "hle": 4.4,
        "gpqa": 49.4,
        "scicode": 17.1,
        "ifbench": 36.6,
        "aime25": 25.7,
        "critpt": 0.0,
        "mmmu_pro": 52.0,
        "livecodebench": 32.0
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-coder-30b-a3b-instruct",
    "canonical_name": "Qwen3 Coder 30B A3B Instruct",
    "model_name": "Qwen3 Coder 30B A3B Instruct",
    "aliases": [
      "Qwen3 Coder 30B A3B Instruct"
    ],
    "provider": "Alibaba",
    "context_window": 262144,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 19.96,
    "coding_score": 19.36,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 763.7987,
    "terminalbench_hard": 0.152,
    "tau2": 0.345,
    "lcr": 29.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.0,
    "gpqa": 51.6,
    "scicode": 27.8,
    "ifbench": 32.7,
    "aime25": 29.0,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 40.3,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.266985+00:00",
        "confidence": 0.79,
        "raw_name": "Qwen3 Coder 30B A3B Instruct",
        "raw_scores": {
          "intelligence_score": 19.96,
          "coding_score": 19.36,
          "context_window": 262144,
          "gdpval": 763.798696968407,
          "terminalbench_hard": 0.152,
          "tau2": 0.345,
          "lcr": 29.0,
          "hle": 4.0,
          "gpqa": 51.6,
          "scicode": 27.8,
          "ifbench": 32.7,
          "aime25": 29.0,
          "critpt": 0.0,
          "livecodebench": 40.3
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.96,
        "coding_score": 19.36,
        "gdpval": 763.798696968407,
        "terminalbench_hard": 0.152,
        "tau2": 0.345,
        "lcr": 29.0,
        "hle": 4.0,
        "gpqa": 51.6,
        "scicode": 27.8,
        "ifbench": 32.7,
        "aime25": 29.0,
        "critpt": 0.0,
        "livecodebench": 40.3
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-vl-30b-a3b-instruct",
    "canonical_name": "Qwen3 VL 30B A3B Instruct",
    "model_name": "Qwen3 VL 30B A3B Instruct",
    "aliases": [
      "Qwen3 VL 30B A3B Instruct"
    ],
    "provider": "Alibaba",
    "context_window": 256000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 16.03,
    "coding_score": 14.3,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 545.9921,
    "terminalbench_hard": 0.061,
    "tau2": 0.19,
    "lcr": 23.7,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 6.4,
    "gpqa": 69.5,
    "scicode": 30.8,
    "ifbench": 33.1,
    "aime25": 72.3,
    "critpt": 0.0,
    "mmmu_pro": 62.1,
    "livecodebench": 47.6,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.267026+00:00",
        "confidence": 0.79,
        "raw_name": "Qwen3 VL 30B A3B Instruct",
        "raw_scores": {
          "intelligence_score": 16.03,
          "coding_score": 14.3,
          "context_window": 256000,
          "gdpval": 545.992099326872,
          "terminalbench_hard": 0.061,
          "tau2": 0.19,
          "lcr": 23.7,
          "hle": 6.4,
          "gpqa": 69.5,
          "scicode": 30.8,
          "ifbench": 33.1,
          "aime25": 72.3,
          "critpt": 0.0,
          "mmmu_pro": 62.1,
          "livecodebench": 47.6
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 16.03,
        "coding_score": 14.3,
        "gdpval": 545.992099326872,
        "terminalbench_hard": 0.061,
        "tau2": 0.19,
        "lcr": 23.7,
        "hle": 6.4,
        "gpqa": 69.5,
        "scicode": 30.8,
        "ifbench": 33.1,
        "aime25": 72.3,
        "critpt": 0.0,
        "mmmu_pro": 62.1,
        "livecodebench": 47.6
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-vl-8b",
    "canonical_name": "Qwen3 VL 8B (Reasoning)",
    "model_name": "Qwen3 VL 8B (Reasoning)",
    "aliases": [
      "Qwen3 VL 8B (Reasoning)"
    ],
    "provider": "Alibaba",
    "context_window": 256000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 16.61,
    "coding_score": 9.82,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 710.543,
    "terminalbench_hard": 0.038,
    "tau2": 0.225,
    "lcr": 31.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 3.3,
    "gpqa": 57.9,
    "scicode": 21.9,
    "ifbench": 39.9,
    "aime25": 30.7,
    "critpt": 0.3,
    "mmmu_pro": 56.6,
    "livecodebench": 35.3,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.267067+00:00",
        "confidence": 0.79,
        "raw_name": "Qwen3 VL 8B (Reasoning)",
        "raw_scores": {
          "intelligence_score": 16.61,
          "coding_score": 9.82,
          "context_window": 256000,
          "gdpval": 710.5430367278635,
          "terminalbench_hard": 0.038,
          "tau2": 0.225,
          "lcr": 31.0,
          "hle": 3.3,
          "gpqa": 57.9,
          "scicode": 21.9,
          "ifbench": 39.9,
          "aime25": 30.7,
          "critpt": 0.3,
          "mmmu_pro": 56.6,
          "livecodebench": 35.3
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 16.61,
        "coding_score": 9.82,
        "gdpval": 710.5430367278635,
        "terminalbench_hard": 0.038,
        "tau2": 0.225,
        "lcr": 31.0,
        "hle": 3.3,
        "gpqa": 57.9,
        "scicode": 21.9,
        "ifbench": 39.9,
        "aime25": 30.7,
        "critpt": 0.3,
        "mmmu_pro": 56.6,
        "livecodebench": 35.3
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-vl-235b",
    "canonical_name": "Qwen3 VL 235B A22B Instruct",
    "model_name": "Qwen3 VL 235B A22B Instruct",
    "aliases": [
      "Qwen3 VL 235B A22B Instruct",
      "qwen3-vl-235b-a22b-instruct",
      "qwen3-vl-235b-a22b-thinking"
    ],
    "provider": "Alibaba",
    "context_window": 262144,
    "open_source": true,
    "arena_votes": 11597,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 20.58,
    "coding_score": 16.51,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1404.85,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 683.8546,
    "terminalbench_hard": 0.068,
    "tau2": 0.351,
    "lcr": 31.7,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 6.3,
    "gpqa": 71.2,
    "scicode": 35.9,
    "ifbench": 42.7,
    "aime25": 70.7,
    "critpt": 0.0,
    "mmmu_pro": 67.6,
    "livecodebench": 59.4,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.267108+00:00",
        "confidence": 0.79,
        "raw_name": "Qwen3 VL 235B A22B Instruct",
        "raw_scores": {
          "intelligence_score": 20.58,
          "coding_score": 16.51,
          "context_window": 262144,
          "gdpval": 683.8545646594081,
          "terminalbench_hard": 0.068,
          "tau2": 0.351,
          "lcr": 31.7,
          "hle": 6.3,
          "gpqa": 71.2,
          "scicode": 35.9,
          "ifbench": 42.7,
          "aime25": 70.7,
          "critpt": 0.0,
          "mmmu_pro": 67.6,
          "livecodebench": 59.4
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125297+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-vl-235b-a22b-instruct",
        "raw_scores": {
          "arena_elo": 1414.77,
          "arena_votes": 11597
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125565+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-vl-235b-a22b-thinking",
        "raw_scores": {
          "arena_elo": 1394.93,
          "arena_votes": 7926
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 20.58,
        "coding_score": 16.51,
        "gdpval": 683.8545646594081,
        "terminalbench_hard": 0.068,
        "tau2": 0.351,
        "lcr": 31.7,
        "hle": 6.3,
        "gpqa": 71.2,
        "scicode": 35.9,
        "ifbench": 42.7,
        "aime25": 70.7,
        "critpt": 0.0,
        "mmmu_pro": 67.6,
        "livecodebench": 59.4
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1414.77
      }
    },
    "confidence_score": 0.93,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-vl-32b",
    "canonical_name": "Qwen3 VL 32B (Reasoning)",
    "model_name": "Qwen3 VL 32B (Reasoning)",
    "aliases": [
      "Qwen3 VL 32B (Reasoning)"
    ],
    "provider": "Alibaba",
    "context_window": 256000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 24.52,
    "coding_score": 14.54,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 711.4649,
    "terminalbench_hard": 0.076,
    "tau2": 0.456,
    "lcr": 55.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 9.6,
    "gpqa": 73.3,
    "scicode": 28.5,
    "ifbench": 59.4,
    "aime25": 84.7,
    "critpt": 0.0,
    "mmmu_pro": 63.4,
    "livecodebench": 73.8,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.267148+00:00",
        "confidence": 0.79,
        "raw_name": "Qwen3 VL 32B (Reasoning)",
        "raw_scores": {
          "intelligence_score": 24.52,
          "coding_score": 14.54,
          "context_window": 256000,
          "gdpval": 711.4649272688403,
          "terminalbench_hard": 0.076,
          "tau2": 0.456,
          "lcr": 55.3,
          "hle": 9.6,
          "gpqa": 73.3,
          "scicode": 28.5,
          "ifbench": 59.4,
          "aime25": 84.7,
          "critpt": 0.0,
          "mmmu_pro": 63.4,
          "livecodebench": 73.8
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 24.52,
        "coding_score": 14.54,
        "gdpval": 711.4649272688403,
        "terminalbench_hard": 0.076,
        "tau2": 0.456,
        "lcr": 55.3,
        "hle": 9.6,
        "gpqa": 73.3,
        "scicode": 28.5,
        "ifbench": 59.4,
        "aime25": 84.7,
        "critpt": 0.0,
        "mmmu_pro": 63.4,
        "livecodebench": 73.8
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-vl-30b-a3b",
    "canonical_name": "Qwen3 VL 30B A3B (Reasoning)",
    "model_name": "Qwen3 VL 30B A3B (Reasoning)",
    "aliases": [
      "Qwen3 VL 30B A3B (Reasoning)"
    ],
    "provider": "Alibaba",
    "context_window": 256000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 19.62,
    "coding_score": 13.14,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 713.0958,
    "terminalbench_hard": 0.053,
    "tau2": 0.199,
    "lcr": 40.7,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 8.7,
    "gpqa": 72.0,
    "scicode": 28.8,
    "ifbench": 45.1,
    "aime25": 82.3,
    "critpt": 0.0,
    "mmmu_pro": 61.8,
    "livecodebench": 69.7,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.267188+00:00",
        "confidence": 0.79,
        "raw_name": "Qwen3 VL 30B A3B (Reasoning)",
        "raw_scores": {
          "intelligence_score": 19.62,
          "coding_score": 13.14,
          "context_window": 256000,
          "gdpval": 713.095765474852,
          "terminalbench_hard": 0.053,
          "tau2": 0.199,
          "lcr": 40.7,
          "hle": 8.7,
          "gpqa": 72.0,
          "scicode": 28.8,
          "ifbench": 45.1,
          "aime25": 82.3,
          "critpt": 0.0,
          "mmmu_pro": 61.8,
          "livecodebench": 69.7
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.62,
        "coding_score": 13.14,
        "gdpval": 713.095765474852,
        "terminalbench_hard": 0.053,
        "tau2": 0.199,
        "lcr": 40.7,
        "hle": 8.7,
        "gpqa": 72.0,
        "scicode": 28.8,
        "ifbench": 45.1,
        "aime25": 82.3,
        "critpt": 0.0,
        "mmmu_pro": 61.8,
        "livecodebench": 69.7
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-max",
    "canonical_name": "Qwen3 Max Thinking (Preview)",
    "model_name": "Qwen3 Max Thinking (Preview)",
    "aliases": [
      "Qwen3 Max",
      "Qwen3 Max (Preview)",
      "Qwen3 Max Thinking",
      "Qwen3 Max Thinking (Preview)",
      "qwen3-max-2025-09-23",
      "qwen3-max-preview"
    ],
    "provider": "Alibaba",
    "context_window": 262144,
    "open_source": null,
    "arena_votes": 27649,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 32.0741,
    "coding_score": 26.5877,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1429.45,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 2.4,
    "latency_seconds": 1.9139,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 43.2902,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 996.7889,
    "terminalbench_hard": 0.2031,
    "tau2": 0.68,
    "lcr": 52.0363,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 14.2311,
    "gpqa": 78.872,
    "scicode": 39.1363,
    "ifbench": 53.5497,
    "aime25": 79.3333,
    "critpt": 0.6119,
    "mmmu_pro": null,
    "livecodebench": 65.1,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.267232+00:00",
        "confidence": 1.0,
        "raw_name": "Qwen3 Max Thinking (Preview)",
        "raw_scores": {
          "intelligence_score": 32.45,
          "coding_score": 24.5,
          "blended_cost_per_1m": 2.4,
          "latency_seconds": 1.68,
          "tokens_per_second": 60.0,
          "context_window": 262144,
          "gdpval": 950.4125594950174,
          "terminalbench_hard": 0.174,
          "tau2": 0.836,
          "lcr": 57.7,
          "hle": 12.0,
          "gpqa": 77.6,
          "scicode": 38.7,
          "ifbench": 53.8,
          "aime25": 82.3,
          "critpt": 0.0,
          "livecodebench": 53.5
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.267555+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "Qwen3 Max Thinking",
        "raw_scores": {
          "intelligence_score": 39.67,
          "coding_score": 30.51,
          "blended_cost_per_1m": 2.4,
          "latency_seconds": 1.73,
          "tokens_per_second": 35.0,
          "context_window": 256000,
          "gdpval": 1153.530782181253,
          "terminalbench_hard": 0.242,
          "tau2": 0.836,
          "lcr": 66.0,
          "hle": 26.2,
          "gpqa": 86.1,
          "scicode": 43.1,
          "ifbench": 70.7,
          "critpt": 1.7
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.267601+00:00",
        "confidence": 1.0,
        "raw_name": "Qwen3 Max",
        "raw_scores": {
          "intelligence_score": 31.33,
          "coding_score": 26.41,
          "blended_cost_per_1m": 2.4,
          "latency_seconds": 2.48,
          "tokens_per_second": 27.0,
          "context_window": 262144,
          "gdpval": 1054.9907679344792,
          "terminalbench_hard": 0.205,
          "tau2": 0.743,
          "lcr": 46.7,
          "hle": 11.1,
          "gpqa": 76.4,
          "scicode": 38.3,
          "ifbench": 44.1,
          "aime25": 80.7,
          "critpt": 0.0,
          "livecodebench": 76.7
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.275000+00:00",
        "confidence": 1.0,
        "raw_name": "Qwen3 Max (Preview)",
        "raw_scores": {
          "intelligence_score": 25.91,
          "coding_score": 25.48,
          "blended_cost_per_1m": 2.4,
          "latency_seconds": 1.74,
          "tokens_per_second": 50.0,
          "context_window": 262144,
          "gdpval": 850.1654179108552,
          "terminalbench_hard": 0.197,
          "tau2": 0.327,
          "lcr": 39.7,
          "hle": 9.3,
          "gpqa": 76.4,
          "scicode": 37.0,
          "ifbench": 48.0,
          "aime25": 75.0,
          "critpt": 0.9,
          "livecodebench": 65.1
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.124969+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-max-preview",
        "raw_scores": {
          "arena_elo": 1434.21,
          "arena_votes": 27649
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125071+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-max-2025-09-23",
        "raw_scores": {
          "arena_elo": 1424.69,
          "arena_votes": 9169
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 32.45,
        "coding_score": 24.5,
        "gdpval": 950.4125594950174,
        "terminalbench_hard": 0.174,
        "tau2": 0.836,
        "lcr": 57.7,
        "hle": 12.0,
        "gpqa": 77.6,
        "scicode": 38.7,
        "ifbench": 53.8,
        "aime25": 82.3,
        "critpt": 0.0,
        "livecodebench": 53.5
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1434.21
      }
    },
    "confidence_score": 0.9767,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-4b-2507",
    "canonical_name": "Qwen3 4B 2507 (Reasoning)",
    "model_name": "Qwen3 4B 2507 (Reasoning)",
    "aliases": [
      "Qwen3 4B 2507 (Reasoning)"
    ],
    "provider": "Alibaba",
    "context_window": 262144,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 18.6,
    "coding_score": 9.54,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 641.5224,
    "terminalbench_hard": 0.015,
    "tau2": 0.254,
    "lcr": 37.7,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.9,
    "gpqa": 66.7,
    "scicode": 25.6,
    "ifbench": 49.8,
    "aime25": 82.7,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 64.1,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.267283+00:00",
        "confidence": 0.79,
        "raw_name": "Qwen3 4B 2507 (Reasoning)",
        "raw_scores": {
          "intelligence_score": 18.6,
          "coding_score": 9.54,
          "context_window": 262144,
          "gdpval": 641.522437798496,
          "terminalbench_hard": 0.015,
          "tau2": 0.254,
          "lcr": 37.7,
          "hle": 5.9,
          "gpqa": 66.7,
          "scicode": 25.6,
          "ifbench": 49.8,
          "aime25": 82.7,
          "critpt": 0.0,
          "livecodebench": 64.1
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 18.6,
        "coding_score": 9.54,
        "gdpval": 641.522437798496,
        "terminalbench_hard": 0.015,
        "tau2": 0.254,
        "lcr": 37.7,
        "hle": 5.9,
        "gpqa": 66.7,
        "scicode": 25.6,
        "ifbench": 49.8,
        "aime25": 82.7,
        "critpt": 0.0,
        "livecodebench": 64.1
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-omni-30b-a3b",
    "canonical_name": "Qwen3 Omni 30B A3B (Reasoning)",
    "model_name": "Qwen3 Omni 30B A3B (Reasoning)",
    "aliases": [
      "Qwen3 Omni 30B A3B (Reasoning)"
    ],
    "provider": "Alibaba",
    "context_window": 65536,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 15.6,
    "coding_score": 12.71,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 554.3753,
    "terminalbench_hard": 0.038,
    "tau2": 0.213,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 7.3,
    "gpqa": 72.6,
    "scicode": 30.6,
    "ifbench": 43.4,
    "aime25": 74.0,
    "critpt": 0.0,
    "mmmu_pro": 60.2,
    "livecodebench": 67.9,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.267324+00:00",
        "confidence": 0.79,
        "raw_name": "Qwen3 Omni 30B A3B (Reasoning)",
        "raw_scores": {
          "intelligence_score": 15.6,
          "coding_score": 12.71,
          "context_window": 65536,
          "gdpval": 554.3753100116267,
          "terminalbench_hard": 0.038,
          "tau2": 0.213,
          "lcr": 0.0,
          "hle": 7.3,
          "gpqa": 72.6,
          "scicode": 30.6,
          "ifbench": 43.4,
          "aime25": 74.0,
          "critpt": 0.0,
          "mmmu_pro": 60.2,
          "livecodebench": 67.9
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.6,
        "coding_score": 12.71,
        "gdpval": 554.3753100116267,
        "terminalbench_hard": 0.038,
        "tau2": 0.213,
        "lcr": 0.0,
        "hle": 7.3,
        "gpqa": 72.6,
        "scicode": 30.6,
        "ifbench": 43.4,
        "aime25": 74.0,
        "critpt": 0.0,
        "mmmu_pro": 60.2,
        "livecodebench": 67.9
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-vl-235b-a22b",
    "canonical_name": "Qwen3 VL 235B A22B (Reasoning)",
    "model_name": "Qwen3 VL 235B A22B (Reasoning)",
    "aliases": [
      "Qwen3 VL 235B A22B (Reasoning)"
    ],
    "provider": "Alibaba",
    "context_window": 262144,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 27.51,
    "coding_score": 20.89,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 753.2944,
    "terminalbench_hard": 0.114,
    "tau2": 0.541,
    "lcr": 58.7,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 10.1,
    "gpqa": 77.2,
    "scicode": 39.9,
    "ifbench": 56.5,
    "aime25": 88.3,
    "critpt": 0.0,
    "mmmu_pro": 68.7,
    "livecodebench": 64.6,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.267365+00:00",
        "confidence": 0.79,
        "raw_name": "Qwen3 VL 235B A22B (Reasoning)",
        "raw_scores": {
          "intelligence_score": 27.51,
          "coding_score": 20.89,
          "context_window": 262144,
          "gdpval": 753.2943937896553,
          "terminalbench_hard": 0.114,
          "tau2": 0.541,
          "lcr": 58.7,
          "hle": 10.1,
          "gpqa": 77.2,
          "scicode": 39.9,
          "ifbench": 56.5,
          "aime25": 88.3,
          "critpt": 0.0,
          "mmmu_pro": 68.7,
          "livecodebench": 64.6
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 27.51,
        "coding_score": 20.89,
        "gdpval": 753.2943937896553,
        "terminalbench_hard": 0.114,
        "tau2": 0.541,
        "lcr": 58.7,
        "hle": 10.1,
        "gpqa": 77.2,
        "scicode": 39.9,
        "ifbench": 56.5,
        "aime25": 88.3,
        "critpt": 0.0,
        "mmmu_pro": 68.7,
        "livecodebench": 64.6
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-30b-a3b-2507-instruct",
    "canonical_name": "Qwen3 30B A3B 2507 Instruct",
    "model_name": "Qwen3 30B A3B 2507 Instruct",
    "aliases": [
      "Qwen3 30B A3B 2507 Instruct"
    ],
    "provider": "Alibaba",
    "context_window": 262144,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 15.0,
    "coding_score": 14.19,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 564.288,
    "terminalbench_hard": 0.061,
    "tau2": 0.102,
    "lcr": 22.7,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 6.8,
    "gpqa": 65.9,
    "scicode": 30.4,
    "ifbench": 33.1,
    "aime25": 66.3,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 51.5,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.267403+00:00",
        "confidence": 0.79,
        "raw_name": "Qwen3 30B A3B 2507 Instruct",
        "raw_scores": {
          "intelligence_score": 15.0,
          "coding_score": 14.19,
          "context_window": 262144,
          "gdpval": 564.2879936625616,
          "terminalbench_hard": 0.061,
          "tau2": 0.102,
          "lcr": 22.7,
          "hle": 6.8,
          "gpqa": 65.9,
          "scicode": 30.4,
          "ifbench": 33.1,
          "aime25": 66.3,
          "critpt": 0.0,
          "livecodebench": 51.5
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.0,
        "coding_score": 14.19,
        "gdpval": 564.2879936625616,
        "terminalbench_hard": 0.061,
        "tau2": 0.102,
        "lcr": 22.7,
        "hle": 6.8,
        "gpqa": 65.9,
        "scicode": 30.4,
        "ifbench": 33.1,
        "aime25": 66.3,
        "critpt": 0.0,
        "livecodebench": 51.5
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-30b-a3b-2507",
    "canonical_name": "Qwen3 30B A3B 2507 (Reasoning)",
    "model_name": "Qwen3 30B A3B 2507 (Reasoning)",
    "aliases": [
      "Qwen3 30B A3B 2507 (Reasoning)"
    ],
    "provider": "Alibaba",
    "context_window": 262144,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 22.43,
    "coding_score": 14.65,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 719.4022,
    "terminalbench_hard": 0.053,
    "tau2": 0.281,
    "lcr": 59.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 9.8,
    "gpqa": 70.7,
    "scicode": 33.3,
    "ifbench": 50.7,
    "aime25": 56.3,
    "critpt": 0.3,
    "mmmu_pro": null,
    "livecodebench": 70.7,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.267443+00:00",
        "confidence": 0.79,
        "raw_name": "Qwen3 30B A3B 2507 (Reasoning)",
        "raw_scores": {
          "intelligence_score": 22.43,
          "coding_score": 14.65,
          "context_window": 262144,
          "gdpval": 719.4021959654211,
          "terminalbench_hard": 0.053,
          "tau2": 0.281,
          "lcr": 59.0,
          "hle": 9.8,
          "gpqa": 70.7,
          "scicode": 33.3,
          "ifbench": 50.7,
          "aime25": 56.3,
          "critpt": 0.3,
          "livecodebench": 70.7
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 22.43,
        "coding_score": 14.65,
        "gdpval": 719.4021959654211,
        "terminalbench_hard": 0.053,
        "tau2": 0.281,
        "lcr": 59.0,
        "hle": 9.8,
        "gpqa": 70.7,
        "scicode": 33.3,
        "ifbench": 50.7,
        "aime25": 56.3,
        "critpt": 0.3,
        "livecodebench": 70.7
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-vl-32b-instruct",
    "canonical_name": "Qwen3 VL 32B Instruct",
    "model_name": "Qwen3 VL 32B Instruct",
    "aliases": [
      "Qwen3 VL 32B Instruct"
    ],
    "provider": "Alibaba",
    "context_window": 256000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 17.17,
    "coding_score": 15.59,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 358.8257,
    "terminalbench_hard": 0.083,
    "tau2": 0.292,
    "lcr": 31.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 6.3,
    "gpqa": 67.1,
    "scicode": 30.1,
    "ifbench": 39.2,
    "aime25": 68.3,
    "critpt": 0.0,
    "mmmu_pro": 64.3,
    "livecodebench": 51.4,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.267483+00:00",
        "confidence": 0.79,
        "raw_name": "Qwen3 VL 32B Instruct",
        "raw_scores": {
          "intelligence_score": 17.17,
          "coding_score": 15.59,
          "context_window": 256000,
          "gdpval": 358.8257395880943,
          "terminalbench_hard": 0.083,
          "tau2": 0.292,
          "lcr": 31.3,
          "hle": 6.3,
          "gpqa": 67.1,
          "scicode": 30.1,
          "ifbench": 39.2,
          "aime25": 68.3,
          "critpt": 0.0,
          "mmmu_pro": 64.3,
          "livecodebench": 51.4
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 17.17,
        "coding_score": 15.59,
        "gdpval": 358.8257395880943,
        "terminalbench_hard": 0.083,
        "tau2": 0.292,
        "lcr": 31.3,
        "hle": 6.3,
        "gpqa": 67.1,
        "scicode": 30.1,
        "ifbench": 39.2,
        "aime25": 68.3,
        "critpt": 0.0,
        "mmmu_pro": 64.3,
        "livecodebench": 51.4
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-coder-next",
    "canonical_name": "Qwen3 Coder Next",
    "model_name": "Qwen3 Coder Next",
    "aliases": [
      "Qwen3 Coder Next"
    ],
    "provider": "Alibaba",
    "context_window": 256000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 28.13,
    "coding_score": 22.89,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.53,
    "latency_seconds": 0.77,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 115.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 949.9096,
    "terminalbench_hard": 0.182,
    "tau2": 0.795,
    "lcr": 40.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 9.3,
    "gpqa": 73.7,
    "scicode": 32.3,
    "ifbench": 35.2,
    "aime25": null,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.267518+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "Qwen3 Coder Next",
        "raw_scores": {
          "intelligence_score": 28.13,
          "coding_score": 22.89,
          "blended_cost_per_1m": 0.53,
          "latency_seconds": 0.77,
          "tokens_per_second": 115.0,
          "context_window": 256000,
          "gdpval": 949.9096165264002,
          "terminalbench_hard": 0.182,
          "tau2": 0.795,
          "lcr": 40.0,
          "hle": 9.3,
          "gpqa": 73.7,
          "scicode": 32.3,
          "ifbench": 35.2,
          "critpt": 0.0
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 28.13,
        "coding_score": 22.89,
        "gdpval": 949.9096165264002,
        "terminalbench_hard": 0.182,
        "tau2": 0.795,
        "lcr": 40.0,
        "hle": 9.3,
        "gpqa": 73.7,
        "scicode": 32.3,
        "ifbench": 35.2,
        "critpt": 0.0
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "ling-flash-20",
    "canonical_name": "Ling-flash-2.0",
    "model_name": "Ling-flash-2.0",
    "aliases": [
      "Ling-flash-2.0",
      "ling-flash-2.0"
    ],
    "provider": "Ant Group",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": 6998,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": 15.47,
    "coding_score": 16.72,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1346.81,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.25,
    "latency_seconds": 1.44,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 57.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 484.5685,
    "terminalbench_hard": 0.106,
    "tau2": 0.208,
    "lcr": 15.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 6.3,
    "gpqa": 65.7,
    "scicode": 28.9,
    "ifbench": 34.4,
    "aime25": 65.3,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 58.9,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.267646+00:00",
        "confidence": 1.0,
        "raw_name": "Ling-flash-2.0",
        "raw_scores": {
          "intelligence_score": 15.47,
          "coding_score": 16.72,
          "blended_cost_per_1m": 0.25,
          "latency_seconds": 1.44,
          "tokens_per_second": 57.0,
          "context_window": 128000,
          "gdpval": 484.5685225517941,
          "terminalbench_hard": 0.106,
          "tau2": 0.208,
          "lcr": 15.0,
          "hle": 6.3,
          "gpqa": 65.7,
          "scicode": 28.9,
          "ifbench": 34.4,
          "aime25": 65.3,
          "critpt": 0.0,
          "livecodebench": 58.9
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126398+00:00",
        "confidence": 1.0,
        "raw_name": "ling-flash-2.0",
        "raw_scores": {
          "arena_elo": 1346.81,
          "arena_votes": 6998
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.47,
        "coding_score": 16.72,
        "gdpval": 484.5685225517941,
        "terminalbench_hard": 0.106,
        "tau2": 0.208,
        "lcr": 15.0,
        "hle": 6.3,
        "gpqa": 65.7,
        "scicode": 28.9,
        "ifbench": 34.4,
        "aime25": 65.3,
        "critpt": 0.0,
        "livecodebench": 58.9
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1346.81
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "ling-1t",
    "canonical_name": "Ling-1T",
    "model_name": "Ling-1T",
    "aliases": [
      "Ling-1T"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": 19.01,
    "coding_score": 18.8,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 463.4553,
    "terminalbench_hard": 0.106,
    "tau2": 0.327,
    "lcr": 34.7,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 7.2,
    "gpqa": 71.9,
    "scicode": 35.2,
    "ifbench": 34.8,
    "aime25": 71.3,
    "critpt": 0.6,
    "mmmu_pro": null,
    "livecodebench": 67.7,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.267689+00:00",
        "confidence": 1.0,
        "raw_name": "Ling-1T",
        "raw_scores": {
          "intelligence_score": 19.01,
          "coding_score": 18.8,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000,
          "gdpval": 463.455256424611,
          "terminalbench_hard": 0.106,
          "tau2": 0.327,
          "lcr": 34.7,
          "hle": 7.2,
          "gpqa": 71.9,
          "scicode": 35.2,
          "ifbench": 34.8,
          "aime25": 71.3,
          "critpt": 0.6,
          "livecodebench": 67.7
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.01,
        "coding_score": 18.8,
        "gdpval": 463.455256424611,
        "terminalbench_hard": 0.106,
        "tau2": 0.327,
        "lcr": 34.7,
        "hle": 7.2,
        "gpqa": 71.9,
        "scicode": 35.2,
        "ifbench": 34.8,
        "aime25": 71.3,
        "critpt": 0.6,
        "livecodebench": 67.7
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "ring-flash-20",
    "canonical_name": "Ring-flash-2.0",
    "model_name": "Ring-flash-2.0",
    "aliases": [
      "Ring-flash-2.0",
      "ring-flash-2.0"
    ],
    "provider": "Ant Group",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": 7149,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": 14.0,
    "coding_score": 10.64,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1320.33,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.25,
    "latency_seconds": 1.37,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 80.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": 0.076,
    "tau2": 0.0,
    "lcr": 21.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 8.9,
    "gpqa": 72.5,
    "scicode": 16.8,
    "ifbench": 43.3,
    "aime25": 83.7,
    "critpt": 0.3,
    "mmmu_pro": null,
    "livecodebench": 62.8,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.267732+00:00",
        "confidence": 1.0,
        "raw_name": "Ring-flash-2.0",
        "raw_scores": {
          "intelligence_score": 14.0,
          "coding_score": 10.64,
          "blended_cost_per_1m": 0.25,
          "latency_seconds": 1.37,
          "tokens_per_second": 80.0,
          "context_window": 128000,
          "terminalbench_hard": 0.076,
          "tau2": 0.0,
          "lcr": 21.0,
          "hle": 8.9,
          "gpqa": 72.5,
          "scicode": 16.8,
          "ifbench": 43.3,
          "aime25": 83.7,
          "critpt": 0.3,
          "livecodebench": 62.8
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126841+00:00",
        "confidence": 1.0,
        "raw_name": "ring-flash-2.0",
        "raw_scores": {
          "arena_elo": 1320.33,
          "arena_votes": 7149
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.0,
        "coding_score": 10.64,
        "terminalbench_hard": 0.076,
        "tau2": 0.0,
        "lcr": 21.0,
        "hle": 8.9,
        "gpqa": 72.5,
        "scicode": 16.8,
        "ifbench": 43.3,
        "aime25": 83.7,
        "critpt": 0.3,
        "livecodebench": 62.8
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1320.33
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "ling-mini-20",
    "canonical_name": "Ling-mini-2.0",
    "model_name": "Ling-mini-2.0",
    "aliases": [
      "Ling-mini-2.0"
    ],
    "provider": null,
    "context_window": 131000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": 8.86,
    "coding_score": 5.02,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.12,
    "latency_seconds": 1.41,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 146.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 322.3076,
    "terminalbench_hard": 0.008,
    "tau2": 0.132,
    "lcr": 6.7,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.0,
    "gpqa": 56.2,
    "scicode": 13.5,
    "ifbench": 23.6,
    "aime25": 49.3,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 42.9,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.267775+00:00",
        "confidence": 1.0,
        "raw_name": "Ling-mini-2.0",
        "raw_scores": {
          "intelligence_score": 8.86,
          "coding_score": 5.02,
          "blended_cost_per_1m": 0.12,
          "latency_seconds": 1.41,
          "tokens_per_second": 146.0,
          "context_window": 131000,
          "gdpval": 322.3075831171809,
          "terminalbench_hard": 0.008,
          "tau2": 0.132,
          "lcr": 6.7,
          "hle": 5.0,
          "gpqa": 56.2,
          "scicode": 13.5,
          "ifbench": 23.6,
          "aime25": 49.3,
          "critpt": 0.0,
          "livecodebench": 42.9
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.86,
        "coding_score": 5.02,
        "gdpval": 322.3075831171809,
        "terminalbench_hard": 0.008,
        "tau2": 0.132,
        "lcr": 6.7,
        "hle": 5.0,
        "gpqa": 56.2,
        "scicode": 13.5,
        "ifbench": 23.6,
        "aime25": 49.3,
        "critpt": 0.0,
        "livecodebench": 42.9
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "ring-1t",
    "canonical_name": "Ring-1T",
    "model_name": "Ring-1T",
    "aliases": [
      "Ring-1T"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": 22.54,
    "coding_score": 16.78,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 744.0793,
    "terminalbench_hard": 0.068,
    "tau2": 0.263,
    "lcr": 45.7,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 10.2,
    "gpqa": 77.4,
    "scicode": 36.7,
    "ifbench": 44.6,
    "aime25": 89.3,
    "critpt": 0.6,
    "mmmu_pro": null,
    "livecodebench": 64.3,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.267816+00:00",
        "confidence": 1.0,
        "raw_name": "Ring-1T",
        "raw_scores": {
          "intelligence_score": 22.54,
          "coding_score": 16.78,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000,
          "gdpval": 744.0793325269998,
          "terminalbench_hard": 0.068,
          "tau2": 0.263,
          "lcr": 45.7,
          "hle": 10.2,
          "gpqa": 77.4,
          "scicode": 36.7,
          "ifbench": 44.6,
          "aime25": 89.3,
          "critpt": 0.6,
          "livecodebench": 64.3
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 22.54,
        "coding_score": 16.78,
        "gdpval": 744.0793325269998,
        "terminalbench_hard": 0.068,
        "tau2": 0.263,
        "lcr": 45.7,
        "hle": 10.2,
        "gpqa": 77.4,
        "scicode": 36.7,
        "ifbench": 44.6,
        "aime25": 89.3,
        "critpt": 0.6,
        "livecodebench": 64.3
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "doubao-seed-20-lite",
    "canonical_name": "Doubao Seed 2.0 lite (Reasoning)",
    "model_name": "Doubao Seed 2.0 lite (Reasoning)",
    "aliases": [
      "Doubao Seed 2.0 lite (Reasoning)"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 36.31,
    "coding_score": 21.35,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 1168.8924,
    "terminalbench_hard": 0.197,
    "tau2": 0.971,
    "lcr": 61.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 22.0,
    "gpqa": 65.6,
    "scicode": 24.7,
    "ifbench": 61.2,
    "aime25": null,
    "critpt": 2.0,
    "mmmu_pro": 73.1,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.267851+00:00",
        "confidence": 0.65,
        "raw_name": "Doubao Seed 2.0 lite (Reasoning)",
        "raw_scores": {
          "intelligence_score": 36.31,
          "coding_score": 21.35,
          "context_window": 128000,
          "gdpval": 1168.8924024582536,
          "terminalbench_hard": 0.197,
          "tau2": 0.971,
          "lcr": 61.3,
          "hle": 22.0,
          "gpqa": 65.6,
          "scicode": 24.7,
          "ifbench": 61.2,
          "critpt": 2.0,
          "mmmu_pro": 73.1
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 36.31,
        "coding_score": 21.35,
        "gdpval": 1168.8924024582536,
        "terminalbench_hard": 0.197,
        "tau2": 0.971,
        "lcr": 61.3,
        "hle": 22.0,
        "gpqa": 65.6,
        "scicode": 24.7,
        "ifbench": 61.2,
        "critpt": 2.0,
        "mmmu_pro": 73.1
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "doubao-seed-code",
    "canonical_name": "Doubao Seed Code",
    "model_name": "Doubao Seed Code",
    "aliases": [
      "Doubao Seed Code"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 33.5,
    "coding_score": 31.26,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 1008.793,
    "terminalbench_hard": 0.265,
    "tau2": 0.582,
    "lcr": 65.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 13.3,
    "gpqa": 76.4,
    "scicode": 40.7,
    "ifbench": 51.4,
    "aime25": 79.3,
    "critpt": 0.3,
    "mmmu_pro": 68.1,
    "livecodebench": 76.6,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.267897+00:00",
        "confidence": 1.0,
        "raw_name": "Doubao Seed Code",
        "raw_scores": {
          "intelligence_score": 33.5,
          "coding_score": 31.26,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 256000,
          "gdpval": 1008.7929543875009,
          "terminalbench_hard": 0.265,
          "tau2": 0.582,
          "lcr": 65.3,
          "hle": 13.3,
          "gpqa": 76.4,
          "scicode": 40.7,
          "ifbench": 51.4,
          "aime25": 79.3,
          "critpt": 0.3,
          "mmmu_pro": 68.1,
          "livecodebench": 76.6
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 33.5,
        "coding_score": 31.26,
        "gdpval": 1008.7929543875009,
        "terminalbench_hard": 0.265,
        "tau2": 0.582,
        "lcr": 65.3,
        "hle": 13.3,
        "gpqa": 76.4,
        "scicode": 40.7,
        "ifbench": 51.4,
        "aime25": 79.3,
        "critpt": 0.3,
        "mmmu_pro": 68.1,
        "livecodebench": 76.6
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "o1",
    "canonical_name": "o1",
    "model_name": "o1",
    "aliases": [
      "o1",
      "o1-2024-12-17"
    ],
    "provider": "OpenAI",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 27822,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 30.69,
    "coding_score": 20.51,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1402.04,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 26.25,
    "latency_seconds": 18.03,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 182.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 774.741,
    "terminalbench_hard": 0.129,
    "tau2": 0.626,
    "lcr": 59.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 7.7,
    "gpqa": 74.7,
    "scicode": 35.8,
    "ifbench": 70.3,
    "aime25": null,
    "critpt": 0.3,
    "mmmu_pro": null,
    "livecodebench": 67.9,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.267939+00:00",
        "confidence": 0.9300000000000002,
        "raw_name": "o1",
        "raw_scores": {
          "intelligence_score": 30.69,
          "coding_score": 20.51,
          "blended_cost_per_1m": 26.25,
          "latency_seconds": 18.03,
          "tokens_per_second": 182.0,
          "context_window": 200000,
          "gdpval": 774.7410468868705,
          "terminalbench_hard": 0.129,
          "tau2": 0.626,
          "lcr": 59.3,
          "hle": 7.7,
          "gpqa": 74.7,
          "scicode": 35.8,
          "ifbench": 70.3,
          "critpt": 0.3,
          "livecodebench": 67.9
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125461+00:00",
        "confidence": 1.0,
        "raw_name": "o1-2024-12-17",
        "raw_scores": {
          "arena_elo": 1402.04,
          "arena_votes": 27822
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 30.69,
        "coding_score": 20.51,
        "gdpval": 774.7410468868705,
        "terminalbench_hard": 0.129,
        "tau2": 0.626,
        "lcr": 59.3,
        "hle": 7.7,
        "gpqa": 74.7,
        "scicode": 35.8,
        "ifbench": 70.3,
        "critpt": 0.3,
        "livecodebench": 67.9
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1402.04
      }
    },
    "confidence_score": 0.965,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "o1-preview",
    "canonical_name": "o1-preview",
    "model_name": "o1-preview",
    "aliases": [
      "o1-preview"
    ],
    "provider": "OpenAI",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 31120,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 23.7429,
    "coding_score": 34.0453,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1388.25,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 28.88,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.267963+00:00",
        "confidence": 0.72,
        "raw_name": "o1-preview",
        "raw_scores": {
          "intelligence_score": 23.742890445410186,
          "coding_score": 34.045327,
          "blended_cost_per_1m": 28.88,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125729+00:00",
        "confidence": 1.0,
        "raw_name": "o1-preview",
        "raw_scores": {
          "arena_elo": 1388.25,
          "arena_votes": 31120
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 23.742890445410186,
        "coding_score": 34.045327
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1388.25
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "o1-mini",
    "canonical_name": "o1-mini",
    "model_name": "o1-mini",
    "aliases": [
      "o1-mini"
    ],
    "provider": "OpenAI",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 51986,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 20.3869,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1336.79,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.9,
    "gpqa": 60.3,
    "scicode": 32.3,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 57.6,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.267994+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "o1-mini",
        "raw_scores": {
          "intelligence_score": 20.38686032302532,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000,
          "hle": 4.9,
          "gpqa": 60.3,
          "scicode": 32.3,
          "livecodebench": 57.6
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126545+00:00",
        "confidence": 1.0,
        "raw_name": "o1-mini",
        "raw_scores": {
          "arena_elo": 1336.79,
          "arena_votes": 51986
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 20.38686032302532,
        "hle": 4.9,
        "gpqa": 60.3,
        "scicode": 32.3,
        "livecodebench": 57.6
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1336.79
      }
    },
    "confidence_score": 0.93,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gpt-4o",
    "canonical_name": "GPT-4o (Aug '24)",
    "model_name": "GPT-4o (Aug '24)",
    "aliases": [
      "GPT-4o (Aug '24)",
      "GPT-4o (ChatGPT)",
      "GPT-4o (March 2025, chatgpt-4o-latest)",
      "GPT-4o (May '24)",
      "GPT-4o (Nov '24)",
      "chatgpt-4o-latest-20250326",
      "gpt-4o-2024-05-13"
    ],
    "provider": "OpenAI",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 112863,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 16.9038,
    "coding_score": 19.0895,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1394.29,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 420.4051,
    "terminalbench_hard": 0.083,
    "tau2": 0.2691,
    "lcr": 29.1609,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 3.5385,
    "gpqa": 55.0294,
    "scicode": 33.4559,
    "ifbench": 35.1106,
    "aime25": 15.3934,
    "critpt": 0.0,
    "mmmu_pro": 56.3,
    "livecodebench": 34.5366,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.268032+00:00",
        "confidence": 0.72,
        "raw_name": "GPT-4o (Aug '24)",
        "raw_scores": {
          "intelligence_score": 18.82,
          "coding_score": 16.59,
          "context_window": 128000,
          "gdpval": 436.08629223550975,
          "terminalbench_hard": 0.083,
          "tau2": 0.289,
          "lcr": 35.0,
          "hle": 2.9,
          "gpqa": 52.1,
          "scicode": 33.1,
          "ifbench": 36.0,
          "critpt": 0.0,
          "mmmu_pro": 56.3,
          "livecodebench": 31.7
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.268060+00:00",
        "confidence": 0.72,
        "raw_name": "GPT-4o (May '24)",
        "raw_scores": {
          "intelligence_score": 16.0,
          "coding_score": 24.2436893,
          "context_window": 128000,
          "hle": 2.8,
          "gpqa": 52.6,
          "scicode": 30.9,
          "livecodebench": 33.4
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.268131+00:00",
        "confidence": 0.79,
        "raw_name": "GPT-4o (Nov '24)",
        "raw_scores": {
          "intelligence_score": 17.27,
          "coding_score": 16.67,
          "context_window": 128000,
          "gdpval": 406.11335343325845,
          "terminalbench_hard": 0.083,
          "tau2": 0.251,
          "lcr": 0.0,
          "hle": 3.3,
          "gpqa": 54.3,
          "scicode": 33.3,
          "ifbench": 34.3,
          "aime25": 6.0,
          "critpt": 0.0,
          "livecodebench": 30.9
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.268400+00:00",
        "confidence": 0.72,
        "raw_name": "GPT-4o (March 2025, chatgpt-4o-latest)",
        "raw_scores": {
          "intelligence_score": 18.558508422577216,
          "context_window": 128000,
          "hle": 5.0,
          "gpqa": 65.5,
          "scicode": 36.6,
          "aime25": 25.7,
          "livecodebench": 42.5
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.268697+00:00",
        "confidence": 0.79,
        "raw_name": "GPT-4o (ChatGPT)",
        "raw_scores": {
          "intelligence_score": 14.107047509866186,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000,
          "lcr": 53.0,
          "hle": 3.7,
          "gpqa": 51.1,
          "scicode": 33.4
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.124878+00:00",
        "confidence": 1.0,
        "raw_name": "chatgpt-4o-latest-20250326",
        "raw_scores": {
          "arena_elo": 1442.73,
          "arena_votes": 82949
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126437+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-4o-2024-05-13",
        "raw_scores": {
          "arena_elo": 1345.85,
          "arena_votes": 112863
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 18.82,
        "coding_score": 16.59,
        "gdpval": 436.08629223550975,
        "terminalbench_hard": 0.083,
        "tau2": 0.289,
        "lcr": 35.0,
        "hle": 2.9,
        "gpqa": 52.1,
        "scicode": 33.1,
        "ifbench": 36.0,
        "critpt": 0.0,
        "mmmu_pro": 56.3,
        "livecodebench": 31.7,
        "aime25": 6.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1442.73
      }
    },
    "confidence_score": 0.82,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gpt-4-turbo",
    "canonical_name": "GPT-4 Turbo",
    "model_name": "GPT-4 Turbo",
    "aliases": [
      "GPT-4 Turbo",
      "gpt-4-turbo-2024-04-09"
    ],
    "provider": "OpenAI",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 98130,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 13.7153,
    "coding_score": 21.4873,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1324.32,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 15.0,
    "latency_seconds": 1.2,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 27.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 3.3,
    "gpqa": null,
    "scicode": 31.9,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 29.1,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.268091+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "GPT-4 Turbo",
        "raw_scores": {
          "intelligence_score": 13.715301370059112,
          "coding_score": 21.4873245,
          "blended_cost_per_1m": 15.0,
          "latency_seconds": 1.2,
          "tokens_per_second": 27.0,
          "context_window": 128000,
          "hle": 3.3,
          "scicode": 31.9,
          "livecodebench": 29.1
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126736+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-4-turbo-2024-04-09",
        "raw_scores": {
          "arena_elo": 1324.32,
          "arena_votes": 98130
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.715301370059112,
        "coding_score": 21.4873245,
        "hle": 3.3,
        "scicode": 31.9,
        "livecodebench": 29.1
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1324.32
      }
    },
    "confidence_score": 0.93,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gpt-4o-mini",
    "canonical_name": "GPT-4o mini",
    "model_name": "GPT-4o mini",
    "aliases": [
      "GPT-4o mini",
      "gpt-4o-mini-2024-07-18"
    ],
    "provider": "OpenAI",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 68794,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 12.6473,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1317.76,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.26,
    "latency_seconds": 0.48,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 54.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.0,
    "gpqa": 42.6,
    "scicode": 22.9,
    "ifbench": 31.0,
    "aime25": 14.7,
    "critpt": null,
    "mmmu_pro": 41.5,
    "livecodebench": 23.4,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.268167+00:00",
        "confidence": 0.9300000000000002,
        "raw_name": "GPT-4o mini",
        "raw_scores": {
          "intelligence_score": 12.647336534486156,
          "blended_cost_per_1m": 0.26,
          "latency_seconds": 0.48,
          "tokens_per_second": 54.0,
          "context_window": 128000,
          "hle": 4.0,
          "gpqa": 42.6,
          "scicode": 22.9,
          "ifbench": 31.0,
          "aime25": 14.7,
          "mmmu_pro": 41.5,
          "livecodebench": 23.4
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126904+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-4o-mini-2024-07-18",
        "raw_scores": {
          "arena_elo": 1317.76,
          "arena_votes": 68794
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.647336534486156,
        "hle": 4.0,
        "gpqa": 42.6,
        "scicode": 22.9,
        "ifbench": 31.0,
        "aime25": 14.7,
        "mmmu_pro": 41.5,
        "livecodebench": 23.4
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1317.76
      }
    },
    "confidence_score": 0.965,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gpt-35-turbo",
    "canonical_name": "GPT-3.5 Turbo",
    "model_name": "GPT-3.5 Turbo",
    "aliases": [
      "GPT-3.5 Turbo",
      "GPT-3.5 Turbo (0613)"
    ],
    "provider": "OpenAI",
    "context_window": 4096,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 8.9897,
    "coding_score": 10.6542,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.4325,
    "latency_seconds": 0.2364,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 57.6642,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": 29.7,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.268195+00:00",
        "confidence": 0.79,
        "raw_name": "GPT-3.5 Turbo",
        "raw_scores": {
          "intelligence_score": 8.989676386007632,
          "coding_score": 10.6541808,
          "blended_cost_per_1m": 0.75,
          "latency_seconds": 0.41,
          "tokens_per_second": 100.0,
          "context_window": 4096,
          "gpqa": 29.7
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.268618+00:00",
        "confidence": 0.5800000000000001,
        "raw_name": "GPT-3.5 Turbo (0613)",
        "raw_scores": {
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 4096
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.989676386007632,
        "coding_score": 10.6541808,
        "gpqa": 29.7
      }
    },
    "confidence_score": 0.685,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gpt-41",
    "canonical_name": "GPT-4.1",
    "model_name": "GPT-4.1",
    "aliases": [
      "GPT-4.1",
      "gpt-4.1-2025-04-14"
    ],
    "provider": "OpenAI",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": 51849,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 25.6,
    "coding_score": 21.78,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1413.43,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.5,
    "latency_seconds": 0.54,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 121.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 810.9888,
    "terminalbench_hard": 0.136,
    "tau2": 0.471,
    "lcr": 61.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.6,
    "gpqa": 66.6,
    "scicode": 38.1,
    "ifbench": 43.0,
    "aime25": 34.7,
    "critpt": 0.0,
    "mmmu_pro": 61.2,
    "livecodebench": 45.7,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.268298+00:00",
        "confidence": 1.0,
        "raw_name": "GPT-4.1",
        "raw_scores": {
          "intelligence_score": 25.6,
          "coding_score": 21.78,
          "blended_cost_per_1m": 3.5,
          "latency_seconds": 0.54,
          "tokens_per_second": 121.0,
          "context_window": 1000000,
          "gdpval": 810.9887661271291,
          "terminalbench_hard": 0.136,
          "tau2": 0.471,
          "lcr": 61.0,
          "hle": 4.6,
          "gpqa": 66.6,
          "scicode": 38.1,
          "ifbench": 43.0,
          "aime25": 34.7,
          "critpt": 0.0,
          "mmmu_pro": 61.2,
          "livecodebench": 45.7
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125323+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-4.1-2025-04-14",
        "raw_scores": {
          "arena_elo": 1413.43,
          "arena_votes": 51849
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 25.6,
        "coding_score": 21.78,
        "gdpval": 810.9887661271291,
        "terminalbench_hard": 0.136,
        "tau2": 0.471,
        "lcr": 61.0,
        "hle": 4.6,
        "gpqa": 66.6,
        "scicode": 38.1,
        "ifbench": 43.0,
        "aime25": 34.7,
        "critpt": 0.0,
        "mmmu_pro": 61.2,
        "livecodebench": 45.7
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1413.43
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gpt-5",
    "canonical_name": "GPT-5 (high)",
    "model_name": "GPT-5 (high)",
    "aliases": [
      "GPT-5 (ChatGPT)",
      "GPT-5 (high)",
      "GPT-5 (low)",
      "GPT-5 (medium)",
      "GPT-5 (minimal)",
      "gpt-5-chat",
      "gpt-5-high"
    ],
    "provider": "OpenAI",
    "context_window": 400000,
    "open_source": null,
    "arena_votes": 32353,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 34.2029,
    "coding_score": 30.39,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1430.195,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.44,
    "latency_seconds": 36.552,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 113.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 979.6683,
    "terminalbench_hard": 0.2562,
    "tau2": 0.645,
    "lcr": 59.16,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 15.92,
    "gpqa": 77.26,
    "scicode": 39.94,
    "ifbench": 60.18,
    "aime25": 69.8,
    "critpt": 1.7,
    "mmmu_pro": 71.1,
    "livecodebench": 68.26,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.268371+00:00",
        "confidence": 1.0,
        "raw_name": "GPT-5 (high)",
        "raw_scores": {
          "intelligence_score": 44.57,
          "coding_score": 36.03,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 105.22,
          "tokens_per_second": 103.0,
          "context_window": 400000,
          "gdpval": 1301.5427931707022,
          "terminalbench_hard": 0.326,
          "tau2": 0.848,
          "lcr": 75.6,
          "hle": 26.5,
          "gpqa": 85.4,
          "scicode": 42.9,
          "ifbench": 73.1,
          "aime25": 94.3,
          "critpt": 5.7,
          "mmmu_pro": 74.2,
          "livecodebench": 84.6
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.268467+00:00",
        "confidence": 1.0,
        "raw_name": "GPT-5 (medium)",
        "raw_scores": {
          "intelligence_score": 41.84,
          "coding_score": 38.95,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 48.88,
          "tokens_per_second": 96.0,
          "context_window": 400000,
          "gdpval": 1013.3844917462206,
          "terminalbench_hard": 0.379,
          "tau2": 0.865,
          "lcr": 72.8,
          "hle": 23.5,
          "gpqa": 84.2,
          "scicode": 41.1,
          "ifbench": 70.6,
          "aime25": 91.7,
          "critpt": 0.0,
          "mmmu_pro": 74.3,
          "livecodebench": 70.3
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.268554+00:00",
        "confidence": 1.0,
        "raw_name": "GPT-5 (low)",
        "raw_scores": {
          "intelligence_score": 39.03,
          "coding_score": 30.72,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 27.12,
          "tokens_per_second": 91.0,
          "context_window": 400000,
          "gdpval": 1153.549337876717,
          "terminalbench_hard": 0.265,
          "tau2": 0.842,
          "lcr": 58.7,
          "hle": 18.4,
          "gpqa": 80.8,
          "scicode": 39.1,
          "ifbench": 66.6,
          "aime25": 83.0,
          "critpt": 1.1,
          "mmmu_pro": 73.8,
          "livecodebench": 76.3
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.268783+00:00",
        "confidence": 1.0,
        "raw_name": "GPT-5 (minimal)",
        "raw_scores": {
          "intelligence_score": 23.74,
          "coding_score": 25.05,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 1.02,
          "tokens_per_second": 68.0,
          "context_window": 400000,
          "gdpval": 450.19674843011194,
          "terminalbench_hard": 0.182,
          "tau2": 0.67,
          "lcr": 25.0,
          "hle": 5.4,
          "gpqa": 67.3,
          "scicode": 38.8,
          "ifbench": 45.6,
          "aime25": 31.7,
          "critpt": 0.0,
          "mmmu_pro": 62.1,
          "livecodebench": 55.8
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.268862+00:00",
        "confidence": 1.0,
        "raw_name": "GPT-5 (ChatGPT)",
        "raw_scores": {
          "intelligence_score": 21.834580028932926,
          "coding_score": 21.2,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 0.52,
          "tokens_per_second": 207.0,
          "context_window": 128000,
          "terminalbench_hard": 0.129,
          "tau2": 0.0,
          "lcr": 63.7,
          "hle": 5.8,
          "gpqa": 68.6,
          "scicode": 37.8,
          "ifbench": 45.0,
          "aime25": 48.3,
          "livecodebench": 54.3
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.124956+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-5-high",
        "raw_scores": {
          "arena_elo": 1434.31,
          "arena_votes": 32353
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125045+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-5-chat",
        "raw_scores": {
          "arena_elo": 1426.08,
          "arena_votes": 31610
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 44.57,
        "coding_score": 36.03,
        "gdpval": 1301.5427931707022,
        "terminalbench_hard": 0.326,
        "tau2": 0.848,
        "lcr": 75.6,
        "hle": 26.5,
        "gpqa": 85.4,
        "scicode": 42.9,
        "ifbench": 73.1,
        "aime25": 94.3,
        "critpt": 5.7,
        "mmmu_pro": 74.2,
        "livecodebench": 84.6
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1434.31
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gpt-45",
    "canonical_name": "GPT-4.5 (Preview)",
    "model_name": "GPT-4.5 (Preview)",
    "aliases": [
      "GPT-4.5 (Preview)"
    ],
    "provider": "OpenAI",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 19.9568,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.268423+00:00",
        "confidence": 0.65,
        "raw_name": "GPT-4.5 (Preview)",
        "raw_scores": {
          "intelligence_score": 19.956828896300806,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.956828896300806
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gpt-41-nano",
    "canonical_name": "GPT-4.1 nano",
    "model_name": "GPT-4.1 nano",
    "aliases": [
      "GPT-4.1 nano",
      "gpt-4.1-nano-2025-04-14"
    ],
    "provider": "OpenAI",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": 6107,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 12.89,
    "coding_score": 11.17,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1321.79,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.17,
    "latency_seconds": 0.35,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 142.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 392.9462,
    "terminalbench_hard": 0.038,
    "tau2": 0.173,
    "lcr": 17.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 3.9,
    "gpqa": 51.2,
    "scicode": 25.9,
    "ifbench": 32.0,
    "aime25": 24.0,
    "critpt": 0.0,
    "mmmu_pro": 40.1,
    "livecodebench": 32.6,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.268510+00:00",
        "confidence": 1.0,
        "raw_name": "GPT-4.1 nano",
        "raw_scores": {
          "intelligence_score": 12.89,
          "coding_score": 11.17,
          "blended_cost_per_1m": 0.17,
          "latency_seconds": 0.35,
          "tokens_per_second": 142.0,
          "context_window": 1000000,
          "gdpval": 392.9462130585239,
          "terminalbench_hard": 0.038,
          "tau2": 0.173,
          "lcr": 17.0,
          "hle": 3.9,
          "gpqa": 51.2,
          "scicode": 25.9,
          "ifbench": 32.0,
          "aime25": 24.0,
          "critpt": 0.0,
          "mmmu_pro": 40.1,
          "livecodebench": 32.6
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126828+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-4.1-nano-2025-04-14",
        "raw_scores": {
          "arena_elo": 1321.79,
          "arena_votes": 6107
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.89,
        "coding_score": 11.17,
        "gdpval": 392.9462130585239,
        "terminalbench_hard": 0.038,
        "tau2": 0.173,
        "lcr": 17.0,
        "hle": 3.9,
        "gpqa": 51.2,
        "scicode": 25.9,
        "ifbench": 32.0,
        "aime25": 24.0,
        "critpt": 0.0,
        "mmmu_pro": 40.1,
        "livecodebench": 32.6
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1321.79
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "o4-mini",
    "canonical_name": "o4-mini (high)",
    "model_name": "o4-mini (high)",
    "aliases": [
      "o4-mini (high)",
      "o4-mini-2025-04-16"
    ],
    "provider": "OpenAI",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 46377,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 33.05,
    "coding_score": 25.61,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1391.1,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.93,
    "latency_seconds": 56.26,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 126.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 1017.0472,
    "terminalbench_hard": 0.152,
    "tau2": 0.556,
    "lcr": 55.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 17.5,
    "gpqa": 78.4,
    "scicode": 46.5,
    "ifbench": 68.7,
    "aime25": 90.7,
    "critpt": 0.6,
    "mmmu_pro": 69.2,
    "livecodebench": 85.9,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.268599+00:00",
        "confidence": 1.0,
        "raw_name": "o4-mini (high)",
        "raw_scores": {
          "intelligence_score": 33.05,
          "coding_score": 25.61,
          "blended_cost_per_1m": 1.93,
          "latency_seconds": 56.26,
          "tokens_per_second": 126.0,
          "context_window": 200000,
          "gdpval": 1017.0471530232453,
          "terminalbench_hard": 0.152,
          "tau2": 0.556,
          "lcr": 55.0,
          "hle": 17.5,
          "gpqa": 78.4,
          "scicode": 46.5,
          "ifbench": 68.7,
          "aime25": 90.7,
          "critpt": 0.6,
          "mmmu_pro": 69.2,
          "livecodebench": 85.9
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125632+00:00",
        "confidence": 1.0,
        "raw_name": "o4-mini-2025-04-16",
        "raw_scores": {
          "arena_elo": 1391.1,
          "arena_votes": 46377
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 33.05,
        "coding_score": 25.61,
        "gdpval": 1017.0471530232453,
        "terminalbench_hard": 0.152,
        "tau2": 0.556,
        "lcr": 55.0,
        "hle": 17.5,
        "gpqa": 78.4,
        "scicode": 46.5,
        "ifbench": 68.7,
        "aime25": 90.7,
        "critpt": 0.6,
        "mmmu_pro": 69.2,
        "livecodebench": 85.9
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1391.1
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gpt-41-mini",
    "canonical_name": "GPT-4.1 mini",
    "model_name": "GPT-4.1 mini",
    "aliases": [
      "GPT-4.1 mini",
      "gpt-4.1-mini-2025-04-14"
    ],
    "provider": "OpenAI",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": 40312,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 22.38,
    "coding_score": 18.52,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1381.98,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.7,
    "latency_seconds": 0.48,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 79.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 669.7836,
    "terminalbench_hard": 0.076,
    "tau2": 0.529,
    "lcr": 42.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.6,
    "gpqa": 66.4,
    "scicode": 40.4,
    "ifbench": 38.3,
    "aime25": 46.3,
    "critpt": 0.0,
    "mmmu_pro": 58.7,
    "livecodebench": 48.3,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.268665+00:00",
        "confidence": 1.0,
        "raw_name": "GPT-4.1 mini",
        "raw_scores": {
          "intelligence_score": 22.38,
          "coding_score": 18.52,
          "blended_cost_per_1m": 0.7,
          "latency_seconds": 0.48,
          "tokens_per_second": 79.0,
          "context_window": 1000000,
          "gdpval": 669.7835945907068,
          "terminalbench_hard": 0.076,
          "tau2": 0.529,
          "lcr": 42.3,
          "hle": 4.6,
          "gpqa": 66.4,
          "scicode": 40.4,
          "ifbench": 38.3,
          "aime25": 46.3,
          "critpt": 0.0,
          "mmmu_pro": 58.7,
          "livecodebench": 48.3
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125945+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-4.1-mini-2025-04-14",
        "raw_scores": {
          "arena_elo": 1381.98,
          "arena_votes": 40312
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 22.38,
        "coding_score": 18.52,
        "gdpval": 669.7835945907068,
        "terminalbench_hard": 0.076,
        "tau2": 0.529,
        "lcr": 42.3,
        "hle": 4.6,
        "gpqa": 66.4,
        "scicode": 40.4,
        "ifbench": 38.3,
        "aime25": 46.3,
        "critpt": 0.0,
        "mmmu_pro": 58.7,
        "livecodebench": 48.3
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1381.98
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "o1-pro",
    "canonical_name": "o1-pro",
    "model_name": "o1-pro",
    "aliases": [
      "o1-pro"
    ],
    "provider": "OpenAI",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 25.7608,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 262.5,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.268822+00:00",
        "confidence": 0.65,
        "raw_name": "o1-pro",
        "raw_scores": {
          "intelligence_score": 25.760825664214558,
          "blended_cost_per_1m": 262.5,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 200000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 25.760825664214558
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gpt-51-codex",
    "canonical_name": "GPT-5.1 Codex (high)",
    "model_name": "GPT-5.1 Codex (high)",
    "aliases": [
      "GPT-5.1 Codex (high)"
    ],
    "provider": "OpenAI",
    "context_window": 400000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 42.19,
    "coding_score": 36.62,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.44,
    "latency_seconds": 10.22,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 290.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 1188.0129,
    "terminalbench_hard": 0.348,
    "tau2": 0.83,
    "lcr": 67.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 23.4,
    "gpqa": 86.0,
    "scicode": 40.2,
    "ifbench": 70.0,
    "aime25": 95.7,
    "critpt": 5.7,
    "mmmu_pro": 72.5,
    "livecodebench": 84.9,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.268906+00:00",
        "confidence": 1.0,
        "raw_name": "GPT-5.1 Codex (high)",
        "raw_scores": {
          "intelligence_score": 42.19,
          "coding_score": 36.62,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 10.22,
          "tokens_per_second": 290.0,
          "context_window": 400000,
          "gdpval": 1188.0128599226437,
          "terminalbench_hard": 0.348,
          "tau2": 0.83,
          "lcr": 67.3,
          "hle": 23.4,
          "gpqa": 86.0,
          "scicode": 40.2,
          "ifbench": 70.0,
          "aime25": 95.7,
          "critpt": 5.7,
          "mmmu_pro": 72.5,
          "livecodebench": 84.9
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 42.19,
        "coding_score": 36.62,
        "gdpval": 1188.0128599226437,
        "terminalbench_hard": 0.348,
        "tau2": 0.83,
        "lcr": 67.3,
        "hle": 23.4,
        "gpqa": 86.0,
        "scicode": 40.2,
        "ifbench": 70.0,
        "aime25": 95.7,
        "critpt": 5.7,
        "mmmu_pro": 72.5,
        "livecodebench": 84.9
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "o3-mini",
    "canonical_name": "o3-mini (high)",
    "model_name": "o3-mini (high)",
    "aliases": [
      "o3-mini",
      "o3-mini (high)"
    ],
    "provider": "OpenAI",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 58459,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 25.4566,
    "coding_score": 17.58,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1348.24,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.93,
    "latency_seconds": 32.21,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 158.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 785.705,
    "terminalbench_hard": 0.0645,
    "tau2": 0.3,
    "lcr": 39.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 10.5,
    "gpqa": 76.05,
    "scicode": 39.85,
    "ifbench": 67.1,
    "aime25": null,
    "critpt": 0.3,
    "mmmu_pro": null,
    "livecodebench": 72.55,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.268947+00:00",
        "confidence": 0.9300000000000002,
        "raw_name": "o3-mini (high)",
        "raw_scores": {
          "intelligence_score": 25.05,
          "coding_score": 17.3,
          "blended_cost_per_1m": 1.93,
          "latency_seconds": 50.34,
          "tokens_per_second": 161.0,
          "context_window": 200000,
          "gdpval": 785.704964339423,
          "terminalbench_hard": 0.061,
          "tau2": 0.313,
          "lcr": 39.3,
          "hle": 12.3,
          "gpqa": 77.3,
          "scicode": 39.8,
          "ifbench": 67.1,
          "critpt": 0.3,
          "livecodebench": 73.4
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.269031+00:00",
        "confidence": 0.9300000000000002,
        "raw_name": "o3-mini",
        "raw_scores": {
          "intelligence_score": 25.863248068693565,
          "coding_score": 17.86,
          "blended_cost_per_1m": 1.93,
          "latency_seconds": 14.08,
          "tokens_per_second": 155.0,
          "context_window": 200000,
          "terminalbench_hard": 0.068,
          "tau2": 0.287,
          "hle": 8.7,
          "gpqa": 74.8,
          "scicode": 39.9,
          "livecodebench": 71.7
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126335+00:00",
        "confidence": 1.0,
        "raw_name": "o3-mini",
        "raw_scores": {
          "arena_elo": 1348.24,
          "arena_votes": 58459
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 25.05,
        "coding_score": 17.3,
        "gdpval": 785.704964339423,
        "terminalbench_hard": 0.061,
        "tau2": 0.313,
        "lcr": 39.3,
        "hle": 12.3,
        "gpqa": 77.3,
        "scicode": 39.8,
        "ifbench": 67.1,
        "critpt": 0.3,
        "livecodebench": 73.4
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1348.24
      }
    },
    "confidence_score": 0.9533,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gpt-51",
    "canonical_name": "GPT-5.1 (high)",
    "model_name": "GPT-5.1 (high)",
    "aliases": [
      "GPT-5.1 (Non-reasoning)",
      "GPT-5.1 (high)",
      "gpt-5.1",
      "gpt-5.1-high"
    ],
    "provider": "OpenAI",
    "context_window": 400000,
    "open_source": null,
    "arena_votes": 35980,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 38.667,
    "coding_score": 37.0374,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1447.485,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.44,
    "latency_seconds": 36.63,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 131.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 1128.6479,
    "terminalbench_hard": 0.3544,
    "tau2": 0.6628,
    "lcr": 61.3184,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 17.0994,
    "gpqa": 77.1492,
    "scicode": 40.2989,
    "ifbench": 59.7922,
    "aime25": 69.2849,
    "critpt": 2.7374,
    "mmmu_pro": 69.7184,
    "livecodebench": 70.2939,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.268995+00:00",
        "confidence": 1.0,
        "raw_name": "GPT-5.1 (high)",
        "raw_scores": {
          "intelligence_score": 47.56,
          "coding_score": 44.73,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 36.63,
          "tokens_per_second": 131.0,
          "context_window": 400000,
          "gdpval": 1230.2798171244715,
          "terminalbench_hard": 0.455,
          "tau2": 0.819,
          "lcr": 75.0,
          "hle": 26.5,
          "gpqa": 87.3,
          "scicode": 43.3,
          "ifbench": 72.9,
          "aime25": 94.0,
          "critpt": 4.9,
          "mmmu_pro": 75.5,
          "livecodebench": 86.8
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.269266+00:00",
        "confidence": 0.79,
        "raw_name": "GPT-5.1 (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 27.41,
          "coding_score": 27.3,
          "context_window": 400000,
          "gdpval": 1000.0,
          "terminalbench_hard": 0.227,
          "tau2": 0.465,
          "lcr": 44.0,
          "hle": 5.2,
          "gpqa": 64.3,
          "scicode": 36.5,
          "ifbench": 43.2,
          "aime25": 38.0,
          "critpt": 0.0,
          "mmmu_pro": 62.4,
          "livecodebench": 49.4
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.124685+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-5.1-high",
        "raw_scores": {
          "arena_elo": 1457.69,
          "arena_votes": 33708
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.124917+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-5.1",
        "raw_scores": {
          "arena_elo": 1437.28,
          "arena_votes": 35980
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 47.56,
        "coding_score": 44.73,
        "gdpval": 1230.2798171244715,
        "terminalbench_hard": 0.455,
        "tau2": 0.819,
        "lcr": 75.0,
        "hle": 26.5,
        "gpqa": 87.3,
        "scicode": 43.3,
        "ifbench": 72.9,
        "aime25": 94.0,
        "critpt": 4.9,
        "mmmu_pro": 75.5,
        "livecodebench": 86.8
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1457.69
      }
    },
    "confidence_score": 0.9475,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gpt-5-codex",
    "canonical_name": "GPT-5 Codex (high)",
    "model_name": "GPT-5 Codex (high)",
    "aliases": [
      "GPT-5 Codex (high)"
    ],
    "provider": "OpenAI",
    "context_window": 400000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 44.52,
    "coding_score": 38.87,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.44,
    "latency_seconds": 13.71,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 343.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 1215.9384,
    "terminalbench_hard": 0.379,
    "tau2": 0.868,
    "lcr": 69.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 25.6,
    "gpqa": 83.7,
    "scicode": 40.9,
    "ifbench": 74.1,
    "aime25": 98.7,
    "critpt": 5.1,
    "mmmu_pro": 73.8,
    "livecodebench": 84.0,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.269074+00:00",
        "confidence": 1.0,
        "raw_name": "GPT-5 Codex (high)",
        "raw_scores": {
          "intelligence_score": 44.52,
          "coding_score": 38.87,
          "blended_cost_per_1m": 3.44,
          "latency_seconds": 13.71,
          "tokens_per_second": 343.0,
          "context_window": 400000,
          "gdpval": 1215.9384488716896,
          "terminalbench_hard": 0.379,
          "tau2": 0.868,
          "lcr": 69.0,
          "hle": 25.6,
          "gpqa": 83.7,
          "scicode": 40.9,
          "ifbench": 74.1,
          "aime25": 98.7,
          "critpt": 5.1,
          "mmmu_pro": 73.8,
          "livecodebench": 84.0
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 44.52,
        "coding_score": 38.87,
        "gdpval": 1215.9384488716896,
        "terminalbench_hard": 0.379,
        "tau2": 0.868,
        "lcr": 69.0,
        "hle": 25.6,
        "gpqa": 83.7,
        "scicode": 40.9,
        "ifbench": 74.1,
        "aime25": 98.7,
        "critpt": 5.1,
        "mmmu_pro": 73.8,
        "livecodebench": 84.0
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gpt-4",
    "canonical_name": "GPT-4",
    "model_name": "GPT-4",
    "aliases": [
      "GPT-4"
    ],
    "provider": "OpenAI",
    "context_window": 8192,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 12.7543,
    "coding_score": 13.1424,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 37.5,
    "latency_seconds": 0.63,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 34.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.269099+00:00",
        "confidence": 0.72,
        "raw_name": "GPT-4",
        "raw_scores": {
          "intelligence_score": 12.754307113238253,
          "coding_score": 13.142408,
          "blended_cost_per_1m": 37.5,
          "latency_seconds": 0.63,
          "tokens_per_second": 34.0,
          "context_window": 8192
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.754307113238253,
        "coding_score": 13.142408
      }
    },
    "confidence_score": 0.72,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "o3-pro",
    "canonical_name": "o3-pro",
    "model_name": "o3-pro",
    "aliases": [
      "o3-pro"
    ],
    "provider": "OpenAI",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 40.6899,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 35.0,
    "latency_seconds": 87.18,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 34.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": 84.5,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.269214+00:00",
        "confidence": 0.72,
        "raw_name": "o3-pro",
        "raw_scores": {
          "intelligence_score": 40.68990197347841,
          "blended_cost_per_1m": 35.0,
          "latency_seconds": 87.18,
          "tokens_per_second": 34.0,
          "context_window": 200000,
          "gpqa": 84.5
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 40.68990197347841,
        "gpqa": 84.5
      }
    },
    "confidence_score": 0.72,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-instruct-70b",
    "canonical_name": "Llama 3.1 Instruct 70B",
    "model_name": "Llama 3.1 Instruct 70B",
    "aliases": [
      "Llama 3.1 Instruct 70B"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT",
    "creator": null,
    "intelligence_score": 12.24,
    "coding_score": 10.93,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 339.2719,
    "terminalbench_hard": 0.03,
    "tau2": 0.152,
    "lcr": 6.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.6,
    "gpqa": 40.9,
    "scicode": 26.7,
    "ifbench": 34.4,
    "aime25": 4.0,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 23.2,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.269307+00:00",
        "confidence": 0.79,
        "raw_name": "Llama 3.1 Instruct 70B",
        "raw_scores": {
          "intelligence_score": 12.24,
          "coding_score": 10.93,
          "context_window": 128000,
          "gdpval": 339.2719130025149,
          "terminalbench_hard": 0.03,
          "tau2": 0.152,
          "lcr": 6.3,
          "hle": 4.6,
          "gpqa": 40.9,
          "scicode": 26.7,
          "ifbench": 34.4,
          "aime25": 4.0,
          "critpt": 0.0,
          "livecodebench": 23.2
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.24,
        "coding_score": 10.93,
        "gdpval": 339.2719130025149,
        "terminalbench_hard": 0.03,
        "tau2": 0.152,
        "lcr": 6.3,
        "hle": 4.6,
        "gpqa": 40.9,
        "scicode": 26.7,
        "ifbench": 34.4,
        "aime25": 4.0,
        "critpt": 0.0,
        "livecodebench": 23.2
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-instruct-8b",
    "canonical_name": "Llama 3.1 Instruct 8B",
    "model_name": "Llama 3.1 Instruct 8B",
    "aliases": [
      "Llama 3.1 Instruct 8B"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT",
    "creator": null,
    "intelligence_score": 11.68,
    "coding_score": 4.9,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 343.1581,
    "terminalbench_hard": 0.008,
    "tau2": 0.164,
    "lcr": 15.7,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.1,
    "gpqa": 25.9,
    "scicode": 13.2,
    "ifbench": 28.6,
    "aime25": 4.3,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 11.6,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.269349+00:00",
        "confidence": 0.79,
        "raw_name": "Llama 3.1 Instruct 8B",
        "raw_scores": {
          "intelligence_score": 11.68,
          "coding_score": 4.9,
          "context_window": 128000,
          "gdpval": 343.1580788979113,
          "terminalbench_hard": 0.008,
          "tau2": 0.164,
          "lcr": 15.7,
          "hle": 5.1,
          "gpqa": 25.9,
          "scicode": 13.2,
          "ifbench": 28.6,
          "aime25": 4.3,
          "critpt": 0.0,
          "livecodebench": 11.6
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 11.68,
        "coding_score": 4.9,
        "gdpval": 343.1580788979113,
        "terminalbench_hard": 0.008,
        "tau2": 0.164,
        "lcr": 15.7,
        "hle": 5.1,
        "gpqa": 25.9,
        "scicode": 13.2,
        "ifbench": 28.6,
        "aime25": 4.3,
        "critpt": 0.0,
        "livecodebench": 11.6
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-32-instruct-3b",
    "canonical_name": "Llama 3.2 Instruct 3B",
    "model_name": "Llama 3.2 Instruct 3B",
    "aliases": [
      "Llama 3.2 Instruct 3B"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "LLAMA 3.2 COMMUNITY LICENSE AGREEMENT",
    "creator": null,
    "intelligence_score": 9.7022,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": 0.211,
    "lcr": 2.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.2,
    "gpqa": 25.5,
    "scicode": 5.2,
    "ifbench": 26.2,
    "aime25": 3.3,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 8.3,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.269388+00:00",
        "confidence": 0.72,
        "raw_name": "Llama 3.2 Instruct 3B",
        "raw_scores": {
          "intelligence_score": 9.702177369527044,
          "context_window": 128000,
          "tau2": 0.211,
          "lcr": 2.0,
          "hle": 5.2,
          "gpqa": 25.5,
          "scicode": 5.2,
          "ifbench": 26.2,
          "aime25": 3.3,
          "livecodebench": 8.3
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.702177369527044,
        "tau2": 0.211,
        "lcr": 2.0,
        "hle": 5.2,
        "gpqa": 25.5,
        "scicode": 5.2,
        "ifbench": 26.2,
        "aime25": 3.3,
        "livecodebench": 8.3
      }
    },
    "confidence_score": 0.72,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-3-instruct-70b",
    "canonical_name": "Llama 3 Instruct 70B",
    "model_name": "Llama 3 Instruct 70B",
    "aliases": [
      "Llama 3 Instruct 70B"
    ],
    "provider": "Meta",
    "context_window": 8192,
    "open_source": true,
    "arena_votes": null,
    "license_type": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT",
    "creator": null,
    "intelligence_score": 8.81,
    "coding_score": 6.79,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": 0.008,
    "tau2": 0.0,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.4,
    "gpqa": 37.9,
    "scicode": 18.9,
    "ifbench": 37.1,
    "aime25": null,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 19.8,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.269426+00:00",
        "confidence": 0.72,
        "raw_name": "Llama 3 Instruct 70B",
        "raw_scores": {
          "intelligence_score": 8.81,
          "coding_score": 6.79,
          "context_window": 8192,
          "terminalbench_hard": 0.008,
          "tau2": 0.0,
          "lcr": 0.0,
          "hle": 4.4,
          "gpqa": 37.9,
          "scicode": 18.9,
          "ifbench": 37.1,
          "critpt": 0.0,
          "livecodebench": 19.8
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.81,
        "coding_score": 6.79,
        "terminalbench_hard": 0.008,
        "tau2": 0.0,
        "lcr": 0.0,
        "hle": 4.4,
        "gpqa": 37.9,
        "scicode": 18.9,
        "ifbench": 37.1,
        "critpt": 0.0,
        "livecodebench": 19.8
      }
    },
    "confidence_score": 0.72,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-3-instruct-8b",
    "canonical_name": "Llama 3 Instruct 8B",
    "model_name": "Llama 3 Instruct 8B",
    "aliases": [
      "Llama 3 Instruct 8B"
    ],
    "provider": "Meta",
    "context_window": 8192,
    "open_source": true,
    "arena_votes": null,
    "license_type": "META LLAMA 3 COMMUNITY LICENSE AGREEMENT",
    "creator": null,
    "intelligence_score": 6.27,
    "coding_score": 3.98,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": 0.0,
    "tau2": 0.0,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.1,
    "gpqa": 29.6,
    "scicode": 11.9,
    "ifbench": 24.6,
    "aime25": null,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 9.6,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.269460+00:00",
        "confidence": 0.72,
        "raw_name": "Llama 3 Instruct 8B",
        "raw_scores": {
          "intelligence_score": 6.27,
          "coding_score": 3.98,
          "context_window": 8192,
          "terminalbench_hard": 0.0,
          "tau2": 0.0,
          "lcr": 0.0,
          "hle": 5.1,
          "gpqa": 29.6,
          "scicode": 11.9,
          "ifbench": 24.6,
          "critpt": 0.0,
          "livecodebench": 9.6
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 6.27,
        "coding_score": 3.98,
        "terminalbench_hard": 0.0,
        "tau2": 0.0,
        "lcr": 0.0,
        "hle": 5.1,
        "gpqa": 29.6,
        "scicode": 11.9,
        "ifbench": 24.6,
        "critpt": 0.0,
        "livecodebench": 9.6
      }
    },
    "confidence_score": 0.72,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-32-instruct-1b",
    "canonical_name": "Llama 3.2 Instruct 1B",
    "model_name": "Llama 3.2 Instruct 1B",
    "aliases": [
      "Llama 3.2 Instruct 1B"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "LLAMA 3.2 COMMUNITY LICENSE AGREEMENT",
    "creator": null,
    "intelligence_score": 6.28,
    "coding_score": 0.58,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": 0.0,
    "tau2": 0.0,
    "lcr": 5.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.3,
    "gpqa": 19.6,
    "scicode": 1.7,
    "ifbench": 22.8,
    "aime25": 0.0,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 1.9,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.269495+00:00",
        "confidence": 0.79,
        "raw_name": "Llama 3.2 Instruct 1B",
        "raw_scores": {
          "intelligence_score": 6.28,
          "coding_score": 0.58,
          "context_window": 128000,
          "terminalbench_hard": 0.0,
          "tau2": 0.0,
          "lcr": 5.0,
          "hle": 5.3,
          "gpqa": 19.6,
          "scicode": 1.7,
          "ifbench": 22.8,
          "aime25": 0.0,
          "critpt": 0.0,
          "livecodebench": 1.9
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 6.28,
        "coding_score": 0.58,
        "terminalbench_hard": 0.0,
        "tau2": 0.0,
        "lcr": 5.0,
        "hle": 5.3,
        "gpqa": 19.6,
        "scicode": 1.7,
        "ifbench": 22.8,
        "aime25": 0.0,
        "critpt": 0.0,
        "livecodebench": 1.9
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-2-chat-70b",
    "canonical_name": "Llama 2 Chat 70B",
    "model_name": "Llama 2 Chat 70B",
    "aliases": [
      "Llama 2 Chat 70B"
    ],
    "provider": "Meta",
    "context_window": 4096,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Llama 2 Community License Agreement",
    "creator": null,
    "intelligence_score": 7.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.0,
    "gpqa": 32.7,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 9.8,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.269523+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "Llama 2 Chat 70B",
        "raw_scores": {
          "intelligence_score": 7.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 4096,
          "hle": 5.0,
          "gpqa": 32.7,
          "livecodebench": 9.8
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 7.0,
        "hle": 5.0,
        "gpqa": 32.7,
        "livecodebench": 9.8
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-2-chat-13b",
    "canonical_name": "Llama 2 Chat 13B",
    "model_name": "Llama 2 Chat 13B",
    "aliases": [
      "Llama 2 Chat 13B"
    ],
    "provider": "Meta",
    "context_window": 4096,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Llama 2 Community License Agreement",
    "creator": null,
    "intelligence_score": 5.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.7,
    "gpqa": 32.1,
    "scicode": 11.8,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 9.8,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.269552+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "Llama 2 Chat 13B",
        "raw_scores": {
          "intelligence_score": 5.0,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 4096,
          "hle": 4.7,
          "gpqa": 32.1,
          "scicode": 11.8,
          "livecodebench": 9.8
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 5.0,
        "hle": 4.7,
        "gpqa": 32.1,
        "scicode": 11.8,
        "livecodebench": 9.8
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-2-chat-7b",
    "canonical_name": "Llama 2 Chat 7B",
    "model_name": "Llama 2 Chat 7B",
    "aliases": [
      "Llama 2 Chat 7B"
    ],
    "provider": "Meta",
    "context_window": 4096,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Llama 2 Community License Agreement",
    "creator": null,
    "intelligence_score": 4.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.1,
    "latency_seconds": 0.54,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 112.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.8,
    "gpqa": 22.7,
    "scicode": 0.0,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 0.2,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.269580+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "Llama 2 Chat 7B",
        "raw_scores": {
          "intelligence_score": 4.0,
          "blended_cost_per_1m": 0.1,
          "latency_seconds": 0.54,
          "tokens_per_second": 112.0,
          "context_window": 4096,
          "hle": 5.8,
          "gpqa": 22.7,
          "scicode": 0.0,
          "livecodebench": 0.2
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 4.0,
        "hle": 5.8,
        "gpqa": 22.7,
        "scicode": 0.0,
        "livecodebench": 0.2
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemini-20-pro-experimental",
    "canonical_name": "Gemini 2.0 Pro Experimental (Feb '25)",
    "model_name": "Gemini 2.0 Pro Experimental (Feb '25)",
    "aliases": [
      "Gemini 2.0 Pro Experimental (Feb '25)"
    ],
    "provider": "Google",
    "context_window": 2000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 18.0526,
    "coding_score": 25.5479,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 6.8,
    "gpqa": 62.2,
    "scicode": 31.2,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 34.7,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.269610+00:00",
        "confidence": 0.72,
        "raw_name": "Gemini 2.0 Pro Experimental (Feb '25)",
        "raw_scores": {
          "intelligence_score": 18.052648552336592,
          "coding_score": 25.5478568,
          "context_window": 2000000,
          "hle": 6.8,
          "gpqa": 62.2,
          "scicode": 31.2,
          "livecodebench": 34.7
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 18.052648552336592,
        "coding_score": 25.5478568,
        "hle": 6.8,
        "gpqa": 62.2,
        "scicode": 31.2,
        "livecodebench": 34.7
      }
    },
    "confidence_score": 0.72,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemini-20-flash",
    "canonical_name": "Gemini 2.0 Flash (experimental)",
    "model_name": "Gemini 2.0 Flash (experimental)",
    "aliases": [
      "Gemini 2.0 Flash (Feb '25)",
      "Gemini 2.0 Flash (experimental)",
      "gemini-2.0-flash-001"
    ],
    "provider": "Google",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": 44686,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 17.7211,
    "coding_score": 13.64,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1360.82,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 624.9006,
    "terminalbench_hard": 0.038,
    "tau2": 0.295,
    "lcr": 28.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.0292,
    "gpqa": 62.8868,
    "scicode": 33.616,
    "ifbench": 40.2,
    "aime25": 21.7,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 27.8028,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.269637+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 2.0 Flash (experimental)",
        "raw_scores": {
          "intelligence_score": 16.7744977006624,
          "context_window": 1000000,
          "hle": 4.7,
          "gpqa": 63.6,
          "scicode": 34.0,
          "livecodebench": 21.0
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.269739+00:00",
        "confidence": 0.79,
        "raw_name": "Gemini 2.0 Flash (Feb '25)",
        "raw_scores": {
          "intelligence_score": 18.5,
          "coding_score": 13.64,
          "context_window": 1000000,
          "gdpval": 624.9006413888179,
          "terminalbench_hard": 0.038,
          "tau2": 0.295,
          "lcr": 28.3,
          "hle": 5.3,
          "gpqa": 62.3,
          "scicode": 33.3,
          "ifbench": 40.2,
          "aime25": 21.7,
          "critpt": 0.0,
          "livecodebench": 33.4
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126170+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-2.0-flash-001",
        "raw_scores": {
          "arena_elo": 1360.82,
          "arena_votes": 44686
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 16.7744977006624,
        "hle": 4.7,
        "gpqa": 63.6,
        "scicode": 34.0,
        "livecodebench": 21.0,
        "coding_score": 13.64,
        "gdpval": 624.9006413888179,
        "terminalbench_hard": 0.038,
        "tau2": 0.295,
        "lcr": 28.3,
        "ifbench": 40.2,
        "aime25": 21.7,
        "critpt": 0.0
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1360.82
      }
    },
    "confidence_score": 0.8133,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemini-15-pro",
    "canonical_name": "Gemini 1.5 Pro (Sep '24)",
    "model_name": "Gemini 1.5 Pro (Sep '24)",
    "aliases": [
      "Gemini 1.5 Pro (May '24)",
      "Gemini 1.5 Pro (Sep '24)",
      "gemini-1.5-pro-001",
      "gemini-1.5-pro-002"
    ],
    "provider": "Google",
    "context_window": 2000000,
    "open_source": null,
    "arena_votes": 79132,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 13.9949,
    "coding_score": 21.7064,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1337.245,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.4,
    "gpqa": 48.0,
    "scicode": 28.45,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": 55.0,
    "livecodebench": 28.0,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.269667+00:00",
        "confidence": 0.72,
        "raw_name": "Gemini 1.5 Pro (Sep '24)",
        "raw_scores": {
          "intelligence_score": 15.99411151166208,
          "coding_score": 23.6279234,
          "context_window": 2000000,
          "hle": 4.9,
          "gpqa": 58.9,
          "scicode": 29.5,
          "mmmu_pro": 55.0,
          "livecodebench": 31.6
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.269872+00:00",
        "confidence": 0.72,
        "raw_name": "Gemini 1.5 Pro (May '24)",
        "raw_scores": {
          "intelligence_score": 11.995643433356523,
          "coding_score": 19.7848523,
          "context_window": 2000000,
          "hle": 3.9,
          "gpqa": 37.1,
          "scicode": 27.4,
          "livecodebench": 24.4
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126297+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-1.5-pro-002",
        "raw_scores": {
          "arena_elo": 1351.36,
          "arena_votes": 55607
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126778+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-1.5-pro-001",
        "raw_scores": {
          "arena_elo": 1323.13,
          "arena_votes": 79132
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.99411151166208,
        "coding_score": 23.6279234,
        "hle": 4.9,
        "gpqa": 58.9,
        "scicode": 29.5,
        "mmmu_pro": 55.0,
        "livecodebench": 31.6
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1351.36
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemini-20-flash-lite",
    "canonical_name": "Gemini 2.0 Flash-Lite (Preview)",
    "model_name": "Gemini 2.0 Flash-Lite (Preview)",
    "aliases": [
      "Gemini 2.0 Flash-Lite (Feb '25)",
      "Gemini 2.0 Flash-Lite (Preview)"
    ],
    "provider": "Google",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 14.5797,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.0556,
    "gpqa": 53.8987,
    "scicode": 24.8291,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 18.1583,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.269698+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "Gemini 2.0 Flash-Lite (Preview)",
        "raw_scores": {
          "intelligence_score": 14.487085601010705,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000,
          "hle": 4.4,
          "gpqa": 54.2,
          "scicode": 24.7,
          "livecodebench": 17.9
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.270280+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 2.0 Flash-Lite (Feb '25)",
        "raw_scores": {
          "intelligence_score": 14.702194584063244,
          "context_window": 1000000,
          "hle": 3.6,
          "gpqa": 53.5,
          "scicode": 25.0,
          "livecodebench": 18.5
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.487085601010705,
        "hle": 4.4,
        "gpqa": 54.2,
        "scicode": 24.7,
        "livecodebench": 17.9
      }
    },
    "confidence_score": 0.755,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemini-15-flash",
    "canonical_name": "Gemini 1.5 Flash (Sep '24)",
    "model_name": "Gemini 1.5 Flash (Sep '24)",
    "aliases": [
      "Gemini 1.5 Flash (May '24)",
      "Gemini 1.5 Flash (Sep '24)",
      "gemini-1.5-flash-001",
      "gemini-1.5-flash-002"
    ],
    "provider": "Google",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": 62823,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 12.1263,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1297.73,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 3.85,
    "gpqa": 39.35,
    "scicode": 22.4,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": 48.4,
    "livecodebench": 23.45,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.269769+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 1.5 Flash (Sep '24)",
        "raw_scores": {
          "intelligence_score": 13.791318335280737,
          "context_window": 1000000,
          "hle": 3.5,
          "gpqa": 46.3,
          "scicode": 26.7,
          "mmmu_pro": 48.4,
          "livecodebench": 27.3
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.270076+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 1.5 Flash (May '24)",
        "raw_scores": {
          "intelligence_score": 10.46126910425808,
          "context_window": 1000000,
          "hle": 4.2,
          "gpqa": 32.4,
          "scicode": 18.1,
          "livecodebench": 19.6
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127019+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-1.5-flash-002",
        "raw_scores": {
          "arena_elo": 1309.8,
          "arena_votes": 34909
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127310+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-1.5-flash-001",
        "raw_scores": {
          "arena_elo": 1285.66,
          "arena_votes": 62823
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.791318335280737,
        "hle": 3.5,
        "gpqa": 46.3,
        "scicode": 26.7,
        "mmmu_pro": 48.4,
        "livecodebench": 27.3
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1309.8
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemini-15-flash-8b",
    "canonical_name": "Gemini 1.5 Flash-8B",
    "model_name": "Gemini 1.5 Flash-8B",
    "aliases": [
      "Gemini 1.5 Flash-8B"
    ],
    "provider": "Google",
    "context_window": 1048576,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 11.1317,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.5,
    "gpqa": 35.9,
    "scicode": 22.9,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": 36.5,
    "livecodebench": 21.7,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.269801+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "Gemini 1.5 Flash-8B",
        "raw_scores": {
          "intelligence_score": 11.131677468292837,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1048576,
          "hle": 4.5,
          "gpqa": 35.9,
          "scicode": 22.9,
          "mmmu_pro": 36.5,
          "livecodebench": 21.7
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 11.131677468292837,
        "hle": 4.5,
        "gpqa": 35.9,
        "scicode": 22.9,
        "mmmu_pro": 36.5,
        "livecodebench": 21.7
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemini-25-flash-lite",
    "canonical_name": "Gemini 2.5 Flash-Lite (Non-reasoning)",
    "model_name": "Gemini 2.5 Flash-Lite (Non-reasoning)",
    "aliases": [
      "Gemini 2.5 Flash-Lite (Non-reasoning)",
      "Gemini 2.5 Flash-Lite (Reasoning)"
    ],
    "provider": "Google",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 14.975,
    "coding_score": 8.445,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 369.8115,
    "terminalbench_hard": 0.034,
    "tau2": 0.187,
    "lcr": 41.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.05,
    "gpqa": 54.95,
    "scicode": 18.5,
    "ifbench": 40.7,
    "aime25": 44.3,
    "critpt": 0.0,
    "mmmu_pro": 56.1,
    "livecodebench": 49.65,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.269841+00:00",
        "confidence": 0.79,
        "raw_name": "Gemini 2.5 Flash-Lite (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 12.52,
          "coding_score": 7.42,
          "context_window": 1000000,
          "gdpval": 366.73187680947467,
          "terminalbench_hard": 0.023,
          "tau2": 0.19,
          "lcr": 31.3,
          "hle": 3.7,
          "gpqa": 47.4,
          "scicode": 17.7,
          "ifbench": 31.5,
          "aime25": 35.3,
          "critpt": 0.0,
          "mmmu_pro": 54.0,
          "livecodebench": 40.0
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.269914+00:00",
        "confidence": 0.79,
        "raw_name": "Gemini 2.5 Flash-Lite (Reasoning)",
        "raw_scores": {
          "intelligence_score": 17.43,
          "coding_score": 9.47,
          "context_window": 1000000,
          "gdpval": 372.89107712368855,
          "terminalbench_hard": 0.045,
          "tau2": 0.184,
          "lcr": 51.3,
          "hle": 6.4,
          "gpqa": 62.5,
          "scicode": 19.3,
          "ifbench": 49.9,
          "aime25": 53.3,
          "critpt": 0.0,
          "mmmu_pro": 58.2,
          "livecodebench": 59.3
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.52,
        "coding_score": 7.42,
        "gdpval": 366.73187680947467,
        "terminalbench_hard": 0.023,
        "tau2": 0.19,
        "lcr": 31.3,
        "hle": 3.7,
        "gpqa": 47.4,
        "scicode": 17.7,
        "ifbench": 31.5,
        "aime25": 35.3,
        "critpt": 0.0,
        "mmmu_pro": 54.0,
        "livecodebench": 40.0
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemini-20-flash-thinking-experimental",
    "canonical_name": "Gemini 2.0 Flash Thinking Experimental (Dec '24)",
    "model_name": "Gemini 2.0 Flash Thinking Experimental (Dec '24)",
    "aliases": [
      "Gemini 2.0 Flash Thinking Experimental (Dec '24)",
      "Gemini 2.0 Flash Thinking Experimental (Jan '25)"
    ],
    "provider": "Google",
    "context_window": 2000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 16.8448,
    "coding_score": 24.1093,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 7.1,
    "gpqa": 70.1,
    "scicode": 32.9,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 32.1,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.269933+00:00",
        "confidence": 0.44,
        "raw_name": "Gemini 2.0 Flash Thinking Experimental (Dec '24)",
        "raw_scores": {
          "intelligence_score": 12.331778143209375,
          "context_window": 2000000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.270138+00:00",
        "confidence": 0.72,
        "raw_name": "Gemini 2.0 Flash Thinking Experimental (Jan '25)",
        "raw_scores": {
          "intelligence_score": 19.60282838932838,
          "coding_score": 24.1092929,
          "context_window": 1000000,
          "hle": 7.1,
          "gpqa": 70.1,
          "scicode": 32.9,
          "livecodebench": 32.1
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.331778143209375,
        "coding_score": 24.1092929,
        "hle": 7.1,
        "gpqa": 70.1,
        "scicode": 32.9,
        "livecodebench": 32.1
      }
    },
    "confidence_score": 0.58,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemini-25-flash-preview",
    "canonical_name": "Gemini 2.5 Flash Preview (Sep '25) (Reasoning)",
    "model_name": "Gemini 2.5 Flash Preview (Sep '25) (Reasoning)",
    "aliases": [
      "Gemini 2.5 Flash Preview (Non-reasoning)",
      "Gemini 2.5 Flash Preview (Reasoning)",
      "Gemini 2.5 Flash Preview (Sep '25) (Non-reasoning)",
      "Gemini 2.5 Flash Preview (Sep '25) (Reasoning)"
    ],
    "provider": "Google",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 25.0359,
    "coding_score": 23.355,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 984.5165,
    "terminalbench_hard": 0.1555,
    "tau2": 0.37,
    "lcr": 60.5,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 9.3698,
    "gpqa": 71.924,
    "scicode": 34.7569,
    "ifbench": 47.9,
    "aime25": 67.5,
    "critpt": 0.15,
    "mmmu_pro": 68.8372,
    "livecodebench": 57.2628,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.270019+00:00",
        "confidence": 0.79,
        "raw_name": "Gemini 2.5 Flash Preview (Sep '25) (Reasoning)",
        "raw_scores": {
          "intelligence_score": 31.09,
          "coding_score": 24.61,
          "context_window": 1000000,
          "gdpval": 1092.7719516665775,
          "terminalbench_hard": 0.167,
          "tau2": 0.456,
          "lcr": 64.3,
          "hle": 12.7,
          "gpqa": 79.3,
          "scicode": 40.5,
          "ifbench": 52.3,
          "aime25": 78.3,
          "critpt": 0.3,
          "mmmu_pro": 73.1,
          "livecodebench": 71.3
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.270180+00:00",
        "confidence": 0.79,
        "raw_name": "Gemini 2.5 Flash Preview (Sep '25) (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 25.51,
          "coding_score": 22.1,
          "context_window": 1000000,
          "gdpval": 876.261001725923,
          "terminalbench_hard": 0.144,
          "tau2": 0.284,
          "lcr": 56.7,
          "hle": 7.8,
          "gpqa": 76.6,
          "scicode": 37.5,
          "ifbench": 43.5,
          "aime25": 56.7,
          "critpt": 0.0,
          "mmmu_pro": 70.2,
          "livecodebench": 62.5
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.270210+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 2.5 Flash Preview (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 17.844790713497186,
          "context_window": 1000000,
          "hle": 5.0,
          "gpqa": 59.4,
          "scicode": 23.3,
          "mmmu_pro": 62.0,
          "livecodebench": 40.6
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.270351+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 2.5 Flash Preview (Reasoning)",
        "raw_scores": {
          "intelligence_score": 24.29283568571511,
          "context_window": 1000000,
          "hle": 11.6,
          "gpqa": 69.8,
          "scicode": 35.9,
          "livecodebench": 50.5
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 31.09,
        "coding_score": 24.61,
        "gdpval": 1092.7719516665775,
        "terminalbench_hard": 0.167,
        "tau2": 0.456,
        "lcr": 64.3,
        "hle": 12.7,
        "gpqa": 79.3,
        "scicode": 40.5,
        "ifbench": 52.3,
        "aime25": 78.3,
        "critpt": 0.3,
        "mmmu_pro": 73.1,
        "livecodebench": 71.3
      }
    },
    "confidence_score": 0.72,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemma-3n-e4b-instruct-preview",
    "canonical_name": "Gemma 3n E4B Instruct Preview (May '25)",
    "model_name": "Gemma 3n E4B Instruct Preview (May '25)",
    "aliases": [
      "Gemma 3n E4B Instruct Preview (May '25)"
    ],
    "provider": "Google",
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 10.059,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.9,
    "gpqa": 27.8,
    "scicode": 8.6,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 13.8,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.270048+00:00",
        "confidence": 0.65,
        "raw_name": "Gemma 3n E4B Instruct Preview (May '25)",
        "raw_scores": {
          "intelligence_score": 10.058952665396129,
          "context_window": 32000,
          "hle": 4.9,
          "gpqa": 27.8,
          "scicode": 8.6,
          "livecodebench": 13.8
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.058952665396129,
        "hle": 4.9,
        "gpqa": 27.8,
        "scicode": 8.6,
        "livecodebench": 13.8
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemini-10-pro",
    "canonical_name": "Gemini 1.0 Pro",
    "model_name": "Gemini 1.0 Pro",
    "aliases": [
      "Gemini 1.0 Pro"
    ],
    "provider": "Google",
    "context_window": 32768,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 8.5018,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.6,
    "gpqa": 27.7,
    "scicode": 11.7,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 11.6,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.270109+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "Gemini 1.0 Pro",
        "raw_scores": {
          "intelligence_score": 8.501805478425053,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32768,
          "hle": 4.6,
          "gpqa": 27.7,
          "scicode": 11.7,
          "livecodebench": 11.6
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.501805478425053,
        "hle": 4.6,
        "gpqa": 27.7,
        "scicode": 11.7,
        "livecodebench": 11.6
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemini-25-pro-preview",
    "canonical_name": "Gemini 2.5 Pro Preview (May' 25)",
    "model_name": "Gemini 2.5 Pro Preview (May' 25)",
    "aliases": [
      "Gemini 2.5 Pro Preview (Mar' 25)",
      "Gemini 2.5 Pro Preview (May' 25)"
    ],
    "provider": "Google",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 29.9408,
    "coding_score": 46.7293,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 16.2934,
    "gpqa": 82.9358,
    "scicode": 40.4964,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 77.4204,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.270238+00:00",
        "confidence": 0.65,
        "raw_name": "Gemini 2.5 Pro Preview (May' 25)",
        "raw_scores": {
          "intelligence_score": 29.54758250414228,
          "context_window": 1000000,
          "hle": 15.4,
          "gpqa": 82.2,
          "scicode": 41.6,
          "livecodebench": 77.0
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.270381+00:00",
        "confidence": 0.72,
        "raw_name": "Gemini 2.5 Pro Preview (Mar' 25)",
        "raw_scores": {
          "intelligence_score": 30.295702949046902,
          "coding_score": 46.7292835,
          "context_window": 1000000,
          "hle": 17.1,
          "gpqa": 83.6,
          "scicode": 39.5,
          "livecodebench": 77.8
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 29.54758250414228,
        "hle": 15.4,
        "gpqa": 82.2,
        "scicode": 41.6,
        "livecodebench": 77.0,
        "coding_score": 46.7292835
      }
    },
    "confidence_score": 0.685,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemini-25-flash",
    "canonical_name": "Gemini 2.5 Flash (Non-reasoning)",
    "model_name": "Gemini 2.5 Flash (Non-reasoning)",
    "aliases": [
      "Gemini 2.5 Flash (Non-reasoning)",
      "Gemini 2.5 Flash (Reasoning)",
      "gemini-2.5-flash",
      "gemini-2.5-flash-preview-09-2025"
    ],
    "provider": "Google",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": 95890,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 23.675,
    "coding_score": 19.985,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1407.635,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 734.3409,
    "terminalbench_hard": 0.1285,
    "tau2": 0.2325,
    "lcr": 53.8,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 8.1,
    "gpqa": 73.65,
    "scicode": 34.25,
    "ifbench": 44.65,
    "aime25": 66.8,
    "critpt": 1.25,
    "mmmu_pro": 67.3,
    "livecodebench": 59.5,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.270322+00:00",
        "confidence": 0.79,
        "raw_name": "Gemini 2.5 Flash (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 20.54,
          "coding_score": 17.76,
          "context_window": 1000000,
          "gdpval": 759.4623371446949,
          "terminalbench_hard": 0.121,
          "tau2": 0.149,
          "lcr": 45.9,
          "hle": 5.1,
          "gpqa": 68.3,
          "scicode": 29.1,
          "ifbench": 39.0,
          "aime25": 60.3,
          "critpt": 1.4,
          "mmmu_pro": 65.5,
          "livecodebench": 49.5
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.270473+00:00",
        "confidence": 0.79,
        "raw_name": "Gemini 2.5 Flash (Reasoning)",
        "raw_scores": {
          "intelligence_score": 26.81,
          "coding_score": 22.21,
          "context_window": 1000000,
          "gdpval": 709.2194383648553,
          "terminalbench_hard": 0.136,
          "tau2": 0.316,
          "lcr": 61.7,
          "hle": 11.1,
          "gpqa": 79.0,
          "scicode": 39.4,
          "ifbench": 50.3,
          "aime25": 73.3,
          "critpt": 1.1,
          "mmmu_pro": 69.1,
          "livecodebench": 69.5
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125375+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-2.5-flash",
        "raw_scores": {
          "arena_elo": 1411.0,
          "arena_votes": 95890
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125434+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-2.5-flash-preview-09-2025",
        "raw_scores": {
          "arena_elo": 1404.27,
          "arena_votes": 32547
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 20.54,
        "coding_score": 17.76,
        "gdpval": 759.4623371446949,
        "terminalbench_hard": 0.121,
        "tau2": 0.149,
        "lcr": 45.9,
        "hle": 5.1,
        "gpqa": 68.3,
        "scicode": 29.1,
        "ifbench": 39.0,
        "aime25": 60.3,
        "critpt": 1.4,
        "mmmu_pro": 65.5,
        "livecodebench": 49.5
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1411.0
      }
    },
    "confidence_score": 0.895,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "palm-2",
    "canonical_name": "PALM-2",
    "model_name": "PALM-2",
    "aliases": [
      "PALM-2",
      "palm-2"
    ],
    "provider": "Google",
    "context_window": 8000,
    "open_source": null,
    "arena_votes": 8554,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 8.594,
    "coding_score": 4.5591,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1137.47,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.270405+00:00",
        "confidence": 0.72,
        "raw_name": "PALM-2",
        "raw_scores": {
          "intelligence_score": 8.594046799469973,
          "coding_score": 4.5591306,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 8000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128451+00:00",
        "confidence": 1.0,
        "raw_name": "palm-2",
        "raw_scores": {
          "arena_elo": 1137.47,
          "arena_votes": 8554
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.594046799469973,
        "coding_score": 4.5591306
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1137.47
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemini-10-ultra",
    "canonical_name": "Gemini 1.0 Ultra",
    "model_name": "Gemini 1.0 Ultra",
    "aliases": [
      "Gemini 1.0 Ultra"
    ],
    "provider": "Google",
    "context_window": 32768,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 10.1467,
    "coding_score": 17.6498,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.270431+00:00",
        "confidence": 0.72,
        "raw_name": "Gemini 1.0 Ultra",
        "raw_scores": {
          "intelligence_score": 10.146700927796493,
          "coding_score": 17.6497963,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32768
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.146700927796493,
        "coding_score": 17.6497963
      }
    },
    "confidence_score": 0.72,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "claude-35-sonnet",
    "canonical_name": "Claude 3.5 Sonnet (Oct '24)",
    "model_name": "Claude 3.5 Sonnet (Oct '24)",
    "aliases": [
      "Claude 3.5 Sonnet (June '24)",
      "Claude 3.5 Sonnet (Oct '24)",
      "claude-3.5-sonnet-20241022"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 89295,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 15.0935,
    "coding_score": 28.2088,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1372.54,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 3.8051,
    "gpqa": 58.0496,
    "scicode": 34.2277,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 38.1,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.270501+00:00",
        "confidence": 0.72,
        "raw_name": "Claude 3.5 Sonnet (Oct '24)",
        "raw_scores": {
          "intelligence_score": 15.926898851351913,
          "coding_score": 30.1638764,
          "context_window": 200000,
          "hle": 3.9,
          "gpqa": 59.9,
          "scicode": 36.6,
          "livecodebench": 38.1
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.270530+00:00",
        "confidence": 0.65,
        "raw_name": "Claude 3.5 Sonnet (June '24)",
        "raw_scores": {
          "intelligence_score": 14.170308711536471,
          "coding_score": 26.0431282,
          "context_window": 200000,
          "hle": 3.7,
          "gpqa": 56.0,
          "scicode": 31.6
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126037+00:00",
        "confidence": 1.0,
        "raw_name": "claude-3.5-sonnet-20241022",
        "raw_scores": {
          "arena_elo": 1372.54,
          "arena_votes": 89295
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.926898851351913,
        "coding_score": 30.1638764,
        "hle": 3.9,
        "gpqa": 59.9,
        "scicode": 36.6,
        "livecodebench": 38.1
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1372.54
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "claude-3-opus",
    "canonical_name": "Claude 3 Opus",
    "model_name": "Claude 3 Opus",
    "aliases": [
      "Claude 3 Opus",
      "claude-3-opus-20240229"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 194904,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 12.4525,
    "coding_score": 19.5267,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1322.18,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 30.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 3.1,
    "gpqa": 48.9,
    "scicode": 23.3,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 27.9,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.270565+00:00",
        "confidence": 0.9300000000000002,
        "raw_name": "Claude 3 Opus",
        "raw_scores": {
          "intelligence_score": 12.452455969031023,
          "coding_score": 19.5266898,
          "blended_cost_per_1m": 30.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 200000,
          "hle": 3.1,
          "gpqa": 48.9,
          "scicode": 23.3,
          "livecodebench": 27.9
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126803+00:00",
        "confidence": 1.0,
        "raw_name": "claude-3-opus-20240229",
        "raw_scores": {
          "arena_elo": 1322.18,
          "arena_votes": 194904
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.452455969031023,
        "coding_score": 19.5266898,
        "hle": 3.1,
        "gpqa": 48.9,
        "scicode": 23.3,
        "livecodebench": 27.9
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1322.18
      }
    },
    "confidence_score": 0.965,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "claude-35-haiku",
    "canonical_name": "Claude 3.5 Haiku",
    "model_name": "Claude 3.5 Haiku",
    "aliases": [
      "Claude 3.5 Haiku",
      "claude-3.5-haiku-20241022"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 70978,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 18.67,
    "coding_score": 10.66,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1323.59,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.6,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 763.8109,
    "terminalbench_hard": 0.023,
    "tau2": 0.246,
    "lcr": 23.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 3.5,
    "gpqa": 40.8,
    "scicode": 27.4,
    "ifbench": 42.8,
    "aime25": null,
    "critpt": 0.0,
    "mmmu_pro": 45.6,
    "livecodebench": 31.4,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.270608+00:00",
        "confidence": 0.9300000000000002,
        "raw_name": "Claude 3.5 Haiku",
        "raw_scores": {
          "intelligence_score": 18.67,
          "coding_score": 10.66,
          "blended_cost_per_1m": 1.6,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 200000,
          "gdpval": 763.8108571585316,
          "terminalbench_hard": 0.023,
          "tau2": 0.246,
          "lcr": 23.3,
          "hle": 3.5,
          "gpqa": 40.8,
          "scicode": 27.4,
          "ifbench": 42.8,
          "critpt": 0.0,
          "mmmu_pro": 45.6,
          "livecodebench": 31.4
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126752+00:00",
        "confidence": 1.0,
        "raw_name": "claude-3.5-haiku-20241022",
        "raw_scores": {
          "arena_elo": 1323.59,
          "arena_votes": 70978
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 18.67,
        "coding_score": 10.66,
        "gdpval": 763.8108571585316,
        "terminalbench_hard": 0.023,
        "tau2": 0.246,
        "lcr": 23.3,
        "hle": 3.5,
        "gpqa": 40.8,
        "scicode": 27.4,
        "ifbench": 42.8,
        "critpt": 0.0,
        "mmmu_pro": 45.6,
        "livecodebench": 31.4
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1323.59
      }
    },
    "confidence_score": 0.965,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "claude-3-sonnet",
    "canonical_name": "Claude 3 Sonnet",
    "model_name": "Claude 3 Sonnet",
    "aliases": [
      "Claude 3 Sonnet"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 10.2703,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 6.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 3.8,
    "gpqa": 40.0,
    "scicode": 22.9,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 17.5,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.270642+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "Claude 3 Sonnet",
        "raw_scores": {
          "intelligence_score": 10.270295671896926,
          "blended_cost_per_1m": 6.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 200000,
          "hle": 3.8,
          "gpqa": 40.0,
          "scicode": 22.9,
          "livecodebench": 17.5
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.270295671896926,
        "hle": 3.8,
        "gpqa": 40.0,
        "scicode": 22.9,
        "livecodebench": 17.5
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "claude-3-haiku",
    "canonical_name": "Claude 3 Haiku",
    "model_name": "Claude 3 Haiku",
    "aliases": [
      "Claude 3 Haiku"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 12.1,
    "coding_score": 6.72,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.5,
    "latency_seconds": 0.42,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 120.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 433.4527,
    "terminalbench_hard": 0.008,
    "tau2": 0.211,
    "lcr": 21.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 3.9,
    "gpqa": 37.4,
    "scicode": 18.6,
    "ifbench": 36.1,
    "aime25": null,
    "critpt": 0.0,
    "mmmu_pro": 30.8,
    "livecodebench": 15.4,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.270682+00:00",
        "confidence": 0.9300000000000002,
        "raw_name": "Claude 3 Haiku",
        "raw_scores": {
          "intelligence_score": 12.1,
          "coding_score": 6.72,
          "blended_cost_per_1m": 0.5,
          "latency_seconds": 0.42,
          "tokens_per_second": 120.0,
          "context_window": 200000,
          "gdpval": 433.4526886724086,
          "terminalbench_hard": 0.008,
          "tau2": 0.211,
          "lcr": 21.0,
          "hle": 3.9,
          "gpqa": 37.4,
          "scicode": 18.6,
          "ifbench": 36.1,
          "critpt": 0.0,
          "mmmu_pro": 30.8,
          "livecodebench": 15.4
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.1,
        "coding_score": 6.72,
        "gdpval": 433.4526886724086,
        "terminalbench_hard": 0.008,
        "tau2": 0.211,
        "lcr": 21.0,
        "hle": 3.9,
        "gpqa": 37.4,
        "scicode": 18.6,
        "ifbench": 36.1,
        "critpt": 0.0,
        "mmmu_pro": 30.8,
        "livecodebench": 15.4
      }
    },
    "confidence_score": 0.93,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "claude-instant",
    "canonical_name": "Claude Instant",
    "model_name": "Claude Instant",
    "aliases": [
      "Claude Instant"
    ],
    "provider": "Anthropic",
    "context_window": 100000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 7.4139,
    "coding_score": 7.7554,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 3.8,
    "gpqa": 33.0,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 10.9,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.270713+00:00",
        "confidence": 0.9300000000000002,
        "raw_name": "Claude Instant",
        "raw_scores": {
          "intelligence_score": 7.413887665229345,
          "coding_score": 7.7553606,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 100000,
          "hle": 3.8,
          "gpqa": 33.0,
          "livecodebench": 10.9
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 7.413887665229345,
        "coding_score": 7.7553606,
        "hle": 3.8,
        "gpqa": 33.0,
        "livecodebench": 10.9
      }
    },
    "confidence_score": 0.93,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "claude-37-sonnet",
    "canonical_name": "Claude 3.7 Sonnet (Non-reasoning)",
    "model_name": "Claude 3.7 Sonnet (Non-reasoning)",
    "aliases": [
      "Claude 3.7 Sonnet (Non-reasoning)",
      "Claude 3.7 Sonnet (Reasoning)",
      "claude-3.7-sonnet-20250219"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 44271,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 32.675,
    "coding_score": 27.125,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1371.55,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 1066.5398,
    "terminalbench_hard": 0.212,
    "tau2": 0.5235,
    "lcr": 54.5,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 7.55,
    "gpqa": 71.4,
    "scicode": 38.95,
    "ifbench": 46.15,
    "aime25": 38.65,
    "critpt": 0.45,
    "mmmu_pro": 60.1,
    "livecodebench": 43.35,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.270754+00:00",
        "confidence": 0.79,
        "raw_name": "Claude 3.7 Sonnet (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 30.75,
          "coding_score": 26.68,
          "context_window": 200000,
          "gdpval": 1068.150862185076,
          "terminalbench_hard": 0.212,
          "tau2": 0.5,
          "lcr": 48.3,
          "hle": 4.8,
          "gpqa": 65.6,
          "scicode": 37.6,
          "ifbench": 44.0,
          "aime25": 21.0,
          "critpt": 0.0,
          "mmmu_pro": 60.1,
          "livecodebench": 39.4
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.271093+00:00",
        "confidence": 0.79,
        "raw_name": "Claude 3.7 Sonnet (Reasoning)",
        "raw_scores": {
          "intelligence_score": 34.6,
          "coding_score": 27.57,
          "context_window": 200000,
          "gdpval": 1064.9288251878947,
          "terminalbench_hard": 0.212,
          "tau2": 0.547,
          "lcr": 60.7,
          "hle": 10.3,
          "gpqa": 77.2,
          "scicode": 40.3,
          "ifbench": 48.3,
          "aime25": 56.3,
          "critpt": 0.9,
          "livecodebench": 47.3
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126068+00:00",
        "confidence": 1.0,
        "raw_name": "claude-3.7-sonnet-20250219",
        "raw_scores": {
          "arena_elo": 1371.55,
          "arena_votes": 44271
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 30.75,
        "coding_score": 26.68,
        "gdpval": 1068.150862185076,
        "terminalbench_hard": 0.212,
        "tau2": 0.5,
        "lcr": 48.3,
        "hle": 4.8,
        "gpqa": 65.6,
        "scicode": 37.6,
        "ifbench": 44.0,
        "aime25": 21.0,
        "critpt": 0.0,
        "mmmu_pro": 60.1,
        "livecodebench": 39.4
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1371.55
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "claude-45-sonnet",
    "canonical_name": "Claude 4.5 Sonnet (Non-reasoning)",
    "model_name": "Claude 4.5 Sonnet (Non-reasoning)",
    "aliases": [
      "Claude 4.5 Sonnet (Non-reasoning)",
      "Claude 4.5 Sonnet (Reasoning)"
    ],
    "provider": "Anthropic",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 39.99,
    "coding_score": 36.05,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 1297.4521,
    "terminalbench_hard": 0.322,
    "tau2": 0.743,
    "lcr": 58.5,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 12.2,
    "gpqa": 78.05,
    "scicode": 43.75,
    "ifbench": 50.0,
    "aime25": 62.5,
    "critpt": 0.55,
    "mmmu_pro": 66.95,
    "livecodebench": 65.2,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.270794+00:00",
        "confidence": 0.79,
        "raw_name": "Claude 4.5 Sonnet (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 37.06,
          "coding_score": 33.47,
          "context_window": 1000000,
          "gdpval": 1319.2956855638495,
          "terminalbench_hard": 0.288,
          "tau2": 0.705,
          "lcr": 51.3,
          "hle": 7.1,
          "gpqa": 72.7,
          "scicode": 42.8,
          "ifbench": 42.7,
          "aime25": 37.0,
          "critpt": 0.0,
          "mmmu_pro": 65.2,
          "livecodebench": 59.0
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.271198+00:00",
        "confidence": 0.79,
        "raw_name": "Claude 4.5 Sonnet (Reasoning)",
        "raw_scores": {
          "intelligence_score": 42.92,
          "coding_score": 38.63,
          "context_window": 1000000,
          "gdpval": 1275.6086138003407,
          "terminalbench_hard": 0.356,
          "tau2": 0.781,
          "lcr": 65.7,
          "hle": 17.3,
          "gpqa": 83.4,
          "scicode": 44.7,
          "ifbench": 57.3,
          "aime25": 88.0,
          "critpt": 1.1,
          "mmmu_pro": 68.7,
          "livecodebench": 71.4
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 37.06,
        "coding_score": 33.47,
        "gdpval": 1319.2956855638495,
        "terminalbench_hard": 0.288,
        "tau2": 0.705,
        "lcr": 51.3,
        "hle": 7.1,
        "gpqa": 72.7,
        "scicode": 42.8,
        "ifbench": 42.7,
        "aime25": 37.0,
        "critpt": 0.0,
        "mmmu_pro": 65.2,
        "livecodebench": 59.0
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "claude-4-sonnet",
    "canonical_name": "Claude 4 Sonnet (Non-reasoning)",
    "model_name": "Claude 4 Sonnet (Non-reasoning)",
    "aliases": [
      "Claude 4 Sonnet (Non-reasoning)",
      "Claude 4 Sonnet (Reasoning)"
    ],
    "provider": "Anthropic",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 35.76,
    "coding_score": 32.33,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 1156.2937,
    "terminalbench_hard": 0.292,
    "tau2": 0.5845,
    "lcr": 54.5,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 6.8,
    "gpqa": 73.0,
    "scicode": 38.65,
    "ifbench": 50.05,
    "aime25": 56.15,
    "critpt": 0.7,
    "mmmu_pro": 62.1,
    "livecodebench": 55.2,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.270836+00:00",
        "confidence": 0.79,
        "raw_name": "Claude 4 Sonnet (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 32.96,
          "coding_score": 30.6,
          "context_window": 1000000,
          "gdpval": 1161.1750703631078,
          "terminalbench_hard": 0.273,
          "tau2": 0.523,
          "lcr": 44.3,
          "hle": 4.0,
          "gpqa": 68.3,
          "scicode": 37.3,
          "ifbench": 45.4,
          "aime25": 38.0,
          "critpt": 1.1,
          "mmmu_pro": 62.4,
          "livecodebench": 44.9
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.271296+00:00",
        "confidence": 0.79,
        "raw_name": "Claude 4 Sonnet (Reasoning)",
        "raw_scores": {
          "intelligence_score": 38.56,
          "coding_score": 34.06,
          "context_window": 1000000,
          "gdpval": 1151.4123702390045,
          "terminalbench_hard": 0.311,
          "tau2": 0.646,
          "lcr": 64.7,
          "hle": 9.6,
          "gpqa": 77.7,
          "scicode": 40.0,
          "ifbench": 54.7,
          "aime25": 74.3,
          "critpt": 0.3,
          "mmmu_pro": 61.8,
          "livecodebench": 65.5
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 32.96,
        "coding_score": 30.6,
        "gdpval": 1161.1750703631078,
        "terminalbench_hard": 0.273,
        "tau2": 0.523,
        "lcr": 44.3,
        "hle": 4.0,
        "gpqa": 68.3,
        "scicode": 37.3,
        "ifbench": 45.4,
        "aime25": 38.0,
        "critpt": 1.1,
        "mmmu_pro": 62.4,
        "livecodebench": 44.9
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "claude-opus-4",
    "canonical_name": "Claude 4 Opus (Non-reasoning)",
    "model_name": "Claude 4 Opus (Non-reasoning)",
    "aliases": [
      "Claude 4 Opus (Non-reasoning)",
      "Claude 4 Opus (Reasoning)",
      "claude-opus-4-20250514",
      "claude-opus-4-20250514-thinking-16k"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 45304,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 24.8868,
    "coding_score": 33.98,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1418.505,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": 0.311,
    "tau2": 0.705,
    "lcr": 34.7967,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 8.9344,
    "gpqa": 75.0702,
    "scicode": 40.3245,
    "ifbench": 48.7411,
    "aime25": 55.6576,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 59.1179,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.270871+00:00",
        "confidence": 0.72,
        "raw_name": "Claude 4 Opus (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 22.171205776538883,
          "context_window": 200000,
          "lcr": 36.0,
          "hle": 5.9,
          "gpqa": 70.1,
          "scicode": 40.9,
          "ifbench": 43.3,
          "aime25": 36.3,
          "livecodebench": 54.2
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.271334+00:00",
        "confidence": 0.79,
        "raw_name": "Claude 4 Opus (Reasoning)",
        "raw_scores": {
          "intelligence_score": 27.361794173399694,
          "coding_score": 33.98,
          "context_window": 200000,
          "terminalbench_hard": 0.311,
          "tau2": 0.705,
          "lcr": 33.7,
          "hle": 11.7,
          "gpqa": 79.6,
          "scicode": 39.8,
          "ifbench": 53.7,
          "aime25": 73.3,
          "livecodebench": 63.6
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125085+00:00",
        "confidence": 1.0,
        "raw_name": "claude-opus-4-20250514-thinking-16k",
        "raw_scores": {
          "arena_elo": 1423.89,
          "arena_votes": 37723
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125336+00:00",
        "confidence": 1.0,
        "raw_name": "claude-opus-4-20250514",
        "raw_scores": {
          "arena_elo": 1413.12,
          "arena_votes": 45304
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 22.171205776538883,
        "lcr": 36.0,
        "hle": 5.9,
        "gpqa": 70.1,
        "scicode": 40.9,
        "ifbench": 43.3,
        "aime25": 36.3,
        "livecodebench": 54.2,
        "coding_score": 33.98,
        "terminalbench_hard": 0.311,
        "tau2": 0.705
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1423.89
      }
    },
    "confidence_score": 0.8775,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "claude-opus-41",
    "canonical_name": "Claude 4.1 Opus (Reasoning)",
    "model_name": "Claude 4.1 Opus (Reasoning)",
    "aliases": [
      "Claude 4.1 Opus (Non-reasoning)",
      "Claude 4.1 Opus (Reasoning)",
      "claude-opus-4.1-20250805",
      "claude-opus-4.1-20250805-thinking-16k"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 77081,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 28.9111,
    "coding_score": 36.52,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1447.515,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": 0.343,
    "tau2": 0.714,
    "lcr": 66.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 11.9,
    "gpqa": 80.9,
    "scicode": 40.9,
    "ifbench": 55.4,
    "aime25": 80.3,
    "critpt": 0.0,
    "mmmu_pro": 67.9,
    "livecodebench": 65.4,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.270913+00:00",
        "confidence": 0.79,
        "raw_name": "Claude 4.1 Opus (Reasoning)",
        "raw_scores": {
          "intelligence_score": 31.888270712229925,
          "coding_score": 36.52,
          "context_window": 200000,
          "terminalbench_hard": 0.343,
          "tau2": 0.714,
          "lcr": 66.3,
          "hle": 11.9,
          "gpqa": 80.9,
          "scicode": 40.9,
          "ifbench": 55.4,
          "aime25": 80.3,
          "critpt": 0.0,
          "mmmu_pro": 67.9,
          "livecodebench": 65.4
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.271114+00:00",
        "confidence": 0.44,
        "raw_name": "Claude 4.1 Opus (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 23.565610165346172,
          "context_window": 200000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.124835+00:00",
        "confidence": 1.0,
        "raw_name": "claude-opus-4.1-20250805-thinking-16k",
        "raw_scores": {
          "arena_elo": 1448.71,
          "arena_votes": 49616
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.124852+00:00",
        "confidence": 1.0,
        "raw_name": "claude-opus-4.1-20250805",
        "raw_scores": {
          "arena_elo": 1446.32,
          "arena_votes": 77081
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 31.888270712229925,
        "coding_score": 36.52,
        "terminalbench_hard": 0.343,
        "tau2": 0.714,
        "lcr": 66.3,
        "hle": 11.9,
        "gpqa": 80.9,
        "scicode": 40.9,
        "ifbench": 55.4,
        "aime25": 80.3,
        "critpt": 0.0,
        "mmmu_pro": 67.9,
        "livecodebench": 65.4
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1448.71
      }
    },
    "confidence_score": 0.8075,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "claude-opus-45",
    "canonical_name": "Claude Opus 4.5 (Non-reasoning)",
    "model_name": "Claude Opus 4.5 (Non-reasoning)",
    "aliases": [
      "Claude Opus 4.5 (Non-reasoning)",
      "Claude Opus 4.5 (Reasoning)",
      "claude-opus-4.5-20251101",
      "claude-opus-4.5-20251101-thinking-32k"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": 34720,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 46.37,
    "coding_score": 45.385,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1469.375,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 1408.0567,
    "terminalbench_hard": 0.4395,
    "tau2": 0.879,
    "lcr": 69.65,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 20.65,
    "gpqa": 83.8,
    "scicode": 48.25,
    "ifbench": 50.5,
    "aime25": 77.0,
    "critpt": 2.45,
    "mmmu_pro": 72.6,
    "livecodebench": 80.45,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.271156+00:00",
        "confidence": 0.79,
        "raw_name": "Claude Opus 4.5 (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 43.05,
          "coding_score": 42.94,
          "context_window": 200000,
          "gdpval": 1416.0977341083603,
          "terminalbench_hard": 0.409,
          "tau2": 0.863,
          "lcr": 65.3,
          "hle": 12.9,
          "gpqa": 81.0,
          "scicode": 47.0,
          "ifbench": 43.0,
          "aime25": 62.7,
          "critpt": 0.3,
          "mmmu_pro": 71.2,
          "livecodebench": 73.8
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.271240+00:00",
        "confidence": 0.79,
        "raw_name": "Claude Opus 4.5 (Reasoning)",
        "raw_scores": {
          "intelligence_score": 49.69,
          "coding_score": 47.83,
          "context_window": 200000,
          "gdpval": 1400.015736858286,
          "terminalbench_hard": 0.47,
          "tau2": 0.895,
          "lcr": 74.0,
          "hle": 28.4,
          "gpqa": 86.6,
          "scicode": 49.5,
          "ifbench": 58.0,
          "aime25": 91.3,
          "critpt": 4.6,
          "mmmu_pro": 74.0,
          "livecodebench": 87.1
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.124625+00:00",
        "confidence": 1.0,
        "raw_name": "claude-opus-4.5-20251101-thinking-32k",
        "raw_scores": {
          "arena_elo": 1471.59,
          "arena_votes": 29789
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.124643+00:00",
        "confidence": 1.0,
        "raw_name": "claude-opus-4.5-20251101",
        "raw_scores": {
          "arena_elo": 1467.16,
          "arena_votes": 34720
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 43.05,
        "coding_score": 42.94,
        "gdpval": 1416.0977341083603,
        "terminalbench_hard": 0.409,
        "tau2": 0.863,
        "lcr": 65.3,
        "hle": 12.9,
        "gpqa": 81.0,
        "scicode": 47.0,
        "ifbench": 43.0,
        "aime25": 62.7,
        "critpt": 0.3,
        "mmmu_pro": 71.2,
        "livecodebench": 73.8
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1471.59
      }
    },
    "confidence_score": 0.895,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "claude-21",
    "canonical_name": "Claude 2.1",
    "model_name": "Claude 2.1",
    "aliases": [
      "Claude 2.1"
    ],
    "provider": "Anthropic",
    "context_window": 200000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 9.3247,
    "coding_score": 14.0194,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.2,
    "gpqa": 31.9,
    "scicode": 18.4,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 19.5,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.271367+00:00",
        "confidence": 0.9300000000000002,
        "raw_name": "Claude 2.1",
        "raw_scores": {
          "intelligence_score": 9.324651438021968,
          "coding_score": 14.019371,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 200000,
          "hle": 4.2,
          "gpqa": 31.9,
          "scicode": 18.4,
          "livecodebench": 19.5
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.324651438021968,
        "coding_score": 14.019371,
        "hle": 4.2,
        "gpqa": 31.9,
        "scicode": 18.4,
        "livecodebench": 19.5
      }
    },
    "confidence_score": 0.93,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "claude-20",
    "canonical_name": "Claude 2.0",
    "model_name": "Claude 2.0",
    "aliases": [
      "Claude 2.0"
    ],
    "provider": "Anthropic",
    "context_window": 100000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 9.0586,
    "coding_score": 12.8597,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": 34.4,
    "scicode": 19.4,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 17.1,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.271397+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "Claude 2.0",
        "raw_scores": {
          "intelligence_score": 9.058555199878974,
          "coding_score": 12.8596855,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 100000,
          "gpqa": 34.4,
          "scicode": 19.4,
          "livecodebench": 17.1
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.058555199878974,
        "coding_score": 12.8596855,
        "gpqa": 34.4,
        "scicode": 19.4,
        "livecodebench": 17.1
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "mistral-large-2",
    "canonical_name": "Mistral Large 2 (Nov '24)",
    "model_name": "Mistral Large 2 (Nov '24)",
    "aliases": [
      "Mistral Large 2 (Jul '24)",
      "Mistral Large 2 (Nov '24)"
    ],
    "provider": "Mistral AI",
    "context_window": 128000,
    "open_source": false,
    "arena_votes": null,
    "license_type": "Mistral Research License",
    "creator": null,
    "intelligence_score": 14.0883,
    "coding_score": 13.76,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 386.0259,
    "terminalbench_hard": 0.061,
    "tau2": 0.318,
    "lcr": 3.5834,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 3.6185,
    "gpqa": 47.9325,
    "scicode": 28.1987,
    "ifbench": 31.3907,
    "aime25": 7.3245,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 28.0603,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.271440+00:00",
        "confidence": 0.79,
        "raw_name": "Mistral Large 2 (Nov '24)",
        "raw_scores": {
          "intelligence_score": 15.05,
          "coding_score": 13.76,
          "context_window": 128000,
          "gdpval": 386.02590141043595,
          "terminalbench_hard": 0.061,
          "tau2": 0.307,
          "lcr": 5.3,
          "hle": 4.0,
          "gpqa": 48.6,
          "scicode": 29.2,
          "ifbench": 31.2,
          "aime25": 14.0,
          "critpt": 0.0,
          "livecodebench": 29.3
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.271474+00:00",
        "confidence": 0.72,
        "raw_name": "Mistral Large 2 (Jul '24)",
        "raw_scores": {
          "intelligence_score": 13.033082438627458,
          "context_window": 128000,
          "tau2": 0.33,
          "lcr": 1.7,
          "hle": 3.2,
          "gpqa": 47.2,
          "scicode": 27.1,
          "ifbench": 31.6,
          "aime25": 0.0,
          "livecodebench": 26.7
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.05,
        "coding_score": 13.76,
        "gdpval": 386.02590141043595,
        "terminalbench_hard": 0.061,
        "tau2": 0.307,
        "lcr": 5.3,
        "hle": 4.0,
        "gpqa": 48.6,
        "scicode": 29.2,
        "ifbench": 31.2,
        "aime25": 14.0,
        "critpt": 0.0,
        "livecodebench": 29.3
      }
    },
    "confidence_score": 0.755,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "pixtral-large",
    "canonical_name": "Pixtral Large",
    "model_name": "Pixtral Large",
    "aliases": [
      "Pixtral Large"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": false,
    "arena_votes": null,
    "license_type": "Mistral Research License",
    "creator": null,
    "intelligence_score": 14.0002,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.0,
    "latency_seconds": 0.44,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 49.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": 0.365,
    "lcr": 10.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 3.6,
    "gpqa": 50.5,
    "scicode": 29.2,
    "ifbench": 34.5,
    "aime25": 2.3,
    "critpt": null,
    "mmmu_pro": 50.6,
    "livecodebench": 26.1,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.271514+00:00",
        "confidence": 0.9300000000000002,
        "raw_name": "Pixtral Large",
        "raw_scores": {
          "intelligence_score": 14.000187381306647,
          "blended_cost_per_1m": 3.0,
          "latency_seconds": 0.44,
          "tokens_per_second": 49.0,
          "context_window": 128000,
          "tau2": 0.365,
          "lcr": 10.3,
          "hle": 3.6,
          "gpqa": 50.5,
          "scicode": 29.2,
          "ifbench": 34.5,
          "aime25": 2.3,
          "mmmu_pro": 50.6,
          "livecodebench": 26.1
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.000187381306647,
        "tau2": 0.365,
        "lcr": 10.3,
        "hle": 3.6,
        "gpqa": 50.5,
        "scicode": 29.2,
        "ifbench": 34.5,
        "aime25": 2.3,
        "mmmu_pro": 50.6,
        "livecodebench": 26.1
      }
    },
    "confidence_score": 0.93,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "mistral-small-3",
    "canonical_name": "Mistral Small 3",
    "model_name": "Mistral Small 3",
    "aliases": [
      "Mistral Small 3"
    ],
    "provider": "Mistral AI",
    "context_window": 32000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 12.6671,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.15,
    "latency_seconds": 0.35,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 234.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": 0.196,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.1,
    "gpqa": 46.2,
    "scicode": 23.6,
    "ifbench": 26.4,
    "aime25": 4.3,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 25.2,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.271552+00:00",
        "confidence": 0.9300000000000002,
        "raw_name": "Mistral Small 3",
        "raw_scores": {
          "intelligence_score": 12.667127328098278,
          "blended_cost_per_1m": 0.15,
          "latency_seconds": 0.35,
          "tokens_per_second": 234.0,
          "context_window": 32000,
          "tau2": 0.196,
          "lcr": 0.0,
          "hle": 4.1,
          "gpqa": 46.2,
          "scicode": 23.6,
          "ifbench": 26.4,
          "aime25": 4.3,
          "livecodebench": 25.2
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.667127328098278,
        "tau2": 0.196,
        "lcr": 0.0,
        "hle": 4.1,
        "gpqa": 46.2,
        "scicode": 23.6,
        "ifbench": 26.4,
        "aime25": 4.3,
        "livecodebench": 25.2
      }
    },
    "confidence_score": 0.93,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "mistral-small",
    "canonical_name": "Mistral Small (Sep '24)",
    "model_name": "Mistral Small (Sep '24)",
    "aliases": [
      "Mistral Small (Feb '24)",
      "Mistral Small (Sep '24)"
    ],
    "provider": "Mistral AI",
    "context_window": 32768,
    "open_source": false,
    "arena_votes": null,
    "license_type": "Mistral Research License",
    "creator": null,
    "intelligence_score": 9.6092,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.35,
    "gpqa": 34.15,
    "scicode": 14.5,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 12.6,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.271581+00:00",
        "confidence": 0.65,
        "raw_name": "Mistral Small (Sep '24)",
        "raw_scores": {
          "intelligence_score": 10.178799016274557,
          "context_window": 32768,
          "hle": 4.3,
          "gpqa": 38.1,
          "scicode": 15.6,
          "livecodebench": 14.1
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.271637+00:00",
        "confidence": 0.65,
        "raw_name": "Mistral Small (Feb '24)",
        "raw_scores": {
          "intelligence_score": 9.039501606668157,
          "context_window": 32768,
          "hle": 4.4,
          "gpqa": 30.2,
          "scicode": 13.4,
          "livecodebench": 11.1
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.178799016274557,
        "hle": 4.3,
        "gpqa": 38.1,
        "scicode": 15.6,
        "livecodebench": 14.1
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "mixtral-8x22b-instruct",
    "canonical_name": "Mixtral 8x22B Instruct",
    "model_name": "Mixtral 8x22B Instruct",
    "aliases": [
      "Mixtral 8x22B Instruct"
    ],
    "provider": "Mistral AI",
    "context_window": 65384,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 9.8442,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.1,
    "gpqa": 33.2,
    "scicode": 18.8,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 14.8,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.271609+00:00",
        "confidence": 0.65,
        "raw_name": "Mixtral 8x22B Instruct",
        "raw_scores": {
          "intelligence_score": 9.844182670676119,
          "context_window": 65384,
          "hle": 4.1,
          "gpqa": 33.2,
          "scicode": 18.8,
          "livecodebench": 14.8
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.844182670676119,
        "hle": 4.1,
        "gpqa": 33.2,
        "scicode": 18.8,
        "livecodebench": 14.8
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "mistral-large",
    "canonical_name": "Mistral Large (Feb '24)",
    "model_name": "Mistral Large (Feb '24)",
    "aliases": [
      "Mistral Large (Feb '24)"
    ],
    "provider": "Mistral AI",
    "context_window": 32768,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 9.9092,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 3.4,
    "gpqa": 35.1,
    "scicode": 20.8,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 17.8,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.271665+00:00",
        "confidence": 0.65,
        "raw_name": "Mistral Large (Feb '24)",
        "raw_scores": {
          "intelligence_score": 9.90917085347575,
          "context_window": 32768,
          "hle": 3.4,
          "gpqa": 35.1,
          "scicode": 20.8,
          "livecodebench": 17.8
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.90917085347575,
        "hle": 3.4,
        "gpqa": 35.1,
        "scicode": 20.8,
        "livecodebench": 17.8
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "mixtral-8x7b-instruct",
    "canonical_name": "Mixtral 8x7B Instruct",
    "model_name": "Mixtral 8x7B Instruct",
    "aliases": [
      "Mixtral 8x7B Instruct"
    ],
    "provider": "Mistral AI",
    "context_window": 32768,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 7.7312,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.5,
    "gpqa": 29.2,
    "scicode": 2.8,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 6.6,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.271693+00:00",
        "confidence": 0.65,
        "raw_name": "Mixtral 8x7B Instruct",
        "raw_scores": {
          "intelligence_score": 7.731195590246845,
          "context_window": 32768,
          "hle": 4.5,
          "gpqa": 29.2,
          "scicode": 2.8,
          "livecodebench": 6.6
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 7.731195590246845,
        "hle": 4.5,
        "gpqa": 29.2,
        "scicode": 2.8,
        "livecodebench": 6.6
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "mistral-7b-instruct",
    "canonical_name": "Mistral 7B Instruct",
    "model_name": "Mistral 7B Instruct",
    "aliases": [
      "Mistral 7B Instruct",
      "mistral-7b-instruct"
    ],
    "provider": "Mistral",
    "context_window": 8192,
    "open_source": true,
    "arena_votes": 8977,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 7.4139,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1109.9,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": 0.0,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.3,
    "gpqa": 17.7,
    "scicode": 2.4,
    "ifbench": 19.9,
    "aime25": null,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 4.6,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.271725+00:00",
        "confidence": 0.65,
        "raw_name": "Mistral 7B Instruct",
        "raw_scores": {
          "intelligence_score": 7.413887665229345,
          "context_window": 8192,
          "tau2": 0.0,
          "lcr": 0.0,
          "hle": 4.3,
          "gpqa": 17.7,
          "scicode": 2.4,
          "ifbench": 19.9,
          "critpt": 0.0,
          "livecodebench": 4.6
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128626+00:00",
        "confidence": 1.0,
        "raw_name": "mistral-7b-instruct",
        "raw_scores": {
          "arena_elo": 1109.9,
          "arena_votes": 8977
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 7.413887665229345,
        "tau2": 0.0,
        "lcr": 0.0,
        "hle": 4.3,
        "gpqa": 17.7,
        "scicode": 2.4,
        "ifbench": 19.9,
        "critpt": 0.0,
        "livecodebench": 4.6
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1109.9
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "mistral-small-31",
    "canonical_name": "Mistral Small 3.1",
    "model_name": "Mistral Small 3.1",
    "aliases": [
      "Mistral Small 3.1"
    ],
    "provider": "Mistral AI",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 14.39,
    "coding_score": 13.89,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.15,
    "latency_seconds": 0.29,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 130.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 393.9885,
    "terminalbench_hard": 0.076,
    "tau2": 0.251,
    "lcr": 19.7,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.8,
    "gpqa": 45.4,
    "scicode": 26.5,
    "ifbench": 29.9,
    "aime25": 3.7,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 21.2,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.271768+00:00",
        "confidence": 1.0,
        "raw_name": "Mistral Small 3.1",
        "raw_scores": {
          "intelligence_score": 14.39,
          "coding_score": 13.89,
          "blended_cost_per_1m": 0.15,
          "latency_seconds": 0.29,
          "tokens_per_second": 130.0,
          "context_window": 128000,
          "gdpval": 393.98852621720334,
          "terminalbench_hard": 0.076,
          "tau2": 0.251,
          "lcr": 19.7,
          "hle": 4.8,
          "gpqa": 45.4,
          "scicode": 26.5,
          "ifbench": 29.9,
          "aime25": 3.7,
          "critpt": 0.0,
          "livecodebench": 21.2
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.39,
        "coding_score": 13.89,
        "gdpval": 393.98852621720334,
        "terminalbench_hard": 0.076,
        "tau2": 0.251,
        "lcr": 19.7,
        "hle": 4.8,
        "gpqa": 45.4,
        "scicode": 26.5,
        "ifbench": 29.9,
        "aime25": 3.7,
        "critpt": 0.0,
        "livecodebench": 21.2
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "magistral-small-1",
    "canonical_name": "Magistral Small 1",
    "model_name": "Magistral Small 1",
    "aliases": [
      "Magistral Small 1"
    ],
    "provider": null,
    "context_window": 40000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 16.7916,
    "coding_score": 11.05,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": 0.045,
    "tau2": 0.266,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 7.2,
    "gpqa": 64.1,
    "scicode": 24.1,
    "ifbench": 24.8,
    "aime25": 41.3,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 51.4,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.271814+00:00",
        "confidence": 1.0,
        "raw_name": "Magistral Small 1",
        "raw_scores": {
          "intelligence_score": 16.791620007828033,
          "coding_score": 11.05,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 40000,
          "terminalbench_hard": 0.045,
          "tau2": 0.266,
          "lcr": 0.0,
          "hle": 7.2,
          "gpqa": 64.1,
          "scicode": 24.1,
          "ifbench": 24.8,
          "aime25": 41.3,
          "critpt": 0.0,
          "livecodebench": 51.4
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 16.791620007828033,
        "coding_score": 11.05,
        "terminalbench_hard": 0.045,
        "tau2": 0.266,
        "lcr": 0.0,
        "hle": 7.2,
        "gpqa": 64.1,
        "scicode": 24.1,
        "ifbench": 24.8,
        "aime25": 41.3,
        "critpt": 0.0,
        "livecodebench": 51.4
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "devstral-small",
    "canonical_name": "Devstral Small (Jul '25)",
    "model_name": "Devstral Small (Jul '25)",
    "aliases": [
      "Devstral Small (Jul '25)",
      "Devstral Small (May '25)"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 16.5446,
    "coding_score": 12.1781,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 733.9725,
    "terminalbench_hard": 0.061,
    "tau2": 0.3298,
    "lcr": 21.6252,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 3.843,
    "gpqa": 42.3536,
    "scicode": 24.3954,
    "ifbench": 33.1695,
    "aime25": 29.3,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 25.5907,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.271853+00:00",
        "confidence": 0.79,
        "raw_name": "Devstral Small (Jul '25)",
        "raw_scores": {
          "intelligence_score": 15.2,
          "coding_score": 12.14,
          "context_window": 256000,
          "gdpval": 613.876312663865,
          "terminalbench_hard": 0.061,
          "tau2": 0.284,
          "lcr": 17.0,
          "hle": 3.7,
          "gpqa": 41.4,
          "scicode": 24.3,
          "ifbench": 34.6,
          "aime25": 29.3,
          "critpt": 0.0,
          "livecodebench": 25.4
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.272046+00:00",
        "confidence": 0.72,
        "raw_name": "Devstral Small (May '25)",
        "raw_scores": {
          "intelligence_score": 18.02,
          "coding_score": 12.22,
          "context_window": 256000,
          "gdpval": 865.7446301117379,
          "terminalbench_hard": 0.061,
          "tau2": 0.38,
          "lcr": 26.7,
          "hle": 4.0,
          "gpqa": 43.4,
          "scicode": 24.5,
          "ifbench": 31.6,
          "critpt": 0.0,
          "livecodebench": 25.8
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.2,
        "coding_score": 12.14,
        "gdpval": 613.876312663865,
        "terminalbench_hard": 0.061,
        "tau2": 0.284,
        "lcr": 17.0,
        "hle": 3.7,
        "gpqa": 41.4,
        "scicode": 24.3,
        "ifbench": 34.6,
        "aime25": 29.3,
        "critpt": 0.0,
        "livecodebench": 25.4
      }
    },
    "confidence_score": 0.755,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "mistral-saba",
    "canonical_name": "Mistral Saba",
    "model_name": "Mistral Saba",
    "aliases": [
      "Mistral Saba"
    ],
    "provider": "Mistral AI",
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 12.129,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.1,
    "gpqa": 42.4,
    "scicode": 24.1,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.271889+00:00",
        "confidence": 0.79,
        "raw_name": "Mistral Saba",
        "raw_scores": {
          "intelligence_score": 12.128983524455348,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32000,
          "hle": 4.1,
          "gpqa": 42.4,
          "scicode": 24.1
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.128983524455348,
        "hle": 4.1,
        "gpqa": 42.4,
        "scicode": 24.1
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "devstral-medium",
    "canonical_name": "Devstral Medium",
    "model_name": "Devstral Medium",
    "aliases": [
      "Devstral Medium"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 18.62,
    "coding_score": 15.86,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.8,
    "latency_seconds": 0.43,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 112.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 743.9865,
    "terminalbench_hard": 0.091,
    "tau2": 0.199,
    "lcr": 28.7,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 3.8,
    "gpqa": 49.2,
    "scicode": 29.4,
    "ifbench": 29.9,
    "aime25": 4.7,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 33.7,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.271931+00:00",
        "confidence": 1.0,
        "raw_name": "Devstral Medium",
        "raw_scores": {
          "intelligence_score": 18.62,
          "coding_score": 15.86,
          "blended_cost_per_1m": 0.8,
          "latency_seconds": 0.43,
          "tokens_per_second": 112.0,
          "context_window": 256000,
          "gdpval": 743.9865302424693,
          "terminalbench_hard": 0.091,
          "tau2": 0.199,
          "lcr": 28.7,
          "hle": 3.8,
          "gpqa": 49.2,
          "scicode": 29.4,
          "ifbench": 29.9,
          "aime25": 4.7,
          "critpt": 0.0,
          "livecodebench": 33.7
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 18.62,
        "coding_score": 15.86,
        "gdpval": 743.9865302424693,
        "terminalbench_hard": 0.091,
        "tau2": 0.199,
        "lcr": 28.7,
        "hle": 3.8,
        "gpqa": 49.2,
        "scicode": 29.4,
        "ifbench": 29.9,
        "aime25": 4.7,
        "critpt": 0.0,
        "livecodebench": 33.7
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "mistral-medium-3",
    "canonical_name": "Mistral Medium 3",
    "model_name": "Mistral Medium 3",
    "aliases": [
      "Mistral Medium 3"
    ],
    "provider": "Mistral AI",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 18.73,
    "coding_score": 13.56,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.8,
    "latency_seconds": 0.39,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 79.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 647.1915,
    "terminalbench_hard": 0.038,
    "tau2": 0.243,
    "lcr": 28.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.3,
    "gpqa": 57.8,
    "scicode": 33.1,
    "ifbench": 39.3,
    "aime25": 30.3,
    "critpt": 0.0,
    "mmmu_pro": 53.0,
    "livecodebench": 40.0,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.271975+00:00",
        "confidence": 1.0,
        "raw_name": "Mistral Medium 3",
        "raw_scores": {
          "intelligence_score": 18.73,
          "coding_score": 13.56,
          "blended_cost_per_1m": 0.8,
          "latency_seconds": 0.39,
          "tokens_per_second": 79.0,
          "context_window": 128000,
          "gdpval": 647.191497881223,
          "terminalbench_hard": 0.038,
          "tau2": 0.243,
          "lcr": 28.0,
          "hle": 4.3,
          "gpqa": 57.8,
          "scicode": 33.1,
          "ifbench": 39.3,
          "aime25": 30.3,
          "critpt": 0.0,
          "mmmu_pro": 53.0,
          "livecodebench": 40.0
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 18.73,
        "coding_score": 13.56,
        "gdpval": 647.191497881223,
        "terminalbench_hard": 0.038,
        "tau2": 0.243,
        "lcr": 28.0,
        "hle": 4.3,
        "gpqa": 57.8,
        "scicode": 33.1,
        "ifbench": 39.3,
        "aime25": 30.3,
        "critpt": 0.0,
        "mmmu_pro": 53.0,
        "livecodebench": 40.0
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "mistral-medium",
    "canonical_name": "Mistral Medium",
    "model_name": "Mistral Medium",
    "aliases": [
      "Mistral Medium",
      "mistral-medium",
      "mistral-medium-2508"
    ],
    "provider": "Mistral",
    "context_window": 32768,
    "open_source": null,
    "arena_votes": 64949,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 9.011,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1317.165,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 4.09,
    "latency_seconds": 0.39,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 97.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 3.4,
    "gpqa": 34.9,
    "scicode": 11.8,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 9.9,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.272008+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "Mistral Medium",
        "raw_scores": {
          "intelligence_score": 9.010996334814534,
          "blended_cost_per_1m": 4.09,
          "latency_seconds": 0.39,
          "tokens_per_second": 97.0,
          "context_window": 32768,
          "hle": 3.4,
          "gpqa": 34.9,
          "scicode": 11.8,
          "livecodebench": 9.9
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125363+00:00",
        "confidence": 1.0,
        "raw_name": "mistral-medium-2508",
        "raw_scores": {
          "arena_elo": 1411.09,
          "arena_votes": 64949
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127778+00:00",
        "confidence": 1.0,
        "raw_name": "mistral-medium",
        "raw_scores": {
          "arena_elo": 1223.24,
          "arena_votes": 34552
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.010996334814534,
        "hle": 3.4,
        "gpqa": 34.9,
        "scicode": 11.8,
        "livecodebench": 9.9
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1411.09
      }
    },
    "confidence_score": 0.9533,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "magistral-medium-1",
    "canonical_name": "Magistral Medium 1",
    "model_name": "Magistral Medium 1",
    "aliases": [
      "Magistral Medium 1"
    ],
    "provider": null,
    "context_window": 40000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 18.73,
    "coding_score": 15.96,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 2.75,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 711.9373,
    "terminalbench_hard": 0.091,
    "tau2": 0.231,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 9.5,
    "gpqa": 67.9,
    "scicode": 29.7,
    "ifbench": 25.1,
    "aime25": 40.3,
    "critpt": 0.3,
    "mmmu_pro": null,
    "livecodebench": 52.7,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.272089+00:00",
        "confidence": 1.0,
        "raw_name": "Magistral Medium 1",
        "raw_scores": {
          "intelligence_score": 18.73,
          "coding_score": 15.96,
          "blended_cost_per_1m": 2.75,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 40000,
          "gdpval": 711.9373246499536,
          "terminalbench_hard": 0.091,
          "tau2": 0.231,
          "lcr": 0.0,
          "hle": 9.5,
          "gpqa": 67.9,
          "scicode": 29.7,
          "ifbench": 25.1,
          "aime25": 40.3,
          "critpt": 0.3,
          "livecodebench": 52.7
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 18.73,
        "coding_score": 15.96,
        "gdpval": 711.9373246499536,
        "terminalbench_hard": 0.091,
        "tau2": 0.231,
        "lcr": 0.0,
        "hle": 9.5,
        "gpqa": 67.9,
        "scicode": 29.7,
        "ifbench": 25.1,
        "aime25": 40.3,
        "critpt": 0.3,
        "livecodebench": 52.7
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-r1-distill-qwen-32b",
    "canonical_name": "DeepSeek R1 Distill Qwen 32B",
    "model_name": "DeepSeek R1 Distill Qwen 32B",
    "aliases": [
      "DeepSeek R1 Distill Qwen 32B"
    ],
    "provider": "Alibaba",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 17.1667,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.27,
    "latency_seconds": 0.25,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 57.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": 9.7,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.5,
    "gpqa": 61.5,
    "scicode": 37.6,
    "ifbench": 22.9,
    "aime25": 63.0,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 27.0,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.272126+00:00",
        "confidence": 0.9300000000000002,
        "raw_name": "DeepSeek R1 Distill Qwen 32B",
        "raw_scores": {
          "intelligence_score": 17.166714190986596,
          "blended_cost_per_1m": 0.27,
          "latency_seconds": 0.25,
          "tokens_per_second": 57.0,
          "context_window": 128000,
          "lcr": 9.7,
          "hle": 5.5,
          "gpqa": 61.5,
          "scicode": 37.6,
          "ifbench": 22.9,
          "aime25": 63.0,
          "livecodebench": 27.0
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 17.166714190986596,
        "lcr": 9.7,
        "hle": 5.5,
        "gpqa": 61.5,
        "scicode": 37.6,
        "ifbench": 22.9,
        "aime25": 63.0,
        "livecodebench": 27.0
      }
    },
    "confidence_score": 0.93,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-v3",
    "canonical_name": "DeepSeek V3 (Dec '24)",
    "model_name": "DeepSeek V3 (Dec '24)",
    "aliases": [
      "DeepSeek V3 (Dec '24)",
      "deepseek-v3"
    ],
    "provider": "DeepSeek",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": 21788,
    "license_type": "DEEPSEEK LICENSE AGREEMENT",
    "creator": null,
    "intelligence_score": 16.39,
    "coding_score": 16.35,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1358.54,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 477.6691,
    "terminalbench_hard": 0.068,
    "tau2": 0.228,
    "lcr": 29.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 3.6,
    "gpqa": 55.7,
    "scicode": 35.4,
    "ifbench": 34.8,
    "aime25": 26.0,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 35.9,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.272168+00:00",
        "confidence": 0.79,
        "raw_name": "DeepSeek V3 (Dec '24)",
        "raw_scores": {
          "intelligence_score": 16.39,
          "coding_score": 16.35,
          "context_window": 128000,
          "gdpval": 477.66908740790177,
          "terminalbench_hard": 0.068,
          "tau2": 0.228,
          "lcr": 29.0,
          "hle": 3.6,
          "gpqa": 55.7,
          "scicode": 35.4,
          "ifbench": 34.8,
          "aime25": 26.0,
          "critpt": 0.0,
          "livecodebench": 35.9
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126182+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-v3",
        "raw_scores": {
          "arena_elo": 1358.54,
          "arena_votes": 21788
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 16.39,
        "coding_score": 16.35,
        "gdpval": 477.66908740790177,
        "terminalbench_hard": 0.068,
        "tau2": 0.228,
        "lcr": 29.0,
        "hle": 3.6,
        "gpqa": 55.7,
        "scicode": 35.4,
        "ifbench": 34.8,
        "aime25": 26.0,
        "critpt": 0.0,
        "livecodebench": 35.9
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1358.54
      }
    },
    "confidence_score": 0.895,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-r1-distill-qwen-14b",
    "canonical_name": "DeepSeek R1 Distill Qwen 14B",
    "model_name": "DeepSeek R1 Distill Qwen 14B",
    "aliases": [
      "DeepSeek R1 Distill Qwen 14B"
    ],
    "provider": "Alibaba",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 15.8445,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": 7.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.4,
    "gpqa": 48.4,
    "scicode": 23.9,
    "ifbench": 22.1,
    "aime25": 55.7,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 37.6,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.272205+00:00",
        "confidence": 0.9300000000000002,
        "raw_name": "DeepSeek R1 Distill Qwen 14B",
        "raw_scores": {
          "intelligence_score": 15.844510353679771,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000,
          "lcr": 7.0,
          "hle": 4.4,
          "gpqa": 48.4,
          "scicode": 23.9,
          "ifbench": 22.1,
          "aime25": 55.7,
          "livecodebench": 37.6
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.844510353679771,
        "lcr": 7.0,
        "hle": 4.4,
        "gpqa": 48.4,
        "scicode": 23.9,
        "ifbench": 22.1,
        "aime25": 55.7,
        "livecodebench": 37.6
      }
    },
    "confidence_score": 0.93,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-v25",
    "canonical_name": "DeepSeek-V2.5 (Dec '24)",
    "model_name": "DeepSeek-V2.5 (Dec '24)",
    "aliases": [
      "DeepSeek-V2.5",
      "DeepSeek-V2.5 (Dec '24)",
      "deepseek-v2.5"
    ],
    "provider": "DeepSeek",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": 24574,
    "license_type": "DEEPSEEK LICENSE AGREEMENT",
    "creator": null,
    "intelligence_score": 12.4005,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1307.09,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.272225+00:00",
        "confidence": 0.44,
        "raw_name": "DeepSeek-V2.5 (Dec '24)",
        "raw_scores": {
          "intelligence_score": 12.511590737265823,
          "context_window": 128000
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.272422+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek-V2.5",
        "raw_scores": {
          "intelligence_score": 12.3252882665075,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127057+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-v2.5",
        "raw_scores": {
          "arena_elo": 1307.09,
          "arena_votes": 24574
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.511590737265823
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1307.09
      }
    },
    "confidence_score": 0.6967,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-coder-v2",
    "canonical_name": "DeepSeek-Coder-V2",
    "model_name": "DeepSeek-Coder-V2",
    "aliases": [
      "DeepSeek-Coder-V2",
      "deepseek-coder-v2"
    ],
    "provider": "DeepSeek",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": 15147,
    "license_type": "DEEPSEEK LICENSE AGREEMENT",
    "creator": null,
    "intelligence_score": 10.6082,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1264.42,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.272260+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek-Coder-V2",
        "raw_scores": {
          "intelligence_score": 10.608221945579603,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127487+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-coder-v2",
        "raw_scores": {
          "arena_elo": 1264.42,
          "arena_votes": 15147
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.608221945579603
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1264.42
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-r1-distill-llama-8b",
    "canonical_name": "DeepSeek R1 Distill Llama 8B",
    "model_name": "DeepSeek R1 Distill Llama 8B",
    "aliases": [
      "DeepSeek R1 Distill Llama 8B"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT",
    "creator": null,
    "intelligence_score": 12.1003,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.2,
    "gpqa": 30.2,
    "scicode": 11.9,
    "ifbench": 17.6,
    "aime25": 41.3,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 23.3,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.272297+00:00",
        "confidence": 0.9300000000000002,
        "raw_name": "DeepSeek R1 Distill Llama 8B",
        "raw_scores": {
          "intelligence_score": 12.10028639307147,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000,
          "lcr": 0.0,
          "hle": 4.2,
          "gpqa": 30.2,
          "scicode": 11.9,
          "ifbench": 17.6,
          "aime25": 41.3,
          "livecodebench": 23.3
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.10028639307147,
        "lcr": 0.0,
        "hle": 4.2,
        "gpqa": 30.2,
        "scicode": 11.9,
        "ifbench": 17.6,
        "aime25": 41.3,
        "livecodebench": 23.3
      }
    },
    "confidence_score": 0.93,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-llm-67b-chat",
    "canonical_name": "DeepSeek LLM 67B Chat (V1)",
    "model_name": "DeepSeek LLM 67B Chat (V1)",
    "aliases": [
      "DeepSeek LLM 67B Chat (V1)",
      "deepseek-llm-67b-chat"
    ],
    "provider": "DeepSeek",
    "context_window": 4096,
    "open_source": true,
    "arena_votes": 4933,
    "license_type": "DEEPSEEK LICENSE AGREEMENT",
    "creator": null,
    "intelligence_score": 8.3708,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1184.66,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.272316+00:00",
        "confidence": 0.44,
        "raw_name": "DeepSeek LLM 67B Chat (V1)",
        "raw_scores": {
          "intelligence_score": 8.370802665737399,
          "context_window": 4096
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128050+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-llm-67b-chat",
        "raw_scores": {
          "arena_elo": 1184.66,
          "arena_votes": 4933
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.370802665737399
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1184.66
      }
    },
    "confidence_score": 0.72,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-r1-distill-qwen-15b",
    "canonical_name": "DeepSeek R1 Distill Qwen 1.5B",
    "model_name": "DeepSeek R1 Distill Qwen 1.5B",
    "aliases": [
      "DeepSeek R1 Distill Qwen 1.5B"
    ],
    "provider": "Alibaba",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 9.0753,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": 0.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 3.3,
    "gpqa": 9.8,
    "scicode": 6.6,
    "ifbench": 13.2,
    "aime25": 22.0,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 7.0,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.272357+00:00",
        "confidence": 0.9300000000000002,
        "raw_name": "DeepSeek R1 Distill Qwen 1.5B",
        "raw_scores": {
          "intelligence_score": 9.075326286181491,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000,
          "lcr": 0.3,
          "hle": 3.3,
          "gpqa": 9.8,
          "scicode": 6.6,
          "ifbench": 13.2,
          "aime25": 22.0,
          "livecodebench": 7.0
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.075326286181491,
        "lcr": 0.3,
        "hle": 3.3,
        "gpqa": 9.8,
        "scicode": 6.6,
        "ifbench": 13.2,
        "aime25": 22.0,
        "livecodebench": 7.0
      }
    },
    "confidence_score": 0.93,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-v3-0324",
    "canonical_name": "DeepSeek V3 0324",
    "model_name": "DeepSeek V3 0324",
    "aliases": [
      "DeepSeek V3 0324",
      "deepseek-v3-0324"
    ],
    "provider": "DeepSeek",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": 46439,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": 21.81,
    "coding_score": 22.02,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1394.15,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.25,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 465.0103,
    "terminalbench_hard": 0.152,
    "tau2": 0.471,
    "lcr": 41.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.2,
    "gpqa": 65.5,
    "scicode": 35.8,
    "ifbench": 41.0,
    "aime25": 41.0,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 40.5,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.272400+00:00",
        "confidence": 1.0,
        "raw_name": "DeepSeek V3 0324",
        "raw_scores": {
          "intelligence_score": 21.81,
          "coding_score": 22.02,
          "blended_cost_per_1m": 1.25,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000,
          "gdpval": 465.0103030855703,
          "terminalbench_hard": 0.152,
          "tau2": 0.471,
          "lcr": 41.0,
          "hle": 5.2,
          "gpqa": 65.5,
          "scicode": 35.8,
          "ifbench": 41.0,
          "aime25": 41.0,
          "critpt": 0.0,
          "livecodebench": 40.5
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125593+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-v3-0324",
        "raw_scores": {
          "arena_elo": 1394.15,
          "arena_votes": 46439
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 21.81,
        "coding_score": 22.02,
        "gdpval": 465.0103030855703,
        "terminalbench_hard": 0.152,
        "tau2": 0.471,
        "lcr": 41.0,
        "hle": 5.2,
        "gpqa": 65.5,
        "scicode": 35.8,
        "ifbench": 41.0,
        "aime25": 41.0,
        "critpt": 0.0,
        "livecodebench": 40.5
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1394.15
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-v31",
    "canonical_name": "DeepSeek V3.1 (Non-reasoning)",
    "model_name": "DeepSeek V3.1 (Non-reasoning)",
    "aliases": [
      "DeepSeek V3.1 (Non-reasoning)",
      "DeepSeek V3.1 (Reasoning)",
      "DeepSeek V3.1 Terminus (Non-reasoning)",
      "DeepSeek V3.1 Terminus (Reasoning)",
      "deepseek-v3.1",
      "deepseek-v3.1-terminus",
      "deepseek-v3.1-terminus-thinking",
      "deepseek-v3.1-thinking"
    ],
    "provider": "DeepSeek",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": 15197,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": 29.4375,
    "coding_score": 30.935,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1416.7975,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 941.8796,
    "terminalbench_hard": 0.2782,
    "tau2": 0.366,
    "lcr": 51.65,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 10.725,
    "gpqa": 76.425,
    "scicode": 37.125,
    "ifbench": 44.375,
    "aime25": 70.7,
    "critpt": 0.925,
    "mmmu_pro": null,
    "livecodebench": 67.2,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.272541+00:00",
        "confidence": 0.79,
        "raw_name": "DeepSeek V3.1 (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 28.0,
          "coding_score": 28.39,
          "context_window": 128000,
          "gdpval": 1114.4490186096189,
          "terminalbench_hard": 0.242,
          "tau2": 0.348,
          "lcr": 45.0,
          "hle": 6.3,
          "gpqa": 73.5,
          "scicode": 36.7,
          "ifbench": 37.8,
          "aime25": 49.7,
          "critpt": 0.0,
          "livecodebench": 57.7
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.272583+00:00",
        "confidence": 0.79,
        "raw_name": "DeepSeek V3.1 Terminus (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 28.37,
          "coding_score": 31.9,
          "context_window": 128000,
          "gdpval": 990.4297329818044,
          "terminalbench_hard": 0.318,
          "tau2": 0.371,
          "lcr": 43.3,
          "hle": 8.4,
          "gpqa": 75.1,
          "scicode": 32.1,
          "ifbench": 41.2,
          "aime25": 53.7,
          "critpt": 0.0,
          "livecodebench": 52.9
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.272624+00:00",
        "confidence": 0.79,
        "raw_name": "DeepSeek V3.1 (Reasoning)",
        "raw_scores": {
          "intelligence_score": 27.59,
          "coding_score": 29.71,
          "context_window": 128000,
          "gdpval": 636.6598039978802,
          "terminalbench_hard": 0.25,
          "tau2": 0.374,
          "lcr": 53.3,
          "hle": 13.0,
          "gpqa": 77.9,
          "scicode": 39.1,
          "ifbench": 41.5,
          "aime25": 89.7,
          "critpt": 2.0,
          "livecodebench": 78.4
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.272664+00:00",
        "confidence": 0.79,
        "raw_name": "DeepSeek V3.1 Terminus (Reasoning)",
        "raw_scores": {
          "intelligence_score": 33.79,
          "coding_score": 33.74,
          "context_window": 128000,
          "gdpval": 1025.979767853997,
          "terminalbench_hard": 0.303,
          "tau2": 0.371,
          "lcr": 65.0,
          "hle": 15.2,
          "gpqa": 79.2,
          "scicode": 40.6,
          "ifbench": 57.0,
          "aime25": 89.7,
          "critpt": 1.7,
          "livecodebench": 79.8
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125203+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-v3.1",
        "raw_scores": {
          "arena_elo": 1418.25,
          "arena_votes": 15197
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125229+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-v3.1-thinking",
        "raw_scores": {
          "arena_elo": 1417.22,
          "arena_votes": 11917
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125270+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-v3.1-terminus",
        "raw_scores": {
          "arena_elo": 1415.99,
          "arena_votes": 3745
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125283+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-v3.1-terminus-thinking",
        "raw_scores": {
          "arena_elo": 1415.73,
          "arena_votes": 3538
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 28.0,
        "coding_score": 28.39,
        "gdpval": 1114.4490186096189,
        "terminalbench_hard": 0.242,
        "tau2": 0.348,
        "lcr": 45.0,
        "hle": 6.3,
        "gpqa": 73.5,
        "scicode": 36.7,
        "ifbench": 37.8,
        "aime25": 49.7,
        "critpt": 0.0,
        "livecodebench": 57.7
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1418.25
      }
    },
    "confidence_score": 0.895,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-v2-chat",
    "canonical_name": "DeepSeek-V2-Chat",
    "model_name": "DeepSeek-V2-Chat",
    "aliases": [
      "DeepSeek-V2-Chat"
    ],
    "provider": "DeepSeek",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "DEEPSEEK LICENSE AGREEMENT",
    "creator": null,
    "intelligence_score": 9.0586,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.272722+00:00",
        "confidence": 0.44,
        "raw_name": "DeepSeek-V2-Chat",
        "raw_scores": {
          "intelligence_score": 9.058555199878974,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.058555199878974
      }
    },
    "confidence_score": 0.44,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-coder-v2-lite-instruct",
    "canonical_name": "DeepSeek Coder V2 Lite Instruct",
    "model_name": "DeepSeek Coder V2 Lite Instruct",
    "aliases": [
      "DeepSeek Coder V2 Lite Instruct"
    ],
    "provider": "DeepSeek",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "DEEPSEEK LICENSE AGREEMENT",
    "creator": null,
    "intelligence_score": 8.4795,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.3,
    "gpqa": 31.9,
    "scicode": 13.9,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 15.8,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.272750+00:00",
        "confidence": 0.65,
        "raw_name": "DeepSeek Coder V2 Lite Instruct",
        "raw_scores": {
          "intelligence_score": 8.479458137084212,
          "context_window": 128000,
          "hle": 5.3,
          "gpqa": 31.9,
          "scicode": 13.9,
          "livecodebench": 15.8
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.479458137084212,
        "hle": 5.3,
        "gpqa": 31.9,
        "scicode": 13.9,
        "livecodebench": 15.8
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "sonar-reasoning-pro",
    "canonical_name": "Sonar Reasoning Pro",
    "model_name": "Sonar Reasoning Pro",
    "aliases": [
      "Sonar Reasoning Pro"
    ],
    "provider": null,
    "context_window": 127000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 24.6211,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.272771+00:00",
        "confidence": 0.65,
        "raw_name": "Sonar Reasoning Pro",
        "raw_scores": {
          "intelligence_score": 24.62112108368442,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 127000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 24.62112108368442
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "sonar",
    "canonical_name": "Sonar",
    "model_name": "Sonar",
    "aliases": [
      "Sonar"
    ],
    "provider": null,
    "context_window": 127000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 15.4928,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.0,
    "latency_seconds": 1.35,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 120.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 7.3,
    "gpqa": 47.1,
    "scicode": 22.9,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 29.5,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.272802+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "Sonar",
        "raw_scores": {
          "intelligence_score": 15.492770267156052,
          "blended_cost_per_1m": 1.0,
          "latency_seconds": 1.35,
          "tokens_per_second": 120.0,
          "context_window": 127000,
          "hle": 7.3,
          "gpqa": 47.1,
          "scicode": 22.9,
          "livecodebench": 29.5
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.492770267156052,
        "hle": 7.3,
        "gpqa": 47.1,
        "scicode": 22.9,
        "livecodebench": 29.5
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "sonar-pro",
    "canonical_name": "Sonar Pro",
    "model_name": "Sonar Pro",
    "aliases": [
      "Sonar Pro"
    ],
    "provider": null,
    "context_window": 200000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 15.226,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 6.0,
    "latency_seconds": 1.32,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 123.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 7.9,
    "gpqa": 57.8,
    "scicode": 22.6,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 27.5,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.272833+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "Sonar Pro",
        "raw_scores": {
          "intelligence_score": 15.225966789192796,
          "blended_cost_per_1m": 6.0,
          "latency_seconds": 1.32,
          "tokens_per_second": 123.0,
          "context_window": 200000,
          "hle": 7.9,
          "gpqa": 57.8,
          "scicode": 22.6,
          "livecodebench": 27.5
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.225966789192796,
        "hle": 7.9,
        "gpqa": 57.8,
        "scicode": 22.6,
        "livecodebench": 27.5
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "sonar-reasoning",
    "canonical_name": "Sonar Reasoning",
    "model_name": "Sonar Reasoning",
    "aliases": [
      "Sonar Reasoning"
    ],
    "provider": null,
    "context_window": 127000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 17.8777,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": 62.3,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.272858+00:00",
        "confidence": 0.72,
        "raw_name": "Sonar Reasoning",
        "raw_scores": {
          "intelligence_score": 17.87769906391809,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 127000,
          "gpqa": 62.3
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 17.87769906391809,
        "gpqa": 62.3
      }
    },
    "confidence_score": 0.72,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "grok-beta",
    "canonical_name": "Grok Beta",
    "model_name": "Grok Beta",
    "aliases": [
      "Grok Beta"
    ],
    "provider": "xAI",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 13.2819,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.7,
    "gpqa": 47.1,
    "scicode": 29.5,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 24.1,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.272888+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "Grok Beta",
        "raw_scores": {
          "intelligence_score": 13.281894010187271,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000,
          "hle": 4.7,
          "gpqa": 47.1,
          "scicode": 29.5,
          "livecodebench": 24.1
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.281894010187271,
        "hle": 4.7,
        "gpqa": 47.1,
        "scicode": 29.5,
        "livecodebench": 24.1
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "grok-2",
    "canonical_name": "Grok 2 (Dec '24)",
    "model_name": "Grok 2 (Dec '24)",
    "aliases": [
      "Grok 2 (Dec '24)"
    ],
    "provider": "xAI",
    "context_window": 131072,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Grok 2 Community License Agreement",
    "creator": null,
    "intelligence_score": 13.886,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 3.8,
    "gpqa": 51.0,
    "scicode": 28.5,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 26.7,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.272915+00:00",
        "confidence": 0.65,
        "raw_name": "Grok 2 (Dec '24)",
        "raw_scores": {
          "intelligence_score": 13.886018572918001,
          "context_window": 131072,
          "hle": 3.8,
          "gpqa": 51.0,
          "scicode": 28.5,
          "livecodebench": 26.7
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.886018572918001,
        "hle": 3.8,
        "gpqa": 51.0,
        "scicode": 28.5,
        "livecodebench": 26.7
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "grok-3",
    "canonical_name": "Grok 3",
    "model_name": "Grok 3",
    "aliases": [
      "Grok 3",
      "grok-3-preview-02-24"
    ],
    "provider": "xAI",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": 33844,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 25.01,
    "coding_score": 19.84,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1411.29,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 6.0,
    "latency_seconds": 0.75,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 68.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 704.7202,
    "terminalbench_hard": 0.114,
    "tau2": 0.488,
    "lcr": 54.7,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.1,
    "gpqa": 69.3,
    "scicode": 36.8,
    "ifbench": 46.9,
    "aime25": 58.0,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 42.5,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.272960+00:00",
        "confidence": 1.0,
        "raw_name": "Grok 3",
        "raw_scores": {
          "intelligence_score": 25.01,
          "coding_score": 19.84,
          "blended_cost_per_1m": 6.0,
          "latency_seconds": 0.75,
          "tokens_per_second": 68.0,
          "context_window": 1000000,
          "gdpval": 704.7201519314299,
          "terminalbench_hard": 0.114,
          "tau2": 0.488,
          "lcr": 54.7,
          "hle": 5.1,
          "gpqa": 69.3,
          "scicode": 36.8,
          "ifbench": 46.9,
          "aime25": 58.0,
          "critpt": 0.0,
          "livecodebench": 42.5
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125349+00:00",
        "confidence": 1.0,
        "raw_name": "grok-3-preview-02-24",
        "raw_scores": {
          "arena_elo": 1411.29,
          "arena_votes": 33844
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 25.01,
        "coding_score": 19.84,
        "gdpval": 704.7201519314299,
        "terminalbench_hard": 0.114,
        "tau2": 0.488,
        "lcr": 54.7,
        "hle": 5.1,
        "gpqa": 69.3,
        "scicode": 36.8,
        "ifbench": 46.9,
        "aime25": 58.0,
        "critpt": 0.0,
        "livecodebench": 42.5
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1411.29
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "grok-3-reasoning-beta",
    "canonical_name": "Grok 3 Reasoning Beta",
    "model_name": "Grok 3 Reasoning Beta",
    "aliases": [
      "Grok 3 Reasoning Beta"
    ],
    "provider": "xAI",
    "context_window": 1000000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 21.6477,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.272983+00:00",
        "confidence": 0.65,
        "raw_name": "Grok 3 Reasoning Beta",
        "raw_scores": {
          "intelligence_score": 21.647717992955027,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 21.647717992955027
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "grok-4-fast",
    "canonical_name": "Grok 4 Fast (Reasoning)",
    "model_name": "Grok 4 Fast (Reasoning)",
    "aliases": [
      "Grok 4 Fast (Non-reasoning)",
      "Grok 4 Fast (Reasoning)",
      "grok-4-fast-chat",
      "grok-4-fast-reasoning"
    ],
    "provider": "xAI",
    "context_window": 2000000,
    "open_source": null,
    "arena_votes": 18442,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 28.785,
    "coding_score": 23.2,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1412.745,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 915.0997,
    "terminalbench_hard": 0.155,
    "tau2": 0.6475,
    "lcr": 42.35,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 11.0,
    "gpqa": 72.65,
    "scicode": 38.55,
    "ifbench": 44.1,
    "aime25": 65.5,
    "critpt": 1.45,
    "mmmu_pro": 54.95,
    "livecodebench": 61.65,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.273025+00:00",
        "confidence": 0.79,
        "raw_name": "Grok 4 Fast (Reasoning)",
        "raw_scores": {
          "intelligence_score": 34.93,
          "coding_score": 27.36,
          "context_window": 2000000,
          "gdpval": 1026.7390297503496,
          "terminalbench_hard": 0.189,
          "tau2": 0.658,
          "lcr": 64.7,
          "hle": 17.0,
          "gpqa": 84.7,
          "scicode": 44.2,
          "ifbench": 50.5,
          "aime25": 89.7,
          "critpt": 2.9,
          "mmmu_pro": 61.8,
          "livecodebench": 83.2
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.273068+00:00",
        "confidence": 0.79,
        "raw_name": "Grok 4 Fast (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 22.64,
          "coding_score": 19.04,
          "context_window": 2000000,
          "gdpval": 803.4603704982821,
          "terminalbench_hard": 0.121,
          "tau2": 0.637,
          "lcr": 20.0,
          "hle": 5.0,
          "gpqa": 60.6,
          "scicode": 32.9,
          "ifbench": 37.7,
          "aime25": 41.3,
          "critpt": 0.0,
          "mmmu_pro": 48.1,
          "livecodebench": 40.1
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125138+00:00",
        "confidence": 1.0,
        "raw_name": "grok-4-fast-chat",
        "raw_scores": {
          "arena_elo": 1421.88,
          "arena_votes": 6962
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125447+00:00",
        "confidence": 1.0,
        "raw_name": "grok-4-fast-reasoning",
        "raw_scores": {
          "arena_elo": 1403.61,
          "arena_votes": 18442
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 34.93,
        "coding_score": 27.36,
        "gdpval": 1026.7390297503496,
        "terminalbench_hard": 0.189,
        "tau2": 0.658,
        "lcr": 64.7,
        "hle": 17.0,
        "gpqa": 84.7,
        "scicode": 44.2,
        "ifbench": 50.5,
        "aime25": 89.7,
        "critpt": 2.9,
        "mmmu_pro": 61.8,
        "livecodebench": 83.2
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1421.88
      }
    },
    "confidence_score": 0.895,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "openchat-35",
    "canonical_name": "OpenChat 3.5 (1210)",
    "model_name": "OpenChat 3.5 (1210)",
    "aliases": [
      "OpenChat 3.5 (1210)",
      "openchat-3.5"
    ],
    "provider": "OpenChat",
    "context_window": 8192,
    "open_source": true,
    "arena_votes": 7967,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 8.3203,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1182.52,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.8,
    "gpqa": 23.0,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 11.5,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.273095+00:00",
        "confidence": 0.65,
        "raw_name": "OpenChat 3.5 (1210)",
        "raw_scores": {
          "intelligence_score": 8.320282434218926,
          "context_window": 8192,
          "hle": 4.8,
          "gpqa": 23.0,
          "livecodebench": 11.5
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128087+00:00",
        "confidence": 1.0,
        "raw_name": "openchat-3.5",
        "raw_scores": {
          "arena_elo": 1182.52,
          "arena_votes": 7967
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.320282434218926,
        "hle": 4.8,
        "gpqa": 23.0,
        "livecodebench": 11.5
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1182.52
      }
    },
    "confidence_score": 0.825,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "nova-pro",
    "canonical_name": "Nova Pro",
    "model_name": "Nova Pro",
    "aliases": [
      "Nova Pro",
      "amazon-nova-pro-v1.0"
    ],
    "provider": "Amazon",
    "context_window": 300000,
    "open_source": null,
    "arena_votes": 24753,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 13.46,
    "coding_score": 10.98,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1290.27,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.4,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 442.3388,
    "terminalbench_hard": 0.061,
    "tau2": 0.14,
    "lcr": 19.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 3.4,
    "gpqa": 49.9,
    "scicode": 20.8,
    "ifbench": 38.1,
    "aime25": 7.0,
    "critpt": 0.0,
    "mmmu_pro": 44.3,
    "livecodebench": 23.3,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.273140+00:00",
        "confidence": 1.0,
        "raw_name": "Nova Pro",
        "raw_scores": {
          "intelligence_score": 13.46,
          "coding_score": 10.98,
          "blended_cost_per_1m": 1.4,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 300000,
          "gdpval": 442.3387922879648,
          "terminalbench_hard": 0.061,
          "tau2": 0.14,
          "lcr": 19.0,
          "hle": 3.4,
          "gpqa": 49.9,
          "scicode": 20.8,
          "ifbench": 38.1,
          "aime25": 7.0,
          "critpt": 0.0,
          "mmmu_pro": 44.3,
          "livecodebench": 23.3
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127195+00:00",
        "confidence": 1.0,
        "raw_name": "amazon-nova-pro-v1.0",
        "raw_scores": {
          "arena_elo": 1290.27,
          "arena_votes": 24753
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.46,
        "coding_score": 10.98,
        "gdpval": 442.3387922879648,
        "terminalbench_hard": 0.061,
        "tau2": 0.14,
        "lcr": 19.0,
        "hle": 3.4,
        "gpqa": 49.9,
        "scicode": 20.8,
        "ifbench": 38.1,
        "aime25": 7.0,
        "critpt": 0.0,
        "mmmu_pro": 44.3,
        "livecodebench": 23.3
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1290.27
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "nova-lite",
    "canonical_name": "Nova Lite",
    "model_name": "Nova Lite",
    "aliases": [
      "Nova Lite",
      "amazon-nova-lite-v1.0"
    ],
    "provider": "Amazon",
    "context_window": 300000,
    "open_source": null,
    "arena_votes": 19376,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 12.45,
    "coding_score": 5.13,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1260.76,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.1,
    "latency_seconds": 0.38,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 229.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 402.3161,
    "terminalbench_hard": 0.008,
    "tau2": 0.175,
    "lcr": 17.7,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.6,
    "gpqa": 43.3,
    "scicode": 13.9,
    "ifbench": 34.1,
    "aime25": 7.0,
    "critpt": 0.0,
    "mmmu_pro": 37.8,
    "livecodebench": 16.7,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.273184+00:00",
        "confidence": 1.0,
        "raw_name": "Nova Lite",
        "raw_scores": {
          "intelligence_score": 12.45,
          "coding_score": 5.13,
          "blended_cost_per_1m": 0.1,
          "latency_seconds": 0.38,
          "tokens_per_second": 229.0,
          "context_window": 300000,
          "gdpval": 402.31605859565866,
          "terminalbench_hard": 0.008,
          "tau2": 0.175,
          "lcr": 17.7,
          "hle": 4.6,
          "gpqa": 43.3,
          "scicode": 13.9,
          "ifbench": 34.1,
          "aime25": 7.0,
          "critpt": 0.0,
          "mmmu_pro": 37.8,
          "livecodebench": 16.7
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127538+00:00",
        "confidence": 1.0,
        "raw_name": "amazon-nova-lite-v1.0",
        "raw_scores": {
          "arena_elo": 1260.76,
          "arena_votes": 19376
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.45,
        "coding_score": 5.13,
        "gdpval": 402.31605859565866,
        "terminalbench_hard": 0.008,
        "tau2": 0.175,
        "lcr": 17.7,
        "hle": 4.6,
        "gpqa": 43.3,
        "scicode": 13.9,
        "ifbench": 34.1,
        "aime25": 7.0,
        "critpt": 0.0,
        "mmmu_pro": 37.8,
        "livecodebench": 16.7
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1260.76
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "phi-3-mini-instruct-38b",
    "canonical_name": "Phi-3 Mini Instruct 3.8B",
    "model_name": "Phi-3 Mini Instruct 3.8B",
    "aliases": [
      "Phi-3 Mini Instruct 3.8B"
    ],
    "provider": "Microsoft",
    "context_window": 4096,
    "open_source": true,
    "arena_votes": null,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": 10.1008,
    "coding_score": 3.01,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": 0.0,
    "tau2": 0.0,
    "lcr": 2.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.4,
    "gpqa": 31.9,
    "scicode": 9.0,
    "ifbench": 23.9,
    "aime25": 0.3,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 11.6,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.273219+00:00",
        "confidence": 0.79,
        "raw_name": "Phi-3 Mini Instruct 3.8B",
        "raw_scores": {
          "intelligence_score": 10.10075277153229,
          "coding_score": 3.01,
          "context_window": 4096,
          "terminalbench_hard": 0.0,
          "tau2": 0.0,
          "lcr": 2.0,
          "hle": 4.4,
          "gpqa": 31.9,
          "scicode": 9.0,
          "ifbench": 23.9,
          "aime25": 0.3,
          "livecodebench": 11.6
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.10075277153229,
        "coding_score": 3.01,
        "terminalbench_hard": 0.0,
        "tau2": 0.0,
        "lcr": 2.0,
        "hle": 4.4,
        "gpqa": 31.9,
        "scicode": 9.0,
        "ifbench": 23.9,
        "aime25": 0.3,
        "livecodebench": 11.6
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "lfm-40b",
    "canonical_name": "LFM 40B",
    "model_name": "LFM 40B",
    "aliases": [
      "LFM 40B"
    ],
    "provider": null,
    "context_window": 32000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 8.7608,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.9,
    "gpqa": 32.7,
    "scicode": 7.1,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 9.6,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.273262+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "LFM 40B",
        "raw_scores": {
          "intelligence_score": 8.760765585157351,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32000,
          "hle": 4.9,
          "gpqa": 32.7,
          "scicode": 7.1,
          "livecodebench": 9.6
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.760765585157351,
        "hle": 4.9,
        "gpqa": 32.7,
        "scicode": 7.1,
        "livecodebench": 9.6
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "lfm2-12b",
    "canonical_name": "LFM2 1.2B",
    "model_name": "LFM2 1.2B",
    "aliases": [
      "LFM2 1.2B"
    ],
    "provider": null,
    "context_window": 32768,
    "open_source": true,
    "arena_votes": null,
    "license_type": "lfm 1.0",
    "creator": null,
    "intelligence_score": 6.36,
    "coding_score": 0.85,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 346.76,
    "terminalbench_hard": 0.0,
    "tau2": 0.126,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.7,
    "gpqa": 22.8,
    "scicode": 2.5,
    "ifbench": 22.0,
    "aime25": 3.3,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 2.0,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.273306+00:00",
        "confidence": 1.0,
        "raw_name": "LFM2 1.2B",
        "raw_scores": {
          "intelligence_score": 6.36,
          "coding_score": 0.85,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32768,
          "gdpval": 346.7599527411388,
          "terminalbench_hard": 0.0,
          "tau2": 0.126,
          "lcr": 0.0,
          "hle": 5.7,
          "gpqa": 22.8,
          "scicode": 2.5,
          "ifbench": 22.0,
          "aime25": 3.3,
          "critpt": 0.0,
          "livecodebench": 2.0
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 6.36,
        "coding_score": 0.85,
        "gdpval": 346.7599527411388,
        "terminalbench_hard": 0.0,
        "tau2": 0.126,
        "lcr": 0.0,
        "hle": 5.7,
        "gpqa": 22.8,
        "scicode": 2.5,
        "ifbench": 22.0,
        "aime25": 3.3,
        "critpt": 0.0,
        "livecodebench": 2.0
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "solar-mini",
    "canonical_name": "Solar Mini",
    "model_name": "Solar Mini",
    "aliases": [
      "Solar Mini"
    ],
    "provider": null,
    "context_window": 4096,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 8.0,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.15,
    "latency_seconds": 1.46,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 78.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": 0.202,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.273331+00:00",
        "confidence": 0.65,
        "raw_name": "Solar Mini",
        "raw_scores": {
          "intelligence_score": 8.0,
          "blended_cost_per_1m": 0.15,
          "latency_seconds": 1.46,
          "tokens_per_second": 78.0,
          "context_window": 4096,
          "tau2": 0.202
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.0,
        "tau2": 0.202
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "dbrx-instruct",
    "canonical_name": "DBRX Instruct",
    "model_name": "DBRX Instruct",
    "aliases": [
      "DBRX Instruct"
    ],
    "provider": "Databricks",
    "context_window": 32768,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Databricks Open Model License",
    "creator": null,
    "intelligence_score": 8.3159,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 6.6,
    "gpqa": 33.1,
    "scicode": 11.8,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 9.3,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.273414+00:00",
        "confidence": 0.65,
        "raw_name": "DBRX Instruct",
        "raw_scores": {
          "intelligence_score": 8.315903697714282,
          "context_window": 32768,
          "hle": 6.6,
          "gpqa": 33.1,
          "scicode": 11.8,
          "livecodebench": 9.3
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.315903697714282,
        "hle": 6.6,
        "gpqa": 33.1,
        "scicode": 11.8,
        "livecodebench": 9.3
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "minimax-m2",
    "canonical_name": "MiniMax-M2",
    "model_name": "MiniMax-M2",
    "aliases": [
      "MiniMax-M2",
      "minimax-m2"
    ],
    "provider": "MiniMax",
    "context_window": 204800,
    "open_source": true,
    "arena_votes": 6684,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": 35.98,
    "coding_score": 29.21,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1346.88,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.53,
    "latency_seconds": 2.16,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 61.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 1054.1143,
    "terminalbench_hard": 0.258,
    "tau2": 0.868,
    "lcr": 61.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 12.5,
    "gpqa": 77.7,
    "scicode": 36.1,
    "ifbench": 72.3,
    "aime25": 78.3,
    "critpt": 0.9,
    "mmmu_pro": null,
    "livecodebench": 82.6,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.273457+00:00",
        "confidence": 1.0,
        "raw_name": "MiniMax-M2",
        "raw_scores": {
          "intelligence_score": 35.98,
          "coding_score": 29.21,
          "blended_cost_per_1m": 0.53,
          "latency_seconds": 2.16,
          "tokens_per_second": 61.0,
          "context_window": 204800,
          "gdpval": 1054.1143075292032,
          "terminalbench_hard": 0.258,
          "tau2": 0.868,
          "lcr": 61.0,
          "hle": 12.5,
          "gpqa": 77.7,
          "scicode": 36.1,
          "ifbench": 72.3,
          "aime25": 78.3,
          "critpt": 0.9,
          "livecodebench": 82.6
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126386+00:00",
        "confidence": 1.0,
        "raw_name": "minimax-m2",
        "raw_scores": {
          "arena_elo": 1346.88,
          "arena_votes": 6684
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 35.98,
        "coding_score": 29.21,
        "gdpval": 1054.1143075292032,
        "terminalbench_hard": 0.258,
        "tau2": 0.868,
        "lcr": 61.0,
        "hle": 12.5,
        "gpqa": 77.7,
        "scicode": 36.1,
        "ifbench": 72.3,
        "aime25": 78.3,
        "critpt": 0.9,
        "livecodebench": 82.6
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1346.88
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "minimax-m1-40k",
    "canonical_name": "MiniMax M1 40k",
    "model_name": "MiniMax M1 40k",
    "aliases": [
      "MiniMax M1 40k"
    ],
    "provider": "MiniMax",
    "context_window": 1000000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 20.8562,
    "coding_score": 14.13,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": 0.023,
    "tau2": 0.316,
    "lcr": 51.7,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 7.5,
    "gpqa": 68.2,
    "scicode": 37.8,
    "ifbench": 41.2,
    "aime25": 13.7,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 65.7,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.273498+00:00",
        "confidence": 1.0,
        "raw_name": "MiniMax M1 40k",
        "raw_scores": {
          "intelligence_score": 20.856172610675117,
          "coding_score": 14.13,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000,
          "terminalbench_hard": 0.023,
          "tau2": 0.316,
          "lcr": 51.7,
          "hle": 7.5,
          "gpqa": 68.2,
          "scicode": 37.8,
          "ifbench": 41.2,
          "aime25": 13.7,
          "livecodebench": 65.7
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 20.856172610675117,
        "coding_score": 14.13,
        "terminalbench_hard": 0.023,
        "tau2": 0.316,
        "lcr": 51.7,
        "hle": 7.5,
        "gpqa": 68.2,
        "scicode": 37.8,
        "ifbench": 41.2,
        "aime25": 13.7,
        "livecodebench": 65.7
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "minimax-m21",
    "canonical_name": "MiniMax-M2.1",
    "model_name": "MiniMax-M2.1",
    "aliases": [
      "MiniMax-M2.1"
    ],
    "provider": "MiniMax",
    "context_window": 204800,
    "open_source": true,
    "arena_votes": null,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": 39.55,
    "coding_score": 32.77,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.53,
    "latency_seconds": 2.76,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 58.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 1084.9172,
    "terminalbench_hard": 0.288,
    "tau2": 0.854,
    "lcr": 59.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 22.2,
    "gpqa": 83.0,
    "scicode": 40.7,
    "ifbench": 69.9,
    "aime25": 82.7,
    "critpt": 0.3,
    "mmmu_pro": null,
    "livecodebench": 81.0,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.273542+00:00",
        "confidence": 1.0,
        "raw_name": "MiniMax-M2.1",
        "raw_scores": {
          "intelligence_score": 39.55,
          "coding_score": 32.77,
          "blended_cost_per_1m": 0.53,
          "latency_seconds": 2.76,
          "tokens_per_second": 58.0,
          "context_window": 204800,
          "gdpval": 1084.917158575816,
          "terminalbench_hard": 0.288,
          "tau2": 0.854,
          "lcr": 59.0,
          "hle": 22.2,
          "gpqa": 83.0,
          "scicode": 40.7,
          "ifbench": 69.9,
          "aime25": 82.7,
          "critpt": 0.3,
          "livecodebench": 81.0
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 39.55,
        "coding_score": 32.77,
        "gdpval": 1084.917158575816,
        "terminalbench_hard": 0.288,
        "tau2": 0.854,
        "lcr": 59.0,
        "hle": 22.2,
        "gpqa": 83.0,
        "scicode": 40.7,
        "ifbench": 69.9,
        "aime25": 82.7,
        "critpt": 0.3,
        "livecodebench": 81.0
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "minimax-m1-80k",
    "canonical_name": "MiniMax M1 80k",
    "model_name": "MiniMax M1 80k",
    "aliases": [
      "MiniMax M1 80k"
    ],
    "provider": "MiniMax",
    "context_window": 1000000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 24.26,
    "coding_score": 14.48,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.96,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 1026.897,
    "terminalbench_hard": 0.03,
    "tau2": 0.342,
    "lcr": 54.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 8.2,
    "gpqa": 69.7,
    "scicode": 37.4,
    "ifbench": 41.8,
    "aime25": 61.0,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 71.1,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.273584+00:00",
        "confidence": 1.0,
        "raw_name": "MiniMax M1 80k",
        "raw_scores": {
          "intelligence_score": 24.26,
          "coding_score": 14.48,
          "blended_cost_per_1m": 0.96,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 1000000,
          "gdpval": 1026.897046032135,
          "terminalbench_hard": 0.03,
          "tau2": 0.342,
          "lcr": 54.3,
          "hle": 8.2,
          "gpqa": 69.7,
          "scicode": 37.4,
          "ifbench": 41.8,
          "aime25": 61.0,
          "critpt": 0.0,
          "livecodebench": 71.1
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 24.26,
        "coding_score": 14.48,
        "gdpval": 1026.897046032135,
        "terminalbench_hard": 0.03,
        "tau2": 0.342,
        "lcr": 54.3,
        "hle": 8.2,
        "gpqa": 69.7,
        "scicode": 37.4,
        "ifbench": 41.8,
        "aime25": 61.0,
        "critpt": 0.0,
        "livecodebench": 71.1
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "kimi-k2-0905",
    "canonical_name": "Kimi K2 0905",
    "model_name": "Kimi K2 0905",
    "aliases": [
      "Kimi K2 0905"
    ],
    "provider": "Moonshot",
    "context_window": 256000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Modified MIT License",
    "creator": null,
    "intelligence_score": 30.81,
    "coding_score": 25.88,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.2,
    "latency_seconds": 0.51,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 62.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 887.2012,
    "terminalbench_hard": 0.235,
    "tau2": 0.734,
    "lcr": 52.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 6.3,
    "gpqa": 76.7,
    "scicode": 30.7,
    "ifbench": 41.7,
    "aime25": 57.3,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 61.0,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.273627+00:00",
        "confidence": 1.0,
        "raw_name": "Kimi K2 0905",
        "raw_scores": {
          "intelligence_score": 30.81,
          "coding_score": 25.88,
          "blended_cost_per_1m": 1.2,
          "latency_seconds": 0.51,
          "tokens_per_second": 62.0,
          "context_window": 256000,
          "gdpval": 887.2011725112129,
          "terminalbench_hard": 0.235,
          "tau2": 0.734,
          "lcr": 52.3,
          "hle": 6.3,
          "gpqa": 76.7,
          "scicode": 30.7,
          "ifbench": 41.7,
          "aime25": 57.3,
          "critpt": 0.0,
          "livecodebench": 61.0
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 30.81,
        "coding_score": 25.88,
        "gdpval": 887.2011725112129,
        "terminalbench_hard": 0.235,
        "tau2": 0.734,
        "lcr": 52.3,
        "hle": 6.3,
        "gpqa": 76.7,
        "scicode": 30.7,
        "ifbench": 41.7,
        "aime25": 57.3,
        "critpt": 0.0,
        "livecodebench": 61.0
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "kimi-k2-thinking",
    "canonical_name": "Kimi K2 Thinking",
    "model_name": "Kimi K2 Thinking",
    "aliases": [
      "Kimi K2 Thinking"
    ],
    "provider": "Moonshot",
    "context_window": 256000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Modified MIT License",
    "creator": null,
    "intelligence_score": 40.7,
    "coding_score": 34.83,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.07,
    "latency_seconds": 0.69,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 81.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 1011.9656,
    "terminalbench_hard": 0.311,
    "tau2": 0.93,
    "lcr": 66.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 22.3,
    "gpqa": 83.8,
    "scicode": 42.4,
    "ifbench": 68.1,
    "aime25": 94.7,
    "critpt": 2.6,
    "mmmu_pro": null,
    "livecodebench": 85.3,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.273672+00:00",
        "confidence": 1.0,
        "raw_name": "Kimi K2 Thinking",
        "raw_scores": {
          "intelligence_score": 40.7,
          "coding_score": 34.83,
          "blended_cost_per_1m": 1.07,
          "latency_seconds": 0.69,
          "tokens_per_second": 81.0,
          "context_window": 256000,
          "gdpval": 1011.9655791424589,
          "terminalbench_hard": 0.311,
          "tau2": 0.93,
          "lcr": 66.3,
          "hle": 22.3,
          "gpqa": 83.8,
          "scicode": 42.4,
          "ifbench": 68.1,
          "aime25": 94.7,
          "critpt": 2.6,
          "livecodebench": 85.3
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 40.7,
        "coding_score": 34.83,
        "gdpval": 1011.9655791424589,
        "terminalbench_hard": 0.311,
        "tau2": 0.93,
        "lcr": 66.3,
        "hle": 22.3,
        "gpqa": 83.8,
        "scicode": 42.4,
        "ifbench": 68.1,
        "aime25": 94.7,
        "critpt": 2.6,
        "livecodebench": 85.3
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "kimi-k2",
    "canonical_name": "Kimi K2",
    "model_name": "Kimi K2",
    "aliases": [
      "Kimi K2",
      "kimi-k2-0711-preview",
      "kimi-k2-0905-preview"
    ],
    "provider": "Moonshot",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": 28443,
    "license_type": "Modified MIT License",
    "creator": null,
    "intelligence_score": 26.19,
    "coding_score": 22.1,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1417.21,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 1.07,
    "latency_seconds": 0.6,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 38.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 568.0924,
    "terminalbench_hard": 0.159,
    "tau2": 0.611,
    "lcr": 51.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 7.0,
    "gpqa": 76.6,
    "scicode": 34.5,
    "ifbench": 41.5,
    "aime25": 57.0,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 55.6,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.273714+00:00",
        "confidence": 1.0,
        "raw_name": "Kimi K2",
        "raw_scores": {
          "intelligence_score": 26.19,
          "coding_score": 22.1,
          "blended_cost_per_1m": 1.07,
          "latency_seconds": 0.6,
          "tokens_per_second": 38.0,
          "context_window": 128000,
          "gdpval": 568.0923960107618,
          "terminalbench_hard": 0.159,
          "tau2": 0.611,
          "lcr": 51.0,
          "hle": 7.0,
          "gpqa": 76.6,
          "scicode": 34.5,
          "ifbench": 41.5,
          "aime25": 57.0,
          "critpt": 0.0,
          "livecodebench": 55.6
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125216+00:00",
        "confidence": 1.0,
        "raw_name": "kimi-k2-0905-preview",
        "raw_scores": {
          "arena_elo": 1417.47,
          "arena_votes": 11912
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125242+00:00",
        "confidence": 1.0,
        "raw_name": "kimi-k2-0711-preview",
        "raw_scores": {
          "arena_elo": 1416.95,
          "arena_votes": 28443
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 26.19,
        "coding_score": 22.1,
        "gdpval": 568.0923960107618,
        "terminalbench_hard": 0.159,
        "tau2": 0.611,
        "lcr": 51.0,
        "hle": 7.0,
        "gpqa": 76.6,
        "scicode": 34.5,
        "ifbench": 41.5,
        "aime25": 57.0,
        "critpt": 0.0,
        "livecodebench": 55.6
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1417.47
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-tulu3-405b",
    "canonical_name": "Llama 3.1 Tulu3 405B",
    "model_name": "Llama 3.1 Tulu3 405B",
    "aliases": [
      "Llama 3.1 Tulu3 405B"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT",
    "creator": null,
    "intelligence_score": 14.1405,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 3.5,
    "gpqa": 51.6,
    "scicode": 30.2,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 29.1,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.273743+00:00",
        "confidence": 0.65,
        "raw_name": "Llama 3.1 Tulu3 405B",
        "raw_scores": {
          "intelligence_score": 14.140503152934265,
          "context_window": 128000,
          "hle": 3.5,
          "gpqa": 51.6,
          "scicode": 30.2,
          "livecodebench": 29.1
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.140503152934265,
        "hle": 3.5,
        "gpqa": 51.6,
        "scicode": 30.2,
        "livecodebench": 29.1
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "olmo-3-32b-think",
    "canonical_name": "Olmo 3 32B Think",
    "model_name": "Olmo 3 32B Think",
    "aliases": [
      "Olmo 3 32B Think",
      "olmo-3-32b-think"
    ],
    "provider": "Allen AI",
    "context_window": 65536,
    "open_source": true,
    "arena_votes": 5868,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 11.99,
    "coding_score": 10.54,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1305.6,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": 0.015,
    "tau2": 0.0,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.9,
    "gpqa": 61.0,
    "scicode": 28.6,
    "ifbench": 49.1,
    "aime25": 73.7,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 67.2,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.273782+00:00",
        "confidence": 1.0,
        "raw_name": "Olmo 3 32B Think",
        "raw_scores": {
          "intelligence_score": 11.99,
          "coding_score": 10.54,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 65536,
          "terminalbench_hard": 0.015,
          "tau2": 0.0,
          "lcr": 0.0,
          "hle": 5.9,
          "gpqa": 61.0,
          "scicode": 28.6,
          "ifbench": 49.1,
          "aime25": 73.7,
          "critpt": 0.0,
          "livecodebench": 67.2
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127082+00:00",
        "confidence": 1.0,
        "raw_name": "olmo-3-32b-think",
        "raw_scores": {
          "arena_elo": 1305.6,
          "arena_votes": 5868
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 11.99,
        "coding_score": 10.54,
        "terminalbench_hard": 0.015,
        "tau2": 0.0,
        "lcr": 0.0,
        "hle": 5.9,
        "gpqa": 61.0,
        "scicode": 28.6,
        "ifbench": 49.1,
        "aime25": 73.7,
        "critpt": 0.0,
        "livecodebench": 67.2
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1305.6
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "olmo-2-32b",
    "canonical_name": "OLMo 2 32B",
    "model_name": "OLMo 2 32B",
    "aliases": [
      "OLMo 2 32B"
    ],
    "provider": null,
    "context_window": 4096,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 10.5662,
    "coding_score": 2.66,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": 0.0,
    "tau2": 0.0,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 3.7,
    "gpqa": 32.8,
    "scicode": 8.0,
    "ifbench": 38.1,
    "aime25": 3.3,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 6.8,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.273823+00:00",
        "confidence": 1.0,
        "raw_name": "OLMo 2 32B",
        "raw_scores": {
          "intelligence_score": 10.566197101720523,
          "coding_score": 2.66,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 4096,
          "terminalbench_hard": 0.0,
          "tau2": 0.0,
          "lcr": 0.0,
          "hle": 3.7,
          "gpqa": 32.8,
          "scicode": 8.0,
          "ifbench": 38.1,
          "aime25": 3.3,
          "livecodebench": 6.8
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.566197101720523,
        "coding_score": 2.66,
        "terminalbench_hard": 0.0,
        "tau2": 0.0,
        "lcr": 0.0,
        "hle": 3.7,
        "gpqa": 32.8,
        "scicode": 8.0,
        "ifbench": 38.1,
        "aime25": 3.3,
        "livecodebench": 6.8
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "olmo-2-7b",
    "canonical_name": "OLMo 2 7B",
    "model_name": "OLMo 2 7B",
    "aliases": [
      "OLMo 2 7B"
    ],
    "provider": null,
    "context_window": 4096,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 9.2968,
    "coding_score": 1.23,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": 0.0,
    "tau2": 0.0,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.5,
    "gpqa": 28.8,
    "scicode": 3.7,
    "ifbench": 24.4,
    "aime25": 0.7,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 4.1,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.273861+00:00",
        "confidence": 1.0,
        "raw_name": "OLMo 2 7B",
        "raw_scores": {
          "intelligence_score": 9.296750708294477,
          "coding_score": 1.23,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 4096,
          "terminalbench_hard": 0.0,
          "tau2": 0.0,
          "lcr": 0.0,
          "hle": 5.5,
          "gpqa": 28.8,
          "scicode": 3.7,
          "ifbench": 24.4,
          "aime25": 0.7,
          "livecodebench": 4.1
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.296750708294477,
        "coding_score": 1.23,
        "terminalbench_hard": 0.0,
        "tau2": 0.0,
        "lcr": 0.0,
        "hle": 5.5,
        "gpqa": 28.8,
        "scicode": 3.7,
        "ifbench": 24.4,
        "aime25": 0.7,
        "livecodebench": 4.1
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "granite-33-8b",
    "canonical_name": "Granite 3.3 8B (Non-reasoning)",
    "model_name": "Granite 3.3 8B (Non-reasoning)",
    "aliases": [
      "Granite 3.3 8B (Non-reasoning)"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 6.85,
    "coding_score": 3.36,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 281.3301,
    "terminalbench_hard": 0.0,
    "tau2": 0.105,
    "lcr": 4.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.2,
    "gpqa": 33.8,
    "scicode": 10.1,
    "ifbench": 22.4,
    "aime25": 6.7,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 12.7,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.273906+00:00",
        "confidence": 0.79,
        "raw_name": "Granite 3.3 8B (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 6.85,
          "coding_score": 3.36,
          "context_window": 128000,
          "gdpval": 281.3300647611467,
          "terminalbench_hard": 0.0,
          "tau2": 0.105,
          "lcr": 4.3,
          "hle": 4.2,
          "gpqa": 33.8,
          "scicode": 10.1,
          "ifbench": 22.4,
          "aime25": 6.7,
          "critpt": 0.0,
          "livecodebench": 12.7
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 6.85,
        "coding_score": 3.36,
        "gdpval": 281.3300647611467,
        "terminalbench_hard": 0.0,
        "tau2": 0.105,
        "lcr": 4.3,
        "hle": 4.2,
        "gpqa": 33.8,
        "scicode": 10.1,
        "ifbench": 22.4,
        "aime25": 6.7,
        "critpt": 0.0,
        "livecodebench": 12.7
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "reka-flash",
    "canonical_name": "Reka Flash (Sep '24)",
    "model_name": "Reka Flash (Sep '24)",
    "aliases": [
      "Reka Flash (Sep '24)"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 11.9673,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.273926+00:00",
        "confidence": 0.44,
        "raw_name": "Reka Flash (Sep '24)",
        "raw_scores": {
          "intelligence_score": 11.967262408951813,
          "context_window": 128000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 11.967262408951813
      }
    },
    "confidence_score": 0.44,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "hermes-3---llama-31-70b",
    "canonical_name": "Hermes 3 - Llama-3.1 70B",
    "model_name": "Hermes 3 - Llama-3.1 70B",
    "aliases": [
      "Hermes 3 - Llama-3.1 70B"
    ],
    "provider": "Meta",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "LLAMA 3.1 COMMUNITY LICENSE AGREEMENT",
    "creator": null,
    "intelligence_score": 10.6474,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.3,
    "latency_seconds": 0.28,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 36.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.1,
    "gpqa": 40.1,
    "scicode": 23.1,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 18.8,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.273957+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "Hermes 3 - Llama-3.1 70B",
        "raw_scores": {
          "intelligence_score": 10.647383158323558,
          "blended_cost_per_1m": 0.3,
          "latency_seconds": 0.28,
          "tokens_per_second": 36.0,
          "context_window": 128000,
          "hle": 4.1,
          "gpqa": 40.1,
          "scicode": 23.1,
          "livecodebench": 18.8
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.647383158323558,
        "hle": 4.1,
        "gpqa": 40.1,
        "scicode": 23.1,
        "livecodebench": 18.8
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "glm-45-air",
    "canonical_name": "GLM-4.5-Air",
    "model_name": "GLM-4.5-Air",
    "aliases": [
      "GLM-4.5-Air",
      "glm-4.5-air"
    ],
    "provider": "Z.ai",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": 31160,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": 23.16,
    "coding_score": 23.82,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1371.66,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.42,
    "latency_seconds": 1.21,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 260.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 620.1305,
    "terminalbench_hard": 0.205,
    "tau2": 0.465,
    "lcr": 43.7,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 6.8,
    "gpqa": 73.3,
    "scicode": 30.6,
    "ifbench": 37.6,
    "aime25": 80.7,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 68.4,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.274043+00:00",
        "confidence": 1.0,
        "raw_name": "GLM-4.5-Air",
        "raw_scores": {
          "intelligence_score": 23.16,
          "coding_score": 23.82,
          "blended_cost_per_1m": 0.42,
          "latency_seconds": 1.21,
          "tokens_per_second": 260.0,
          "context_window": 128000,
          "gdpval": 620.130501753253,
          "terminalbench_hard": 0.205,
          "tau2": 0.465,
          "lcr": 43.7,
          "hle": 6.8,
          "gpqa": 73.3,
          "scicode": 30.6,
          "ifbench": 37.6,
          "aime25": 80.7,
          "critpt": 0.0,
          "livecodebench": 68.4
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126050+00:00",
        "confidence": 1.0,
        "raw_name": "glm-4.5-air",
        "raw_scores": {
          "arena_elo": 1371.66,
          "arena_votes": 31160
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 23.16,
        "coding_score": 23.82,
        "gdpval": 620.130501753253,
        "terminalbench_hard": 0.205,
        "tau2": 0.465,
        "lcr": 43.7,
        "hle": 6.8,
        "gpqa": 73.3,
        "scicode": 30.6,
        "ifbench": 37.6,
        "aime25": 80.7,
        "critpt": 0.0,
        "livecodebench": 68.4
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1371.66
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "glm-45",
    "canonical_name": "GLM-4.5 (Reasoning)",
    "model_name": "GLM-4.5 (Reasoning)",
    "aliases": [
      "GLM-4.5 (Reasoning)",
      "glm-4.5"
    ],
    "provider": "Z.ai",
    "context_window": 128000,
    "open_source": null,
    "arena_votes": 24604,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": 26.21,
    "coding_score": 26.26,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1409.99,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 509.3909,
    "terminalbench_hard": 0.22,
    "tau2": 0.43,
    "lcr": 48.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 12.2,
    "gpqa": 78.2,
    "scicode": 34.8,
    "ifbench": 44.1,
    "aime25": 73.7,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 73.8,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.274082+00:00",
        "confidence": 0.79,
        "raw_name": "GLM-4.5 (Reasoning)",
        "raw_scores": {
          "intelligence_score": 26.21,
          "coding_score": 26.26,
          "context_window": 128000,
          "gdpval": 509.39092365961403,
          "terminalbench_hard": 0.22,
          "tau2": 0.43,
          "lcr": 48.3,
          "hle": 12.2,
          "gpqa": 78.2,
          "scicode": 34.8,
          "ifbench": 44.1,
          "aime25": 73.7,
          "critpt": 0.0,
          "livecodebench": 73.8
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125389+00:00",
        "confidence": 1.0,
        "raw_name": "glm-4.5",
        "raw_scores": {
          "arena_elo": 1409.99,
          "arena_votes": 24604
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 26.21,
        "coding_score": 26.26,
        "gdpval": 509.39092365961403,
        "terminalbench_hard": 0.22,
        "tau2": 0.43,
        "lcr": 48.3,
        "hle": 12.2,
        "gpqa": 78.2,
        "scicode": 34.8,
        "ifbench": 44.1,
        "aime25": 73.7,
        "critpt": 0.0,
        "livecodebench": 73.8
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1409.99
      }
    },
    "confidence_score": 0.895,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "glm-47",
    "canonical_name": "GLM-4.7 (Non-reasoning)",
    "model_name": "GLM-4.7 (Non-reasoning)",
    "aliases": [
      "GLM-4.7 (Non-reasoning)",
      "GLM-4.7 (Reasoning)",
      "glm-4.7"
    ],
    "provider": "Z.ai",
    "context_window": 200000,
    "open_source": true,
    "arena_votes": 11934,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": 38.075,
    "coding_score": 34.135,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1440.92,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 1197.8923,
    "terminalbench_hard": 0.3105,
    "tau2": 0.9505,
    "lcr": 50.15,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 15.6,
    "gpqa": 76.15,
    "scicode": 40.25,
    "ifbench": 61.25,
    "aime25": 71.5,
    "critpt": 0.85,
    "mmmu_pro": null,
    "livecodebench": 72.8,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.274119+00:00",
        "confidence": 0.79,
        "raw_name": "GLM-4.7 (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 34.1,
          "coding_score": 32.01,
          "context_window": 200000,
          "gdpval": 1195.384766286105,
          "terminalbench_hard": 0.303,
          "tau2": 0.942,
          "lcr": 36.3,
          "hle": 6.1,
          "gpqa": 66.4,
          "scicode": 35.4,
          "ifbench": 54.6,
          "aime25": 48.0,
          "critpt": 0.0,
          "livecodebench": 56.2
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.274197+00:00",
        "confidence": 0.79,
        "raw_name": "GLM-4.7 (Reasoning)",
        "raw_scores": {
          "intelligence_score": 42.05,
          "coding_score": 36.26,
          "context_window": 200000,
          "gdpval": 1200.3998974697706,
          "terminalbench_hard": 0.318,
          "tau2": 0.959,
          "lcr": 64.0,
          "hle": 25.1,
          "gpqa": 85.9,
          "scicode": 45.1,
          "ifbench": 67.9,
          "aime25": 95.0,
          "critpt": 1.7,
          "livecodebench": 89.4
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.124891+00:00",
        "confidence": 1.0,
        "raw_name": "glm-4.7",
        "raw_scores": {
          "arena_elo": 1440.92,
          "arena_votes": 11934
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 34.1,
        "coding_score": 32.01,
        "gdpval": 1195.384766286105,
        "terminalbench_hard": 0.303,
        "tau2": 0.942,
        "lcr": 36.3,
        "hle": 6.1,
        "gpqa": 66.4,
        "scicode": 35.4,
        "ifbench": 54.6,
        "aime25": 48.0,
        "critpt": 0.0,
        "livecodebench": 56.2
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1440.92
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "glm-46",
    "canonical_name": "GLM-4.6 (Non-reasoning)",
    "model_name": "GLM-4.6 (Non-reasoning)",
    "aliases": [
      "GLM-4.6 (Non-reasoning)",
      "GLM-4.6 (Reasoning)",
      "glm-4.6"
    ],
    "provider": "Z.ai",
    "context_window": 200000,
    "open_source": true,
    "arena_votes": 35124,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": 31.335,
    "coding_score": 29.855,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1425.03,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 1028.6293,
    "terminalbench_hard": 0.269,
    "tau2": 0.737,
    "lcr": 40.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 9.25,
    "gpqa": 70.6,
    "scicode": 35.75,
    "ifbench": 40.05,
    "aime25": 65.15,
    "critpt": 0.55,
    "mmmu_pro": null,
    "livecodebench": 62.8,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.274158+00:00",
        "confidence": 0.79,
        "raw_name": "GLM-4.6 (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 30.15,
          "coding_score": 30.23,
          "context_window": 200000,
          "gdpval": 1011.376334502283,
          "terminalbench_hard": 0.288,
          "tau2": 0.769,
          "lcr": 26.3,
          "hle": 5.2,
          "gpqa": 63.2,
          "scicode": 33.1,
          "ifbench": 36.7,
          "aime25": 44.3,
          "critpt": 0.0,
          "livecodebench": 56.1
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.274236+00:00",
        "confidence": 0.79,
        "raw_name": "GLM-4.6 (Reasoning)",
        "raw_scores": {
          "intelligence_score": 32.52,
          "coding_score": 29.48,
          "context_window": 200000,
          "gdpval": 1045.8823433274345,
          "terminalbench_hard": 0.25,
          "tau2": 0.705,
          "lcr": 54.3,
          "hle": 13.3,
          "gpqa": 78.0,
          "scicode": 38.4,
          "ifbench": 43.4,
          "aime25": 86.0,
          "critpt": 1.1,
          "livecodebench": 69.5
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125058+00:00",
        "confidence": 1.0,
        "raw_name": "glm-4.6",
        "raw_scores": {
          "arena_elo": 1425.03,
          "arena_votes": 35124
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 30.15,
        "coding_score": 30.23,
        "gdpval": 1011.376334502283,
        "terminalbench_hard": 0.288,
        "tau2": 0.769,
        "lcr": 26.3,
        "hle": 5.2,
        "gpqa": 63.2,
        "scicode": 33.1,
        "ifbench": 36.7,
        "aime25": 44.3,
        "critpt": 0.0,
        "livecodebench": 56.1
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1425.03
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "glm-45v",
    "canonical_name": "GLM-4.5V (Reasoning)",
    "model_name": "GLM-4.5V (Reasoning)",
    "aliases": [
      "GLM-4.5V (Non-reasoning)",
      "GLM-4.5V (Reasoning)",
      "glm-4.5v"
    ],
    "provider": "Z.ai",
    "context_window": 64000,
    "open_source": true,
    "arena_votes": 4956,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": 13.72,
    "coding_score": 10.85,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1353.27,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 542.5187,
    "terminalbench_hard": 0.0605,
    "tau2": 0.2105,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.75,
    "gpqa": 62.85,
    "scicode": 20.45,
    "ifbench": 31.4,
    "aime25": 44.15,
    "critpt": 0.0,
    "mmmu_pro": 46.65,
    "livecodebench": 47.8,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.274292+00:00",
        "confidence": 0.79,
        "raw_name": "GLM-4.5V (Reasoning)",
        "raw_scores": {
          "intelligence_score": 14.91,
          "coding_score": 10.9,
          "context_window": 64000,
          "gdpval": 567.0286117921494,
          "terminalbench_hard": 0.053,
          "tau2": 0.225,
          "lcr": 0.0,
          "hle": 5.9,
          "gpqa": 68.4,
          "scicode": 22.1,
          "ifbench": 34.2,
          "aime25": 73.0,
          "critpt": 0.0,
          "mmmu_pro": 50.5,
          "livecodebench": 60.4
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.274333+00:00",
        "confidence": 0.79,
        "raw_name": "GLM-4.5V (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 12.53,
          "coding_score": 10.8,
          "context_window": 64000,
          "gdpval": 518.0088585205435,
          "terminalbench_hard": 0.068,
          "tau2": 0.196,
          "lcr": 0.0,
          "hle": 3.6,
          "gpqa": 57.3,
          "scicode": 18.8,
          "ifbench": 28.6,
          "aime25": 15.3,
          "critpt": 0.0,
          "mmmu_pro": 42.8,
          "livecodebench": 35.2
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126272+00:00",
        "confidence": 1.0,
        "raw_name": "glm-4.5v",
        "raw_scores": {
          "arena_elo": 1353.27,
          "arena_votes": 4956
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.91,
        "coding_score": 10.9,
        "gdpval": 567.0286117921494,
        "terminalbench_hard": 0.053,
        "tau2": 0.225,
        "lcr": 0.0,
        "hle": 5.9,
        "gpqa": 68.4,
        "scicode": 22.1,
        "ifbench": 34.2,
        "aime25": 73.0,
        "critpt": 0.0,
        "mmmu_pro": 50.5,
        "livecodebench": 60.4
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1353.27
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "command-r",
    "canonical_name": "Command-R+ (Apr '24)",
    "model_name": "Command-R+ (Apr '24)",
    "aliases": [
      "Command-R (Mar '24)",
      "Command-R+ (Apr '24)",
      "command-r"
    ],
    "provider": "Cohere",
    "context_window": 128000,
    "open_source": false,
    "arena_votes": 54038,
    "license_type": "CC-BY-NC 4.0 License with Acceptable Use Addendum",
    "creator": null,
    "intelligence_score": 7.8813,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1227.22,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.65,
    "gpqa": 30.35,
    "scicode": 9.0,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 8.5,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.274361+00:00",
        "confidence": 0.65,
        "raw_name": "Command-R+ (Apr '24)",
        "raw_scores": {
          "intelligence_score": 8.348799720910122,
          "context_window": 128000,
          "hle": 4.5,
          "gpqa": 32.3,
          "scicode": 11.8,
          "livecodebench": 12.2
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.274390+00:00",
        "confidence": 0.65,
        "raw_name": "Command-R (Mar '24)",
        "raw_scores": {
          "intelligence_score": 7.413887665229345,
          "context_window": 128000,
          "hle": 4.8,
          "gpqa": 28.4,
          "scicode": 6.2,
          "livecodebench": 4.8
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127728+00:00",
        "confidence": 1.0,
        "raw_name": "command-r",
        "raw_scores": {
          "arena_elo": 1227.22,
          "arena_votes": 54038
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.348799720910122,
        "hle": 4.5,
        "gpqa": 32.3,
        "scicode": 11.8,
        "livecodebench": 12.2
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1227.22
      }
    },
    "confidence_score": 0.7667,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "apriel-v15-15b-thinker",
    "canonical_name": "Apriel-v1.5-15B-Thinker",
    "model_name": "Apriel-v1.5-15B-Thinker",
    "aliases": [
      "Apriel-v1.5-15B-Thinker"
    ],
    "provider": null,
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": 28.3319,
    "coding_score": 18.68,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.18,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 150.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": 0.106,
    "tau2": 0.684,
    "lcr": 20.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 12.0,
    "gpqa": 71.3,
    "scicode": 34.8,
    "ifbench": 61.7,
    "aime25": 87.5,
    "critpt": 1.1,
    "mmmu_pro": 57.1,
    "livecodebench": 72.8,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.274438+00:00",
        "confidence": 1.0,
        "raw_name": "Apriel-v1.5-15B-Thinker",
        "raw_scores": {
          "intelligence_score": 28.33194461137262,
          "coding_score": 18.68,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.18,
          "tokens_per_second": 150.0,
          "context_window": 128000,
          "terminalbench_hard": 0.106,
          "tau2": 0.684,
          "lcr": 20.0,
          "hle": 12.0,
          "gpqa": 71.3,
          "scicode": 34.8,
          "ifbench": 61.7,
          "aime25": 87.5,
          "critpt": 1.1,
          "mmmu_pro": 57.1,
          "livecodebench": 72.8
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 28.33194461137262,
        "coding_score": 18.68,
        "terminalbench_hard": 0.106,
        "tau2": 0.684,
        "lcr": 20.0,
        "hle": 12.0,
        "gpqa": 71.3,
        "scicode": 34.8,
        "ifbench": 61.7,
        "aime25": 87.5,
        "critpt": 1.1,
        "mmmu_pro": 57.1,
        "livecodebench": 72.8
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "jamba-15-large",
    "canonical_name": "Jamba 1.5 Large",
    "model_name": "Jamba 1.5 Large",
    "aliases": [
      "Jamba 1.5 Large",
      "jamba-1.5-large"
    ],
    "provider": "AI21 Labs",
    "context_window": 256000,
    "open_source": true,
    "arena_votes": 8659,
    "license_type": "Jamba Open Model License Agreement",
    "creator": null,
    "intelligence_score": 10.6951,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1288.81,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.5,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.0,
    "gpqa": 42.7,
    "scicode": 16.3,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 14.3,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.274472+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "Jamba 1.5 Large",
        "raw_scores": {
          "intelligence_score": 10.695130465051701,
          "blended_cost_per_1m": 3.5,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 256000,
          "hle": 4.0,
          "gpqa": 42.7,
          "scicode": 16.3,
          "livecodebench": 14.3
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127207+00:00",
        "confidence": 1.0,
        "raw_name": "jamba-1.5-large",
        "raw_scores": {
          "arena_elo": 1288.81,
          "arena_votes": 8659
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.695130465051701,
        "hle": 4.0,
        "gpqa": 42.7,
        "scicode": 16.3,
        "livecodebench": 14.3
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1288.81
      }
    },
    "confidence_score": 0.93,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "jamba-15-mini",
    "canonical_name": "Jamba 1.5 Mini",
    "model_name": "Jamba 1.5 Mini",
    "aliases": [
      "Jamba 1.5 Mini",
      "jamba-1.5-mini"
    ],
    "provider": "AI21 Labs",
    "context_window": 256000,
    "open_source": true,
    "arena_votes": 8854,
    "license_type": "Jamba Open Model License Agreement",
    "creator": null,
    "intelligence_score": 8.0277,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1239.05,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.25,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.1,
    "gpqa": 30.2,
    "scicode": 8.0,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 6.2,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.274508+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "Jamba 1.5 Mini",
        "raw_scores": {
          "intelligence_score": 8.027724014032357,
          "blended_cost_per_1m": 0.25,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 256000,
          "hle": 5.1,
          "gpqa": 30.2,
          "scicode": 8.0,
          "livecodebench": 6.2
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127626+00:00",
        "confidence": 1.0,
        "raw_name": "jamba-1.5-mini",
        "raw_scores": {
          "arena_elo": 1239.05,
          "arena_votes": 8854
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.027724014032357,
        "hle": 5.1,
        "gpqa": 30.2,
        "scicode": 8.0,
        "livecodebench": 6.2
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1239.05
      }
    },
    "confidence_score": 0.93,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "jamba-16-large",
    "canonical_name": "Jamba 1.6 Large",
    "model_name": "Jamba 1.6 Large",
    "aliases": [
      "Jamba 1.6 Large"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Jamba Open Model License Agreement",
    "creator": null,
    "intelligence_score": 10.5553,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 3.5,
    "latency_seconds": 0.79,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 52.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.0,
    "gpqa": 38.7,
    "scicode": 18.4,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 17.2,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.274540+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "Jamba 1.6 Large",
        "raw_scores": {
          "intelligence_score": 10.555304867718469,
          "blended_cost_per_1m": 3.5,
          "latency_seconds": 0.79,
          "tokens_per_second": 52.0,
          "context_window": 256000,
          "hle": 4.0,
          "gpqa": 38.7,
          "scicode": 18.4,
          "livecodebench": 17.2
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 10.555304867718469,
        "hle": 4.0,
        "gpqa": 38.7,
        "scicode": 18.4,
        "livecodebench": 17.2
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "jamba-16-mini",
    "canonical_name": "Jamba 1.6 Mini",
    "model_name": "Jamba 1.6 Mini",
    "aliases": [
      "Jamba 1.6 Mini"
    ],
    "provider": null,
    "context_window": 256000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Jamba Open Model License Agreement",
    "creator": null,
    "intelligence_score": 7.8708,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.25,
    "latency_seconds": 0.67,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 181.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.6,
    "gpqa": 30.0,
    "scicode": 10.1,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 7.1,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.274572+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "Jamba 1.6 Mini",
        "raw_scores": {
          "intelligence_score": 7.870810849851021,
          "blended_cost_per_1m": 0.25,
          "latency_seconds": 0.67,
          "tokens_per_second": 181.0,
          "context_window": 256000,
          "hle": 4.6,
          "gpqa": 30.0,
          "scicode": 10.1,
          "livecodebench": 7.1
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 7.870810849851021,
        "hle": 4.6,
        "gpqa": 30.0,
        "scicode": 10.1,
        "livecodebench": 7.1
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "arctic-instruct",
    "canonical_name": "Arctic Instruct",
    "model_name": "Arctic Instruct",
    "aliases": [
      "Arctic Instruct"
    ],
    "provider": null,
    "context_window": 4000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 8.8232,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.274593+00:00",
        "confidence": 0.44,
        "raw_name": "Arctic Instruct",
        "raw_scores": {
          "intelligence_score": 8.823244716278813,
          "context_window": 4000
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.823244716278813
      }
    },
    "confidence_score": 0.44,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen25-max",
    "canonical_name": "Qwen2.5 Max",
    "model_name": "Qwen2.5 Max",
    "aliases": [
      "Qwen2.5 Max",
      "qwen2.5-max"
    ],
    "provider": "Alibaba",
    "context_window": 32000,
    "open_source": null,
    "arena_votes": 33203,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": 16.2829,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1374.19,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 2.8,
    "latency_seconds": 1.06,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 41.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.5,
    "gpqa": 58.7,
    "scicode": 33.7,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 35.9,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.274625+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "Qwen2.5 Max",
        "raw_scores": {
          "intelligence_score": 16.282944203161424,
          "blended_cost_per_1m": 2.8,
          "latency_seconds": 1.06,
          "tokens_per_second": 41.0,
          "context_window": 32000,
          "hle": 4.5,
          "gpqa": 58.7,
          "scicode": 33.7,
          "livecodebench": 35.9
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126020+00:00",
        "confidence": 1.0,
        "raw_name": "qwen2.5-max",
        "raw_scores": {
          "arena_elo": 1374.19,
          "arena_votes": 33203
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 16.282944203161424,
        "hle": 4.5,
        "gpqa": 58.7,
        "scicode": 33.7,
        "livecodebench": 35.9
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1374.19
      }
    },
    "confidence_score": 0.93,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen25-instruct-72b",
    "canonical_name": "Qwen2.5 Instruct 72B",
    "model_name": "Qwen2.5 Instruct 72B",
    "aliases": [
      "Qwen2.5 Instruct 72B"
    ],
    "provider": "Alibaba",
    "context_window": 131072,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Qwen License Agreement",
    "creator": null,
    "intelligence_score": 15.5578,
    "coding_score": 11.94,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": 0.045,
    "tau2": 0.345,
    "lcr": 20.3,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.2,
    "gpqa": 49.1,
    "scicode": 26.7,
    "ifbench": 36.9,
    "aime25": 14.0,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 27.6,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.274664+00:00",
        "confidence": 0.79,
        "raw_name": "Qwen2.5 Instruct 72B",
        "raw_scores": {
          "intelligence_score": 15.557766275790943,
          "coding_score": 11.94,
          "context_window": 131072,
          "terminalbench_hard": 0.045,
          "tau2": 0.345,
          "lcr": 20.3,
          "hle": 4.2,
          "gpqa": 49.1,
          "scicode": 26.7,
          "ifbench": 36.9,
          "aime25": 14.0,
          "critpt": 0.0,
          "livecodebench": 27.6
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.557766275790943,
        "coding_score": 11.94,
        "terminalbench_hard": 0.045,
        "tau2": 0.345,
        "lcr": 20.3,
        "hle": 4.2,
        "gpqa": 49.1,
        "scicode": 26.7,
        "ifbench": 36.9,
        "aime25": 14.0,
        "critpt": 0.0,
        "livecodebench": 27.6
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen25-coder-instruct-32b",
    "canonical_name": "Qwen2.5 Coder Instruct 32B",
    "model_name": "Qwen2.5 Coder Instruct 32B",
    "aliases": [
      "Qwen2.5 Coder Instruct 32B"
    ],
    "provider": "Alibaba",
    "context_window": 131072,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 12.8656,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 3.8,
    "gpqa": 41.7,
    "scicode": 27.1,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 29.5,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.274692+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen2.5 Coder Instruct 32B",
        "raw_scores": {
          "intelligence_score": 12.865568210057065,
          "context_window": 131072,
          "hle": 3.8,
          "gpqa": 41.7,
          "scicode": 27.1,
          "livecodebench": 29.5
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 12.865568210057065,
        "hle": 3.8,
        "gpqa": 41.7,
        "scicode": 27.1,
        "livecodebench": 29.5
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen25-turbo",
    "canonical_name": "Qwen2.5 Turbo",
    "model_name": "Qwen2.5 Turbo",
    "aliases": [
      "Qwen2.5 Turbo"
    ],
    "provider": "Alibaba",
    "context_window": 1000000,
    "open_source": true,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 11.9736,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.09,
    "latency_seconds": 0.97,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 69.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.2,
    "gpqa": 41.0,
    "scicode": 15.3,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 16.3,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.274724+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "Qwen2.5 Turbo",
        "raw_scores": {
          "intelligence_score": 11.973563045943266,
          "blended_cost_per_1m": 0.09,
          "latency_seconds": 0.97,
          "tokens_per_second": 69.0,
          "context_window": 1000000,
          "hle": 4.2,
          "gpqa": 41.0,
          "scicode": 15.3,
          "livecodebench": 16.3
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 11.973563045943266,
        "hle": 4.2,
        "gpqa": 41.0,
        "scicode": 15.3,
        "livecodebench": 16.3
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen2-instruct-72b",
    "canonical_name": "Qwen2 Instruct 72B",
    "model_name": "Qwen2 Instruct 72B",
    "aliases": [
      "Qwen2 Instruct 72B"
    ],
    "provider": "Alibaba",
    "context_window": 131072,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Tongyi Qianwen LICENSE AGREEMENT",
    "creator": null,
    "intelligence_score": 11.6625,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 3.7,
    "gpqa": 37.1,
    "scicode": 22.9,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 15.9,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.274753+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen2 Instruct 72B",
        "raw_scores": {
          "intelligence_score": 11.662530563545237,
          "context_window": 131072,
          "hle": 3.7,
          "gpqa": 37.1,
          "scicode": 22.9,
          "livecodebench": 15.9
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 11.662530563545237,
        "hle": 3.7,
        "gpqa": 37.1,
        "scicode": 22.9,
        "livecodebench": 15.9
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-4b",
    "canonical_name": "Qwen3 4B (Reasoning)",
    "model_name": "Qwen3 4B (Reasoning)",
    "aliases": [
      "Qwen3 4B (Non-reasoning)",
      "Qwen3 4B (Reasoning)"
    ],
    "provider": "Alibaba",
    "context_window": 32000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 13.4004,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": 0.19,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.4358,
    "gpqa": 46.3168,
    "scicode": 9.7628,
    "ifbench": 32.5,
    "aime25": 22.3,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 35.4927,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.274786+00:00",
        "confidence": 0.72,
        "raw_name": "Qwen3 4B (Reasoning)",
        "raw_scores": {
          "intelligence_score": 14.220680621459485,
          "context_window": 32000,
          "tau2": 0.19,
          "lcr": 0.0,
          "hle": 5.1,
          "gpqa": 52.2,
          "scicode": 3.5,
          "ifbench": 32.5,
          "aime25": 22.3,
          "livecodebench": 46.5
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.275406+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen3 4B (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 12.49184791077126,
          "context_window": 32000,
          "hle": 3.7,
          "gpqa": 39.8,
          "scicode": 16.7,
          "livecodebench": 23.3
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.220680621459485,
        "tau2": 0.19,
        "lcr": 0.0,
        "hle": 5.1,
        "gpqa": 52.2,
        "scicode": 3.5,
        "ifbench": 32.5,
        "aime25": 22.3,
        "livecodebench": 46.5
      }
    },
    "confidence_score": 0.685,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-235b-a22b",
    "canonical_name": "Qwen3 235B A22B (Non-reasoning)",
    "model_name": "Qwen3 235B A22B (Non-reasoning)",
    "aliases": [
      "Qwen3 235B A22B (Non-reasoning)",
      "Qwen3 235B A22B (Reasoning)",
      "qwen3-235b-a22b"
    ],
    "provider": "Alibaba",
    "context_window": 32768,
    "open_source": true,
    "arena_votes": 27025,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 18.35,
    "coding_score": 15.67,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1374.8,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 786.1847,
    "terminalbench_hard": 0.061,
    "tau2": 0.256,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 8.2,
    "gpqa": 65.65,
    "scicode": 34.9,
    "ifbench": 37.65,
    "aime25": 52.85,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 48.25,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.274827+00:00",
        "confidence": 0.79,
        "raw_name": "Qwen3 235B A22B (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 16.93,
          "coding_score": 13.99,
          "context_window": 32768,
          "gdpval": 783.3263479943075,
          "terminalbench_hard": 0.061,
          "tau2": 0.272,
          "lcr": 0.0,
          "hle": 4.7,
          "gpqa": 61.3,
          "scicode": 29.9,
          "ifbench": 36.6,
          "aime25": 23.7,
          "critpt": 0.0,
          "livecodebench": 34.3
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.275071+00:00",
        "confidence": 0.79,
        "raw_name": "Qwen3 235B A22B (Reasoning)",
        "raw_scores": {
          "intelligence_score": 19.77,
          "coding_score": 17.35,
          "context_window": 32768,
          "gdpval": 789.0431340050426,
          "terminalbench_hard": 0.061,
          "tau2": 0.24,
          "lcr": 0.0,
          "hle": 11.7,
          "gpqa": 70.0,
          "scicode": 39.9,
          "ifbench": 38.7,
          "aime25": 82.0,
          "critpt": 0.0,
          "livecodebench": 62.2
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125995+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-235b-a22b",
        "raw_scores": {
          "arena_elo": 1374.8,
          "arena_votes": 27025
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 16.93,
        "coding_score": 13.99,
        "gdpval": 783.3263479943075,
        "terminalbench_hard": 0.061,
        "tau2": 0.272,
        "lcr": 0.0,
        "hle": 4.7,
        "gpqa": 61.3,
        "scicode": 29.9,
        "ifbench": 36.6,
        "aime25": 23.7,
        "critpt": 0.0,
        "livecodebench": 34.3
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1374.8
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-30b-a3b",
    "canonical_name": "Qwen3 30B A3B (Reasoning)",
    "model_name": "Qwen3 30B A3B (Reasoning)",
    "aliases": [
      "Qwen3 30B A3B (Non-reasoning)",
      "Qwen3 30B A3B (Reasoning)",
      "qwen3-30b-a3b"
    ],
    "provider": "Alibaba",
    "context_window": 32768,
    "open_source": true,
    "arena_votes": 27284,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 13.805,
    "coding_score": 12.175,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1328.15,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 470.5229,
    "terminalbench_hard": 0.0455,
    "tau2": 0.241,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 5.6,
    "gpqa": 56.55,
    "scicode": 27.45,
    "ifbench": 36.7,
    "aime25": 47.0,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 41.4,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.274865+00:00",
        "confidence": 0.79,
        "raw_name": "Qwen3 30B A3B (Reasoning)",
        "raw_scores": {
          "intelligence_score": 15.25,
          "coding_score": 11.01,
          "context_window": 32768,
          "gdpval": 554.2922450835997,
          "terminalbench_hard": 0.023,
          "tau2": 0.26,
          "lcr": 0.0,
          "hle": 6.6,
          "gpqa": 61.6,
          "scicode": 28.5,
          "ifbench": 41.5,
          "aime25": 72.3,
          "critpt": 0.0,
          "livecodebench": 50.6
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.275374+00:00",
        "confidence": 0.79,
        "raw_name": "Qwen3 30B A3B (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 12.36,
          "coding_score": 13.34,
          "context_window": 32768,
          "gdpval": 386.753468838431,
          "terminalbench_hard": 0.068,
          "tau2": 0.222,
          "lcr": 0.0,
          "hle": 4.6,
          "gpqa": 51.5,
          "scicode": 26.4,
          "ifbench": 31.9,
          "aime25": 21.7,
          "critpt": 0.0,
          "livecodebench": 32.2
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126685+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-30b-a3b",
        "raw_scores": {
          "arena_elo": 1328.15,
          "arena_votes": 27284
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.25,
        "coding_score": 11.01,
        "gdpval": 554.2922450835997,
        "terminalbench_hard": 0.023,
        "tau2": 0.26,
        "lcr": 0.0,
        "hle": 6.6,
        "gpqa": 61.6,
        "scicode": 28.5,
        "ifbench": 41.5,
        "aime25": 72.3,
        "critpt": 0.0,
        "livecodebench": 50.6
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1328.15
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-14b",
    "canonical_name": "Qwen3 14B (Reasoning)",
    "model_name": "Qwen3 14B (Reasoning)",
    "aliases": [
      "Qwen3 14B (Non-reasoning)",
      "Qwen3 14B (Reasoning)"
    ],
    "provider": "Alibaba",
    "context_window": 32768,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 14.44,
    "coding_score": 12.715,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 533.1245,
    "terminalbench_hard": 0.0455,
    "tau2": 0.3335,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.25,
    "gpqa": 53.7,
    "scicode": 29.05,
    "ifbench": 32.2,
    "aime25": 56.85,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 40.15,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.274903+00:00",
        "confidence": 0.79,
        "raw_name": "Qwen3 14B (Reasoning)",
        "raw_scores": {
          "intelligence_score": 16.16,
          "coding_score": 13.06,
          "context_window": 32768,
          "gdpval": 535.5886050179225,
          "terminalbench_hard": 0.038,
          "tau2": 0.345,
          "lcr": 0.0,
          "hle": 4.3,
          "gpqa": 60.4,
          "scicode": 31.6,
          "ifbench": 40.5,
          "aime25": 55.7,
          "critpt": 0.0,
          "livecodebench": 52.3
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.275337+00:00",
        "confidence": 0.79,
        "raw_name": "Qwen3 14B (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 12.72,
          "coding_score": 12.37,
          "context_window": 32768,
          "gdpval": 530.6604456979462,
          "terminalbench_hard": 0.053,
          "tau2": 0.322,
          "lcr": 0.0,
          "hle": 4.2,
          "gpqa": 47.0,
          "scicode": 26.5,
          "ifbench": 23.9,
          "aime25": 58.0,
          "critpt": 0.0,
          "livecodebench": 28.0
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 16.16,
        "coding_score": 13.06,
        "gdpval": 535.5886050179225,
        "terminalbench_hard": 0.038,
        "tau2": 0.345,
        "lcr": 0.0,
        "hle": 4.3,
        "gpqa": 60.4,
        "scicode": 31.6,
        "ifbench": 40.5,
        "aime25": 55.7,
        "critpt": 0.0,
        "livecodebench": 52.3
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen-chat-72b",
    "canonical_name": "Qwen Chat 72B",
    "model_name": "Qwen Chat 72B",
    "aliases": [
      "Qwen Chat 72B"
    ],
    "provider": "Alibaba",
    "context_window": 33792,
    "open_source": null,
    "arena_votes": null,
    "license_type": null,
    "creator": null,
    "intelligence_score": 8.8232,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.274926+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen Chat 72B",
        "raw_scores": {
          "intelligence_score": 8.823244716278813,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 33792
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 8.823244716278813
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen25-instruct-32b",
    "canonical_name": "Qwen2.5 Instruct 32B",
    "model_name": "Qwen2.5 Instruct 32B",
    "aliases": [
      "Qwen2.5 Instruct 32B"
    ],
    "provider": "Alibaba",
    "context_window": 128000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 13.2365,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 3.8,
    "gpqa": 46.6,
    "scicode": 22.9,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 24.8,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.274957+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "Qwen2.5 Instruct 32B",
        "raw_scores": {
          "intelligence_score": 13.236526421623505,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 128000,
          "hle": 3.8,
          "gpqa": 46.6,
          "scicode": 22.9,
          "livecodebench": 24.8
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.236526421623505,
        "hle": 3.8,
        "gpqa": 46.6,
        "scicode": 22.9,
        "livecodebench": 24.8
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwq-32b",
    "canonical_name": "QwQ 32B",
    "model_name": "QwQ 32B",
    "aliases": [
      "QwQ 32B",
      "qwq-32b"
    ],
    "provider": "Alibaba",
    "context_window": 131072,
    "open_source": true,
    "arena_votes": 26003,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 19.7242,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1335.75,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": 25.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 8.2,
    "gpqa": 59.3,
    "scicode": 35.8,
    "ifbench": 38.8,
    "aime25": 29.0,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 63.1,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.275033+00:00",
        "confidence": 0.72,
        "raw_name": "QwQ 32B",
        "raw_scores": {
          "intelligence_score": 19.724216680037447,
          "context_window": 131072,
          "lcr": 25.0,
          "hle": 8.2,
          "gpqa": 59.3,
          "scicode": 35.8,
          "ifbench": 38.8,
          "aime25": 29.0,
          "livecodebench": 63.1
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126558+00:00",
        "confidence": 1.0,
        "raw_name": "qwq-32b",
        "raw_scores": {
          "arena_elo": 1335.75,
          "arena_votes": 26003
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 19.724216680037447,
        "lcr": 25.0,
        "hle": 8.2,
        "gpqa": 59.3,
        "scicode": 35.8,
        "ifbench": 38.8,
        "aime25": 29.0,
        "livecodebench": 63.1
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1335.75
      }
    },
    "confidence_score": 0.86,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-32b",
    "canonical_name": "Qwen3 32B (Non-reasoning)",
    "model_name": "Qwen3 32B (Non-reasoning)",
    "aliases": [
      "Qwen3 32B (Non-reasoning)",
      "Qwen3 32B (Reasoning)",
      "qwen3-32b"
    ],
    "provider": "Alibaba",
    "context_window": 32768,
    "open_source": true,
    "arena_votes": 3932,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 15.567,
    "coding_score": 13.83,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1346.98,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 552.4027,
    "terminalbench_hard": 0.03,
    "tau2": 0.298,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 6.3927,
    "gpqa": 60.4583,
    "scicode": 31.8715,
    "ifbench": 34.0113,
    "aime25": 47.5854,
    "critpt": 0.3,
    "mmmu_pro": null,
    "livecodebench": 42.298,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.275104+00:00",
        "confidence": 0.72,
        "raw_name": "Qwen3 32B (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 14.532286886975053,
          "context_window": 32768,
          "lcr": 0.0,
          "hle": 4.3,
          "gpqa": 53.5,
          "scicode": 28.0,
          "ifbench": 31.5,
          "aime25": 19.7,
          "livecodebench": 28.8
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.275188+00:00",
        "confidence": 0.79,
        "raw_name": "Qwen3 32B (Reasoning)",
        "raw_scores": {
          "intelligence_score": 16.51,
          "coding_score": 13.83,
          "context_window": 32768,
          "gdpval": 552.402696512489,
          "terminalbench_hard": 0.03,
          "tau2": 0.298,
          "lcr": 0.0,
          "hle": 8.3,
          "gpqa": 66.8,
          "scicode": 35.4,
          "ifbench": 36.3,
          "aime25": 73.0,
          "critpt": 0.3,
          "livecodebench": 54.6
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126373+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-32b",
        "raw_scores": {
          "arena_elo": 1346.98,
          "arena_votes": 3932
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 14.532286886975053,
        "lcr": 0.0,
        "hle": 4.3,
        "gpqa": 53.5,
        "scicode": 28.0,
        "ifbench": 31.5,
        "aime25": 19.7,
        "livecodebench": 28.8,
        "coding_score": 13.83,
        "gdpval": 552.402696512489,
        "terminalbench_hard": 0.03,
        "tau2": 0.298,
        "critpt": 0.3
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1346.98
      }
    },
    "confidence_score": 0.8367,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-8b",
    "canonical_name": "Qwen3 8B (Reasoning)",
    "model_name": "Qwen3 8B (Reasoning)",
    "aliases": [
      "Qwen3 8B (Non-reasoning)",
      "Qwen3 8B (Reasoning)"
    ],
    "provider": "Alibaba",
    "context_window": 131072,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 11.825,
    "coding_score": 8.075,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 548.436,
    "terminalbench_hard": 0.023,
    "tau2": 0.2635,
    "lcr": 0.0,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 3.5,
    "gpqa": 52.05,
    "scicode": 19.7,
    "ifbench": 31.05,
    "aime25": 21.65,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 30.4,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.275146+00:00",
        "confidence": 0.79,
        "raw_name": "Qwen3 8B (Reasoning)",
        "raw_scores": {
          "intelligence_score": 13.1,
          "coding_score": 9.04,
          "context_window": 131072,
          "gdpval": 558.7613998797134,
          "terminalbench_hard": 0.023,
          "tau2": 0.278,
          "lcr": 0.0,
          "hle": 4.2,
          "gpqa": 58.9,
          "scicode": 22.6,
          "ifbench": 33.5,
          "aime25": 19.0,
          "critpt": 0.0,
          "livecodebench": 40.6
        }
      },
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.275226+00:00",
        "confidence": 0.79,
        "raw_name": "Qwen3 8B (Non-reasoning)",
        "raw_scores": {
          "intelligence_score": 10.55,
          "coding_score": 7.11,
          "context_window": 32768,
          "gdpval": 538.1106244151956,
          "terminalbench_hard": 0.023,
          "tau2": 0.249,
          "lcr": 0.0,
          "hle": 2.8,
          "gpqa": 45.2,
          "scicode": 16.8,
          "ifbench": 28.6,
          "aime25": 24.3,
          "critpt": 0.0,
          "livecodebench": 20.2
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 13.1,
        "coding_score": 9.04,
        "gdpval": 558.7613998797134,
        "terminalbench_hard": 0.023,
        "tau2": 0.278,
        "lcr": 0.0,
        "hle": 4.2,
        "gpqa": 58.9,
        "scicode": 22.6,
        "ifbench": 33.5,
        "aime25": 19.0,
        "critpt": 0.0,
        "livecodebench": 40.6
      }
    },
    "confidence_score": 0.79,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwq-32b-preview",
    "canonical_name": "QwQ 32B-Preview",
    "model_name": "QwQ 32B-Preview",
    "aliases": [
      "QwQ 32B-Preview",
      "qwq-32b-preview"
    ],
    "provider": "Alibaba",
    "context_window": 32768,
    "open_source": true,
    "arena_votes": 3233,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 15.174,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1157.1,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.14,
    "latency_seconds": 0.27,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 57.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.8,
    "gpqa": 55.7,
    "scicode": 3.8,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 33.7,
    "sources": [
      "Artificial Analysis",
      "LMSYS Chatbot Arena"
    ],
    "source_count": 2,
    "data_tier": 1,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.275271+00:00",
        "confidence": 0.8600000000000001,
        "raw_name": "QwQ 32B-Preview",
        "raw_scores": {
          "intelligence_score": 15.173958740020906,
          "blended_cost_per_1m": 0.14,
          "latency_seconds": 0.27,
          "tokens_per_second": 57.0,
          "context_window": 32768,
          "hle": 4.8,
          "gpqa": 55.7,
          "scicode": 3.8,
          "livecodebench": 33.7
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128276+00:00",
        "confidence": 1.0,
        "raw_name": "qwq-32b-preview",
        "raw_scores": {
          "arena_elo": 1157.1,
          "arena_votes": 3233
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 15.173958740020906,
        "hle": 4.8,
        "gpqa": 55.7,
        "scicode": 3.8,
        "livecodebench": 33.7
      },
      "LMSYS Chatbot Arena": {
        "arena_elo": 1157.1
      }
    },
    "confidence_score": 0.93,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen15-chat-110b",
    "canonical_name": "Qwen1.5 Chat 110B",
    "model_name": "Qwen1.5 Chat 110B",
    "aliases": [
      "Qwen1.5 Chat 110B"
    ],
    "provider": "Alibaba",
    "context_window": 32000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Tongyi Qianwen LICENSE AGREEMENT",
    "creator": null,
    "intelligence_score": 9.5482,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.0,
    "latency_seconds": 0.0,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 0.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": 28.9,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.275298+00:00",
        "confidence": 0.72,
        "raw_name": "Qwen1.5 Chat 110B",
        "raw_scores": {
          "intelligence_score": 9.5481702885671,
          "blended_cost_per_1m": 0.0,
          "latency_seconds": 0.0,
          "tokens_per_second": 0.0,
          "context_window": 32000,
          "gpqa": 28.9
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.5481702885671,
        "gpqa": 28.9
      }
    },
    "confidence_score": 0.72,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen25-coder-instruct-7b",
    "canonical_name": "Qwen2.5 Coder Instruct 7B",
    "model_name": "Qwen2.5 Coder Instruct 7B",
    "aliases": [
      "Qwen2.5 Coder Instruct 7B"
    ],
    "provider": "Alibaba",
    "context_window": 131072,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 9.9825,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 4.8,
    "gpqa": 33.9,
    "scicode": 14.8,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": 12.6,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.275434+00:00",
        "confidence": 0.65,
        "raw_name": "Qwen2.5 Coder Instruct 7B ",
        "raw_scores": {
          "intelligence_score": 9.982467098648165,
          "context_window": 131072,
          "hle": 4.8,
          "gpqa": 33.9,
          "scicode": 14.8,
          "livecodebench": 12.6
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 9.982467098648165,
        "hle": 4.8,
        "gpqa": 33.9,
        "scicode": 14.8,
        "livecodebench": 12.6
      }
    },
    "confidence_score": 0.65,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "seed-oss-36b-instruct",
    "canonical_name": "Seed-OSS-36B-Instruct",
    "model_name": "Seed-OSS-36B-Instruct",
    "aliases": [
      "Seed-OSS-36B-Instruct"
    ],
    "provider": null,
    "context_window": 512000,
    "open_source": true,
    "arena_votes": null,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": 24.99,
    "coding_score": 16.7,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": null,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": 0.3,
    "latency_seconds": 1.58,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": 32.0,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": 809.2808,
    "terminalbench_hard": 0.068,
    "tau2": 0.494,
    "lcr": 57.7,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": 9.1,
    "gpqa": 72.6,
    "scicode": 36.5,
    "ifbench": 41.9,
    "aime25": 84.7,
    "critpt": 0.0,
    "mmmu_pro": null,
    "livecodebench": 76.5,
    "sources": [
      "Artificial Analysis"
    ],
    "source_count": 1,
    "data_tier": 2,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "Artificial Analysis",
        "scraped_at": "2026-02-24T21:08:14.275477+00:00",
        "confidence": 1.0,
        "raw_name": "Seed-OSS-36B-Instruct",
        "raw_scores": {
          "intelligence_score": 24.99,
          "coding_score": 16.7,
          "blended_cost_per_1m": 0.3,
          "latency_seconds": 1.58,
          "tokens_per_second": 32.0,
          "context_window": 512000,
          "gdpval": 809.2807853800691,
          "terminalbench_hard": 0.068,
          "tau2": 0.494,
          "lcr": 57.7,
          "hle": 9.1,
          "gpqa": 72.6,
          "scicode": 36.5,
          "ifbench": 41.9,
          "aime25": 84.7,
          "critpt": 0.0,
          "livecodebench": 76.5
        }
      }
    ],
    "benchmark_breakdown": {
      "Artificial Analysis": {
        "intelligence_score": 24.99,
        "coding_score": 16.7,
        "gdpval": 809.2807853800691,
        "terminalbench_hard": 0.068,
        "tau2": 0.494,
        "lcr": 57.7,
        "hle": 9.1,
        "gpqa": 72.6,
        "scicode": 36.5,
        "ifbench": 41.9,
        "aime25": 84.7,
        "critpt": 0.0,
        "livecodebench": 76.5
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "dola-seed-20",
    "canonical_name": "dola-seed-2.0-preview",
    "model_name": "dola-seed-2.0-preview",
    "aliases": [
      "dola-seed-2.0-preview"
    ],
    "provider": "Bytedance",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3924,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1474.03,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.124575+00:00",
        "confidence": 1.0,
        "raw_name": "dola-seed-2.0-preview",
        "raw_scores": {
          "arena_elo": 1474.03,
          "arena_votes": 3924
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1474.03
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "grok-41",
    "canonical_name": "grok-4.1-thinking",
    "model_name": "grok-4.1-thinking",
    "aliases": [
      "grok-4.1",
      "grok-4.1-thinking"
    ],
    "provider": "xAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 41067,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1468.0,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.124588+00:00",
        "confidence": 1.0,
        "raw_name": "grok-4.1-thinking",
        "raw_scores": {
          "arena_elo": 1473.23,
          "arena_votes": 36844
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.124657+00:00",
        "confidence": 1.0,
        "raw_name": "grok-4.1",
        "raw_scores": {
          "arena_elo": 1462.77,
          "arena_votes": 41067
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1473.23
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemini-3-flash",
    "canonical_name": "gemini-3-flash (thinking-minimal)",
    "model_name": "gemini-3-flash (thinking-minimal)",
    "aliases": [
      "gemini-3-flash",
      "gemini-3-flash (thinking-minimal)"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 28520,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1467.44,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.124605+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-3-flash",
        "raw_scores": {
          "arena_elo": 1473.1,
          "arena_votes": 28520
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.124672+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-3-flash (thinking-minimal)",
        "raw_scores": {
          "arena_elo": 1461.78,
          "arena_votes": 19891
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1473.1
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "ernie-50",
    "canonical_name": "ernie-5.0-0110",
    "model_name": "ernie-5.0-0110",
    "aliases": [
      "ernie-5.0-0110"
    ],
    "provider": "Baidu",
    "context_window": null,
    "open_source": null,
    "arena_votes": 13184,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1452.47,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.124729+00:00",
        "confidence": 1.0,
        "raw_name": "ernie-5.0-0110",
        "raw_scores": {
          "arena_elo": 1452.47,
          "arena_votes": 13184
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1452.47
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "claude-sonnet-45",
    "canonical_name": "claude-sonnet-4.5-20250929",
    "model_name": "claude-sonnet-4.5-20250929",
    "aliases": [
      "claude-sonnet-4.5-20250929",
      "claude-sonnet-4.5-20250929-thinking-32k"
    ],
    "provider": "Anthropic",
    "context_window": null,
    "open_source": null,
    "arena_votes": 48195,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1449.925,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.124761+00:00",
        "confidence": 1.0,
        "raw_name": "claude-sonnet-4.5-20250929",
        "raw_scores": {
          "arena_elo": 1450.12,
          "arena_votes": 46018
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.124792+00:00",
        "confidence": 1.0,
        "raw_name": "claude-sonnet-4.5-20250929-thinking-32k",
        "raw_scores": {
          "arena_elo": 1449.73,
          "arena_votes": 48195
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1450.12
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "ernie-50-preview",
    "canonical_name": "ernie-5.0-preview-1203",
    "model_name": "ernie-5.0-preview-1203",
    "aliases": [
      "ernie-5.0-preview-1022",
      "ernie-5.0-preview-1203"
    ],
    "provider": "Baidu",
    "context_window": null,
    "open_source": null,
    "arena_votes": 9724,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1433.75,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.124819+00:00",
        "confidence": 1.0,
        "raw_name": "ernie-5.0-preview-1203",
        "raw_scores": {
          "arena_elo": 1449.16,
          "arena_votes": 9724
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125190+00:00",
        "confidence": 1.0,
        "raw_name": "ernie-5.0-preview-1022",
        "raw_scores": {
          "arena_elo": 1418.34,
          "arena_votes": 4563
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1449.16
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gpt-45-preview",
    "canonical_name": "gpt-4.5-preview-2025-02-27",
    "model_name": "gpt-4.5-preview-2025-02-27",
    "aliases": [
      "gpt-4.5-preview-2025-02-27"
    ],
    "provider": "OpenAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 14549,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1444.32,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.124865+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-4.5-preview-2025-02-27",
        "raw_scores": {
          "arena_elo": 1444.32,
          "arena_votes": 14549
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1444.32
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "kimi-k25-instant",
    "canonical_name": "kimi-k2.5-instant",
    "model_name": "kimi-k2.5-instant",
    "aliases": [
      "kimi-k2.5-instant"
    ],
    "provider": "Moonshot",
    "context_window": null,
    "open_source": null,
    "arena_votes": 6476,
    "license_type": "Modified MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1435.86,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.124943+00:00",
        "confidence": 1.0,
        "raw_name": "kimi-k2.5-instant",
        "raw_scores": {
          "arena_elo": 1435.86,
          "arena_votes": 6476
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1435.86
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "kimi-k2-turbo",
    "canonical_name": "kimi-k2-thinking-turbo",
    "model_name": "kimi-k2-thinking-turbo",
    "aliases": [
      "kimi-k2-thinking-turbo"
    ],
    "provider": "Moonshot",
    "context_window": null,
    "open_source": null,
    "arena_votes": 35502,
    "license_type": "Modified MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1429.17,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125032+00:00",
        "confidence": 1.0,
        "raw_name": "kimi-k2-thinking-turbo",
        "raw_scores": {
          "arena_elo": 1429.17,
          "arena_votes": 35502
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1429.17
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-235b",
    "canonical_name": "qwen3-235b-a22b-instruct-2507",
    "model_name": "qwen3-235b-a22b-instruct-2507",
    "aliases": [
      "qwen3-235b-a22b-instruct-2507",
      "qwen3-235b-a22b-no-thinking"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 70948,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1412.06,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125125+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-235b-a22b-instruct-2507",
        "raw_scores": {
          "arena_elo": 1422.11,
          "arena_votes": 70948
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125473+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-235b-a22b-no-thinking",
        "raw_scores": {
          "arena_elo": 1402.01,
          "arena_votes": 39296
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1422.11
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "claude-sonnet-4",
    "canonical_name": "claude-sonnet-4-20250514-thinking-32k",
    "model_name": "claude-sonnet-4-20250514-thinking-32k",
    "aliases": [
      "claude-sonnet-4-20250514",
      "claude-sonnet-4-20250514-thinking-32k"
    ],
    "provider": "Anthropic",
    "context_window": null,
    "open_source": null,
    "arena_votes": 41364,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1394.855,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125500+00:00",
        "confidence": 1.0,
        "raw_name": "claude-sonnet-4-20250514-thinking-32k",
        "raw_scores": {
          "arena_elo": 1399.95,
          "arena_votes": 35976
        }
      },
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125671+00:00",
        "confidence": 1.0,
        "raw_name": "claude-sonnet-4-20250514",
        "raw_scores": {
          "arena_elo": 1389.76,
          "arena_votes": 41364
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1399.95
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "longcat-flash-chat",
    "canonical_name": "longcat-flash-chat",
    "model_name": "longcat-flash-chat",
    "aliases": [
      "longcat-flash-chat"
    ],
    "provider": "Meituan",
    "context_window": null,
    "open_source": null,
    "arena_votes": 11489,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1399.93,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125513+00:00",
        "confidence": 1.0,
        "raw_name": "longcat-flash-chat",
        "raw_scores": {
          "arena_elo": 1399.93,
          "arena_votes": 11489
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1399.93
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-235b-a22b-thinking-2507",
    "canonical_name": "qwen3-235b-a22b-thinking-2507",
    "model_name": "qwen3-235b-a22b-thinking-2507",
    "aliases": [
      "qwen3-235b-a22b-thinking-2507"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 9189,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1398.52,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125526+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-235b-a22b-thinking-2507",
        "raw_scores": {
          "arena_elo": 1398.52,
          "arena_votes": 9189
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1398.52
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "nova-experimental",
    "canonical_name": "amazon-nova-experimental-chat-12-10",
    "model_name": "amazon-nova-experimental-chat-12-10",
    "aliases": [
      "amazon-nova-experimental-chat-12-10"
    ],
    "provider": "Amazon",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3701,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1394.54,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125578+00:00",
        "confidence": 1.0,
        "raw_name": "amazon-nova-experimental-chat-12-10",
        "raw_scores": {
          "arena_elo": 1394.54,
          "arena_votes": 3701
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1394.54
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "hunyuan-vision-15",
    "canonical_name": "hunyuan-vision-1.5-thinking",
    "model_name": "hunyuan-vision-1.5-thinking",
    "aliases": [
      "hunyuan-vision-1.5-thinking"
    ],
    "provider": "Tencent",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2217,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1393.5,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125606+00:00",
        "confidence": 1.0,
        "raw_name": "hunyuan-vision-1.5-thinking",
        "raw_scores": {
          "arena_elo": 1393.5,
          "arena_votes": 2217
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1393.5
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "mai-1-preview",
    "canonical_name": "mai-1-preview",
    "model_name": "mai-1-preview",
    "aliases": [
      "mai-1-preview"
    ],
    "provider": "Microsoft AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 18015,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1391.94,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125619+00:00",
        "confidence": 1.0,
        "raw_name": "mai-1-preview",
        "raw_scores": {
          "arena_elo": 1391.94,
          "arena_votes": 18015
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1391.94
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "step-35-flash",
    "canonical_name": "step-3.5-flash",
    "model_name": "step-3.5-flash",
    "aliases": [
      "step-3.5-flash"
    ],
    "provider": "StepFun",
    "context_window": null,
    "open_source": null,
    "arena_votes": 7982,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1390.23,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125658+00:00",
        "confidence": 1.0,
        "raw_name": "step-3.5-flash",
        "raw_scores": {
          "arena_elo": 1390.23,
          "arena_votes": 7982
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1390.23
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "claude-37-sonnet-20250219-thinking-32k",
    "canonical_name": "claude-3.7-sonnet-20250219-thinking-32k",
    "model_name": "claude-3.7-sonnet-20250219-thinking-32k",
    "aliases": [
      "claude-3.7-sonnet-20250219-thinking-32k"
    ],
    "provider": "Anthropic",
    "context_window": null,
    "open_source": null,
    "arena_votes": 39729,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1388.48,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125714+00:00",
        "confidence": 1.0,
        "raw_name": "claude-3.7-sonnet-20250219-thinking-32k",
        "raw_scores": {
          "arena_elo": 1388.48,
          "arena_votes": 39729
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1388.48
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "hunyuan-t1-20250711",
    "canonical_name": "hunyuan-t1-20250711",
    "model_name": "hunyuan-t1-20250711",
    "aliases": [
      "hunyuan-t1-20250711"
    ],
    "provider": "Tencent",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4767,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1386.65,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125755+00:00",
        "confidence": 1.0,
        "raw_name": "hunyuan-t1-20250711",
        "raw_scores": {
          "arena_elo": 1386.65,
          "arena_votes": 4767
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1386.65
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "minimax-m21-preview",
    "canonical_name": "minimax-m2.1-preview",
    "model_name": "minimax-m2.1-preview",
    "aliases": [
      "minimax-m2.1-preview"
    ],
    "provider": "MiniMax",
    "context_window": null,
    "open_source": null,
    "arena_votes": 17098,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1385.43,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125782+00:00",
        "confidence": 1.0,
        "raw_name": "minimax-m2.1-preview",
        "raw_scores": {
          "arena_elo": 1385.43,
          "arena_votes": 17098
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1385.43
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "mistral-medium-2505",
    "canonical_name": "mistral-medium-2505",
    "model_name": "mistral-medium-2505",
    "aliases": [
      "mistral-medium-2505"
    ],
    "provider": "Mistral",
    "context_window": null,
    "open_source": null,
    "arena_votes": 34388,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1384.59,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125902+00:00",
        "confidence": 1.0,
        "raw_name": "mistral-medium-2505",
        "raw_scores": {
          "arena_elo": 1384.59,
          "arena_votes": 34388
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1384.59
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-30b-a3b-instruct-2507",
    "canonical_name": "qwen3-30b-a3b-instruct-2507",
    "model_name": "qwen3-30b-a3b-instruct-2507",
    "aliases": [
      "qwen3-30b-a3b-instruct-2507"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 23949,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1383.71,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125918+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-30b-a3b-instruct-2507",
        "raw_scores": {
          "arena_elo": 1383.71,
          "arena_votes": 23949
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1383.71
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "hunyuan-turbos-20250416",
    "canonical_name": "hunyuan-turbos-20250416",
    "model_name": "hunyuan-turbos-20250416",
    "aliases": [
      "hunyuan-turbos-20250416"
    ],
    "provider": "Tencent",
    "context_window": null,
    "open_source": null,
    "arena_votes": 11000,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1382.58,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125931+00:00",
        "confidence": 1.0,
        "raw_name": "hunyuan-turbos-20250416",
        "raw_scores": {
          "arena_elo": 1382.58,
          "arena_votes": 11000
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1382.58
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemini-25-flash-lite-preview-09-2025-no-thinking",
    "canonical_name": "gemini-2.5-flash-lite-preview-09-2025-no-thinking",
    "model_name": "gemini-2.5-flash-lite-preview-09-2025-no-thinking",
    "aliases": [
      "gemini-2.5-flash-lite-preview-09-2025-no-thinking"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 46863,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1379.57,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125957+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-2.5-flash-lite-preview-09-2025-no-thinking",
        "raw_scores": {
          "arena_elo": 1379.57,
          "arena_votes": 46863
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1379.57
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "trinity-large",
    "canonical_name": "trinity-large",
    "model_name": "trinity-large",
    "aliases": [
      "trinity-large"
    ],
    "provider": "Arcee AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 1324,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1375.25,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.125982+00:00",
        "confidence": 1.0,
        "raw_name": "trinity-large",
        "raw_scores": {
          "arena_elo": 1375.25,
          "arena_votes": 1324
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1375.25
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemini-25-flash-lite-preview-06-17-thinking",
    "canonical_name": "gemini-2.5-flash-lite-preview-06-17-thinking",
    "model_name": "gemini-2.5-flash-lite-preview-06-17-thinking",
    "aliases": [
      "gemini-2.5-flash-lite-preview-06-17-thinking"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 33675,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1374.66,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126007+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-2.5-flash-lite-preview-06-17-thinking",
        "raw_scores": {
          "arena_elo": 1374.66,
          "arena_votes": 33675
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1374.66
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen3-next-80b-a3b-thinking",
    "canonical_name": "qwen3-next-80b-a3b-thinking",
    "model_name": "qwen3-next-80b-a3b-thinking",
    "aliases": [
      "qwen3-next-80b-a3b-thinking"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 13764,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1368.85,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126081+00:00",
        "confidence": 1.0,
        "raw_name": "qwen3-next-80b-a3b-thinking",
        "raw_scores": {
          "arena_elo": 1368.85,
          "arena_votes": 13764
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1368.85
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "minimax-m1",
    "canonical_name": "minimax-m1",
    "model_name": "minimax-m1",
    "aliases": [
      "minimax-m1"
    ],
    "provider": "MiniMax",
    "context_window": null,
    "open_source": null,
    "arena_votes": 36568,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1367.36,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126094+00:00",
        "confidence": 1.0,
        "raw_name": "minimax-m1",
        "raw_scores": {
          "arena_elo": 1367.36,
          "arena_votes": 36568
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1367.36
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemma-3-27b-it",
    "canonical_name": "gemma-3-27b-it",
    "model_name": "gemma-3-27b-it",
    "aliases": [
      "gemma-3-27b-it"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 48464,
    "license_type": "Gemma",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1365.12,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126107+00:00",
        "confidence": 1.0,
        "raw_name": "gemma-3-27b-it",
        "raw_scores": {
          "arena_elo": 1365.12,
          "arena_votes": 48464
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1365.12
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "amazon-nova-experimental-chat-11-10",
    "canonical_name": "amazon-nova-experimental-chat-11-10",
    "model_name": "amazon-nova-experimental-chat-11-10",
    "aliases": [
      "amazon-nova-experimental-chat-11-10"
    ],
    "provider": "Amazon",
    "context_window": null,
    "open_source": null,
    "arena_votes": 18446,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1364.9,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126120+00:00",
        "confidence": 1.0,
        "raw_name": "amazon-nova-experimental-chat-11-10",
        "raw_scores": {
          "arena_elo": 1364.9,
          "arena_votes": 18446
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1364.9
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "o3-mini-high",
    "canonical_name": "o3-mini-high",
    "model_name": "o3-mini-high",
    "aliases": [
      "o3-mini-high"
    ],
    "provider": "OpenAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 18584,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1364.06,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126144+00:00",
        "confidence": 1.0,
        "raw_name": "o3-mini-high",
        "raw_scores": {
          "arena_elo": 1364.06,
          "arena_votes": 18584
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1364.06
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "grok-3-mini-beta",
    "canonical_name": "grok-3-mini-beta",
    "model_name": "grok-3-mini-beta",
    "aliases": [
      "grok-3-mini-beta"
    ],
    "provider": "xAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 23619,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1356.78,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126195+00:00",
        "confidence": 1.0,
        "raw_name": "grok-3-mini-beta",
        "raw_scores": {
          "arena_elo": 1356.78,
          "arena_votes": 23619
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1356.78
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "mistral-small-2506",
    "canonical_name": "mistral-small-2506",
    "model_name": "mistral-small-2506",
    "aliases": [
      "mistral-small-2506"
    ],
    "provider": "Mistral",
    "context_window": null,
    "open_source": null,
    "arena_votes": 18235,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1355.99,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126220+00:00",
        "confidence": 1.0,
        "raw_name": "mistral-small-2506",
        "raw_scores": {
          "arena_elo": 1355.99,
          "arena_votes": 18235
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1355.99
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemini-20-flash-lite-preview-02-05",
    "canonical_name": "gemini-2.0-flash-lite-preview-02-05",
    "model_name": "gemini-2.0-flash-lite-preview-02-05",
    "aliases": [
      "gemini-2.0-flash-lite-preview-02-05"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 24951,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1353.34,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126258+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-2.0-flash-lite-preview-02-05",
        "raw_scores": {
          "arena_elo": 1353.34,
          "arena_votes": 24951
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1353.34
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "amazon-nova-experimental-chat-10-20",
    "canonical_name": "amazon-nova-experimental-chat-10-20",
    "model_name": "amazon-nova-experimental-chat-10-20",
    "aliases": [
      "amazon-nova-experimental-chat-10-20"
    ],
    "provider": "Amazon",
    "context_window": null,
    "open_source": null,
    "arena_votes": 11338,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1349.98,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126310+00:00",
        "confidence": 1.0,
        "raw_name": "amazon-nova-experimental-chat-10-20",
        "raw_scores": {
          "arena_elo": 1349.98,
          "arena_votes": 11338
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1349.98
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "hunyuan-turbos-20250226",
    "canonical_name": "hunyuan-turbos-20250226",
    "model_name": "hunyuan-turbos-20250226",
    "aliases": [
      "hunyuan-turbos-20250226"
    ],
    "provider": "Tencent",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2226,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1348.86,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126323+00:00",
        "confidence": 1.0,
        "raw_name": "hunyuan-turbos-20250226",
        "raw_scores": {
          "arena_elo": 1348.86,
          "arena_votes": 2226
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1348.86
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "amazon-nova-experimental-chat-10-09",
    "canonical_name": "amazon-nova-experimental-chat-10-09",
    "model_name": "amazon-nova-experimental-chat-10-09",
    "aliases": [
      "amazon-nova-experimental-chat-10-09"
    ],
    "provider": "Amazon",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2875,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1347.19,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126360+00:00",
        "confidence": 1.0,
        "raw_name": "amazon-nova-experimental-chat-10-09",
        "raw_scores": {
          "arena_elo": 1347.19,
          "arena_votes": 2875
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1347.19
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "step-3",
    "canonical_name": "step-3",
    "model_name": "step-3",
    "aliases": [
      "step-3"
    ],
    "provider": "StepFun",
    "context_window": null,
    "open_source": null,
    "arena_votes": 6569,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1346.48,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126411+00:00",
        "confidence": 1.0,
        "raw_name": "step-3",
        "raw_scores": {
          "arena_elo": 1346.48,
          "arena_votes": 6569
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1346.48
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen-plus-0125",
    "canonical_name": "qwen-plus-0125",
    "model_name": "qwen-plus-0125",
    "aliases": [
      "qwen-plus-0125"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 5823,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1346.24,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126424+00:00",
        "confidence": 1.0,
        "raw_name": "qwen-plus-0125",
        "raw_scores": {
          "arena_elo": 1346.24,
          "arena_votes": 5823
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1346.24
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "glm-4-plus-0111",
    "canonical_name": "glm-4-plus-0111",
    "model_name": "glm-4-plus-0111",
    "aliases": [
      "glm-4-plus-0111"
    ],
    "provider": "Zhipu",
    "context_window": null,
    "open_source": null,
    "arena_votes": 5760,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1343.19,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126450+00:00",
        "confidence": 1.0,
        "raw_name": "glm-4-plus-0111",
        "raw_scores": {
          "arena_elo": 1343.19,
          "arena_votes": 5760
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1343.19
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "claude-35-sonnet-20240620",
    "canonical_name": "claude-3.5-sonnet-20240620",
    "model_name": "claude-3.5-sonnet-20240620",
    "aliases": [
      "claude-3.5-sonnet-20240620"
    ],
    "provider": "Anthropic",
    "context_window": null,
    "open_source": null,
    "arena_votes": 82417,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1342.68,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126468+00:00",
        "confidence": 1.0,
        "raw_name": "claude-3.5-sonnet-20240620",
        "raw_scores": {
          "arena_elo": 1342.68,
          "arena_votes": 82417
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1342.68
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemma-3-12b-it",
    "canonical_name": "gemma-3-12b-it",
    "model_name": "gemma-3-12b-it",
    "aliases": [
      "gemma-3-12b-it"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3829,
    "license_type": "Gemma",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1341.62,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126481+00:00",
        "confidence": 1.0,
        "raw_name": "gemma-3-12b-it",
        "raw_scores": {
          "arena_elo": 1341.62,
          "arena_votes": 3829
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1341.62
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "nvidia-llama-33-nemotron-super-49b-v15",
    "canonical_name": "nvidia-llama-3.3-nemotron-super-49b-v1.5",
    "model_name": "nvidia-llama-3.3-nemotron-super-49b-v1.5",
    "aliases": [
      "nvidia-llama-3.3-nemotron-super-49b-v1.5"
    ],
    "provider": "Nvidia",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3402,
    "license_type": "Nvidia Open",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1341.47,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126494+00:00",
        "confidence": 1.0,
        "raw_name": "nvidia-llama-3.3-nemotron-super-49b-v1.5",
        "raw_scores": {
          "arena_elo": 1341.47,
          "arena_votes": 3402
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1341.47
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "hunyuan-turbo-0110",
    "canonical_name": "hunyuan-turbo-0110",
    "model_name": "hunyuan-turbo-0110",
    "aliases": [
      "hunyuan-turbo-0110"
    ],
    "provider": "Tencent",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2295,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1340.49,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126507+00:00",
        "confidence": 1.0,
        "raw_name": "hunyuan-turbo-0110",
        "raw_scores": {
          "arena_elo": 1340.49,
          "arena_votes": 2295
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1340.49
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "nova-2-lite",
    "canonical_name": "nova-2-lite",
    "model_name": "nova-2-lite",
    "aliases": [
      "nova-2-lite"
    ],
    "provider": "Amazon",
    "context_window": null,
    "open_source": null,
    "arena_votes": 12111,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1336.94,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126532+00:00",
        "confidence": 1.0,
        "raw_name": "nova-2-lite",
        "raw_scores": {
          "arena_elo": 1336.94,
          "arena_votes": 12111
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1336.94
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-405b-instruct-bf16",
    "canonical_name": "llama-3.1-405b-instruct-bf16",
    "model_name": "llama-3.1-405b-instruct-bf16",
    "aliases": [
      "llama-3.1-405b-instruct-bf16"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 41392,
    "license_type": "Llama 3.1 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1335.43,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126570+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.1-405b-instruct-bf16",
        "raw_scores": {
          "arena_elo": 1335.43,
          "arena_votes": 41392
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1335.43
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "grok-2-2024-08-13",
    "canonical_name": "grok-2-2024-08-13",
    "model_name": "grok-2-2024-08-13",
    "aliases": [
      "grok-2-2024-08-13"
    ],
    "provider": "xAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 63495,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1335.15,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126583+00:00",
        "confidence": 1.0,
        "raw_name": "grok-2-2024-08-13",
        "raw_scores": {
          "arena_elo": 1335.15,
          "arena_votes": 63495
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1335.15
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gpt-4o-2024-08-06",
    "canonical_name": "gpt-4o-2024-08-06",
    "model_name": "gpt-4o-2024-08-06",
    "aliases": [
      "gpt-4o-2024-08-06"
    ],
    "provider": "OpenAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 45498,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1335.1,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126596+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-4o-2024-08-06",
        "raw_scores": {
          "arena_elo": 1335.1,
          "arena_votes": 45498
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1335.1
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemini-advanced-0514",
    "canonical_name": "gemini-advanced-0514",
    "model_name": "gemini-advanced-0514",
    "aliases": [
      "gemini-advanced-0514"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 50142,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1334.93,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126608+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-advanced-0514",
        "raw_scores": {
          "arena_elo": 1334.93,
          "arena_votes": 50142
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1334.93
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "step-2-16k-exp-202412",
    "canonical_name": "step-2-16k-exp-202412",
    "model_name": "step-2-16k-exp-202412",
    "aliases": [
      "step-2-16k-exp-202412"
    ],
    "provider": "StepFun",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4829,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1334.05,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126621+00:00",
        "confidence": 1.0,
        "raw_name": "step-2-16k-exp-202412",
        "raw_scores": {
          "arena_elo": 1334.05,
          "arena_votes": 4829
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1334.05
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-405b-instruct-fp8",
    "canonical_name": "llama-3.1-405b-instruct-fp8",
    "model_name": "llama-3.1-405b-instruct-fp8",
    "aliases": [
      "llama-3.1-405b-instruct-fp8"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 59655,
    "license_type": "Llama 3.1 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1333.61,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126633+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.1-405b-instruct-fp8",
        "raw_scores": {
          "arena_elo": 1333.61,
          "arena_votes": 59655
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1333.61
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "molmo-2-8b",
    "canonical_name": "molmo-2-8b",
    "model_name": "molmo-2-8b",
    "aliases": [
      "molmo-2-8b"
    ],
    "provider": "AI2",
    "context_window": null,
    "open_source": null,
    "arena_votes": 816,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1329.25,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126658+00:00",
        "confidence": 1.0,
        "raw_name": "molmo-2-8b",
        "raw_scores": {
          "arena_elo": 1329.25,
          "arena_votes": 816
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1329.25
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "yi-lightning",
    "canonical_name": "yi-lightning",
    "model_name": "yi-lightning",
    "aliases": [
      "yi-lightning"
    ],
    "provider": "01 AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 27340,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1328.57,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126671+00:00",
        "confidence": 1.0,
        "raw_name": "yi-lightning",
        "raw_scores": {
          "arena_elo": 1328.57,
          "arena_votes": 27340
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1328.57
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-33-nemotron-49b-super-v1",
    "canonical_name": "llama-3.3-nemotron-49b-super-v1",
    "model_name": "llama-3.3-nemotron-49b-super-v1",
    "aliases": [
      "llama-3.3-nemotron-49b-super-v1"
    ],
    "provider": "Nvidia",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2230,
    "license_type": "Nvidia",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1327.08,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126710+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.3-nemotron-49b-super-v1",
        "raw_scores": {
          "arena_elo": 1327.08,
          "arena_votes": 2230
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1327.08
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "hunyuan-large-2025-02-10",
    "canonical_name": "hunyuan-large-2025-02-10",
    "model_name": "hunyuan-large-2025-02-10",
    "aliases": [
      "hunyuan-large-2025-02-10"
    ],
    "provider": "Tencent",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3738,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1326.52,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126723+00:00",
        "confidence": 1.0,
        "raw_name": "hunyuan-large-2025-02-10",
        "raw_scores": {
          "arena_elo": 1326.52,
          "arena_votes": 3738
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1326.52
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "deepseek-v25-1210",
    "canonical_name": "deepseek-v2.5-1210",
    "model_name": "deepseek-v2.5-1210",
    "aliases": [
      "deepseek-v2.5-1210"
    ],
    "provider": "DeepSeek",
    "context_window": null,
    "open_source": null,
    "arena_votes": 6793,
    "license_type": "DeepSeek",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1323.31,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126765+00:00",
        "confidence": 1.0,
        "raw_name": "deepseek-v2.5-1210",
        "raw_scores": {
          "arena_elo": 1323.31,
          "arena_votes": 6793
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1323.31
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "step-1o-turbo-202506",
    "canonical_name": "step-1o-turbo-202506",
    "model_name": "step-1o-turbo-202506",
    "aliases": [
      "step-1o-turbo-202506"
    ],
    "provider": "StepFun",
    "context_window": null,
    "open_source": null,
    "arena_votes": 9621,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1321.9,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126816+00:00",
        "confidence": 1.0,
        "raw_name": "step-1o-turbo-202506",
        "raw_scores": {
          "arena_elo": 1321.9,
          "arena_votes": 9621
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1321.9
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-33-70b-instruct",
    "canonical_name": "llama-3.3-70b-instruct",
    "model_name": "llama-3.3-70b-instruct",
    "aliases": [
      "llama-3.3-70b-instruct"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 55453,
    "license_type": "Llama-3.3",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1319.51,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126854+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.3-70b-instruct",
        "raw_scores": {
          "arena_elo": 1319.51,
          "arena_votes": 55453
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1319.51
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "glm-4-plus",
    "canonical_name": "glm-4-plus",
    "model_name": "glm-4-plus",
    "aliases": [
      "glm-4-plus"
    ],
    "provider": "Zhipu AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 26134,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1319.41,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126866+00:00",
        "confidence": 1.0,
        "raw_name": "glm-4-plus",
        "raw_scores": {
          "arena_elo": 1319.41,
          "arena_votes": 26134
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1319.41
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemma-3n-e4b-it",
    "canonical_name": "gemma-3n-e4b-it",
    "model_name": "gemma-3n-e4b-it",
    "aliases": [
      "gemma-3n-e4b-it"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 23195,
    "license_type": "Gemma",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1319.3,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126879+00:00",
        "confidence": 1.0,
        "raw_name": "gemma-3n-e4b-it",
        "raw_scores": {
          "arena_elo": 1319.3,
          "arena_votes": 23195
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1319.3
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen-max-0919",
    "canonical_name": "qwen-max-0919",
    "model_name": "qwen-max-0919",
    "aliases": [
      "qwen-max-0919"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 16479,
    "license_type": "Qwen",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1318.16,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126892+00:00",
        "confidence": 1.0,
        "raw_name": "qwen-max-0919",
        "raw_scores": {
          "arena_elo": 1318.16,
          "arena_votes": 16479
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1318.16
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "nvidia-nemotron-3-nano-30b-a3b-bf16",
    "canonical_name": "nvidia-nemotron-3-nano-30b-a3b-bf16",
    "model_name": "nvidia-nemotron-3-nano-30b-a3b-bf16",
    "aliases": [
      "nvidia-nemotron-3-nano-30b-a3b-bf16"
    ],
    "provider": "Nvidia",
    "context_window": null,
    "open_source": null,
    "arena_votes": 15405,
    "license_type": "NVIDIA Open Model",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1316.9,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126929+00:00",
        "confidence": 1.0,
        "raw_name": "nvidia-nemotron-3-nano-30b-a3b-bf16",
        "raw_scores": {
          "arena_elo": 1316.9,
          "arena_votes": 15405
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1316.9
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen25-plus-1127",
    "canonical_name": "qwen2.5-plus-1127",
    "model_name": "qwen2.5-plus-1127",
    "aliases": [
      "qwen2.5-plus-1127"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 10179,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1315.44,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126942+00:00",
        "confidence": 1.0,
        "raw_name": "qwen2.5-plus-1127",
        "raw_scores": {
          "arena_elo": 1315.44,
          "arena_votes": 10179
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1315.44
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "athene-v2-chat",
    "canonical_name": "athene-v2-chat",
    "model_name": "athene-v2-chat",
    "aliases": [
      "athene-v2-chat"
    ],
    "provider": "NexusFlow",
    "context_window": null,
    "open_source": null,
    "arena_votes": 24746,
    "license_type": "NexusFlow",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1314.51,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126955+00:00",
        "confidence": 1.0,
        "raw_name": "athene-v2-chat",
        "raw_scores": {
          "arena_elo": 1314.51,
          "arena_votes": 24746
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1314.51
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "mistral-large-2407",
    "canonical_name": "mistral-large-2407",
    "model_name": "mistral-large-2407",
    "aliases": [
      "mistral-large-2407"
    ],
    "provider": "Mistral",
    "context_window": null,
    "open_source": null,
    "arena_votes": 45460,
    "license_type": "Mistral Research",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1314.16,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126967+00:00",
        "confidence": 1.0,
        "raw_name": "mistral-large-2407",
        "raw_scores": {
          "arena_elo": 1314.16,
          "arena_votes": 45460
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1314.16
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gpt-4-0125-preview",
    "canonical_name": "gpt-4-0125-preview",
    "model_name": "gpt-4-0125-preview",
    "aliases": [
      "gpt-4-0125-preview"
    ],
    "provider": "OpenAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 93439,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1313.33,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126980+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-4-0125-preview",
        "raw_scores": {
          "arena_elo": 1313.33,
          "arena_votes": 93439
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1313.33
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gpt-4-1106-preview",
    "canonical_name": "gpt-4-1106-preview",
    "model_name": "gpt-4-1106-preview",
    "aliases": [
      "gpt-4-1106-preview"
    ],
    "provider": "OpenAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 100107,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1313.29,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.126993+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-4-1106-preview",
        "raw_scores": {
          "arena_elo": 1313.29,
          "arena_votes": 100107
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1313.29
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "hunyuan-standard-2025-02-10",
    "canonical_name": "hunyuan-standard-2025-02-10",
    "model_name": "hunyuan-standard-2025-02-10",
    "aliases": [
      "hunyuan-standard-2025-02-10"
    ],
    "provider": "Tencent",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3905,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1311.65,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127006+00:00",
        "confidence": 1.0,
        "raw_name": "hunyuan-standard-2025-02-10",
        "raw_scores": {
          "arena_elo": 1311.65,
          "arena_votes": 3905
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1311.65
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "mercury",
    "canonical_name": "mercury",
    "model_name": "mercury",
    "aliases": [
      "mercury"
    ],
    "provider": "Inception AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 1887,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1308.85,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127032+00:00",
        "confidence": 1.0,
        "raw_name": "mercury",
        "raw_scores": {
          "arena_elo": 1308.85,
          "arena_votes": 1887
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1308.85
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "grok-2-mini-2024-08-13",
    "canonical_name": "grok-2-mini-2024-08-13",
    "model_name": "grok-2-mini-2024-08-13",
    "aliases": [
      "grok-2-mini-2024-08-13"
    ],
    "provider": "xAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 52574,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1308.01,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127044+00:00",
        "confidence": 1.0,
        "raw_name": "grok-2-mini-2024-08-13",
        "raw_scores": {
          "arena_elo": 1308.01,
          "arena_votes": 52574
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1308.01
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "athene-70b-0725",
    "canonical_name": "athene-70b-0725",
    "model_name": "athene-70b-0725",
    "aliases": [
      "athene-70b-0725"
    ],
    "provider": "NexusFlow",
    "context_window": null,
    "open_source": null,
    "arena_votes": 19622,
    "license_type": "CC-BY-NC-4.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1306.07,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127069+00:00",
        "confidence": 1.0,
        "raw_name": "athene-70b-0725",
        "raw_scores": {
          "arena_elo": 1306.07,
          "arena_votes": 19622
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1306.07
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "mistral-large-2411",
    "canonical_name": "mistral-large-2411",
    "model_name": "mistral-large-2411",
    "aliases": [
      "mistral-large-2411"
    ],
    "provider": "Mistral",
    "context_window": null,
    "open_source": null,
    "arena_votes": 28081,
    "license_type": "MRL",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1305.2,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127094+00:00",
        "confidence": 1.0,
        "raw_name": "mistral-large-2411",
        "raw_scores": {
          "arena_elo": 1305.2,
          "arena_votes": 28081
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1305.2
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "magistral-medium-2506",
    "canonical_name": "magistral-medium-2506",
    "model_name": "magistral-medium-2506",
    "aliases": [
      "magistral-medium-2506"
    ],
    "provider": "Mistral",
    "context_window": null,
    "open_source": null,
    "arena_votes": 11987,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1304.98,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127107+00:00",
        "confidence": 1.0,
        "raw_name": "magistral-medium-2506",
        "raw_scores": {
          "arena_elo": 1304.98,
          "arena_votes": 11987
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1304.98
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "mistral-small-31-24b-instruct-2503",
    "canonical_name": "mistral-small-3.1-24b-instruct-2503",
    "model_name": "mistral-small-3.1-24b-instruct-2503",
    "aliases": [
      "mistral-small-3.1-24b-instruct-2503"
    ],
    "provider": "Mistral",
    "context_window": null,
    "open_source": null,
    "arena_votes": 33906,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1304.42,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127119+00:00",
        "confidence": 1.0,
        "raw_name": "mistral-small-3.1-24b-instruct-2503",
        "raw_scores": {
          "arena_elo": 1304.42,
          "arena_votes": 33906
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1304.42
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemma-3-4b-it",
    "canonical_name": "gemma-3-4b-it",
    "model_name": "gemma-3-4b-it",
    "aliases": [
      "gemma-3-4b-it"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4177,
    "license_type": "Gemma",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1303.27,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127132+00:00",
        "confidence": 1.0,
        "raw_name": "gemma-3-4b-it",
        "raw_scores": {
          "arena_elo": 1303.27,
          "arena_votes": 4177
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1303.27
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen25-72b-instruct",
    "canonical_name": "qwen2.5-72b-instruct",
    "model_name": "qwen2.5-72b-instruct",
    "aliases": [
      "qwen2.5-72b-instruct"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 39409,
    "license_type": "Qwen",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1302.73,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127145+00:00",
        "confidence": 1.0,
        "raw_name": "qwen2.5-72b-instruct",
        "raw_scores": {
          "arena_elo": 1302.73,
          "arena_votes": 39409
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1302.73
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-nemotron-70b-instruct",
    "canonical_name": "llama-3.1-nemotron-70b-instruct",
    "model_name": "llama-3.1-nemotron-70b-instruct",
    "aliases": [
      "llama-3.1-nemotron-70b-instruct"
    ],
    "provider": "Nvidia",
    "context_window": null,
    "open_source": null,
    "arena_votes": 7136,
    "license_type": "Llama 3.1",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1298.64,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127157+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.1-nemotron-70b-instruct",
        "raw_scores": {
          "arena_elo": 1298.64,
          "arena_votes": 7136
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1298.64
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "hunyuan-large-vision",
    "canonical_name": "hunyuan-large-vision",
    "model_name": "hunyuan-large-vision",
    "aliases": [
      "hunyuan-large-vision"
    ],
    "provider": "Tencent",
    "context_window": null,
    "open_source": null,
    "arena_votes": 5566,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1296.03,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127170+00:00",
        "confidence": 1.0,
        "raw_name": "hunyuan-large-vision",
        "raw_scores": {
          "arena_elo": 1296.03,
          "arena_votes": 5566
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1296.03
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-70b-instruct",
    "canonical_name": "llama-3.1-70b-instruct",
    "model_name": "llama-3.1-70b-instruct",
    "aliases": [
      "llama-3.1-70b-instruct"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 55234,
    "license_type": "Llama 3.1 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1293.55,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127182+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.1-70b-instruct",
        "raw_scores": {
          "arena_elo": 1293.55,
          "arena_votes": 55234
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1293.55
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemma-2-27b-it",
    "canonical_name": "gemma-2-27b-it",
    "model_name": "gemma-2-27b-it",
    "aliases": [
      "gemma-2-27b-it"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 75764,
    "license_type": "Gemma license",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1288.17,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127220+00:00",
        "confidence": 1.0,
        "raw_name": "gemma-2-27b-it",
        "raw_scores": {
          "arena_elo": 1288.17,
          "arena_votes": 75764
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1288.17
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "reka-core-20240904",
    "canonical_name": "reka-core-20240904",
    "model_name": "reka-core-20240904",
    "aliases": [
      "reka-core-20240904"
    ],
    "provider": "Reka AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 7309,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1287.95,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127232+00:00",
        "confidence": 1.0,
        "raw_name": "reka-core-20240904",
        "raw_scores": {
          "arena_elo": 1287.95,
          "arena_votes": 7309
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1287.95
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gpt-4-0314",
    "canonical_name": "gpt-4-0314",
    "model_name": "gpt-4-0314",
    "aliases": [
      "gpt-4-0314"
    ],
    "provider": "OpenAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 54167,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1287.25,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127257+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-4-0314",
        "raw_scores": {
          "arena_elo": 1287.25,
          "arena_votes": 54167
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1287.25
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "ibm-granite-h-small",
    "canonical_name": "ibm-granite-h-small",
    "model_name": "ibm-granite-h-small",
    "aliases": [
      "ibm-granite-h-small"
    ],
    "provider": "IBM",
    "context_window": null,
    "open_source": null,
    "arena_votes": 5621,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1287.1,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127272+00:00",
        "confidence": 1.0,
        "raw_name": "ibm-granite-h-small",
        "raw_scores": {
          "arena_elo": 1287.1,
          "arena_votes": 5621
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1287.1
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-tulu-3-70b",
    "canonical_name": "llama-3.1-tulu-3-70b",
    "model_name": "llama-3.1-tulu-3-70b",
    "aliases": [
      "llama-3.1-tulu-3-70b"
    ],
    "provider": "Ai2",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2846,
    "license_type": "Llama 3.1",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1286.67,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127284+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.1-tulu-3-70b",
        "raw_scores": {
          "arena_elo": 1286.67,
          "arena_votes": 2846
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1286.67
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-nemotron-51b-instruct",
    "canonical_name": "llama-3.1-nemotron-51b-instruct",
    "model_name": "llama-3.1-nemotron-51b-instruct",
    "aliases": [
      "llama-3.1-nemotron-51b-instruct"
    ],
    "provider": "Nvidia",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3749,
    "license_type": "Llama 3.1",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1286.48,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127297+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.1-nemotron-51b-instruct",
        "raw_scores": {
          "arena_elo": 1286.48,
          "arena_votes": 3749
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1286.48
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "claude-3-sonnet-20240229",
    "canonical_name": "claude-3-sonnet-20240229",
    "model_name": "claude-3-sonnet-20240229",
    "aliases": [
      "claude-3-sonnet-20240229"
    ],
    "provider": "Anthropic",
    "context_window": null,
    "open_source": null,
    "arena_votes": 109289,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1281.23,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127335+00:00",
        "confidence": 1.0,
        "raw_name": "claude-3-sonnet-20240229",
        "raw_scores": {
          "arena_elo": 1281.23,
          "arena_votes": 109289
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1281.23
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemma-2-9b-it-simpo",
    "canonical_name": "gemma-2-9b-it-simpo",
    "model_name": "gemma-2-9b-it-simpo",
    "aliases": [
      "gemma-2-9b-it-simpo"
    ],
    "provider": "Princeton",
    "context_window": null,
    "open_source": null,
    "arena_votes": 10069,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1279.51,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127348+00:00",
        "confidence": 1.0,
        "raw_name": "gemma-2-9b-it-simpo",
        "raw_scores": {
          "arena_elo": 1279.51,
          "arena_votes": 10069
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1279.51
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "nemotron-4-340b-instruct",
    "canonical_name": "nemotron-4-340b-instruct",
    "model_name": "nemotron-4-340b-instruct",
    "aliases": [
      "nemotron-4-340b-instruct"
    ],
    "provider": "Nvidia",
    "context_window": null,
    "open_source": null,
    "arena_votes": 19661,
    "license_type": "NVIDIA Open Model",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1277.62,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127361+00:00",
        "confidence": 1.0,
        "raw_name": "nemotron-4-340b-instruct",
        "raw_scores": {
          "arena_elo": 1277.62,
          "arena_votes": 19661
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1277.62
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "command-r-plus-08-2024",
    "canonical_name": "command-r-plus-08-2024",
    "model_name": "command-r-plus-08-2024",
    "aliases": [
      "command-r-plus-08-2024"
    ],
    "provider": "Cohere",
    "context_window": null,
    "open_source": null,
    "arena_votes": 9869,
    "license_type": "CC-BY-NC-4.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1276.61,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127373+00:00",
        "confidence": 1.0,
        "raw_name": "command-r-plus-08-2024",
        "raw_scores": {
          "arena_elo": 1276.61,
          "arena_votes": 9869
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1276.61
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-3-70b-instruct",
    "canonical_name": "llama-3-70b-instruct",
    "model_name": "llama-3-70b-instruct",
    "aliases": [
      "llama-3-70b-instruct"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 156880,
    "license_type": "Llama 3 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1276.14,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127385+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3-70b-instruct",
        "raw_scores": {
          "arena_elo": 1276.14,
          "arena_votes": 156880
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1276.14
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gpt-4-0613",
    "canonical_name": "gpt-4-0613",
    "model_name": "gpt-4-0613",
    "aliases": [
      "gpt-4-0613"
    ],
    "provider": "OpenAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 88721,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1275.39,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127398+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-4-0613",
        "raw_scores": {
          "arena_elo": 1275.39,
          "arena_votes": 88721
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1275.39
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "mistral-small-24b-instruct-2501",
    "canonical_name": "mistral-small-24b-instruct-2501",
    "model_name": "mistral-small-24b-instruct-2501",
    "aliases": [
      "mistral-small-24b-instruct-2501"
    ],
    "provider": "Mistral",
    "context_window": null,
    "open_source": null,
    "arena_votes": 14677,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1273.97,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127411+00:00",
        "confidence": 1.0,
        "raw_name": "mistral-small-24b-instruct-2501",
        "raw_scores": {
          "arena_elo": 1273.97,
          "arena_votes": 14677
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1273.97
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "glm-4-0520",
    "canonical_name": "glm-4-0520",
    "model_name": "glm-4-0520",
    "aliases": [
      "glm-4-0520"
    ],
    "provider": "Zhipu AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 9788,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1273.55,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127424+00:00",
        "confidence": 1.0,
        "raw_name": "glm-4-0520",
        "raw_scores": {
          "arena_elo": 1273.55,
          "arena_votes": 9788
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1273.55
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "reka-flash-20240904",
    "canonical_name": "reka-flash-20240904",
    "model_name": "reka-flash-20240904",
    "aliases": [
      "reka-flash-20240904"
    ],
    "provider": "Reka AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 7537,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1272.33,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127436+00:00",
        "confidence": 1.0,
        "raw_name": "reka-flash-20240904",
        "raw_scores": {
          "arena_elo": 1272.33,
          "arena_votes": 7537
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1272.33
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen25-coder-32b-instruct",
    "canonical_name": "qwen2.5-coder-32b-instruct",
    "model_name": "qwen2.5-coder-32b-instruct",
    "aliases": [
      "qwen2.5-coder-32b-instruct"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 5430,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1270.71,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127449+00:00",
        "confidence": 1.0,
        "raw_name": "qwen2.5-coder-32b-instruct",
        "raw_scores": {
          "arena_elo": 1270.71,
          "arena_votes": 5430
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1270.71
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "c4ai-aya-expanse-32b",
    "canonical_name": "c4ai-aya-expanse-32b",
    "model_name": "c4ai-aya-expanse-32b",
    "aliases": [
      "c4ai-aya-expanse-32b"
    ],
    "provider": "Cohere",
    "context_window": null,
    "open_source": null,
    "arena_votes": 27123,
    "license_type": "CC-BY-NC-4.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1267.17,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127462+00:00",
        "confidence": 1.0,
        "raw_name": "c4ai-aya-expanse-32b",
        "raw_scores": {
          "arena_elo": 1267.17,
          "arena_votes": 27123
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1267.17
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemma-2-9b-it",
    "canonical_name": "gemma-2-9b-it",
    "model_name": "gemma-2-9b-it",
    "aliases": [
      "gemma-2-9b-it"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 54615,
    "license_type": "Gemma license",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1265.59,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127474+00:00",
        "confidence": 1.0,
        "raw_name": "gemma-2-9b-it",
        "raw_scores": {
          "arena_elo": 1265.59,
          "arena_votes": 54615
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1265.59
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "command-r-plus",
    "canonical_name": "command-r-plus",
    "model_name": "command-r-plus",
    "aliases": [
      "command-r-plus"
    ],
    "provider": "Cohere",
    "context_window": null,
    "open_source": null,
    "arena_votes": 77556,
    "license_type": "CC-BY-NC-4.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1262.16,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127500+00:00",
        "confidence": 1.0,
        "raw_name": "command-r-plus",
        "raw_scores": {
          "arena_elo": 1262.16,
          "arena_votes": 77556
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1262.16
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen2-72b-instruct",
    "canonical_name": "qwen2-72b-instruct",
    "model_name": "qwen2-72b-instruct",
    "aliases": [
      "qwen2-72b-instruct"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 37325,
    "license_type": "Qianwen LICENSE",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1262.04,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127513+00:00",
        "confidence": 1.0,
        "raw_name": "qwen2-72b-instruct",
        "raw_scores": {
          "arena_elo": 1262.04,
          "arena_votes": 37325
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1262.04
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "claude-3-haiku-20240307",
    "canonical_name": "claude-3-haiku-20240307",
    "model_name": "claude-3-haiku-20240307",
    "aliases": [
      "claude-3-haiku-20240307"
    ],
    "provider": "Anthropic",
    "context_window": null,
    "open_source": null,
    "arena_votes": 117705,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1261.33,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127525+00:00",
        "confidence": 1.0,
        "raw_name": "claude-3-haiku-20240307",
        "raw_scores": {
          "arena_elo": 1261.33,
          "arena_votes": 117705
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1261.33
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemini-15-flash-8b-001",
    "canonical_name": "gemini-1.5-flash-8b-001",
    "model_name": "gemini-1.5-flash-8b-001",
    "aliases": [
      "gemini-1.5-flash-8b-001"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 35556,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1258.78,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127551+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-1.5-flash-8b-001",
        "raw_scores": {
          "arena_elo": 1258.78,
          "arena_votes": 35556
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1258.78
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "olmo-2-0325-32b-instruct",
    "canonical_name": "olmo-2-0325-32b-instruct",
    "model_name": "olmo-2-0325-32b-instruct",
    "aliases": [
      "olmo-2-0325-32b-instruct"
    ],
    "provider": "Allen AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3335,
    "license_type": "Apache-2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1252.13,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127576+00:00",
        "confidence": 1.0,
        "raw_name": "olmo-2-0325-32b-instruct",
        "raw_scores": {
          "arena_elo": 1252.13,
          "arena_votes": 3335
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1252.13
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "command-r-08-2024",
    "canonical_name": "command-r-08-2024",
    "model_name": "command-r-08-2024",
    "aliases": [
      "command-r-08-2024"
    ],
    "provider": "Cohere",
    "context_window": null,
    "open_source": null,
    "arena_votes": 10141,
    "license_type": "CC-BY-NC-4.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1250.46,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127588+00:00",
        "confidence": 1.0,
        "raw_name": "command-r-08-2024",
        "raw_scores": {
          "arena_elo": 1250.46,
          "arena_votes": 10141
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1250.46
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "mistral-large-2402",
    "canonical_name": "mistral-large-2402",
    "model_name": "mistral-large-2402",
    "aliases": [
      "mistral-large-2402"
    ],
    "provider": "Mistral",
    "context_window": null,
    "open_source": null,
    "arena_votes": 62437,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1242.68,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127601+00:00",
        "confidence": 1.0,
        "raw_name": "mistral-large-2402",
        "raw_scores": {
          "arena_elo": 1242.68,
          "arena_votes": 62437
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1242.68
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "ministral-8b-2410",
    "canonical_name": "ministral-8b-2410",
    "model_name": "ministral-8b-2410",
    "aliases": [
      "ministral-8b-2410"
    ],
    "provider": "Mistral",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4780,
    "license_type": "MRL",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1237.17,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127639+00:00",
        "confidence": 1.0,
        "raw_name": "ministral-8b-2410",
        "raw_scores": {
          "arena_elo": 1237.17,
          "arena_votes": 4780
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1237.17
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemini-pro-dev-api",
    "canonical_name": "gemini-pro-dev-api",
    "model_name": "gemini-pro-dev-api",
    "aliases": [
      "gemini-pro-dev-api"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 18352,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1235.25,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127651+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-pro-dev-api",
        "raw_scores": {
          "arena_elo": 1235.25,
          "arena_votes": 18352
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1235.25
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen15-110b-chat",
    "canonical_name": "qwen1.5-110b-chat",
    "model_name": "qwen1.5-110b-chat",
    "aliases": [
      "qwen1.5-110b-chat"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 26191,
    "license_type": "Qianwen LICENSE",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1234.2,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127664+00:00",
        "confidence": 1.0,
        "raw_name": "qwen1.5-110b-chat",
        "raw_scores": {
          "arena_elo": 1234.2,
          "arena_votes": 26191
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1234.2
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "reka-flash-21b-20240226-online",
    "canonical_name": "reka-flash-21b-20240226-online",
    "model_name": "reka-flash-21b-20240226-online",
    "aliases": [
      "reka-flash-21b-20240226-online"
    ],
    "provider": "Reka AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 15451,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1233.53,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127677+00:00",
        "confidence": 1.0,
        "raw_name": "reka-flash-21b-20240226-online",
        "raw_scores": {
          "arena_elo": 1233.53,
          "arena_votes": 15451
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1233.53
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "hunyuan-standard-256k",
    "canonical_name": "hunyuan-standard-256k",
    "model_name": "hunyuan-standard-256k",
    "aliases": [
      "hunyuan-standard-256k"
    ],
    "provider": "Tencent",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2729,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1233.45,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127690+00:00",
        "confidence": 1.0,
        "raw_name": "hunyuan-standard-256k",
        "raw_scores": {
          "arena_elo": 1233.45,
          "arena_votes": 2729
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1233.45
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen15-72b-chat",
    "canonical_name": "qwen1.5-72b-chat",
    "model_name": "qwen1.5-72b-chat",
    "aliases": [
      "qwen1.5-72b-chat"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 39296,
    "license_type": "Qianwen LICENSE",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1233.41,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127703+00:00",
        "confidence": 1.0,
        "raw_name": "qwen1.5-72b-chat",
        "raw_scores": {
          "arena_elo": 1233.41,
          "arena_votes": 39296
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1233.41
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "mixtral-8x22b-instruct-v01",
    "canonical_name": "mixtral-8x22b-instruct-v0.1",
    "model_name": "mixtral-8x22b-instruct-v0.1",
    "aliases": [
      "mixtral-8x22b-instruct-v0.1"
    ],
    "provider": "Mistral",
    "context_window": null,
    "open_source": null,
    "arena_votes": 51417,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1229.77,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127716+00:00",
        "confidence": 1.0,
        "raw_name": "mixtral-8x22b-instruct-v0.1",
        "raw_scores": {
          "arena_elo": 1229.77,
          "arena_votes": 51417
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1229.77
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "reka-flash-21b-20240226",
    "canonical_name": "reka-flash-21b-20240226",
    "model_name": "reka-flash-21b-20240226",
    "aliases": [
      "reka-flash-21b-20240226"
    ],
    "provider": "Reka AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 24806,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1226.76,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127741+00:00",
        "confidence": 1.0,
        "raw_name": "reka-flash-21b-20240226",
        "raw_scores": {
          "arena_elo": 1226.76,
          "arena_votes": 24806
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1226.76
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gpt-35-turbo-0125",
    "canonical_name": "gpt-3.5-turbo-0125",
    "model_name": "gpt-3.5-turbo-0125",
    "aliases": [
      "gpt-3.5-turbo-0125"
    ],
    "provider": "OpenAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 66191,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1224.3,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127753+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-3.5-turbo-0125",
        "raw_scores": {
          "arena_elo": 1224.3,
          "arena_votes": 66191
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1224.3
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-3-8b-instruct",
    "canonical_name": "llama-3-8b-instruct",
    "model_name": "llama-3-8b-instruct",
    "aliases": [
      "llama-3-8b-instruct"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 104636,
    "license_type": "Llama 3 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1223.33,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127766+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3-8b-instruct",
        "raw_scores": {
          "arena_elo": 1223.33,
          "arena_votes": 104636
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1223.33
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "c4ai-aya-expanse-8b",
    "canonical_name": "c4ai-aya-expanse-8b",
    "model_name": "c4ai-aya-expanse-8b",
    "aliases": [
      "c4ai-aya-expanse-8b"
    ],
    "provider": "Cohere",
    "context_window": null,
    "open_source": null,
    "arena_votes": 9827,
    "license_type": "CC-BY-NC-4.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1223.12,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127791+00:00",
        "confidence": 1.0,
        "raw_name": "c4ai-aya-expanse-8b",
        "raw_scores": {
          "arena_elo": 1223.12,
          "arena_votes": 9827
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1223.12
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemini-pro",
    "canonical_name": "gemini-pro",
    "model_name": "gemini-pro",
    "aliases": [
      "gemini-pro"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 6390,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1221.98,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127804+00:00",
        "confidence": 1.0,
        "raw_name": "gemini-pro",
        "raw_scores": {
          "arena_elo": 1221.98,
          "arena_votes": 6390
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1221.98
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-tulu-3-8b",
    "canonical_name": "llama-3.1-tulu-3-8b",
    "model_name": "llama-3.1-tulu-3-8b",
    "aliases": [
      "llama-3.1-tulu-3-8b"
    ],
    "provider": "Ai2",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2895,
    "license_type": "Llama 3.1",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1220.66,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127817+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.1-tulu-3-8b",
        "raw_scores": {
          "arena_elo": 1220.66,
          "arena_votes": 2895
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1220.66
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "yi-15-34b-chat",
    "canonical_name": "yi-1.5-34b-chat",
    "model_name": "yi-1.5-34b-chat",
    "aliases": [
      "yi-1.5-34b-chat"
    ],
    "provider": "01 AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 24142,
    "license_type": "Apache-2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1213.53,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127830+00:00",
        "confidence": 1.0,
        "raw_name": "yi-1.5-34b-chat",
        "raw_scores": {
          "arena_elo": 1213.53,
          "arena_votes": 24142
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1213.53
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "zephyr-orpo-141b-a35b-v01",
    "canonical_name": "zephyr-orpo-141b-A35b-v0.1",
    "model_name": "zephyr-orpo-141b-A35b-v0.1",
    "aliases": [
      "zephyr-orpo-141b-A35b-v0.1"
    ],
    "provider": "HuggingFace",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4653,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1213.02,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127843+00:00",
        "confidence": 1.0,
        "raw_name": "zephyr-orpo-141b-A35b-v0.1",
        "raw_scores": {
          "arena_elo": 1213.02,
          "arena_votes": 4653
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1213.02
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-31-8b-instruct",
    "canonical_name": "llama-3.1-8b-instruct",
    "model_name": "llama-3.1-8b-instruct",
    "aliases": [
      "llama-3.1-8b-instruct"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 49605,
    "license_type": "Llama 3.1 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1211.55,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127856+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.1-8b-instruct",
        "raw_scores": {
          "arena_elo": 1211.55,
          "arena_votes": 49605
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1211.55
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "granite-31-8b-instruct",
    "canonical_name": "granite-3.1-8b-instruct",
    "model_name": "granite-3.1-8b-instruct",
    "aliases": [
      "granite-3.1-8b-instruct"
    ],
    "provider": "IBM",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3092,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1208.8,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127868+00:00",
        "confidence": 1.0,
        "raw_name": "granite-3.1-8b-instruct",
        "raw_scores": {
          "arena_elo": 1208.8,
          "arena_votes": 3092
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1208.8
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen15-32b-chat",
    "canonical_name": "qwen1.5-32b-chat",
    "model_name": "qwen1.5-32b-chat",
    "aliases": [
      "qwen1.5-32b-chat"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 21744,
    "license_type": "Qianwen LICENSE",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1204.15,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127883+00:00",
        "confidence": 1.0,
        "raw_name": "qwen1.5-32b-chat",
        "raw_scores": {
          "arena_elo": 1204.15,
          "arena_votes": 21744
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1204.15
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gpt-35-turbo-1106",
    "canonical_name": "gpt-3.5-turbo-1106",
    "model_name": "gpt-3.5-turbo-1106",
    "aliases": [
      "gpt-3.5-turbo-1106"
    ],
    "provider": "OpenAI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 16616,
    "license_type": "Proprietary",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1202.77,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127909+00:00",
        "confidence": 1.0,
        "raw_name": "gpt-3.5-turbo-1106",
        "raw_scores": {
          "arena_elo": 1202.77,
          "arena_votes": 16616
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1202.77
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemma-2-2b-it",
    "canonical_name": "gemma-2-2b-it",
    "model_name": "gemma-2-2b-it",
    "aliases": [
      "gemma-2-2b-it"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 46618,
    "license_type": "Gemma license",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1198.77,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127937+00:00",
        "confidence": 1.0,
        "raw_name": "gemma-2-2b-it",
        "raw_scores": {
          "arena_elo": 1198.77,
          "arena_votes": 46618
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1198.77
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "phi-3-medium-4k-instruct",
    "canonical_name": "phi-3-medium-4k-instruct",
    "model_name": "phi-3-medium-4k-instruct",
    "aliases": [
      "phi-3-medium-4k-instruct"
    ],
    "provider": "Microsoft",
    "context_window": null,
    "open_source": null,
    "arena_votes": 25055,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1198.22,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127952+00:00",
        "confidence": 1.0,
        "raw_name": "phi-3-medium-4k-instruct",
        "raw_scores": {
          "arena_elo": 1198.22,
          "arena_votes": 25055
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1198.22
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "mixtral-8x7b-instruct-v01",
    "canonical_name": "mixtral-8x7b-instruct-v0.1",
    "model_name": "mixtral-8x7b-instruct-v0.1",
    "aliases": [
      "mixtral-8x7b-instruct-v0.1"
    ],
    "provider": "Mistral",
    "context_window": null,
    "open_source": null,
    "arena_votes": 73505,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1197.41,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127966+00:00",
        "confidence": 1.0,
        "raw_name": "mixtral-8x7b-instruct-v0.1",
        "raw_scores": {
          "arena_elo": 1197.41,
          "arena_votes": 73505
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1197.41
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "dbrx-instruct-preview",
    "canonical_name": "dbrx-instruct-preview",
    "model_name": "dbrx-instruct-preview",
    "aliases": [
      "dbrx-instruct-preview"
    ],
    "provider": "Databricks",
    "context_window": null,
    "open_source": null,
    "arena_votes": 32196,
    "license_type": "DBRX LICENSE",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1195.23,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127978+00:00",
        "confidence": 1.0,
        "raw_name": "dbrx-instruct-preview",
        "raw_scores": {
          "arena_elo": 1195.23,
          "arena_votes": 32196
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1195.23
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "internlm2_5-20b-chat",
    "canonical_name": "internlm2_5-20b-chat",
    "model_name": "internlm2_5-20b-chat",
    "aliases": [
      "internlm2_5-20b-chat"
    ],
    "provider": "InternLM",
    "context_window": null,
    "open_source": null,
    "arena_votes": 9902,
    "license_type": "Other",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1191.43,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.127998+00:00",
        "confidence": 1.0,
        "raw_name": "internlm2_5-20b-chat",
        "raw_scores": {
          "arena_elo": 1191.43,
          "arena_votes": 9902
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1191.43
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen15-14b-chat",
    "canonical_name": "qwen1.5-14b-chat",
    "model_name": "qwen1.5-14b-chat",
    "aliases": [
      "qwen1.5-14b-chat"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 17841,
    "license_type": "Qianwen LICENSE",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1191.09,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128023+00:00",
        "confidence": 1.0,
        "raw_name": "qwen1.5-14b-chat",
        "raw_scores": {
          "arena_elo": 1191.09,
          "arena_votes": 17841
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1191.09
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "wizardlm-70b",
    "canonical_name": "wizardlm-70b",
    "model_name": "wizardlm-70b",
    "aliases": [
      "wizardlm-70b"
    ],
    "provider": "Microsoft",
    "context_window": null,
    "open_source": null,
    "arena_votes": 8214,
    "license_type": "Llama 2 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1184.92,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128037+00:00",
        "confidence": 1.0,
        "raw_name": "wizardlm-70b",
        "raw_scores": {
          "arena_elo": 1184.92,
          "arena_votes": 8214
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1184.92
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "yi-34b-chat",
    "canonical_name": "yi-34b-chat",
    "model_name": "yi-34b-chat",
    "aliases": [
      "yi-34b-chat"
    ],
    "provider": "01 AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 15483,
    "license_type": "Yi License",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1183.98,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128062+00:00",
        "confidence": 1.0,
        "raw_name": "yi-34b-chat",
        "raw_scores": {
          "arena_elo": 1183.98,
          "arena_votes": 15483
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1183.98
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "openchat-35-0106",
    "canonical_name": "openchat-3.5-0106",
    "model_name": "openchat-3.5-0106",
    "aliases": [
      "openchat-3.5-0106"
    ],
    "provider": "OpenChat",
    "context_window": null,
    "open_source": null,
    "arena_votes": 12636,
    "license_type": "Apache-2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1182.57,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128074+00:00",
        "confidence": 1.0,
        "raw_name": "openchat-3.5-0106",
        "raw_scores": {
          "arena_elo": 1182.57,
          "arena_votes": 12636
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1182.57
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "granite-30-8b-instruct",
    "canonical_name": "granite-3.0-8b-instruct",
    "model_name": "granite-3.0-8b-instruct",
    "aliases": [
      "granite-3.0-8b-instruct"
    ],
    "provider": "IBM",
    "context_window": null,
    "open_source": null,
    "arena_votes": 6643,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1182.22,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128100+00:00",
        "confidence": 1.0,
        "raw_name": "granite-3.0-8b-instruct",
        "raw_scores": {
          "arena_elo": 1182.22,
          "arena_votes": 6643
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1182.22
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemma-11-7b-it",
    "canonical_name": "gemma-1.1-7b-it",
    "model_name": "gemma-1.1-7b-it",
    "aliases": [
      "gemma-1.1-7b-it"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 23893,
    "license_type": "Gemma license",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1180.34,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128113+00:00",
        "confidence": 1.0,
        "raw_name": "gemma-1.1-7b-it",
        "raw_scores": {
          "arena_elo": 1180.34,
          "arena_votes": 23893
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1180.34
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "snowflake-arctic-instruct",
    "canonical_name": "snowflake-arctic-instruct",
    "model_name": "snowflake-arctic-instruct",
    "aliases": [
      "snowflake-arctic-instruct"
    ],
    "provider": "Snowflake",
    "context_window": null,
    "open_source": null,
    "arena_votes": 32836,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1179.76,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128125+00:00",
        "confidence": 1.0,
        "raw_name": "snowflake-arctic-instruct",
        "raw_scores": {
          "arena_elo": 1179.76,
          "arena_votes": 32836
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1179.76
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "granite-31-2b-instruct",
    "canonical_name": "granite-3.1-2b-instruct",
    "model_name": "granite-3.1-2b-instruct",
    "aliases": [
      "granite-3.1-2b-instruct"
    ],
    "provider": "IBM",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3191,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1179.52,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128138+00:00",
        "confidence": 1.0,
        "raw_name": "granite-3.1-2b-instruct",
        "raw_scores": {
          "arena_elo": 1179.52,
          "arena_votes": 3191
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1179.52
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "tulu-2-dpo-70b",
    "canonical_name": "tulu-2-dpo-70b",
    "model_name": "tulu-2-dpo-70b",
    "aliases": [
      "tulu-2-dpo-70b"
    ],
    "provider": "AllenAI/UW",
    "context_window": null,
    "open_source": null,
    "arena_votes": 6534,
    "license_type": "AI2 ImpACT Low-risk",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1178.28,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128151+00:00",
        "confidence": 1.0,
        "raw_name": "tulu-2-dpo-70b",
        "raw_scores": {
          "arena_elo": 1178.28,
          "arena_votes": 6534
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1178.28
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "openhermes-25-mistral-7b",
    "canonical_name": "openhermes-2.5-mistral-7b",
    "model_name": "openhermes-2.5-mistral-7b",
    "aliases": [
      "openhermes-2.5-mistral-7b"
    ],
    "provider": "NousResearch",
    "context_window": null,
    "open_source": null,
    "arena_votes": 5006,
    "license_type": "Apache-2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1175.44,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128163+00:00",
        "confidence": 1.0,
        "raw_name": "openhermes-2.5-mistral-7b",
        "raw_scores": {
          "arena_elo": 1175.44,
          "arena_votes": 5006
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1175.44
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "vicuna-33b",
    "canonical_name": "vicuna-33b",
    "model_name": "vicuna-33b",
    "aliases": [
      "vicuna-33b"
    ],
    "provider": "LMSYS",
    "context_window": null,
    "open_source": null,
    "arena_votes": 22479,
    "license_type": "Non-commercial",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1173.06,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128176+00:00",
        "confidence": 1.0,
        "raw_name": "vicuna-33b",
        "raw_scores": {
          "arena_elo": 1173.06,
          "arena_votes": 22479
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1173.06
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "starling-lm-7b-beta",
    "canonical_name": "starling-lm-7b-beta",
    "model_name": "starling-lm-7b-beta",
    "aliases": [
      "starling-lm-7b-beta"
    ],
    "provider": "Nexusflow",
    "context_window": null,
    "open_source": null,
    "arena_votes": 16057,
    "license_type": "Apache-2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1171.81,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128188+00:00",
        "confidence": 1.0,
        "raw_name": "starling-lm-7b-beta",
        "raw_scores": {
          "arena_elo": 1171.81,
          "arena_votes": 16057
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1171.81
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "phi-3-small-8k-instruct",
    "canonical_name": "phi-3-small-8k-instruct",
    "model_name": "phi-3-small-8k-instruct",
    "aliases": [
      "phi-3-small-8k-instruct"
    ],
    "provider": "Microsoft",
    "context_window": null,
    "open_source": null,
    "arena_votes": 17763,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1171.41,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128200+00:00",
        "confidence": 1.0,
        "raw_name": "phi-3-small-8k-instruct",
        "raw_scores": {
          "arena_elo": 1171.41,
          "arena_votes": 17763
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1171.41
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-2-70b-chat",
    "canonical_name": "llama-2-70b-chat",
    "model_name": "llama-2-70b-chat",
    "aliases": [
      "llama-2-70b-chat"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 38491,
    "license_type": "Llama 2 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1171.04,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128212+00:00",
        "confidence": 1.0,
        "raw_name": "llama-2-70b-chat",
        "raw_scores": {
          "arena_elo": 1171.04,
          "arena_votes": 38491
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1171.04
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "starling-lm-7b-alpha",
    "canonical_name": "starling-lm-7b-alpha",
    "model_name": "starling-lm-7b-alpha",
    "aliases": [
      "starling-lm-7b-alpha"
    ],
    "provider": "UC Berkeley",
    "context_window": null,
    "open_source": null,
    "arena_votes": 10224,
    "license_type": "CC-BY-NC-4.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1167.78,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128225+00:00",
        "confidence": 1.0,
        "raw_name": "starling-lm-7b-alpha",
        "raw_scores": {
          "arena_elo": 1167.78,
          "arena_votes": 10224
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1167.78
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-32-3b-instruct",
    "canonical_name": "llama-3.2-3b-instruct",
    "model_name": "llama-3.2-3b-instruct",
    "aliases": [
      "llama-3.2-3b-instruct"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 7936,
    "license_type": "Llama 3.2",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1166.82,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128237+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.2-3b-instruct",
        "raw_scores": {
          "arena_elo": 1166.82,
          "arena_votes": 7936
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1166.82
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "nous-hermes-2-mixtral-8x7b-dpo",
    "canonical_name": "nous-hermes-2-mixtral-8x7b-dpo",
    "model_name": "nous-hermes-2-mixtral-8x7b-dpo",
    "aliases": [
      "nous-hermes-2-mixtral-8x7b-dpo"
    ],
    "provider": "NousResearch",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3776,
    "license_type": "Apache-2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1164.91,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128263+00:00",
        "confidence": 1.0,
        "raw_name": "nous-hermes-2-mixtral-8x7b-dpo",
        "raw_scores": {
          "arena_elo": 1164.91,
          "arena_votes": 3776
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1164.91
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "granite-30-2b-instruct",
    "canonical_name": "granite-3.0-2b-instruct",
    "model_name": "granite-3.0-2b-instruct",
    "aliases": [
      "granite-3.0-2b-instruct"
    ],
    "provider": "IBM",
    "context_window": null,
    "open_source": null,
    "arena_votes": 6837,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1156.22,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128290+00:00",
        "confidence": 1.0,
        "raw_name": "granite-3.0-2b-instruct",
        "raw_scores": {
          "arena_elo": 1156.22,
          "arena_votes": 6837
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1156.22
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama2-70b-steerlm-chat",
    "canonical_name": "llama2-70b-steerlm-chat",
    "model_name": "llama2-70b-steerlm-chat",
    "aliases": [
      "llama2-70b-steerlm-chat"
    ],
    "provider": "Nvidia",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3584,
    "license_type": "Llama 2 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1155.58,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128303+00:00",
        "confidence": 1.0,
        "raw_name": "llama2-70b-steerlm-chat",
        "raw_scores": {
          "arena_elo": 1155.58,
          "arena_votes": 3584
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1155.58
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "solar-107b-instruct-v10",
    "canonical_name": "solar-10.7b-instruct-v1.0",
    "model_name": "solar-10.7b-instruct-v1.0",
    "aliases": [
      "solar-10.7b-instruct-v1.0"
    ],
    "provider": "Upstage AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4155,
    "license_type": "CC-BY-NC-4.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1152.63,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128315+00:00",
        "confidence": 1.0,
        "raw_name": "solar-10.7b-instruct-v1.0",
        "raw_scores": {
          "arena_elo": 1152.63,
          "arena_votes": 4155
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1152.63
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "dolphin-221-mistral-7b",
    "canonical_name": "dolphin-2.2.1-mistral-7b",
    "model_name": "dolphin-2.2.1-mistral-7b",
    "aliases": [
      "dolphin-2.2.1-mistral-7b"
    ],
    "provider": "Cognitive Computations",
    "context_window": null,
    "open_source": null,
    "arena_votes": 1679,
    "license_type": "Apache-2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1152.24,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128327+00:00",
        "confidence": 1.0,
        "raw_name": "dolphin-2.2.1-mistral-7b",
        "raw_scores": {
          "arena_elo": 1152.24,
          "arena_votes": 1679
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1152.24
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "mpt-30b-chat",
    "canonical_name": "mpt-30b-chat",
    "model_name": "mpt-30b-chat",
    "aliases": [
      "mpt-30b-chat"
    ],
    "provider": "MosaicML",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2571,
    "license_type": "CC-BY-NC-SA-4.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1150.4,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128340+00:00",
        "confidence": 1.0,
        "raw_name": "mpt-30b-chat",
        "raw_scores": {
          "arena_elo": 1150.4,
          "arena_votes": 2571
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1150.4
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "mistral-7b-instruct-v02",
    "canonical_name": "mistral-7b-instruct-v0.2",
    "model_name": "mistral-7b-instruct-v0.2",
    "aliases": [
      "mistral-7b-instruct-v0.2"
    ],
    "provider": "Mistral",
    "context_window": null,
    "open_source": null,
    "arena_votes": 19402,
    "license_type": "Apache-2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1149.88,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128353+00:00",
        "confidence": 1.0,
        "raw_name": "mistral-7b-instruct-v0.2",
        "raw_scores": {
          "arena_elo": 1149.88,
          "arena_votes": 19402
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1149.88
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "wizardlm-13b",
    "canonical_name": "wizardlm-13b",
    "model_name": "wizardlm-13b",
    "aliases": [
      "wizardlm-13b"
    ],
    "provider": "Microsoft",
    "context_window": null,
    "open_source": null,
    "arena_votes": 7046,
    "license_type": "Llama 2 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1149.41,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128365+00:00",
        "confidence": 1.0,
        "raw_name": "wizardlm-13b",
        "raw_scores": {
          "arena_elo": 1149.41,
          "arena_votes": 7046
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1149.41
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "falcon-180b-chat",
    "canonical_name": "falcon-180b-chat",
    "model_name": "falcon-180b-chat",
    "aliases": [
      "falcon-180b-chat"
    ],
    "provider": "TII",
    "context_window": null,
    "open_source": null,
    "arena_votes": 1295,
    "license_type": "Falcon-180B TII License",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1147.29,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128377+00:00",
        "confidence": 1.0,
        "raw_name": "falcon-180b-chat",
        "raw_scores": {
          "arena_elo": 1147.29,
          "arena_votes": 1295
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1147.29
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen15-7b-chat",
    "canonical_name": "qwen1.5-7b-chat",
    "model_name": "qwen1.5-7b-chat",
    "aliases": [
      "qwen1.5-7b-chat"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4735,
    "license_type": "Qianwen LICENSE",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1144.11,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128390+00:00",
        "confidence": 1.0,
        "raw_name": "qwen1.5-7b-chat",
        "raw_scores": {
          "arena_elo": 1144.11,
          "arena_votes": 4735
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1144.11
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "phi-3-mini-4k-instruct-june-2024",
    "canonical_name": "phi-3-mini-4k-instruct-june-2024",
    "model_name": "phi-3-mini-4k-instruct-june-2024",
    "aliases": [
      "phi-3-mini-4k-instruct-june-2024"
    ],
    "provider": "Microsoft",
    "context_window": null,
    "open_source": null,
    "arena_votes": 12296,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1143.25,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128402+00:00",
        "confidence": 1.0,
        "raw_name": "phi-3-mini-4k-instruct-june-2024",
        "raw_scores": {
          "arena_elo": 1143.25,
          "arena_votes": 12296
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1143.25
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-2-13b-chat",
    "canonical_name": "llama-2-13b-chat",
    "model_name": "llama-2-13b-chat",
    "aliases": [
      "llama-2-13b-chat"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 19171,
    "license_type": "Llama 2 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1141.7,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128414+00:00",
        "confidence": 1.0,
        "raw_name": "llama-2-13b-chat",
        "raw_scores": {
          "arena_elo": 1141.7,
          "arena_votes": 19171
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1141.7
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "vicuna-13b",
    "canonical_name": "vicuna-13b",
    "model_name": "vicuna-13b",
    "aliases": [
      "vicuna-13b"
    ],
    "provider": "LMSYS",
    "context_window": null,
    "open_source": null,
    "arena_votes": 19366,
    "license_type": "Llama 2 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1141.18,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128426+00:00",
        "confidence": 1.0,
        "raw_name": "vicuna-13b",
        "raw_scores": {
          "arena_elo": 1141.18,
          "arena_votes": 19366
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1141.18
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen-14b-chat",
    "canonical_name": "qwen-14b-chat",
    "model_name": "qwen-14b-chat",
    "aliases": [
      "qwen-14b-chat"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4964,
    "license_type": "Qianwen LICENSE",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1138.84,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128439+00:00",
        "confidence": 1.0,
        "raw_name": "qwen-14b-chat",
        "raw_scores": {
          "arena_elo": 1138.84,
          "arena_votes": 4964
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1138.84
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "codellama-34b-instruct",
    "canonical_name": "codellama-34b-instruct",
    "model_name": "codellama-34b-instruct",
    "aliases": [
      "codellama-34b-instruct"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 7363,
    "license_type": "Llama 2 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1136.84,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128463+00:00",
        "confidence": 1.0,
        "raw_name": "codellama-34b-instruct",
        "raw_scores": {
          "arena_elo": 1136.84,
          "arena_votes": 7363
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1136.84
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemma-7b-it",
    "canonical_name": "gemma-7b-it",
    "model_name": "gemma-7b-it",
    "aliases": [
      "gemma-7b-it"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 8925,
    "license_type": "Gemma license",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1136.12,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128476+00:00",
        "confidence": 1.0,
        "raw_name": "gemma-7b-it",
        "raw_scores": {
          "arena_elo": 1136.12,
          "arena_votes": 8925
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1136.12
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "zephyr-7b-beta",
    "canonical_name": "zephyr-7b-beta",
    "model_name": "zephyr-7b-beta",
    "aliases": [
      "zephyr-7b-beta"
    ],
    "provider": "HuggingFace",
    "context_window": null,
    "open_source": null,
    "arena_votes": 11116,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1131.32,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128489+00:00",
        "confidence": 1.0,
        "raw_name": "zephyr-7b-beta",
        "raw_scores": {
          "arena_elo": 1131.32,
          "arena_votes": 11116
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1131.32
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "phi-3-mini-128k-instruct",
    "canonical_name": "phi-3-mini-128k-instruct",
    "model_name": "phi-3-mini-128k-instruct",
    "aliases": [
      "phi-3-mini-128k-instruct"
    ],
    "provider": "Microsoft",
    "context_window": null,
    "open_source": null,
    "arena_votes": 20691,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1129.45,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128501+00:00",
        "confidence": 1.0,
        "raw_name": "phi-3-mini-128k-instruct",
        "raw_scores": {
          "arena_elo": 1129.45,
          "arena_votes": 20691
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1129.45
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "phi-3-mini-4k-instruct",
    "canonical_name": "phi-3-mini-4k-instruct",
    "model_name": "phi-3-mini-4k-instruct",
    "aliases": [
      "phi-3-mini-4k-instruct"
    ],
    "provider": "Microsoft",
    "context_window": null,
    "open_source": null,
    "arena_votes": 20115,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1128.59,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128513+00:00",
        "confidence": 1.0,
        "raw_name": "phi-3-mini-4k-instruct",
        "raw_scores": {
          "arena_elo": 1128.59,
          "arena_votes": 20115
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1128.59
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "guanaco-33b",
    "canonical_name": "guanaco-33b",
    "model_name": "guanaco-33b",
    "aliases": [
      "guanaco-33b"
    ],
    "provider": "UW",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2921,
    "license_type": "Non-commercial",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1127.56,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128526+00:00",
        "confidence": 1.0,
        "raw_name": "guanaco-33b",
        "raw_scores": {
          "arena_elo": 1127.56,
          "arena_votes": 2921
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1127.56
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "zephyr-7b-alpha",
    "canonical_name": "zephyr-7b-alpha",
    "model_name": "zephyr-7b-alpha",
    "aliases": [
      "zephyr-7b-alpha"
    ],
    "provider": "HuggingFace",
    "context_window": null,
    "open_source": null,
    "arena_votes": 1785,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1127.16,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128539+00:00",
        "confidence": 1.0,
        "raw_name": "zephyr-7b-alpha",
        "raw_scores": {
          "arena_elo": 1127.16,
          "arena_votes": 1785
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1127.16
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "stripedhyena-nous-7b",
    "canonical_name": "stripedhyena-nous-7b",
    "model_name": "stripedhyena-nous-7b",
    "aliases": [
      "stripedhyena-nous-7b"
    ],
    "provider": "Together AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 5184,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1121.22,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128551+00:00",
        "confidence": 1.0,
        "raw_name": "stripedhyena-nous-7b",
        "raw_scores": {
          "arena_elo": 1121.22,
          "arena_votes": 5184
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1121.22
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "codellama-70b-instruct",
    "canonical_name": "codellama-70b-instruct",
    "model_name": "codellama-70b-instruct",
    "aliases": [
      "codellama-70b-instruct"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 1143,
    "license_type": "Llama 2 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1119.18,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128564+00:00",
        "confidence": 1.0,
        "raw_name": "codellama-70b-instruct",
        "raw_scores": {
          "arena_elo": 1119.18,
          "arena_votes": 1143
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1119.18
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "vicuna-7b",
    "canonical_name": "vicuna-7b",
    "model_name": "vicuna-7b",
    "aliases": [
      "vicuna-7b"
    ],
    "provider": "LMSYS",
    "context_window": null,
    "open_source": null,
    "arena_votes": 6923,
    "license_type": "Llama 2 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1114.89,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128576+00:00",
        "confidence": 1.0,
        "raw_name": "vicuna-7b",
        "raw_scores": {
          "arena_elo": 1114.89,
          "arena_votes": 6923
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1114.89
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "smollm2-17b-instruct",
    "canonical_name": "smollm2-1.7b-instruct",
    "model_name": "smollm2-1.7b-instruct",
    "aliases": [
      "smollm2-1.7b-instruct"
    ],
    "provider": "HuggingFace",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2201,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1114.54,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128589+00:00",
        "confidence": 1.0,
        "raw_name": "smollm2-1.7b-instruct",
        "raw_scores": {
          "arena_elo": 1114.54,
          "arena_votes": 2201
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1114.54
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemma-11-2b-it",
    "canonical_name": "gemma-1.1-2b-it",
    "model_name": "gemma-1.1-2b-it",
    "aliases": [
      "gemma-1.1-2b-it"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 10853,
    "license_type": "Gemma license",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1114.29,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128601+00:00",
        "confidence": 1.0,
        "raw_name": "gemma-1.1-2b-it",
        "raw_scores": {
          "arena_elo": 1114.29,
          "arena_votes": 10853
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1114.29
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-32-1b-instruct",
    "canonical_name": "llama-3.2-1b-instruct",
    "model_name": "llama-3.2-1b-instruct",
    "aliases": [
      "llama-3.2-1b-instruct"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 8045,
    "license_type": "Llama 3.2",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1111.41,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128613+00:00",
        "confidence": 1.0,
        "raw_name": "llama-3.2-1b-instruct",
        "raw_scores": {
          "arena_elo": 1111.41,
          "arena_votes": 8045
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1111.41
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-2-7b-chat",
    "canonical_name": "llama-2-7b-chat",
    "model_name": "llama-2-7b-chat",
    "aliases": [
      "llama-2-7b-chat"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 14148,
    "license_type": "Llama 2 Community",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1108.39,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128638+00:00",
        "confidence": 1.0,
        "raw_name": "llama-2-7b-chat",
        "raw_scores": {
          "arena_elo": 1108.39,
          "arena_votes": 14148
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1108.39
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gemma-2b-it",
    "canonical_name": "gemma-2b-it",
    "model_name": "gemma-2b-it",
    "aliases": [
      "gemma-2b-it"
    ],
    "provider": "Google",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4779,
    "license_type": "Gemma license",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1091.78,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128650+00:00",
        "confidence": 1.0,
        "raw_name": "gemma-2b-it",
        "raw_scores": {
          "arena_elo": 1091.78,
          "arena_votes": 4779
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1091.78
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "qwen15-4b-chat",
    "canonical_name": "qwen1.5-4b-chat",
    "model_name": "qwen1.5-4b-chat",
    "aliases": [
      "qwen1.5-4b-chat"
    ],
    "provider": "Alibaba",
    "context_window": null,
    "open_source": null,
    "arena_votes": 7598,
    "license_type": "Qianwen LICENSE",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1090.4,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128662+00:00",
        "confidence": 1.0,
        "raw_name": "qwen1.5-4b-chat",
        "raw_scores": {
          "arena_elo": 1090.4,
          "arena_votes": 7598
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1090.4
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "olmo-7b-instruct",
    "canonical_name": "olmo-7b-instruct",
    "model_name": "olmo-7b-instruct",
    "aliases": [
      "olmo-7b-instruct"
    ],
    "provider": "Allen AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 6329,
    "license_type": "Apache-2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1074.8,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128675+00:00",
        "confidence": 1.0,
        "raw_name": "olmo-7b-instruct",
        "raw_scores": {
          "arena_elo": 1074.8,
          "arena_votes": 6329
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1074.8
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "koala-13b",
    "canonical_name": "koala-13b",
    "model_name": "koala-13b",
    "aliases": [
      "koala-13b"
    ],
    "provider": "UC Berkeley",
    "context_window": null,
    "open_source": null,
    "arena_votes": 6964,
    "license_type": "Non-commercial",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1070.66,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128687+00:00",
        "confidence": 1.0,
        "raw_name": "koala-13b",
        "raw_scores": {
          "arena_elo": 1070.66,
          "arena_votes": 6964
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1070.66
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "alpaca-13b",
    "canonical_name": "alpaca-13b",
    "model_name": "alpaca-13b",
    "aliases": [
      "alpaca-13b"
    ],
    "provider": "Stanford",
    "context_window": null,
    "open_source": null,
    "arena_votes": 5745,
    "license_type": "Non-commercial",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1067.69,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128699+00:00",
        "confidence": 1.0,
        "raw_name": "alpaca-13b",
        "raw_scores": {
          "arena_elo": 1067.69,
          "arena_votes": 5745
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1067.69
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "gpt4all-13b-snoozy",
    "canonical_name": "gpt4all-13b-snoozy",
    "model_name": "gpt4all-13b-snoozy",
    "aliases": [
      "gpt4all-13b-snoozy"
    ],
    "provider": "Nomic AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 1743,
    "license_type": "Non-commercial",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1066.21,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128712+00:00",
        "confidence": 1.0,
        "raw_name": "gpt4all-13b-snoozy",
        "raw_scores": {
          "arena_elo": 1066.21,
          "arena_votes": 1743
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1066.21
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "mpt-7b-chat",
    "canonical_name": "mpt-7b-chat",
    "model_name": "mpt-7b-chat",
    "aliases": [
      "mpt-7b-chat"
    ],
    "provider": "MosaicML",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3925,
    "license_type": "CC-BY-NC-SA-4.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1062.08,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128724+00:00",
        "confidence": 1.0,
        "raw_name": "mpt-7b-chat",
        "raw_scores": {
          "arena_elo": 1062.08,
          "arena_votes": 3925
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1062.08
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "chatglm3-6b",
    "canonical_name": "chatglm3-6b",
    "model_name": "chatglm3-6b",
    "aliases": [
      "chatglm3-6b"
    ],
    "provider": "Tsinghua",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4658,
    "license_type": "Apache-2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1056.29,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128736+00:00",
        "confidence": 1.0,
        "raw_name": "chatglm3-6b",
        "raw_scores": {
          "arena_elo": 1056.29,
          "arena_votes": 4658
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1056.29
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "rwkv-4-raven-14b",
    "canonical_name": "RWKV-4-Raven-14B",
    "model_name": "RWKV-4-Raven-14B",
    "aliases": [
      "RWKV-4-Raven-14B"
    ],
    "provider": "RWKV",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4845,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1041.53,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128753+00:00",
        "confidence": 1.0,
        "raw_name": "RWKV-4-Raven-14B",
        "raw_scores": {
          "arena_elo": 1041.53,
          "arena_votes": 4845
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1041.53
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "chatglm2-6b",
    "canonical_name": "chatglm2-6b",
    "model_name": "chatglm2-6b",
    "aliases": [
      "chatglm2-6b"
    ],
    "provider": "Tsinghua",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2657,
    "license_type": "Apache-2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1024.43,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128765+00:00",
        "confidence": 1.0,
        "raw_name": "chatglm2-6b",
        "raw_scores": {
          "arena_elo": 1024.43,
          "arena_votes": 2657
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1024.43
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "oasst-pythia-12b",
    "canonical_name": "oasst-pythia-12b",
    "model_name": "oasst-pythia-12b",
    "aliases": [
      "oasst-pythia-12b"
    ],
    "provider": "OpenAssistant",
    "context_window": null,
    "open_source": null,
    "arena_votes": 6311,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 1022.35,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128778+00:00",
        "confidence": 1.0,
        "raw_name": "oasst-pythia-12b",
        "raw_scores": {
          "arena_elo": 1022.35,
          "arena_votes": 6311
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 1022.35
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "chatglm-6b",
    "canonical_name": "chatglm-6b",
    "model_name": "chatglm-6b",
    "aliases": [
      "chatglm-6b"
    ],
    "provider": "Tsinghua",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4914,
    "license_type": "Non-commercial",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 995.792,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128791+00:00",
        "confidence": 1.0,
        "raw_name": "chatglm-6b",
        "raw_scores": {
          "arena_elo": 995.792,
          "arena_votes": 4914
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 995.792
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "fastchat-t5-3b",
    "canonical_name": "fastchat-t5-3b",
    "model_name": "fastchat-t5-3b",
    "aliases": [
      "fastchat-t5-3b"
    ],
    "provider": "LMSYS",
    "context_window": null,
    "open_source": null,
    "arena_votes": 4203,
    "license_type": "Apache 2.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 991.521,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128803+00:00",
        "confidence": 1.0,
        "raw_name": "fastchat-t5-3b",
        "raw_scores": {
          "arena_elo": 991.521,
          "arena_votes": 4203
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 991.521
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "dolly-v2-12b",
    "canonical_name": "dolly-v2-12b",
    "model_name": "dolly-v2-12b",
    "aliases": [
      "dolly-v2-12b"
    ],
    "provider": "Databricks",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3412,
    "license_type": "MIT",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 980.33,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128815+00:00",
        "confidence": 1.0,
        "raw_name": "dolly-v2-12b",
        "raw_scores": {
          "arena_elo": 980.33,
          "arena_votes": 3412
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 980.33
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "llama-13b",
    "canonical_name": "llama-13b",
    "model_name": "llama-13b",
    "aliases": [
      "llama-13b"
    ],
    "provider": "Meta",
    "context_window": null,
    "open_source": null,
    "arena_votes": 2391,
    "license_type": "Non-commercial",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 972.397,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128828+00:00",
        "confidence": 1.0,
        "raw_name": "llama-13b",
        "raw_scores": {
          "arena_elo": 972.397,
          "arena_votes": 2391
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 972.397
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  },
  {
    "model_id": null,
    "model_slug": "stablelm-tuned-alpha-7b",
    "canonical_name": "stablelm-tuned-alpha-7b",
    "model_name": "stablelm-tuned-alpha-7b",
    "aliases": [
      "stablelm-tuned-alpha-7b"
    ],
    "provider": "Stability AI",
    "context_window": null,
    "open_source": null,
    "arena_votes": 3287,
    "license_type": "CC-BY-NC-SA-4.0",
    "creator": null,
    "intelligence_score": null,
    "coding_score": null,
    "reasoning_score": null,
    "multimodal_score": null,
    "arena_elo": 952.816,
    "input_cost_per_1m": null,
    "output_cost_per_1m": null,
    "blended_cost_per_1m": null,
    "latency_seconds": null,
    "latency_first_token": null,
    "latency_p5": null,
    "latency_p25": null,
    "latency_p75": null,
    "latency_p95": null,
    "total_response_time": null,
    "reasoning_time": null,
    "tokens_per_second": null,
    "speed_p5": null,
    "speed_p25": null,
    "speed_p75": null,
    "speed_p95": null,
    "gdpval": null,
    "terminalbench_hard": null,
    "tau2": null,
    "lcr": null,
    "omniscience": null,
    "omniscience_hallucination": null,
    "hle": null,
    "gpqa": null,
    "scicode": null,
    "ifbench": null,
    "aime25": null,
    "critpt": null,
    "mmmu_pro": null,
    "livecodebench": null,
    "sources": [
      "LMSYS Chatbot Arena"
    ],
    "source_count": 1,
    "data_tier": 3,
    "aggregation_method": "weighted_mean",
    "provenance": [
      {
        "source": "LMSYS Chatbot Arena",
        "scraped_at": "2026-02-24T21:08:29.128840+00:00",
        "confidence": 1.0,
        "raw_name": "stablelm-tuned-alpha-7b",
        "raw_scores": {
          "arena_elo": 952.816,
          "arena_votes": 3287
        }
      }
    ],
    "benchmark_breakdown": {
      "LMSYS Chatbot Arena": {
        "arena_elo": 952.816
      }
    },
    "confidence_score": 1.0,
    "snapshot_date": "2026-02-24"
  }
]