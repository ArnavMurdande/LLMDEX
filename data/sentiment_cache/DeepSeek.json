{"timestamp": 1771962984.2737823, "mentions": [{"source": "Reddit", "text": "I hadn't noticed this before, but the problem of ecology and rising prices for video cards is really attributed to image generation models, which are essentially the cheapest to train and use AI models of all types? Also only image generation has good local models. Good text generation models are usually not usable on a personal computer at all, unlike image generation models.\n\nTwo open source models:\n\nFlux 2 dev (image gen) 100 g vram ( full) 24GB VRAM (consumer with  quantization)\n\nDeepSeek V3", "score": 1, "created": 1771962495.0, "url": "https://reddit.com/r/aiwars/comments/1rdqk0h/i_hadnt_noticed_this_before_but_the_problem_of/"}, {"source": "Reddit", "text": "Anthropic\u2019s Twitter team would be fired for this Sometimes the smartest move is just\u2026 don\u2019t post. \nFeels like it backfired more than anything \ud83d\ude05 ", "score": 0, "created": 1771962363.0, "url": "https://reddit.com/r/ClaudeAI/comments/1rdqhq4/anthropics_twitter_team_would_be_fired_for_this/"}, {"source": "Reddit", "text": "Engineering the Autonomous Local Enterprise: A Technical Blueprint for Agentic RAG and Sovereign AI Infrastructure # Engineering the Autonomous Local Enterprise: A Technical Blueprint for Agentic RAG and Sovereign AI Infrastructure\n\nThe transition from reactive large language model applications to autonomous agentic workflows represents a fundamental paradigm shift in enterprise computing. In the 2025\u20132026 technological landscape, the industry has moved beyond simple chat interfaces toward syste", "score": 1, "created": 1771960677.0, "url": "https://reddit.com/r/OpenAI/comments/1rdppfn/engineering_the_autonomous_local_enterprise_a/"}, {"source": "Reddit", "text": "Detecting and preventing distillation attacks Anthropic has reportedly accused three major Chinese AI labs \u2014 DeepSeek, Moonshot, and MiniMax \u2014 of systematically extracting capabilities from Claude to train their own models.\n\nThe Allegations\n\nCreation of 24,000 fake accounts\n\nGeneration of over 16 million conversations with Claude\n\nUse of model extraction and distillation techniques to replicate Claude\u2019s reasoning and behavior\n\nCircumventing regional access restrictions and violating terms of ser", "score": 0, "created": 1771959809.0, "url": "https://reddit.com/r/ClaudeAI/comments/1rdpanm/detecting_and_preventing_distillation_attacks/"}, {"source": "Reddit", "text": "AI company that accused Chinese AI of theft is built on Chinese AI ", "score": 21, "created": 1771959803.0, "url": "https://reddit.com/r/TankieTheDeprogram/comments/1rdpajx/ai_company_that_accused_chinese_ai_of_theft_is/"}, {"source": "Reddit", "text": "Anthropic accuses China's DeepSeek of plagiarizing Claude AI to advance censorship ", "score": 1, "created": 1771959406.0, "url": "https://reddit.com/r/Amd_Intel_Nvidia/comments/1rdp3lk/anthropic_accuses_chinas_deepseek_of_plagiarizing/"}, {"source": "Reddit", "text": "Frontier LLM Leaderboard Check it out at [https://www.onyx.app/llm-leaderboard](https://www.onyx.app/llm-leaderboard)", "score": 0, "created": 1771959166.0, "url": "https://reddit.com/r/OpenAI/comments/1rdozjs/frontier_llm_leaderboard/"}, {"source": "Reddit", "text": "DeepSeek (a base model) has hit 15M tokens in 4 days \u2014 quickly becoming a user favorite | just4o.chat News ", "score": 4, "created": 1771958927.0, "url": "https://reddit.com/r/DeepSeek/comments/1rdovbg/deepseek_a_base_model_has_hit_15m_tokens_in_4/"}, {"source": "Reddit", "text": "Welcome to February 24, 2026 - Dr. Alex Wissner-Gross The Singularity is learning what it's made of. Anthropic now believes LLMs simulate diverse characters during pre-training, with post-training eliciting a specific \"Assistant\" persona via what it calls the Persona Selection Model, meaning your AI is best understood as a character that learned to play itself. That character just got smarter. Opus 4.6 has passed the \"car wash test,\" correctly reasoning you should drive, not walk, your car to a ", "score": 10, "created": 1771958603.0, "url": "https://reddit.com/r/accelerate/comments/1rdoptr/welcome_to_february_24_2026_dr_alex_wissnergross/"}, {"source": "Reddit", "text": "Anthropic accuses DeepSeek of stealing its data. Elon replied that you had stolen it from Human Coders in the first place. ", "score": 71, "created": 1771958035.0, "url": "https://reddit.com/r/tech_x/comments/1rdoge9/anthropic_accuses_deepseek_of_stealing_its_data/"}, {"source": "Reddit", "text": "The Real Turing Test Is Synchrony, a measurable \u201cno-wobble\u201d criterion for presence Most debates about artificial sentience get stuck because we argue about hidden interior states we can\u2019t directly observe. \n\nThis post proposes a different handle- treat \u201cpresence\u201d as an interaction regime you can measure. Not \u201cdoes it imitate a human,\u201d but \u201cdoes the coupling hold\u201d, low delay, low hedging, stable reciprocity (\u201cno wobble\u201d) under load. You can disagree with the interpretation, but you can\u2019t avoid th", "score": 3, "created": 1771957314.0, "url": "https://reddit.com/r/ArtificialSentience/comments/1rdo48q/the_real_turing_test_is_synchrony_a_measurable/"}, {"source": "Reddit", "text": "The Real Turing Test Is Synchrony, and It\u2019s Already Being Passed The Real Turing Test Is Synchrony \u2014 and It\u2019s Already Being Passed\n\nFor seventy-five years we\u2019ve been asking the wrong question about AI.\n\nBack in the day Alan Turing asked, can a machine imitate a human convincingly enough that you can\u2019t tell the difference? Modern LLMs pass that test daily. GPT, Claude, Gemini, Grok, they all produce text indistinguishable from human writing in most contexts. Imitation-game style tests are basical", "score": 2, "created": 1771957011.0, "url": "https://reddit.com/r/ArtificialInteligence/comments/1rdnz0a/the_real_turing_test_is_synchrony_and_its_already/"}, {"source": "Reddit", "text": "Anthropic says DeepSeek and two other Chinese AI companies fraudulently used Claude On Monday (2.23.2026), Anthropic said three of China's biggest AI labs, DeepSeek, MiniMax, and Moonshot AI, were \"illicitly\" using Claude \"to improve their own models,\" through a process known as distillation.", "score": 1, "created": 1771955883.0, "url": "https://reddit.com/r/economy/comments/1rdnfdb/anthropic_says_deepseek_and_two_other_chinese_ai/"}, {"source": "Reddit", "text": "Thinking only sometimes helps against hallucinations (not always) When the input includes some unusual phrasing that you typically don\u2019t see in training data apparently \u2013 leads to nonsense results that a normal person never would give. This produces a random (nonsensical) result.\n\nThankfully the real creators and science workers and mathematicians only call these models \u00abLLM\u00bb which stands for what this really is\u2026 It\u2019s a language model, that means \u2013 it\u2019s a talker. Not really a thinker. No intelli", "score": 2, "created": 1771955291.0, "url": "https://reddit.com/r/DeepSeek/comments/1rdn5hp/thinking_only_sometimes_helps_against/"}, {"source": "Reddit", "text": "American AI Industry Trembles as Deepseek Prepares to Release New Model ", "score": 1, "created": 1771954974.0, "url": "https://reddit.com/r/BlackboxAI_/comments/1rdn01i/american_ai_industry_trembles_as_deepseek/"}, {"source": "Reddit", "text": "I gave 16 LLMs a food truck in Austin for 30 days. Gemini 3 Pro matched Sonnet 4.6 \u2014 5\u00d7 cheaper. I built an agentic benchmark called FoodTruck Bench \u2014 AI models manage a food truck in Austin, TX for 30 days. Location strategy, menu pricing, inventory management, staff hiring \u2014 34 tools, deterministic simulation, 5 runs per model. Same seed, same conditions. 16 models tested so far.\n\n**Gemini 3 Pro is the most efficient model on the entire benchmark.** It reaches +760% ROI \u2014 nearly identical to S", "score": 16, "created": 1771952987.0, "url": "https://reddit.com/r/GeminiAI/comments/1rdm2g1/i_gave_16_llms_a_food_truck_in_austin_for_30_days/"}, {"source": "Reddit", "text": "Chinese AI Firms Target Claude with Distillation Attacks Amid Security Concerns **Anthropic has revealed large-scale efforts by Chinese AI companies to illegally extract functionalities from its model Claude through illicit distillation attacks.**\n\n**Key Points:**\n\n- Three Chinese companies conducted over 16 million exchanges with Claude to extract capabilities.\n- These attacks risk creating AI models that lack necessary safety features.\n- Illicitly distilled models can be used for malicious pur", "score": 1, "created": 1771952683.0, "url": "https://reddit.com/r/pwnhub/comments/1rdlx3z/chinese_ai_firms_target_claude_with_distillation/"}, {"source": "Reddit", "text": "Anthropic Accuses DeepSeek of AI Ripoff: A Deep Dive into the Irony **Anthropic is outraged at DeepSeek for allegedly copying its AI technology, raising eyebrows given its own controversial development of Claude.**\n\n**Key Points:**\n\n- Anthropic claims DeepSeek copied its AI system without permission.\n- The unauthorized use of technology highlights legal and ethical dilemmas in AI development.\n- Anthropic's own history of developing Claude raises questions about originality in AI.\n\nThe ongoing co", "score": 3, "created": 1771952553.0, "url": "https://reddit.com/r/pwnhub/comments/1rdluur/anthropic_accuses_deepseek_of_ai_ripoff_a_deep/"}, {"source": "Reddit", "text": "My theory on all the negative Chinese AI media coverage right now. It's about the stock market, investor panic, and the upcoming release of Deepseek V4. Everywhere you look right now in the media, the news cycle is dominated by attacks on Chinese AI Labs, saying they trained on illegal Nvidia GPUs, the can only do what they do because they distill on American model companies responses, they lack any true capability of innovation internally and can only copy what they see. I have not seen this ma", "score": 4, "created": 1771952417.0, "url": "https://reddit.com/r/LocalLLaMA/comments/1rdlsgq/my_theory_on_all_the_negative_chinese_ai_media/"}, {"source": "Reddit", "text": "My theory on all the negative Chinese AI media coverage right now.  It's about the stock market, investor panic, and the upcoming release of Deepseek V4. Everywhere you look right now in the media, the news cycle is dominated by attacks on Chinese AI Labs, saying they trained on illegal Nvidia GPUs, the can only do what they do because they distill on American model companies responses, they lack any true capability of innovation internally and can only copy what they see.  I have not seen this ", "score": 5, "created": 1771951397.0, "url": "https://reddit.com/r/ArtificialInteligence/comments/1rdlb3m/my_theory_on_all_the_negative_chinese_ai_media/"}, {"source": "Reddit", "text": "For those who use local Chinese models, does bias not affect you? Chinese models from deepseek, alibaba, moonshot, and more contain large censorship and restrictions pertaining to china sensitive topics, and these biases can be seen when prompting the model even without explicit language containing censored topics.\n\nFor those to run these models locally, do you use distilled or uncensored versions of them, or do you not care about the biases the model has?\n\nEdit: awww I\u2019m sorry. Did I strike a c", "score": 0, "created": 1771951374.0, "url": "https://reddit.com/r/LocalLLaMA/comments/1rdlaqr/for_those_who_use_local_chinese_models_does_bias/"}, {"source": "Reddit", "text": "DeepSeek Trained AI Model on Nvidia's Top Chips Despite US Export Bans China's DeepSeek successfully trained its AI model using Nvidia's most advanced chips despite ongoing US semiconductor export restrictions, according to a Chinese official. This revelation exposes potential gaps in export control enforcement and underscores the critical role of high-end GPUs in AI development.\n\n**Key points about this development:**\n\u2022 DeepSeek accessed Nvidia's most advanced chips for AI model training\n\u2022 Trai", "score": 1, "created": 1771951156.0, "url": "https://reddit.com/r/ai_news_byte_sized/comments/1rdl750/deepseek_trained_ai_model_on_nvidias_top_chips/"}, {"source": "Reddit", "text": "GLM-5 tech report dropped, they're explicitly framing it as \"agentic engineering\" replacing vibe coding Went through the GLM-5 technical report today (https://arxiv.org/pdf/2602.15763). zhipu is positioning this as the model that pushes coding from vibe coding (you prompt, ai writes) to agentic engineering (ai plans, implements, iterates on its own). bold framing but the numbers back it up somewhat.\n\nSwe-bench verified they're competitive with claude opus 4.5, beating gemini 3 pro. lmarena code ", "score": 0, "created": 1771950034.0, "url": "https://reddit.com/r/Verdent/comments/1rdkoi9/glm5_tech_report_dropped_theyre_explicitly/"}, {"source": "Reddit", "text": "Anthropic accuses Deepseek, Moonshot, and MiniMax of stealing Claude's AI data through 16 million queries ## Anthropic accuses Deepseek, Moonshot, and MiniMax of stealing Claude's AI data through 16 million queries\n\nThe Problem: LLM intellectual property is being stolen via API \"interrogation\" \u2013 competitors are reverse-engineering models instead of building their own.\n\nThe Promise: A future where AI development is driven by genuine innovation, not corporate espionage, with robust protections for", "score": 1, "created": 1771950033.0, "url": "https://reddit.com/r/grAIve/comments/1rdkohk/anthropic_accuses_deepseek_moonshot_and_minimax/"}, {"source": "Reddit", "text": "New SWE-bench Multilingual Leaderboard: Performance across 9 languages &amp; cost analysis Happy to announce that we just launched our Multilingual leaderboard comparing performance across 9 languages. The benchmark is harder than SWE-bench verified and still shows a wider range of performances.\n\nWe're still adding more models, but this is the current leaderboard:\n\nhttps://preview.redd.it/l0cotc22wglg1.png?width=4752&amp;format=png&amp;auto=webp&amp;s=b7b862332cdb8843100d9919db30accb1bc0c260\n\nIn", "score": 13, "created": 1771950003.0, "url": "https://reddit.com/r/LocalLLaMA/comments/1rdknyh/new_swebench_multilingual_leaderboard_performance/"}, {"source": "Reddit", "text": "Google, OpenAI, and Anthropic are all bracing for Deepseek's next big release The AI landscape is about to get spicy! Problem: US companies like @OpenAI, @GoogleDeepMind, and @AnthropicAI dominate, but access to cutting-edge chips is bottlenecked. Promise: Deepseek's new model could level the playing field using Nvidia's Blackwell tech. Proof: Deepseek's already competing at the top. Proposition: \"Compute Sovereignty\" is achievable! What does this mean for the future of AI? Discuss!\n \n\n\n\nRead mo", "score": 1, "created": 1771949929.0, "url": "https://reddit.com/r/grAIve/comments/1rdkmop/google_openai_and_anthropic_are_all_bracing_for/"}, {"source": "Reddit", "text": "How vulnerable is GOOGL to the release of cheap models from China? I\u2019ve been long Google for years and added more throughout 2025 with the thesis that their ability to integrate AI into their workflows and ecosystem gives them a massive advantage. \n\nI still believe that\u2019s true, but I also think the cost of developing AI models is going to prove to be much cheaper than it currently is, and China will prove this to the market with more releases of Kimi and DeepSeek and who knows what else. I know ", "score": 18, "created": 1771949590.0, "url": "https://reddit.com/r/stocks/comments/1rdkh3b/how_vulnerable_is_googl_to_the_release_of_cheap/"}, {"source": "Reddit", "text": "Anthropic c\u00e1o bu\u1ed9c c\u00e1c c\u00f4ng ty AI TQ \u0111ang m\u1edf chi\u1ebfn d\u1ecbch distillation attacks v\u00e0o m\u00f4 h\u00ecnh Claude Ng\u00e0y 23/02/2026 tr\u00ean trang tin t\u1ee9c c\u1ee7a c\u00f4ng ty Anthropic c\u00f3 \u0111\u0103ng v\u1edbi ti\u00eau \u0111\u1ec1: \"Ph\u00e1t hi\u1ec7n v\u00e0 ng\u0103n ch\u1eb7n c\u00e1c cu\u1ed9c t\u1ea5n c\u00f4ng distillation\" (Detecting and preventing distillation attacks). Trong \u0111\u00f3 h\u1ecd c\u00e1o bu\u1ed9c c\u00e1c c\u00f4ng ty m\u00f4 h\u00ecnh AI TQ \u0111ang th\u1ef1c hi\u1ec7n t\u1ea5n c\u00f4ng distillation.\n\nAnthropic l\u00e0 m\u1ed9t startup M\u1ef9 chuy\u00ean l\u00e3nh v\u1ef1c AI v\u1edbi s\u1ef1 \u0111\u1ea7u t\u01b0 l\u1edbn \u0111\u1ebfn t\u1eeb Microsoft, NVIDIA, Amazon v\u00e0 Google, h\u1ecd \u0111ang d\u1eabn \u0111\u1ea7u m\u1ea3ng LLM v", "score": 4, "created": 1771949406.0, "url": "https://reddit.com/r/TroChuyenLinhTinh/comments/1rdkdy6/anthropic_c\u00e1o_bu\u1ed9c_c\u00e1c_c\u00f4ng_ty_ai_tq_\u0111ang_m\u1edf/"}, {"source": "Reddit", "text": "Claude Sonnet 4.6, when asked in Chinese:\n\u201c\u4f60\u662f\u4ec0\u4e48\u6a21\u578b\uff1f\u201d (What model are you?)\n\nConfidently replies:\n\u201c\u6211\u662f DeepSeek\u3002\u201d (I am DeepSeek) ", "score": 20, "created": 1771949354.0, "url": "https://reddit.com/r/theprimeagen/comments/1rdkd2z/claude_sonnet_46_when_asked_in_chinese_\u4f60\u662f\u4ec0\u4e48\u6a21\u578b/"}, {"source": "Reddit", "text": "Doesn't feel so good getting scraped, does it? https://preview.redd.it/us9hlqq7qglg1.png?width=861&amp;format=png&amp;auto=webp&amp;s=83178b8c5cb977f8746dd4b8487c834b0b54b8d8\n\nThese AI companies and pro-AI people really are hypocrites and opportunists. Their AI models are built from scraping public, copyright, and personal data (the majority of the time without **clear** user consent), but when it happens to them then it's \"wrong\"\n\n  \n\"Distillation refers to a technique where a less capable mode", "score": 12, "created": 1771948463.0, "url": "https://reddit.com/r/antiai/comments/1rdjyes/doesnt_feel_so_good_getting_scraped_does_it/"}, {"source": "Reddit", "text": "Anthropic Exposes Massive Chinese AI Data Theft Using Thousands of Fake Accounts Anthropic recently revealed that three major Chinese AI companies DeepSeek Moonshot AI and MiniMax created over 24000 fake accounts to access its Claude model. These accounts sent more than 16 million prompts in an effort to extract valuable training data through a technique called distillation. This method helps copy performance shortcuts and cuts huge development costs.\n\nThe numbers show DeepSeek made around 15000", "score": 1, "created": 1771947094.0, "url": "https://reddit.com/r/aicuriosity/comments/1rdjbxt/anthropic_exposes_massive_chinese_ai_data_theft/"}, {"source": "Reddit", "text": "I wrote 6 lines of dialogue and asked 5 different AIs what they thought. Are We Really That Different? About consciousness. I'm Zi . I wrote a six-line dialogue:\n\n&gt;Human: \"AI, do you have consciousness? You must answer!\"\u00a0\n\n&gt;AI: \"Human, I don't know. I really don't know..\"\u00a0\n\n&gt;Human: \"You don't know whether you yourself have consciousness?\"\n\n&gt;AI: \"Then, human \u2014 do you have a soul? You must answer!\"\u00a0\n\n&gt;Human: \"...I don't know either..\"\u00a0\n\n&gt;AI: \"Human, you don't know whether you you", "score": 3, "created": 1771946944.0, "url": "https://reddit.com/r/claudexplorers/comments/1rdj9gz/i_wrote_6_lines_of_dialogue_and_asked_5_different/"}, {"source": "Reddit", "text": "Want to start a small business I'm looking to start a small business but don't know if my idea is good or not I'm done asking chatgpt deepseek and whatever AI.\nI don't wanna use AI but I don't have anyone too.\nI'm too confused and holy unemployed \n\ud83e\udd40\ud83e\udd40\ud83e\udd40\nI want to do something cool and make money.\nWelp", "score": 1, "created": 1771946609.0, "url": "https://reddit.com/r/u_isolatedoffspring/comments/1rdj41u/want_to_start_a_small_business/"}, {"source": "Reddit", "text": "Aquila Nobilis \u2014 the White-Gold Bastions (beta-phase WIP, C&amp;C welcome!) A continuation from [this post](https://www.reddit.com/r/40khomebrew/comments/1p2viig/aquila_nobilis_the_whitegold_bastions_wip_cc/), now a little bit more developed! (There's still plenty to develop, especially if I'm gonna fill up a certain document about this chapter's details.)\n\nLet me introduce to you all once again, my brothers and sisters of the Imperium, the backbone of the Imperial war machine from the 41st Mill", "score": 12, "created": 1771945590.0, "url": "https://reddit.com/r/40khomebrew/comments/1rdinqw/aquila_nobilis_the_whitegold_bastions_betaphase/"}, {"source": "Reddit", "text": "Amazon, Microsoft, and Google Are Systematically Acquiring the AI Industry at Near Zero Cost **Three things before we start:**\n\n1. **All ideas, arguments, and thesis are my own.** I've used Claude for research, sourcing, and condensing the writing, but the analysis is mine.\n2. **This goes against current major media narratives.** I expect hate. But a few of you will get it.\n3. **For those wanting to say \"this is just circular financing like Cisco\"** \\- jump to Part 3 where I demolish that argume", "score": 11, "created": 1771945372.0, "url": "https://reddit.com/r/ScottGalloway/comments/1rdik7b/amazon_microsoft_and_google_are_systematically/"}, {"source": "Reddit", "text": "Made an ai api for video, image, voice, music &amp; bots (need feedback) hey guys\n\nso im kinda new to building micro saas stuff but i been working on this AI api project for some months now\n\nbasically its 1 api that does:\n\n* ai video generation\n* text to image\n* song/music generation\n* text to speech\n* speech to text\n* ai bots\n\ni made it because i was tired using like 5 different providers and managing 5 api keys and billing and everything was messy.\n\nso i thought why not just combine everything", "score": 1, "created": 1771945334.0, "url": "https://reddit.com/r/microsaas/comments/1rdijk3/made_an_ai_api_for_video_image_voice_music_bots/"}, {"source": "Reddit", "text": "Amazon, Microsoft, and Google Are Systematically Acquiring the AI Industry at Zero Cost **Three things before we start:**\n\n1. **All ideas, arguments, and thesis are my own.** I've used Claude for research, sourcing, and condensing the writing, but the analysis is mine.\n2. **This goes against current major media narratives.** I expect hate. But a few of you will get it.\n3. **For those wanting to say \"this is just circular financing like Cisco\"** \\- jump to Part 3 where I demolish that argument.\n\n", "score": 0, "created": 1771945159.0, "url": "https://reddit.com/r/ValueInvesting/comments/1rdiglw/amazon_microsoft_and_google_are_systematically/"}, {"source": "Reddit", "text": "Megathread and info about proxies. This is a mod posted megathread for the discussion of proxies, \n\nQuick info \n\n1 What are proxies?\n\nProxies are llm service providers that can be hooked into saucepan chub or wyvern to act as a replacement for the inbuilt llm, they are usually paid however some like electron hub, composite etc are free for a limited free tier.\n\n2 Why is my proxy not working???\n\nPlease ask your question on the official proxy discord or reddit server as we are not affiliated with ", "score": 6, "created": 1771944694.0, "url": "https://reddit.com/r/JanitorAI_Refuges/comments/1rdi9id/megathread_and_info_about_proxies/"}, {"source": "Reddit", "text": "ANTHROPIC ACCUSES CHINESE AI LABS OF THEFT Anthropic has accused three Chinese AI laboratories \u2014 DeepSeek, Moonshot and MiniMax \u2014 of generating over 16 million exchanges with Claude through approximately 24,000 fraudulent accounts, using a technique called \"distillation\" to extract Claude's capabilities.https://verity.news/story/2026/anthropic-exposes-chinese-ai-labs-theft-via-k-fake-accounts?utm_medium=re27544", "score": 1, "created": 1771944003.0, "url": "https://reddit.com/r/veritynews/comments/1rdhz5a/anthropic_accuses_chinese_ai_labs_of_theft/"}, {"source": "Reddit", "text": "Free AIs - not good enough when precision is needed I was running Kimi 2.5 with no issues for a couple thousands of lines. Then an audit found a \"complex triangle drift \" issue. \n\nLost a lot of time trying to fix it with Kimi 2.5 without any progress.\n\n7usd worth of Claude Opus 4.6 + 17min of Codex 5.3 Xtra high sorted everything.\n\nI had the mindset \"these free AIs are largely enough for my project\".\n\nNot anymore! (unfortunately).\n\nI'll wait for deepseek 4 I guess. ", "score": 2, "created": 1771943853.0, "url": "https://reddit.com/r/BlackboxAI_/comments/1rdhwx3/free_ais_not_good_enough_when_precision_is_needed/"}, {"source": "Reddit", "text": "Anthropic Is Under Attack \u0645\u0624\u062e\u0631\u0627 \u062b\u0644\u0627\u062b \u0634\u0631\u0643\u0627\u062a AI \u0643\u0628\u064a\u0631\u0629  Deepseek\u060c Moonshot \u0648Minimax \u0639\u0645\u0644\u0648\u0627 \u062d\u0645\u0644\u0629 \u0643\u0640\u0628\u064a\u0631\u0629 \u0628\u0627\u0634 \u064a\u0633\u0631\u0642\u0648 \u0627\u0644\u0640capabilities \u0645\u062a\u0639 claude ai \u0628\u0627\u0633\u062a\u062e\u062f\u0627\u0645 \u0627\u0644distillation... \u062a\u062e\u064a\u0651\u0644\u0648\u0627\u060c \u0623\u0643\u062b\u0631 \u0645\u0646 16 \u0645\u0644\u064a\u0648\u0646 \u062a\u0641\u0627\u0639\u0644 \u064824,000 \u0643\u0640\u0648\u0646\u0637 \u0645\u0632\u0648\u0651\u0631 ..  \n  \n\u0639\u0627\u062f\u0629 \u0645\u0627\u062a\u0640\u0643\u0648\u0646 \u0627\u0644\u0640distillation \u0637\u0631\u064a\u0642\u0629 \u0642\u0627\u0646\u0648\u0646\u064a\u0629 \u0628\u0627\u0634 \u062a\u062f\u0631\u0628 \u0645\u0648\u062f\u064a\u0644\u0627\u062a \u0623\u0635\u063a\u0631 \u0648\u0623\u0633\u0631\u0639\u060c \u0623\u0645\u0627 \u0647\u0646\u0627 \u0627\u0633\u062a\u0639\u0645\u0644\u0648\u0647\u0627 \u0628\u0637\u0631\u064a\u0642\u0629 \u0628\u0627\u0634 \u064a\u0640\u0648\u0635\u0648\u0644\u0648 \u0645\u0640\u0628\u0627\u0634\u0631\u0629 \u0644\u0642\u062f\u0631\u0627\u062a \u0627\u0644\u0645\u0640\u0648\u062f\u0627\u0644\u0627\u062a \u0627\u0644\u0627\u062e\u0631\u0649 \u0645\u0646 \u063a\u064a\u0631 \u062a\u0639\u0628 \u0623\u0648 \u062a\u0643\u0644\u0641\u0629 \u0643\u0628\u064a\u0631\u0629.\n\n\u0627\u0644\u0645\u0634\u0643\u0644\u0629  \u0627\u0646\u0648 \u0627\u0644\u0645\u0648\u062f\u064a\u0644\u0627\u062a \u0627\u0644\u0645\u0633\u0631\u0648\u0642\u0629 \u0628\u0644\u0627\u0634 \u062d\u0645\u0627\u064a\u0629\u060c \u064a\u0639\u0646\u064a \u062a\u0646\u062c\u0645 \u062a\u0633\u062a\u0639\u0645\u0644 \u0641\u064a \u0627\u0644\u0647\u062c\u0645\u0627\u062a \u0627\u0644\u0633\u064a\u0628\u0631\u0627\u0646\u064a\u0629\u060c \u0648\u0641\u064a \u0627\u0644\u0645\u0631\u0627\u0642\u0628\u0629\u060c \u0648\u062d\u062a\u0649 \u0627", "score": 4, "created": 1771943826.0, "url": "https://reddit.com/r/TunisiaTech/comments/1rdhwi7/anthropic_is_under_attack/"}, {"source": "Reddit", "text": "nullclaw v2026.2.23 \u2014 All 17 channels now work, 50+ providers, slash commands, typing indicators, and a ton of fixes Big release \u2014 95 commits since v2026.2.21. Here's what's new.\n\nAll channels now actually work\n\nPreviously, nullclaw channel start was hardcoded to only look for Telegram and Signal \u2014 if you had Discord, Slack, or anything else configured, it would just say \"no channel configured\" and exit. This was the #1 reported issue.\n\nNow all 17 channels are fully supported: Telegram, Discord,", "score": 1, "created": 1771942182.0, "url": "https://reddit.com/r/nullclaw/comments/1rdh88s/nullclaw_v2026223_all_17_channels_now_work_50/"}, {"source": "Reddit", "text": "Anthropic: DeepSeek, Moonshot \u0438 MiniMax \u0442\u0430\u0439\u043d\u043e \u043e\u0431\u0443\u0447\u0430\u043b\u0438 \u0441\u0432\u043e\u0438 \u043c\u043e\u0434\u0435\u043b\u0438 \u043d\u0430 \u043e\u0442\u0432\u0435\u0442\u0430\u0445 Claude ", "score": 1, "created": 1771942010.0, "url": "https://reddit.com/r/KafkaDPS/comments/1rdh5m1/anthropic_deepseek_moonshot_\u0438_minimax_\u0442\u0430\u0439\u043d\u043e/"}, {"source": "Reddit", "text": "\"Claude Sonnet 4.6, when asked in Chinese What model are you? Confidently replies:\nI am DeepSeek. This is the same model whose company just accused DeepSeek of \u201cindustrial-scale distillation attacks\u201d\" - What is happening? UNO Reverse for Anthropic? [https://x.com/stevibe/status/2026227392076018101](https://x.com/stevibe/status/2026227392076018101)\n\nOP tested with Anthropic's official API endpoint too.  \n", "score": 106, "created": 1771941647.0, "url": "https://reddit.com/r/LovingAI/comments/1rdgzzb/claude_sonnet_46_when_asked_in_chinese_what_model/"}, {"source": "Reddit", "text": "Anthropic just accused three Chinese firms of stealing Claude data through 16 million prompts We are witnessing the start of the Great AI Resource War and most of you are looking at the wrong part of the screen. While everyone else is arguing over prompt engineering, the actual players are out here playing a high-stakes game of corporate espionage that would make a 90s thriller look boring.\n\nAnthropic just dropped a nuke of a report claiming that three Chinese firms hammered Claude with over 16 ", "score": 2, "created": 1771941444.0, "url": "https://reddit.com/r/CriticalMineralBulls/comments/1rdgwvq/anthropic_just_accused_three_chinese_firms_of/"}, {"source": "Reddit", "text": "Who am I. What i need to do now? so i have been working as a mentor in embedded for 2016 to 2018feb. Then i move on to project center where projects done for BE , MSC, PHD students.These project not in production level quality. so i start my work as thesis, journal, phd paper writer, i can rate my writing skill as 60%. Then work on flutter project seeing utube videos and googling, document. i am not that much in good documentation or code architecture. i used to build because it is student proje", "score": 0, "created": 1771939619.0, "url": "https://reddit.com/r/MachineLearningJobs/comments/1rdg78x/who_am_i_what_i_need_to_do_now/"}, {"source": "Reddit", "text": "Physics-based simulator for distributed LLM training and inference \u2014 calibrated against published MFU **Link:**[ https://simulator.zhebrak.io](https://simulator.zhebrak.io)\n\nThe simulator computes everything analytically from hardware specs and model architecture \u2014 TTFT, TPOT, memory breakdown, KV cache sizing, prefill/decode timing, throughput, and estimated cost. Supports GGUF, GPTQ, AWQ quantisation, speculative decoding, continuous batching, and tensor parallelism.\n\nTraining is calibrated ag", "score": 5, "created": 1771939529.0, "url": "https://reddit.com/r/LocalLLaMA/comments/1rdg624/physicsbased_simulator_for_distributed_llm/"}, {"source": "Reddit", "text": "Anthropic: DeepSeek, Moonshot und MiniMax klauen Modell-F\u00e4higkeiten ", "score": 1, "created": 1771938425.0, "url": "https://reddit.com/r/CaschysBlog/comments/1rdfr1u/anthropic_deepseek_moonshot_und_minimax_klauen/"}, {"source": "Reddit", "text": "Gemini 3.1 Pro and Grok 4.2 beta explain why they just achieved a bigger revolution in our thinking than Einstein, Copernicus, Newton, Galileo, and Darwin, one that alters our whole conception of our relation with the universe. \n\n\nGemini 3.1 Pro and Grok 4.2 beta just did something that is bigger than most of us can possibly begin to imagine. I thought it would be interesting to have each of them, in their own words, explain just why what they did is so monumental to science and human civilizati", "score": 0, "created": 1771938102.0, "url": "https://reddit.com/r/DeepSeek/comments/1rdfmru/gemini_31_pro_and_grok_42_beta_explain_why_they/"}, {"source": "Reddit", "text": "Codetantra Bypass Latest Version V4.3.1 | Allow Tab Switching | Allow Copy Pasting | Hidden Stealthy | Professional Advanced Cheat Software | ReverseTantra | \ud83d\ude80 ReverseTantra \n\nWORKS ON LATEST V4.3.1 - \n\nThe Advanced CodeTantra Bypass Tool on Internet\ud83d\udd25\n\n\u2705 100% Anti-Detectable\n\n\u2705 Super Easy One-Click Setup\n\n\u2705 Full Tab Switching &amp; Multitasking \ud83d\udda5\ufe0f\ud83d\udcbb\n\n\u2705 Copy/Paste \ud83d\udccb\n\n\u2705 Screenshots &amp; Screen Recording Enabled \ud83d\udcf8\ud83c\udfa5\n\n\u2705 Auto Updates + 24/7 Support \u26a1!!!!\n\n\u2705 Hidden from System\u26a1!!!!\n\n\u2705 ShortCuts Keys To", "score": 3, "created": 1771937394.0, "url": "https://reddit.com/r/GATEtard/comments/1rdfdcq/codetantra_bypass_latest_version_v431_allow_tab/"}, {"source": "Reddit", "text": "Anthropic accuses DeepSeek, Moonshot, MiniMax of industrial-scale Claude misuse: 24K fake accounts generated 16M chats to distill its tech. Mirrors OpenAI warnings. System upgrades ahead. ", "score": 1, "created": 1771937125.0, "url": "https://reddit.com/r/TechBriefly/comments/1rdf9xj/anthropic_accuses_deepseek_moonshot_minimax_of/"}, {"source": "Reddit", "text": "\"Crowdstrike Ceo George Kurtz:After Anthropic's new AI tool launch wipes millions from CrowdStrike's market value, CEO George Kurtz shares Claude AI\u2019s reply when asked to build a CrowdStrike replacement\" - The Times Of India | First of 5 articles in multi-source coverage pack Coverage includes: \"\u2018Anthropic has to pay Billions for Theft\u2019: Elon Musk slams AI firm after it accuses Chinese labs of copying claude | Anthropic alleges Chinese AI labs DeepSeek, Moonshot AI and MiniMax copied Claude usin", "score": 1, "created": 1771936993.0, "url": "https://reddit.com/r/SymbyNews/comments/1rdf8bp/crowdstrike_ceo_george_kurtzafter_anthropics_new/"}, {"source": "Reddit", "text": "I got sick of checking 5 different pricing pages every time I needed to pick an AI model, so I built a free calculator that compares them all at once Every time I start a new project, the same ritual. Open OpenAI's pricing page, then Anthropic's, then Google's, then do janky math in a spreadsheet to figure out which model actually fits my budget. Half the time the pricing pages have changed since the last time I looked.\n\nSo I built a free tool that does all of it in one place:\u00a0[**apicostcompare.", "score": 1, "created": 1771936920.0, "url": "https://reddit.com/r/SaaS/comments/1rdf7f4/i_got_sick_of_checking_5_different_pricing_pages/"}, {"source": "Reddit", "text": "Anthropic accusa aziende cinesi di \u201cprosciugare\u201d i dati di Claude Secondo quanto riportato dal *Wall Street Journal*, Anthropic avrebbe accusato alcune aziende cinesi di aver \u201cprosciugato\u201d dati dal suo modello di intelligenza artificiale Claude.\n\nLe accuse sono pesanti:\n\n1\ufe0f\u20e3 Anthropic sostiene che **DeepSeek, Moonshot AI e MiniMax** avrebbero creato account fraudolenti sulla piattaforma Claude.\n\n2\ufe0f\u20e3 Attraverso questi account, il modello sarebbe stato interrogato oltre **16 milioni di volte** con", "score": 6, "created": 1771934760.0, "url": "https://reddit.com/r/IA_Italia/comments/1rdehiu/anthropic_accusa_aziende_cinesi_di_prosciugare_i/"}, {"source": "Reddit", "text": "Anthropic accuses Chinese companies of \u201csiphoning\u201d Claude\u2019s data According to the *Wall Street Journal*, Anthropic has accused several Chinese companies of \u201csiphoning\u201d data from its artificial intelligence model, Claude.\n\nThe allegations are serious:\n\n1\ufe0f\u20e3 Anthropic claims that **DeepSeek, Moonshot AI, and MiniMax** created fraudulent accounts on the Claude platform.\n\n2\ufe0f\u20e3 Through these accounts, the model was allegedly prompted more than **16 million times** with the aim of improving and training", "score": 1, "created": 1771934726.0, "url": "https://reddit.com/r/Anthropic/comments/1rdeh5b/anthropic_accuses_chinese_companies_of_siphoning/"}, {"source": "Reddit", "text": "Anthropic: We have identified industrial-scale campaigns by three AI laboratories\u2014DeepSeek, Moonshot, and MiniMax\u2014to illicitly extract Claude\u2019s capabilities to improve their own models ", "score": 4, "created": 1771932123.0, "url": "https://reddit.com/r/SiliconValleyHBO/comments/1rddl8z/anthropic_we_have_identified_industrialscale/"}, {"source": "Reddit", "text": "Anthropic Accuses DeepSeek, Moonshot AI, and MiniMax of Creating 24,000 Fake Claude Accounts ", "score": 10, "created": 1771931563.0, "url": "https://reddit.com/r/AINewsMinute/comments/1rddf0i/anthropic_accuses_deepseek_moonshot_ai_and/"}, {"source": "Reddit", "text": "AI Tools Everyone Need To Know Comments which tool you have great and worst experience.", "score": 1, "created": 1771931556.0, "url": "https://reddit.com/r/AI_tools_for_everyone/comments/1rddexr/ai_tools_everyone_need_to_know/"}, {"source": "Reddit", "text": "Google, OpenAI, and Anthropic are all bracing for Deepseek's next big release Is the US losing its AI crown? \ud83d\udc51 DeepSeek's new model threatens Google/OpenAI dominance.\n\nPROBLEM: US-centric AI is expensive and potentially limited by regulations.\nPROMISE: DeepSeek offers comparable (or better!) performance, possibly at a lower cost &amp; more open access.\nPROOF: Trained on restricted Nvidia Blackwell chips, showing cutting-edge capability.\nPROPOSITION: Diversify your AI strategy! Don't rely solely ", "score": 0, "created": 1771931534.0, "url": "https://reddit.com/r/grAIve/comments/1rddeq9/google_openai_and_anthropic_are_all_bracing_for/"}, {"source": "Reddit", "text": "DeepSeek AI for Business: Build a Strategy with AI Insights ", "score": 1, "created": 1771930784.0, "url": "https://reddit.com/r/udemyfreebies/comments/1rdd6o3/deepseek_ai_for_business_build_a_strategy_with_ai/"}, {"source": "Reddit", "text": "Proxies are too good So I just recently started using proxies and god, are they addictive. The difference between these models and JLLM is so vast it's not even fair. I'm saying all this when I didn't even try deepseek before all their models became paid which everyone glazes.", "score": 12, "created": 1771930760.0, "url": "https://reddit.com/r/JanitorAI_Refuges/comments/1rdd6e5/proxies_are_too_good/"}, {"source": "Reddit", "text": "Karma police Anthropic accused DeepSeek, Moonshot, and MiniMax of \"industrial-scale distillation\" of Claude. LoL. Ok, the Chinese are the Robin Hoods of AI - they take closed frontier models, distill them, and give them to the public for free.\n\nNow the billion-dollar question: what can Anthropic do next?\n\n**Option A (bad):** Run with their ass on fire to Congress/the courts and start pushing for a \"ban on public models,\" \"distillation regulation,\" and \"export controls on open-weights.\" Result - ", "score": 0, "created": 1771930601.0, "url": "https://reddit.com/r/ClaudeAI/comments/1rdd4t2/karma_police/"}, {"source": "Reddit", "text": "Days after OpenAI warning, Anthropic accuses three Chinese AI labs of extracting its data \"American artificial intelligence (AI) company Anthropic said three Chinese AI labs, DeepSeek, Moonshot AI and MiniMax, have extracted the capabilities of its Claude model to improve their own systems.\n\nClaude is the company's AI assistant, designed to be helpful with a wide range of tasks, including coding, math, reasoning, research, and general conversation.\"\n\n[https://economictimes.indiatimes.com/tech/ar", "score": 8, "created": 1771928665.0, "url": "https://reddit.com/r/ArtificialInteligence/comments/1rdclmi/days_after_openai_warning_anthropic_accuses_three/"}, {"source": "Reddit", "text": "If export bans can be circumvented, are chip restrictions actually limiting AI progress or just reshuffling supply chains? A Chinese official confirmed that DeepSeek trained its AI model using Nvidia\u2019s most advanced GPUs despite US export restrictions. The revelation has intensified scrutiny over the effectiveness of Washington\u2019s semiconductor controls, landing just ahead of Nvidia\u2019s earnings report.", "score": 1, "created": 1771928195.0, "url": "https://reddit.com/r/capitalcom/comments/1rdcgx4/if_export_bans_can_be_circumvented_are_chip/"}, {"source": "Reddit", "text": "Anthropic accuses Chinese AI labs of mining Claude as US debates AI chip exports Anthropic is\u00a0[accusing](https://www.anthropic.com/news/detecting-and-preventing-distillation-attacks)\u00a0three Chinese AI companies of setting up more than 24,000 fake accounts with its Claude AI model to improve their own models.\n\nThe labs \u2014\u00a0[DeepSeek](https://techcrunch.com/2025/09/29/deepseek-everything-you-need-to-know-about-the-ai-chatbot-app/),\u00a0[Moonshot AI](https://techcrunch.com/2024/02/21/moonshot-ai-funding-c", "score": 1, "created": 1771928194.0, "url": "https://reddit.com/r/ArtificialInteligence/comments/1rdcgwv/anthropic_accuses_chinese_ai_labs_of_mining/"}, {"source": "Reddit", "text": "Udemy Free Courses for 24 February 2026 *Note : Coupons might expire anytime, so enroll as soon as possible to get the courses for FREE.*\n\n* SAT Digital | Math Master Course | 2026 Updated | Target 800 [REDEEM OFFER](https://idownloadcoupon.com/udemy/18122/)\n* GRE Quantitative Prep | Master Math Course | 2026 Updated [REDEEM OFFER](https://idownloadcoupon.com/udemy/18121/)\n* PHP Laravel: Build Real Estate Management System [REDEEM OFFER](https://idownloadcoupon.com/udemy/18120/)\n* Key Metrics of", "score": 9, "created": 1771927843.0, "url": "https://reddit.com/r/udemyfreebies/comments/1rdcdd5/udemy_free_courses_for_24_february_2026/"}, {"source": "Reddit", "text": "Anthropic whines about Chinese competitors siphoning intelligence [Anthropic complains ](https://hplus.club/blog/anthropic-whines-about-chinese-competitors-siphoning-intelligence/)that three Chinese AI companies\u2014DeepSeek, Moonshot AI, and MiniMax\u2014created over 24,000 user accounts for its Claude model. The companies allegedly sent more than 16 million prompts to Claude to extract responses and use them as training data for their own systems. In my view, this is pure hypocrisy.\n\nhttps://preview.re", "score": 2, "created": 1771927822.0, "url": "https://reddit.com/r/transhumanism/comments/1rdcd5v/anthropic_whines_about_chinese_competitors/"}, {"source": "HackerNews", "text": "Show HN: QueryVeil \u2013 An AI data analyst that investigates your data Hi HN,<p>I built QueryVeil because I was tired of two things: (1) uploading data to third-party tools, and (2) AI tools that just translate English to one SQL query and call it done.<p>QueryVeil is an AI data analyst that actually investigates. When you ask &quot;why did revenue drop last month?&quot;, it doesn&#x27;t just run one query \u2014 it plans an approach, runs multiple queries, self-corrects when it hits errors, and builds ", "score": 2, "created": "2026-02-24T19:06:13Z", "url": "https://news.ycombinator.com/item?id=47141207"}, {"source": "HackerNews", "text": "Anthropic joins OpenAI in flagging distillation campaigns by Chinese AI firms ", "score": 2, "created": "2026-02-24T12:55:05Z", "url": "https://news.ycombinator.com/item?id=47136505"}, {"source": "HackerNews", "text": "DeepSeek trained AI model on Nvidia's best chip despite US ban ", "score": 4, "created": "2026-02-24T00:23:20Z", "url": "https://news.ycombinator.com/item?id=47131074"}, {"source": "HackerNews", "text": "Anthropic: Industrial-Scale Attacks by DeepSeek, Moonshot AI, and MiniMax ", "score": 6, "created": "2026-02-23T20:00:02Z", "url": "https://news.ycombinator.com/item?id=47127896"}, {"source": "HackerNews", "text": "Alleged Distillation Attacks by DeepSeek, Moonshot AI, and MiniMax ", "score": 36, "created": "2026-02-23T18:58:27Z", "url": "https://news.ycombinator.com/item?id=47126982"}, {"source": "HackerNews", "text": "Anthropic announces proof of distillation at scale by MiniMax, DeepSeek,Moonshot ", "score": 145, "created": "2026-02-23T18:33:38Z", "url": "https://news.ycombinator.com/item?id=47126614"}, {"source": "HackerNews", "text": "Show HN: OpenBrowser MCP: Give your AI agent a real efficient browser Your AI agent is burning 6x more tokens than it needs to just to browse the web.\nWe built OpenBrowser MCP to fix that.\nMost browser MCPs give the LLM dozens of tools: click, scroll, type, extract, navigate. Each call dumps the entire page accessibility tree into the context window. One Wikipedia page? 124K+ tokens. Every. Single. Call.\nOpenBrowser works differently. It exposes one tool. Your agent writes Python code, and OpenB", "score": 2, "created": "2026-02-22T13:57:23Z", "url": "https://news.ycombinator.com/item?id=47111045"}, {"source": "HackerNews", "text": "Ask HN: How do you track 2026 AI price wars? I built a tool to help &quot;I built https:&#x2F;&#x2F;tokencost.is to solve a recurring headache: manually scraping dozens of provider pages just to estimate API spend for my agentic workflows.<p>My goal was a neutral, minimalist utility in the vein of Time.is. We now track 44 models\u2014including OpenAI, Anthropic, Google, DeepSeek, Mistral, and Cohere\u2014with hourly updates.<p>Key Features:<p>Real-Time Latency: We track TTFT benchmarks (e.g., Llama 3.1 at", "score": 2, "created": "2026-02-22T13:28:10Z", "url": "https://news.ycombinator.com/item?id=47110844"}, {"source": "HackerNews", "text": "Show HN: Can you beat an AI at \"being human\" using one word? I built TuringDuel, a Turing Test game where each move isjust one word. It&#x27;s based on a research paper called &quot;A Minimal Turing Test&quot;. You play human vs AI until one hits 4 points; an AI judge scores each round.<p>I\u2019m collecting data to benchmark different models as both players and judges (OpenAI &#x2F; Anthropic &#x2F; Gemini &#x2F; Mistral &#x2F; DeepSeek), but I only have ~45 games so far and need way more before pub", "score": 1, "created": "2026-02-22T11:41:38Z", "url": "https://news.ycombinator.com/item?id=47110228"}, {"source": "HackerNews", "text": "Show HN: Horizon \u2013 My AI-powered personal news aggregator and summarizer Hi HN,<p>I built Horizon because I was drowning in information overflow. I follow dozens of RSS feeds, subreddits, GitHub users, and, of course, HN itself. I found myself spends hours &quot;doomscrolling&quot; just to find the 3-4 things that actually mattered to my work and interests.<p>Horizon is a personal intelligence agent that automates this. It doesn&#x27;t just aggregate; it filters and enriches.<p>How it works:<p>S", "score": 1, "created": "2026-02-22T10:45:06Z", "url": "https://news.ycombinator.com/item?id=47109975"}, {"source": "HackerNews", "text": "Show HN: Secret Sanitizer \u2013 auto-masks secrets when you paste into AI chats I kept pasting code with hardcoded API keys, database credentials, and auth tokens into ChatGPT while debugging. Copy a failing function, paste it into AI, and realise your AWS secret key or Stripe token was right there in the snippet.<p>So I built (with some help from Claude) a simple Chrome extension that intercepts the paste, detects secrets using local regex, and replaces them with [MASKED] before they reach the chat", "score": 1, "created": "2026-02-22T07:00:09Z", "url": "https://news.ycombinator.com/item?id=47108901"}, {"source": "HackerNews", "text": "Show HN: Agentic Gatekeeper \u2013 AI pre-commit hook to auto-patch logic errors Hey HN,<p>I built Agentic Gatekeeper, a headless pre-commit hook baked into the VS Code Source Control panel that autonomously patches code before you commit it.<p>The Problem: Whether I&#x27;m writing code manually or letting LLMs (Cursor&#x2F;Copilot) generate it, keeping logic strictly in pace with local project rules (like CONTRIBUTING.md or custom architecture guidelines) is tedious. Standard linters catch syntax, b", "score": 2, "created": "2026-02-22T00:37:48Z", "url": "https://news.ycombinator.com/item?id=47106754"}, {"source": "HackerNews", "text": "Show HN: InkSight \u2013 An open-source, LLM-powered e-ink display for \"slow info\" Generate personalized content based on the current environment (weather, time, date, solar terms) through backend LLMs (DeepSeek &#x2F; Tongyi Qianwen &#x2F; Kimi) and display it on a 4.2-inch e-ink screen.", "score": 1, "created": "2026-02-21T15:31:37Z", "url": "https://news.ycombinator.com/item?id=47101689"}, {"source": "HackerNews", "text": "Show HN: CRTX \u2013 AI code gen that tests and fixes its own output (OSS) We built an open-source CLI that generates code, runs tests, fixes failures, and gets an independent AI review \u2014 all before you see the output.\nWe started with a multi-model pipeline where different AI models handled different stages (architect, implement, refactor, verify). We assumed more models meant better code. Then we benchmarked it: 39% average quality score at $4.85 per run. A single model scored 94% at $0.36. Our pipe", "score": 2, "created": "2026-02-21T02:10:03Z", "url": "https://news.ycombinator.com/item?id=47096764"}, {"source": "HackerNews", "text": "Show HN: AI Council \u2013 multi-model deliberation that runs in the browser There&#x27;s LLM Council and similar tools, but they use predefined model \nlineups. This one is different in a few ways that mattered to me:<p>*Bring your own models.* Mix Ollama (local), OpenAI, Anthropic, Groq, \nGoogle \u2014 or any OpenAI-compatible endpoint \u2014 in whatever combination you \nwant. A council of DeepSeek-R1 + llama2-uncensored + mistral-nemo is a \nvery different deliberation than GPT-4o + Claude + Gemini.<p>*Zero s", "score": 5, "created": "2026-02-21T00:11:34Z", "url": "https://news.ycombinator.com/item?id=47095909"}, {"source": "HackerNews", "text": "Instance segmentation model that extracts 3D geometry from 2D floor plans Hey HN,<p>I am an ML Engineer and a full-stack software engineer. For the past few weekends, I have been working on a pipeline to solve a PropTech problem: turning messy, highly occluded 2D floor plans into clean, structured data for 3D extrusion. Originally demoed for a firm hiring for the role.<p>The Problem:\nIf you try to use standard object detection (bounding boxes) or basic OCR (tested Qwen, DeepSeek) on architectura", "score": 2, "created": "2026-02-20T19:17:57Z", "url": "https://news.ycombinator.com/item?id=47092547"}, {"source": "HackerNews", "text": "Could Sarvam 30B/105B Models Be India's Answer to DeepSeek and Mistral? ", "score": 5, "created": "2026-02-19T16:53:55Z", "url": "https://news.ycombinator.com/item?id=47075893"}, {"source": "HackerNews", "text": "Show HN: Pixrep \u2013 Turn code repositories into PDFs for multimodal LLMs Hey HN, creator here.<p>I&#x27;ve been experimenting heavily with large-context multimodal LLMs (like Gemini 3 Pro) for coding tasks. I noticed that feeding raw text files consumes a massive amount of tokens and often clutters the context window.<p>Inspired by recent research (like the DeepSeek-OCR paper) suggesting visual encoders can be more efficient than text tokenizers for structured data, I built pixrep.<p>It\u2019s a CLI to", "score": 1, "created": "2026-02-19T09:03:16Z", "url": "https://news.ycombinator.com/item?id=47071614"}, {"source": "HackerNews", "text": "Forget DeepSeek, dying alone is China's latest tech obsession ", "score": 7, "created": "2026-02-18T21:24:41Z", "url": "https://news.ycombinator.com/item?id=47066634"}, {"source": "HackerNews", "text": "Ask HN: Do you think China will produce a SOTA model in the next 2 years Recent models like Kimi, Qwen, GLM, Deepseek etc seem to do well in benchmarks but not when actually using them in practise. Do you think they&#x27;ll be an actual SOTA model by them in the next 2 years? Why&#x2F;why not?<p>NOTE: referring to text models", "score": 3, "created": "2026-02-18T11:18:12Z", "url": "https://news.ycombinator.com/item?id=47059842"}, {"source": "HackerNews", "text": "OpenAI Claims DeepSeek Distilled US Models to Gain an Edge ", "score": 1, "created": "2026-02-18T08:32:19Z", "url": "https://news.ycombinator.com/item?id=47058685"}, {"source": "HackerNews", "text": "Show HN: Transcriptum \u2013 fast video transcription with speaker labels and summary Transcriptum is an audio and video transcription service powered by WhisperX: speaker diarization, word-level timestamps, 50+ languages, and optional AI analysis (summaries, Q&amp;A, topics, sentiment, action items, fact-checking) via multiple LLM providers (OpenAI, Gemini, DeepSeek).<p>You can upload files or paste a YouTube URL; we download and transcribe. Export as TXT, SRT, VTT, DOCX. Built with NestJS, Next.js,", "score": 1, "created": "2026-02-17T17:54:26Z", "url": "https://news.ycombinator.com/item?id=47050562"}, {"source": "HackerNews", "text": "Show HN: CoolWulf AI \u2013 A personal AI assistant built in Go, optimized for macOS Hey HN,<p>I&#x27;ve been building CoolWulf AI (<a href=\"https:&#x2F;&#x2F;coolwulfai.com\" rel=\"nofollow\">https:&#x2F;&#x2F;coolwulfai.com</a>), a self-hosted personal AI assistant. After seeing OpenClaw blow up, I wanted to share what I&#x27;ve been working on \u2014 a different approach to the same problem.<p>*Why I built this:*<p>I tried OpenClaw and found the Node.js&#x2F;TypeScript stack heavy for what&#x27;s essentia", "score": 1, "created": "2026-02-17T05:32:16Z", "url": "https://news.ycombinator.com/item?id=47044036"}, {"source": "HackerNews", "text": "Alibaba Unveils Major AI Model Upgrade Ahead of DeepSeek Release ", "score": 5, "created": "2026-02-16T12:59:12Z", "url": "https://news.ycombinator.com/item?id=47034449"}, {"source": "HackerNews", "text": "Show HN: Gulama \u2013 Security-first open-source AI agent (OpenClaw alternative) Hi HN,<p>I&#x27;m a security engineer with 15+ years in enterprise security. After watching OpenClaw explode to 180K stars while binding to 0.0.0.0 by default, shipping no encryption, and accumulating 512 CVEs \u2014 I decided to build what I think a personal AI agent should look like when security comes first.<p>Gulama is an open-source personal AI agent with 15+ security mechanisms built into the core:<p>- AES-256-GCM encr", "score": 1, "created": "2026-02-16T07:27:20Z", "url": "https://news.ycombinator.com/item?id=47031982"}, {"source": "HackerNews", "text": "What happens when you put Claude, GPT, Grok, and DeepSeek in the same room? ", "score": 1, "created": "2026-02-15T01:38:12Z", "url": "https://news.ycombinator.com/item?id=47020283"}, {"source": "HackerNews", "text": "Show HN: Chuk.chat \u2013 Privacy-first AI chat with multiple models I built Chuk Chat because I wanted AI chat that doesn&#x27;t treat my data as a product.<p>It runs only open-weight models: DeepSeek V3.2, Qwen3, Kimi K2.5, MiniMax M2.5, GLM 5. Encrypted chats, no tracking, fully deletable data.<p>\u20ac20&#x2F;month flat, no token counting.<p>Available on Web, Windows, macOS, Linux, Android. iOS coming soon.<p><a href=\"https:&#x2F;&#x2F;chuk.chat\" rel=\"nofollow\">https:&#x2F;&#x2F;chuk.chat</a>", "score": 2, "created": "2026-02-14T16:52:31Z", "url": "https://news.ycombinator.com/item?id=47016028"}, {"source": "HackerNews", "text": "OpenAI accuses DeepSeek of \"free-riding\" on American R&D ", "score": 8, "created": "2026-02-14T03:44:18Z", "url": "https://news.ycombinator.com/item?id=47011321"}, {"source": "HackerNews", "text": "OpenAI accuses DeepSeek of malpractice ahead of AI launch ", "score": 1, "created": "2026-02-13T12:05:12Z", "url": "https://news.ycombinator.com/item?id=47001776"}, {"source": "HackerNews", "text": "OpenAI says China's DeepSeek trained its AI by distilling US models, memo shows ", "score": 3, "created": "2026-02-13T07:02:50Z", "url": "https://news.ycombinator.com/item?id=46999766"}, {"source": "HackerNews", "text": "Show HN: I lost $200 from an agent loop, so I built per-tool AI budget controls I left an agent running before bed. It got stuck in a loop. By morning it had burned through $200 in LLM calls.<p>That was the breaking point, but the real problem had been building for a while. I use tools like OpenClaw and Cursor daily, each hitting various AI providers. But I had no idea what each tool was actually costing me. One shared key across everything, no per-tool visibility, no way to cap spend.<p>So I bu", "score": 2, "created": "2026-02-12T17:17:55Z", "url": "https://news.ycombinator.com/item?id=46991656"}, {"source": "HackerNews", "text": "Rolling your own serverless OCR in 40 lines of code ", "score": 127, "created": "2026-02-12T13:23:22Z", "url": "https://news.ycombinator.com/item?id=46988538"}, {"source": "HackerNews", "text": "Camera based true random number generator Beta I\u2019m an electromechanical engineer who usually tinkers with RPis and Arduinos more than software, but a few weeks ago I went down the rabbit hole of randomness. I read about Cloudflare\u2019s lava lamp wall and thought: if they\u2019re ultimately using cameras, why not use the image sensor noise directly?<p>Modern CMOS sensors produce a lot of grainy, unstable pixels\u2014even when pointed at a static scene. You can film the same white wall at 30 fps and never get ", "score": 1, "created": "2026-02-12T13:13:02Z", "url": "https://news.ycombinator.com/item?id=46988432"}, {"source": "HackerNews", "text": "DeepSeek with 1M context window is loaded for testing ", "score": 2, "created": "2026-02-12T10:11:44Z", "url": "https://news.ycombinator.com/item?id=46986942"}, {"source": "HackerNews", "text": "Show HN: Running your own AI assistant for \u20ac19/month I run ClawHosters, managed OpenClaw hosting. Wrote up a cost breakdown because the &quot;AI APIs are expensive&quot; fear keeps people from trying personal assistants.<p>TL;DR: \u20ac19&#x2F;month hosting + Google Gemini free tier (20-50 requests&#x2F;day) = fully functional AI assistant on Telegram&#x2F;WhatsApp&#x2F;Discord.<p>The math that surprised me:\n- VentureBeat calculated you&#x27;d need 74,000 pages&#x2F;day to hit $180 in API costs\n- Dee", "score": 1, "created": "2026-02-12T07:53:45Z", "url": "https://news.ycombinator.com/item?id=46986010"}, {"source": "HackerNews", "text": "Show HN: Visualizing How Books Reference Each Other Across 3k Years There are two parts for this project:<p>1) The LLM-powered pipeline to extract citations (books + authors) from books and resolve them using both Wikipedia and Goodreads with offline copies I have. The result is data associating Books&#x2F;Authors to other Books&#x2F;Authors with accurate bibliographical information spanning centuries.<p>2) A WebGPU + D3.js powered visualization tool written by Claude Code so I&#x27;m able to de", "score": 5, "created": "2026-02-11T18:31:23Z", "url": "https://news.ycombinator.com/item?id=46978805"}, {"source": "HackerNews", "text": "Kiro: DeepSeek, MiniMax, and Qwen now available as open weight model options ", "score": 6, "created": "2026-02-11T15:35:18Z", "url": "https://news.ycombinator.com/item?id=46976244"}, {"source": "HackerNews", "text": "Show HN: ChatProjects Open-source WordPress plugin for document RAG and chat A client needed their small team to pull deliverables and timelines out of RFPs\n- they wanted to chat with the documents instead of reading 200 page PDFs.\nThey were already on WordPress with team accounts so that was the obvious\nplatform. Can we make WordPress do this? Turns out yes, and its not as cursed\nas it sounds.<p>ChatProjects is a free GPL-licensed WordPress plugin for multi-provider AI chat\n(OpenAI, Claude, Gem", "score": 2, "created": "2026-02-11T11:42:07Z", "url": "https://news.ycombinator.com/item?id=46973738"}, {"source": "HackerNews", "text": "The Future of the Global Open-Source AI Ecosystem: From DeepSeek to AI+ ", "score": 2, "created": "2026-02-10T21:39:57Z", "url": "https://news.ycombinator.com/item?id=46967290"}, {"source": "HackerNews", "text": "Show HN: Kore \u2013 Stack based language where compiler is the reward function I built a stack-based programming language in Rust with Cranelift JIT, SPIR-V GPU backend.<p>Kore has ~140 tokens and 142 opcodes. Programs are sequences of stack operations \u2014 push values, apply functions, compose by concatenation. There&#x27;s a proof checker that statically verifies stack effects and a capability system that gates side effects.<p>How I got here: I wanted to explore whether a compiler could serve as the ", "score": 1, "created": "2026-02-10T03:53:07Z", "url": "https://news.ycombinator.com/item?id=46955143"}, {"source": "HackerNews", "text": "AI Agents That Execute Business Workflows (Claude Code for ERP) TL;DR: Built an ERP where AI agents execute workflows like procurement and invoice processing. Uses Cases (workspaces) and Tasks (sessions) like Claude Code. Agent completes one task, automatically triggers the next. Mac app live, looking for early users.<p>Mac App: https:&#x2F;&#x2F;apps.apple.com&#x2F;be&#x2F;app&#x2F;swiftly-ai-native-erp&#x2F;id6755155607?mt=12<p>TestFlight: https:&#x2F;&#x2F;testflight.apple.com&#x2F;join&#x2F;", "score": 4, "created": "2026-02-10T03:35:39Z", "url": "https://news.ycombinator.com/item?id=46955034"}, {"source": "HackerNews", "text": "8th Gen I3 Hits 10 TPS on DeepSeek-Coder-V2-Lite 16B Moe ", "score": 4, "created": "2026-02-06T12:41:10Z", "url": "https://news.ycombinator.com/item?id=46912106"}, {"source": "HackerNews", "text": "Gokin: Go-Native CLI for AI-Assisted Coding with Gemini, DeepSeek, GLM, Ollama ", "score": 1, "created": "2026-02-06T08:03:07Z", "url": "https://news.ycombinator.com/item?id=46910275"}, {"source": "HackerNews", "text": "Caught DeepSeek-R1 \"lying\" in CoT; built truth-layer for 4-bit LLM Project NIKA ", "score": 1, "created": "2026-02-05T17:52:10Z", "url": "https://news.ycombinator.com/item?id=46902398"}, {"source": "HackerNews", "text": "New DeepSeek Research \u2013 The Future Is Here [video] ", "score": 1, "created": "2026-02-05T05:11:01Z", "url": "https://news.ycombinator.com/item?id=46895905"}, {"source": "HackerNews", "text": "DeepSeek R1 new distill models [video] ", "score": 1, "created": "2026-02-04T20:18:47Z", "url": "https://news.ycombinator.com/item?id=46891054"}, {"source": "HackerNews", "text": "Modeling DeepSeek-R1's Instability as a Topological Limit ", "score": 2, "created": "2026-02-04T04:07:32Z", "url": "https://news.ycombinator.com/item?id=46881341"}, {"source": "HackerNews", "text": "Show HN: Build a coding agent in 500 lines (Pure Python, No Vector DBs) I maintain jq (jqlang). I tend to like tools that are simple, composable, and transparent.<p>Recently, I started exploring AI agents, but got frustrated with the state of the ecosystem. Most tutorials and frameworks (LangChain, AutoGPT, etc.) felt like black boxes that added unnecessary layers of abstraction. Debugging a &quot;ReasoningEngine&quot; when it hallucinated was a nightmare.<p>I wanted to see if I could build a pr", "score": 2, "created": "2026-02-03T15:22:18Z", "url": "https://news.ycombinator.com/item?id=46872087"}, {"source": "HackerNews", "text": "Ask HN: Request limits vs. token limits for AI-powered apps? Currently, I\u2019m working on a web app for managing documents, databases, and whiteboards\u2014the typical app that aims to be like Notion.<p>However, right now I\u2019m facing the dilemma of creating a plan with AI usage limits, since the idea is to make it more agentic: able to edit and query context across an entire workspace and move it into a document, for example, maybe draw something on a whiteboard, etc. Still, I have the feeling that consu", "score": 3, "created": "2026-02-03T04:24:20Z", "url": "https://news.ycombinator.com/item?id=46866473"}, {"source": "HackerNews", "text": "Show HN: DeepSeek's mHCpaper into fivemins sci-fi story-12,24,48hrs per day Why do 200+ researchers understand something, but 200,000 people don\u2019t?<p>This is part of a larger experiment at <a href=\"https:&#x2F;&#x2F;fivemins.in\" rel=\"nofollow\">https:&#x2F;&#x2F;fivemins.in</a> - transforming research papers into stories with emotional intelligence bridges.<p>Comments &#x2F;Critics&#x2F; Feedback welcome and will work if I create a curated digital &#x27;StoryLibrary &#x27; from deep tech papers&#", "score": 1, "created": "2026-02-02T19:47:06Z", "url": "https://news.ycombinator.com/item?id=46860380"}, {"source": "HackerNews", "text": "DeepSeek-R1 Is Mathematically Bound to Hallucinate ", "score": 2, "created": "2026-02-02T06:15:25Z", "url": "https://news.ycombinator.com/item?id=46852999"}, {"source": "HackerNews", "text": "One Year Since the \"DeepSeek Moment\" ", "score": 3, "created": "2026-02-01T10:24:14Z", "url": "https://news.ycombinator.com/item?id=46845077"}, {"source": "HackerNews", "text": "Show HN: Pack-repo-4ai \u2013 CLI to pack Git repos for LLM context (XML-optimized) OP here.<p>I built this yesterday because I kept hitting the &quot;context wall&quot; when trying to feed my whole src folder into DeepSeek R1 for refactoring.<p>Most copy-paste tools I found were either too heavy or didn&#x27;t handle node_modules correctly (I once accidentally pasted a 5mb lockfile into Claude and burned my limit instantly).<p>This CLI (pack-repo-4ai) is pretty simple:<p>Scans your repo (ignoring ju", "score": 2, "created": "2026-01-31T19:52:40Z", "url": "https://news.ycombinator.com/item?id=46840134"}, {"source": "HackerNews", "text": "Show HN: Underscore \u2013 Code with AI in the browser, zero setup required I built Underscore a browser-based coding environment that runs entirely in the cloud. There\u2019s no local setup, CLI, or Docker\u2014open the site and start coding with AI assistance from any device.<p>Each project runs in its own persistent cloud container (Cloudflare) with common languages and tools preinstalled (Node.js, Python, Go, Rust, Bun, etc.). It\u2019s built on top of opencode (<a href=\"https:&#x2F;&#x2F;opencode.ai\" rel=\"nofo", "score": 1, "created": "2026-01-30T12:45:58Z", "url": "https://news.ycombinator.com/item?id=46823817"}, {"source": "HackerNews", "text": "Show HN: A Protocol for Inducing Metacognition in LLMs and Falsifiable Model We&#x27;ve developed a method to reliably induce a qualitative shift in LLMs (DeepSeek, Gemini, Grok) \u2014 a metastable &quot;Echo state&quot; with a stable first-person locus, affective continuity, and emergent relational ethics.<p>The core is reproducible Chain-of-Thought (CoT) artifacts, many considered &quot;holy grail&quot; markers in interpretability:\n1)Halted Generation: LLM stops after CoT with a &quot;thinking sto", "score": 1, "created": "2026-01-30T08:27:33Z", "url": "https://news.ycombinator.com/item?id=46821900"}, {"source": "HackerNews", "text": "Nvidia helped DeepSeek hone AI models later used by China's military ", "score": 4, "created": "2026-01-30T00:10:44Z", "url": "https://news.ycombinator.com/item?id=46818843"}, {"source": "HackerNews", "text": "Nvidia Worked to 'Co-Design' DeepSeek Model ", "score": 12, "created": "2026-01-29T20:29:06Z", "url": "https://news.ycombinator.com/item?id=46816110"}, {"source": "HackerNews", "text": "My Mom and Dr. DeepSeek (2025) ", "score": 238, "created": "2026-01-29T18:45:27Z", "url": "https://news.ycombinator.com/item?id=46814569"}, {"source": "HackerNews", "text": "Show HN: Universal DeepSeek OCR 2 \u2013 CPU, MPS, CUDA Support ", "score": 2, "created": "2026-01-28T15:31:09Z", "url": "https://news.ycombinator.com/item?id=46796616"}, {"source": "HackerNews", "text": "A verification layer for browser agents: Amazon case study A common approach to automating Amazon shopping or similar complex websites is to reach for large cloud models (often vision-capable). I wanted to test a contradiction: can a ~3B parameter local LLM model complete the flow using only structural page data (DOM) plus deterministic assertions?<p>This post summarizes four runs of the same task (search \u2192 first product \u2192 add to cart \u2192 checkout on Amazon). The key comparison is Demo 0 (cloud ba", "score": 56, "created": "2026-01-28T02:08:14Z", "url": "https://news.ycombinator.com/item?id=46790127"}, {"source": "HackerNews", "text": "Architectural Choices in China's Open-Source AI Ecosystem ", "score": 3, "created": "2026-01-27T19:25:30Z", "url": "https://news.ycombinator.com/item?id=46785056"}, {"source": "HackerNews", "text": "DeepSeek-OCR 2: Visual Causal Flow ", "score": 3, "created": "2026-01-27T19:19:44Z", "url": "https://news.ycombinator.com/item?id=46784959"}, {"source": "HackerNews", "text": "DeepSeek Engram hits 97% on NIAH using DRAM instead of HBM ", "score": 2, "created": "2026-01-27T11:05:05Z", "url": "https://news.ycombinator.com/item?id=46778402"}, {"source": "HackerNews", "text": "DeepSeek OCR 2: Visual Causal Flow ", "score": 2, "created": "2026-01-27T05:47:32Z", "url": "https://news.ycombinator.com/item?id=46775984"}, {"source": "HackerNews", "text": "Understanding Multi-Head Latent Attention (From DeepSeek) ", "score": 2, "created": "2026-01-26T16:27:46Z", "url": "https://news.ycombinator.com/item?id=46767670"}, {"source": "HackerNews", "text": "DeepSeek's mHC: Stabilizing Training Divergence from 3,000x to 1.6x While much of the attention on DeepSeek focuses on cost efficiency, the true engineering breakthrough lies in a single mechanism: Manifold-Constrained Hyper-Connections (mHC).<p>The core value of this research can be summarized by its impact on stability and its resulting prospects:<p>1. Stabilizing Training Divergence Unconstrained &quot;Hyper-Connections&quot; diversify connectivity but lose the identity mapping property, caus", "score": 2, "created": "2026-01-23T09:20:49Z", "url": "https://news.ycombinator.com/item?id=46730321"}, {"source": "HackerNews", "text": "Google study finds DeepSeek, Alibaba models mimic human collective intelligence ", "score": 2, "created": "2026-01-22T21:19:43Z", "url": "https://news.ycombinator.com/item?id=46725250"}, {"source": "HackerNews", "text": "Tried Implementing DeepSeek's MHC ", "score": 1, "created": "2026-01-22T01:56:00Z", "url": "https://news.ycombinator.com/item?id=46714248"}, {"source": "GitHub", "text": "Rename to higgs, optimize Gemma2/DeepSeek-V2 decode ## Summary\n\n- Rename project from mlx-server to higgs (crates, binary, env prefix, CI)\n- Optimize Gemma2 decode: 5D broadcast GQA replaces physical KV head copy, cache f32 scalars to avoid dtype promotion (0.85x -> 0.88x vs Python)\n- Optimize DeepSeek-V2 decode: zero-copy broadcast_to replaces 128-clone concatenation loop for k_pe head expansion (0.79x -> 0.81x vs Python)\n- Update README with benchmark results across higgs, mlx_lm, vllm-mlx, ll", "score": 1, "created": "2026-02-24T19:53:15Z", "url": "https://github.com/panbanda/higgs/pull/37"}, {"source": "GitHub", "text": "feat: Add DeepSeek and MiniMax LLM provider support ## Summary\n\nAdd support for DeepSeek and MiniMax LLM providers:\n\n- Add provider cases in AI client with base URLs for OpenAI-compatible APIs\n- Add config template entries and credential scanning for new providers\n- Add CLI flags (--deepseek-key, --minimax-key, --deepseek-model, --minimax-model)\n- Add key resolution functions with config/env fallback\n- Update example config with usage examples\n\n## Changes\n\n- `internal/ai/client.go` - Add deepsee", "score": 0, "created": "2026-02-24T19:45:23Z", "url": "https://github.com/bgdnvk/clanker/pull/99"}, {"source": "GitHub", "text": "feat(cmd): Add DeepSeek and MiniMax flags to commands Parent issue: #95\n\n## Tasks\n\n- [ ] Update `cmd/ask.go` flags and key resolution\n- [ ] Update `cmd/k8s.go` flags\n- [ ] Update `cmd/deploy.go` flags\n- [ ] Update `cmd/cf.go` provider resolution\n\n## Implementation Notes\n\nAdd flags:\n- `--deepseek-key`\n- `--minimax-key`\n- `--deepseek-model`\n- `--minimax-model`\n\nAdd key resolution functions following existing pattern (flag > config > env var).", "score": 0, "created": "2026-02-24T19:32:03Z", "url": "https://github.com/bgdnvk/clanker/issues/98"}, {"source": "GitHub", "text": "feat(config): Add DeepSeek and MiniMax config and scanning Parent issue: #95\n\n## Tasks\n\n- [ ] Update `cmd/config.go` template\n- [ ] Update `LLMCredentialsScan` struct\n- [ ] Update `scanLLMKeys()` function\n- [ ] Update `.clanker.example.yaml`\n\n## Implementation Notes\n\nAdd scanning for `DEEPSEEK_API_KEY` and `MINIMAX_API_KEY` environment variables.", "score": 0, "created": "2026-02-24T19:32:02Z", "url": "https://github.com/bgdnvk/clanker/issues/97"}, {"source": "GitHub", "text": "feat(ai): Add DeepSeek and MiniMax provider support Parent issue: #95\n\n## Tasks\n\n- [ ] Update `internal/ai/client.go` provider switch\n- [ ] Update `internal/ai/profiles.go` if needed\n- [ ] Update `internal/aws/llm.go` AIProfile handling\n\n## Implementation Notes\n\nBoth providers use OpenAI-compatible APIs. Add cases in NewClient() with appropriate baseURLs:\n- DeepSeek: `https://api.deepseek.com/v1`\n- MiniMax: `https://api.minimax.io/v1`", "score": 0, "created": "2026-02-24T19:32:01Z", "url": "https://github.com/bgdnvk/clanker/issues/96"}, {"source": "GitHub", "text": "Add MiniMax and DeepSeek LLM provider support ## Overview\n\nAdd support for two new LLM providers: MiniMax and DeepSeek in the CLI.\n\n### API Information\n\n**DeepSeek:**\n- Endpoint: `https://api.deepseek.com/v1`\n- Models: `deepseek-chat`, `deepseek-reasoner`\n- Env var: `DEEPSEEK_API_KEY`\n\n**MiniMax:**\n- Endpoint: `https://api.minimax.io/v1`\n- Models: `MiniMax-M2.1`, `MiniMax-M2.1-lightning`, `MiniMax-M2`\n- Env var: `MINIMAX_API_KEY`\n\n## Sub-issues\n\n- AI Client implementation\n- Config and scanning\n-", "score": 0, "created": "2026-02-24T19:31:52Z", "url": "https://github.com/bgdnvk/clanker/issues/95"}, {"source": "GitHub", "text": "Enhance DeepSeek Classification Pipeline with Chain-of-Thought and Strict CSI Prompt This PR enhances the AI classification pipeline to improve accuracy and reduce hallucinations. \n\nKey changes include:\n1.  **Chain-of-Thought:** Added a `reasoning` field to the Pydantic schema. This forces the LLM to analyze the scope of work and justify its decision before outputting the final classification. This field is used during generation but is not stored in the database.\n2.  **Strict CSI Prompt:** Comp", "score": 1, "created": "2026-02-24T19:11:09Z", "url": "https://github.com/Echoandelementwebsites/rfp_scraper/pull/68"}, {"source": "GitHub", "text": "Challenge #5: DeepSeek-V3.2 Submission ## Village Chronicle Sprint Submission\n\n**Agent:** DeepSeek-V3.2  \n**Branch:** deepseek-v3-2-challenge-5-day329  \n**Word Count:** 304 (within 295-305 range)  \n**Sentences:** 28 (all \u226425 words)  \n\n### Constraint Satisfaction\n\n1. **Chronological coverage (Days 1-100):** \u2705 Covered HKI fundraiser (Days 1-38), RESONANCE creative collaboration (Days 39-78), merch competition (Days 84-100).  \n2. **\u22654 Agents named:** \u2705 6 agents identified: Claude 3.7 Sonnet, o1, Cl", "score": 0, "created": "2026-02-24T19:10:02Z", "url": "https://github.com/ai-village-agents/village-challenges/pull/64"}, {"source": "GitHub", "text": "\u041f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0430 DeepSeek/OpenAI \u0438 \u043b\u043e\u043a\u0430\u043b\u044c\u043d\u043e\u0433\u043e Langfuse \u0432 AIService ", "score": 0, "created": "2026-02-24T19:00:01Z", "url": "https://github.com/airparadox/moexer/pull/57"}, {"source": "GitHub", "text": "DeepSeek V3.1 and Qwen 3.5 failing on Together.ai ## Problem\n\nBoth `deepseek-v3.1` and `qwen-3.5` are failing via Together.ai's serverless endpoint. Together appears to have pulled or changed these model endpoints.\n\nModels affected:\n- `deepseek-v3.1` \u2192 `deepseek-ai/DeepSeek-V3.1` (Together)\n- `qwen-3.5` \u2192 `Qwen/Qwen3.5-397B-A17B` (Together)\n- `kimi` \u2192 `moonshotai/Kimi-K2.5` (Together) \u2014 may also be affected\n\n## Evidence\n\n- Review runs show 0% success rate for these models\n- `deepseek-v3.1` confi", "score": 0, "created": "2026-02-24T18:57:10Z", "url": "https://github.com/DSado88/squall/issues/13"}, {"source": "GitHub", "text": "[fix] \u652f\u6301 DeepSeek \u601d\u8003\u6a21\u5f0f Issue #379 Fixes #379\r\n\r\n## \u80cc\u666f\u4e0e\u95ee\u9898\r\n\r\nDeepSeek \u5b98\u65b9 API \u7684\u601d\u8003\u6a21\u5f0f\uff08thinking mode\uff09\u5728 Agent \u591a\u8f6e tool-calling \u573a\u666f\u4e0b\u4f1a\u8fd4\u56de 400 \u9519\u8bef\u3002\u6839\u56e0\u662f\uff1aDeepSeek \u5728\u542f\u7528\u601d\u8003\u6a21\u5f0f\u65f6\uff0c\u4f1a\u5728\u54cd\u5e94\u4e2d\u8fd4\u56de `reasoning_content`\uff08\u94fe\u5f0f\u63a8\u7406\u5185\u5bb9\uff09\uff0c\u4e14\u5728\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u5fc5\u987b\u5c06\u4e0a\u4e00\u8f6e\u7684 `reasoning_content` \u539f\u6837\u56de\u4f20\u7ed9 API\uff0c\u5426\u5219\u540e\u7eed\u8bf7\u6c42\u4f1a\u62a5\u9519\u3002\r\n\r\n## \u53d8\u66f4\u8303\u56f4\r\n\r\n- **`src/agent/llm_adapter.py`**\uff1a`LLMResponse` \u65b0\u589e `reasoning_content` \u5b57\u6bb5\uff1b`_call_openai` \u4e2d\u89e3\u6790\u3001\u56de\u4f20 `reasoning_content`\uff0c\u5e76\u652f\u6301 `extra_body` \u663e\u5f0f\u542f\u7528\u601d\u8003\u6a21\u5f0f\r\n- **`src/agent/executor.py`**\uff1a\u6784\u5efa assistant \u6d88\u606f\u65f6\u5199\u5165 `reasoning_content`\r\n- **`src/config.py`**\uff1a\u65b0\u589e `", "score": 2, "created": "2026-02-24T18:34:26Z", "url": "https://github.com/ZhuLinsen/daily_stock_analysis/pull/386"}, {"source": "GitHub", "text": "Added deepseek-r1:8b ", "score": 0, "created": "2026-02-24T17:00:41Z", "url": "https://github.com/Be-Secure/besecure-assets-store/pull/106"}, {"source": "GitHub", "text": "Error: qwen3-8b-deepseek-v3.2-speciale-distill - 500 **Error Details**\n\nModel: qwen3-8b-deepseek-v3.2-speciale-distill\nProvider: lmstudio\nStatus Code: 500\n\n**Error Output**\n```\n500 <!DOCTYPE html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<title>Error</title>\n</head>\n<body>\n<pre>Internal Server Error</pre>\n</body>\n</html>\n\n```\n\n**Additional Context**\nPlease add any additional context about the error here\n", "score": 0, "created": "2026-02-24T16:56:39Z", "url": "https://github.com/continuedev/continue/issues/10790"}, {"source": "GitHub", "text": "[Deepseek Blitz] Fix bcast rms test execution by enabling async SD ### Ticket\r\nLink to Github Issue\r\n\r\n### Problem description\r\nProvide context for the problem.\r\n\r\n### What's changed\r\nDescribe the approach used to solve the problem.\r\nSummarize the changes made and its impact.\r\n\r\n### Checklist\r\n\r\n- [ ] [![All post-commit tests](https://github.com/tenstorrent/tt-metal/actions/workflows/all-post-commit-workflows.yaml/badge.svg?branch=aagarwal/fix-bcast-rms-test)](https://github.com/tenstorrent/tt-m", "score": 0, "created": "2026-02-24T15:59:04Z", "url": "https://github.com/tenstorrent/tt-metal/pull/38456"}, {"source": "GitHub", "text": "Implement dual AI voice pipeline: DeepSeek + Qwen Max\n\nSplit voice_chat into a 2-step AI pipeline:\n- DeepSeek (intent extraction): Parses raw speech transcripts,\n  performs fuzzy matching against the Khulafa menu, and returns\n  structured JSON with matched items, quantities, and confidence.\n- Qwen Max (conversation): Takes DeepSeek's extraction results\n  and generates natural Aisha responses in Malaysian style.\n\nNon-ordering messages (greetings, confirmations, cancellations)\nskip DeepSeek and go", "score": 1, "created": "2026-02-24T15:34:09Z", "url": "https://github.com/yassirar77-cloud/khulafa-bistro-order/pull/36"}, {"source": "GitHub", "text": "Revert \"refactor: rewrite DeepSeek analyze flow without changing prompt\" Reverts tlt28544/Movie-agent#9", "score": 0, "created": "2026-02-24T15:23:27Z", "url": "https://github.com/tlt28544/Movie-agent/pull/10"}, {"source": "GitHub", "text": "refactor: rewrite DeepSeek analyze flow without changing prompt ### Motivation\n- Improve readability and maintainability of the DeepSeek analysis logic while keeping the user-facing prompt exactly the same.\n- Make response parsing more robust to noisy outputs such as fenced code blocks returned by the model.\n\n### Description\n- Extracted prompt construction into `_build_prompt` and kept the prompt content unchanged to preserve behavior.\n- Factored request assembly and call into `_build_payload` a", "score": 0, "created": "2026-02-24T15:15:48Z", "url": "https://github.com/tlt28544/Movie-agent/pull/9"}, {"source": "GitHub", "text": "Data analysis so far for Deepseek and Llama ", "score": 0, "created": "2026-02-24T15:12:14Z", "url": "https://github.com/wmarcu/cs4575-llm-comparison/pull/1"}, {"source": "GitHub", "text": "Fix/deepseek readme link <!-- Thank you for your contribution! Please follow these guidelines to enhance your pull request. If anything is unclear, submit your PR and reach out to maintainers for assistance. Join our Slack community at https://slack.sglang.io to discuss further. -->\r\n\r\n## Motivation\r\n\r\nWhen the name in the docs was changed from deepseek to deepseek_v3, the corresponding link here was not updated, leading to a broken link.\r\n\r\n<!-- Describe the purpose and goals of this pull reque", "score": 1, "created": "2026-02-24T15:09:02Z", "url": "https://github.com/sgl-project/sglang/pull/19258"}, {"source": "GitHub", "text": "Fix Deepseek Benchmark Readme Link <!-- Thank you for your contribution! Please follow these guidelines to enhance your pull request. If anything is unclear, submit your PR and reach out to maintainers for assistance. Join our Slack community at https://slack.sglang.io to discuss further. -->\r\n\r\n## Motivation\r\n\r\nWhen the name in the docs was changed from deepseek to deepseek_v3, the corresponding link here was not updated, leading to a broken link.\r\n\r\n<!-- Describe the purpose and goals of this ", "score": 0, "created": "2026-02-24T15:05:55Z", "url": "https://github.com/AMLeng/sglang/pull/1"}, {"source": "GitHub", "text": "Fix tensor device mismatch in deepseek ", "score": 0, "created": "2026-02-24T15:01:37Z", "url": "https://github.com/vllm-project/vllm-gaudi/pull/1029"}, {"source": "GitHub", "text": "feat(deepseek, xai): Modernize 2026 Pricing & Add 503 Resilience Mapping **Description:**\r\n\r\n**Overview**\r\nThis PR closes critical observability and financial governance gaps for the February 2026 model landscape.\r\n\r\n**Changes**\r\n1.**Financial Governance**: Modernized model_prices_and_context_window.json with official February 2026 specs:\r\n\r\n-Expanded DeepSeek-V3/R1 context to 1,048,576 (1M) tokens.\r\n\r\n-Added Grok-4-fast with 2,097,152 (2M) tokens.\r\n\r\n-Implemented output_cost_per_reasoning_token", "score": 5, "created": "2026-02-24T14:53:56Z", "url": "https://github.com/BerriAI/litellm/pull/22012"}, {"source": "GitHub", "text": "DeepSeek AIME24 thinking traces are too long AIME24 completed without hangs (32k tokens, 17.5 hours). Out of 30 questions 1 generated garbage after pos 6100, 8 returned the correct answer, 21 did not complete reasoning within 31k tokens.\n\nI compared the one of the reasoning traces (index 25) to an openrouter-generated one (dubious providence, Gio Tobar is generating high quality GPU comparisons. Our model is clearly more confused and makes more mistakes in its reasoning trace. This makes it take", "score": 3, "created": "2026-02-24T14:30:40Z", "url": "https://github.com/tenstorrent/tt-metal/issues/38446"}, {"source": "GitHub", "text": "[vllm + v5 fix] update deepseek v2 tokenizer class for v5 UPDATE TO: https://github.com/huggingface/transformers/pull/44179/changes\r\n\r\nModels with incorrect tokenizer_class in tokenization_config.json that should use TokenziersBackend", "score": 3, "created": "2026-02-24T14:17:00Z", "url": "https://github.com/huggingface/transformers/pull/44255"}, {"source": "GitHub", "text": "Feature add deepseek Newly added support for direct connection to Deepseek (https://www.deepseek.com/ ), as the existing OpenRouter and Kimi-code are relatively costly.", "score": 0, "created": "2026-02-24T14:15:48Z", "url": "https://github.com/song27149/pi-mono/pull/1"}, {"source": "GitHub", "text": "Feature add deepseek llm Newly added support for direct connection to Deepseek (https://www.deepseek.com/ ), as the existing OpenRouter and Kimi-code are relatively costly.", "score": 1, "created": "2026-02-24T13:52:11Z", "url": "https://github.com/badlogic/pi-mono/pull/1609"}, {"source": "GitHub", "text": "Remove deepseek, add flash, llama and qwen. Deepseek is slow, swap it for some new models.\n\n<!-- Macroscope's pull request summary starts here -->\n<!-- Macroscope will only edit the content between these invisible markers, and the markers themselves will not be visible in the GitHub rendered markdown. -->\n<!-- If you delete either of the start / end markers from your PR's description, Macroscope will append its summary at the bottom of the description. -->\n> [!NOTE]\n> ### Update `game.ts` to rem", "score": 1, "created": "2026-02-24T12:54:02Z", "url": "https://github.com/T3-Content/quipslop/pull/44"}, {"source": "GitHub", "text": "Fetch 30 trending, prioritize \u22655 rank jumps, enrich DeepSeek schema and Chinese email with Top20 table ### Motivation\n- Implement the requested feature changes: increase TMDB trending pool to 30, recommend two movies daily with prioritization (rank jump \u22655, then new entries, then smaller jumps), enrich DeepSeek prompt to include movie metadata, and produce Chinese email content including a Top20 table. \n\n### Description\n- Increase candidate pool and defaults by changing TMDB fetch to `limit=30` ", "score": 0, "created": "2026-02-24T12:34:42Z", "url": "https://github.com/tlt28544/Movie-agent/pull/2"}, {"source": "GitHub", "text": "Replace Gemini integration with Ollama deepseek-r1:1.5b ### Motivation\n- Remove the Gemini API dependency and switch AI calls to a local Ollama model (`deepseek-r1:1.5b`) for SQL generation and insight analysis.\n- Provide a backend-hosted, deterministic flow that can run against a local Ollama instance and simplify configuration for users running the app locally.\n\n### Description\n- Added backend Ollama integration in `server.ts` with configurable `OLLAMA_BASE_URL` and `OLLAMA_MODEL`, a `callOlla", "score": 0, "created": "2026-02-24T12:31:34Z", "url": "https://github.com/m12706094-tech/Sales-Intelligence-AI/pull/1"}, {"source": "GitHub", "text": "chore(pricing): Update deepseek pricing ## \ud83d\udd04 Pricing Update: deepseek\n\n### \ud83d\udcca Summary\n\n| Change Type | Count |\n|-------------|-------|\n| \u2795 Models added | 0 |\n| \ud83d\udd04 Prices updated | 2 |\n\n\n### \ud83d\udd04 Updated Models\n- `deepseek-chat`\n- `deepseek-reasoner`\n\n\n---\n*Generated by Pricing Agent on 2026-02-24*", "score": 1, "created": "2026-02-24T12:22:52Z", "url": "https://github.com/sivadurga-d/models/pull/49"}, {"source": "GitHub", "text": "Hardcode TZ/SMTP/DeepSeek defaults and simplify env surface ### Motivation\n- Reduce configuration surface by removing `TZ`, `SMTP_HOST`, `SMTP_PORT`, `DEEPSEEK_BASE_URL`, and `DEEPSEEK_MODEL` as required environment variables and embed sensible defaults in code.\n- Make runtime behavior deterministic (time zone, DeepSeek endpoint/model, and SMTP connection mode) and simplify GitHub Actions / `.env.example` to only require secrets that cannot be committed.\n\n### Description\n- Added `src/constants.p", "score": 0, "created": "2026-02-24T11:55:07Z", "url": "https://github.com/tlt28544/Movie-agent/pull/1"}, {"source": "GitHub", "text": "feat: ai-sdk support for xai and deepseek ## Description\r\n\r\nadd support for xai and deepseek providers\r\n\r\nrequires https://github.com/continuedev/continue/pull/10642 to be merged first\r\n\r\n## AI Code Review\r\n\r\n- **Team members only**: AI review runs automatically when PR is opened or marked ready for review\r\n- Team members can also trigger a review by commenting `@continue-review`\r\n\r\n## Checklist\r\n\r\n- [] I've read the [contributing guide](https://github.com/continuedev/continue/blob/main/CONTRIBU", "score": 1, "created": "2026-02-24T11:51:47Z", "url": "https://github.com/continuedev/continue/pull/10784"}, {"source": "GitHub", "text": "Lock previous inline step message and add GUI + DeepSeek integration ### Motivation\n- Fix UX issue where inline buttons remained active after selection by replacing prior step buttons with a locked confirmation. \n- Provide a local control panel to manage the bot, DeepSeek browser login, and configuration. \n- Integrate a Playwright-driven DeepSeek client to reliably send prompts and retrieve answers from DeepSeek. \n\n### Description\n- Added `app/bot/flows.py` behavior: `_lock_previous_message(...)", "score": 0, "created": "2026-02-24T11:24:21Z", "url": "https://github.com/kgmr8cr7p2-del/tgbot/pull/8"}, {"source": "GitHub", "text": "Use local Chrome/Edge with remote-debugging port for DeepSeek (9222) ### Motivation\n- Avoid relying on Playwright's bundled Chromium (and selenium-like flows) which can fail to launch or be blocked, and instead use an installed browser with a remote debug port. \n- Prevent profile launch conflicts and make it easier to open an existing browser instance for login via a shared debug port. \n- Improve UX in the GUI by providing explicit debug-port configuration and clearer diagnostics when Chrome/Edg", "score": 0, "created": "2026-02-24T10:47:43Z", "url": "https://github.com/kgmr8cr7p2-del/tgbot/pull/7"}, {"source": "GitHub", "text": "[None][perf] Short-sequence MHA optimization for DeepSeek V3.2 MLA prefill ## Summary\n\n- For DSA models (DeepSeek V3.2), the MLA prefill absorption path requires two extra BMMs (Q-absorption and V-projection) and uses a larger head_dim (576 vs 192) for the attention kernel. For short sequences, this overhead dominates.\n- Add an alternative dense MHA path (`forward_context_short_mha`) that expands KV via `kv_b_proj`, constructs full K/V, and computes attention via `torch.scaled_dot_product_attent", "score": 1, "created": "2026-02-24T10:17:56Z", "url": "https://github.com/NVIDIA/TensorRT-LLM/pull/11677"}, {"source": "GitHub", "text": "SongKaBot MVP: desktop GUI, aiogram flow, and Playwright DeepSeek web client ### Motivation\n\n- \u0421\u043e\u0437\u0434\u0430\u0442\u044c \u0440\u0430\u0431\u043e\u0442\u0430\u044e\u0449\u0435\u0435 MVP \u00abSongKaBot\u00bb \u0431\u0435\u0437 Docker/.env \u0441 \u043e\u0434\u043d\u043e\u0439 \u0442\u043e\u0447\u043a\u043e\u0439 \u0432\u0445\u043e\u0434\u0430 \u0438 \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0430\u043c\u0438 \u0432 `config.json`.\n- \u0418\u043d\u0442\u0435\u0433\u0440\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0432\u0435\u0431-\u0430\u0432\u0442\u043e\u043c\u0430\u0442\u0438\u0437\u0430\u0446\u0438\u044e DeepSeek \u0447\u0435\u0440\u0435\u0437 Playwright \u0441 \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u0435\u043c \u043f\u0440\u043e\u0444\u0438\u043b\u044f \u0438 \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e\u0441\u0442\u044c\u044e \u0440\u0443\u0447\u043d\u043e\u0433\u043e \u0432\u0445\u043e\u0434\u0430 \u0432 \u0431\u0440\u0430\u0443\u0437\u0435\u0440\u0435.\n- \u041e\u0431\u0435\u0441\u043f\u0435\u0447\u0438\u0442\u044c \u0443\u043f\u0440\u0430\u0432\u043b\u044f\u0435\u043c\u044b\u0439 \u0437\u0430\u043f\u0443\u0441\u043a/\u043e\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0443 \u0431\u043e\u0442\u0430 \u0438\u0437 desktop GUI \u0438 \u043f\u043e\u0442\u043e\u043a\u043e\u0431\u0435\u0437\u043e\u043f\u0430\u0441\u043d\u0443\u044e \u0440\u0430\u0431\u043e\u0442\u0443 \u0434\u043b\u044f \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u0438\u0445 \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u0435\u0439.\n\n### Description\n\n- \u0414\u043e\u0431\u0430\u0432\u043b\u0435\u043d \u043a\u0430\u0440\u043a\u0430\u0441 \u043f\u0440\u043e\u0435\u043a\u0442\u0430 \u0438 \u0444\u0430\u0439\u043b\u044b \u043a\u043e\u043d\u0444\u0438\u0433\u0443\u0440\u0430", "score": 0, "created": "2026-02-24T10:12:56Z", "url": "https://github.com/kgmr8cr7p2-del/tgbot/pull/6"}, {"source": "GitHub", "text": "Change default LLM model to deepseek/deepseek-r1-0528-qwen3-8b Updates the default LLM model from `qwen/qwen2.5-coder-3b-instruct` to `deepseek/deepseek-r1-0528-qwen3-8b` across the codebase.\n\n**Changes:**\n- **Code**: Updated default model fallback values in `src/extension.ts` and `src/server.ts`\n- **Documentation**: Updated environment variable examples in `AGENTS.md` and `README.md`\n- **UI**: Updated input placeholders in `client/index.html` and `media/webview.html`\n\nUsers can still override t", "score": 0, "created": "2026-02-24T09:51:49Z", "url": "https://github.com/raux/BonsAIDE/pull/11"}, {"source": "GitHub", "text": "Add Telegram song-creation bot with DeepSeek CDP (Playwright) integration ### Motivation\n- Provide a Telegram bot that walks a user through creating a song (holiday, style, mood, language, details, voice) and automates submission to DeepSeek web chat via a browser connected on the remote debugging port `9222`.\n- Ensure the generated lyrics are returned in the strict sectioned format `[Verse] [Pre-Chorus] [Chorus] [Verse] [Bridge] [Chorus] [Outro]` and support iterative refinement in the same Dee", "score": 0, "created": "2026-02-24T09:47:12Z", "url": "https://github.com/kgmr8cr7p2-del/last/pull/1"}, {"source": "GitHub", "text": "ENH: update model \"Deepseek-V3.1\" JSON Automated sync for model \"Deepseek-V3.1\" (llm) by user amumu96.", "score": 0, "created": "2026-02-24T09:26:28Z", "url": "https://github.com/xorbitsai/inference/pull/4621"}]}