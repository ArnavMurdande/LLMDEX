{"timestamp": 1771962992.9553957, "mentions": [{"source": "Reddit", "text": "How many tokens do you \ud83d\udd25 per month &amp; what\u2019s the real cost? (API) \nGuys, can you drop a number for models like \n\nMiniMax M2.5 \n\nKimi 2.5 \n\nGLM5 \n\nQwen 3.5plus\n\nGemini 3.1 Pro\n\nGPT5.3 codex\n\nClaude Sonnet/Opus 4.6\n\nUsecase would be cool to know \n\nThanks in advance ", "score": 2, "created": 1771961297.0, "url": "https://reddit.com/r/openclaw/comments/1rdpzyc/how_many_tokens_do_you_per_month_whats_the_real/"}, {"source": "Reddit", "text": "Frontier LLM Leaderboard Check it out at [https://www.onyx.app/llm-leaderboard](https://www.onyx.app/llm-leaderboard)", "score": 0, "created": 1771959166.0, "url": "https://reddit.com/r/OpenAI/comments/1rdozjs/frontier_llm_leaderboard/"}, {"source": "Reddit", "text": "Built Manifest -&gt; Local OpenRouter Alternative for OpenClaw (LLM Router to Save Costs) https://preview.redd.it/3p6hnhx3mhlg1.png?width=1440&amp;format=png&amp;auto=webp&amp;s=d1215d1dc59f0a062b7650fc3ebc89d489ec9dba\n\n\n\n**OpenClaw sends all your requests to the same model,** which is not cost-effective since you summon big models for tiny tasks. Manifest intercepts your query and **sends it to the most suitable model**. Examples:\n\n\\- \"what's the capital of France\" -&gt; Simple (Kimi k2)  \n\\- \"", "score": 1, "created": 1771958914.0, "url": "https://reddit.com/r/openclaw/comments/1rdov37/built_manifest_local_openrouter_alternative_for/"}, {"source": "Reddit", "text": "DeepSeek (a base model) has hit 15M tokens in 4 days \u2014 quickly becoming a user favorite | just4o.chat News [DeepSeek v3.2 on the news - very 4o-like](https://preview.redd.it/cyogj4p1nhlg1.png?width=3019&amp;format=png&amp;auto=webp&amp;s=88e316f9212171b127d90369eb872d8dcf636ee2)\n\n  \nWe added DeepSeek v3.1 and v3.2 (*as base models!)* to [just4o.chat](http://just4o.chat) four days ago, and the response has been pretty strong according to our usage analytics.\n\nIn that short time, DeepSeek has alre", "score": 7, "created": 1771958882.0, "url": "https://reddit.com/r/just4ochat/comments/1rdouiy/deepseek_a_base_model_has_hit_15m_tokens_in_4/"}, {"source": "Reddit", "text": "Anthropic detects distillation from Moonshot, falsely accusing Kimi of lacking safeguards Anthropic just published this blog post: [https://www.anthropic.com/news/detecting-and-preventing-distillation-attacks](https://www.anthropic.com/news/detecting-and-preventing-distillation-attacks)\n\nThey detected large-scale distillation use from Moonshot.\n\nThey do not say *when* it occurred, so we don't know which models it might have affected.\n\nThey say \"Models built through illicit distillation are unlik", "score": 2, "created": 1771958686.0, "url": "https://reddit.com/r/kimi/comments/1rdor6w/anthropic_detects_distillation_from_moonshot/"}, {"source": "Reddit", "text": "Kimi K2.5 identified itself as \"Claude\" after a long conversation \u2014 possible distillation from Anthropic's models? A few weeks ago when Kimi K2.5 was freshly released on Hugging Face, I was casually testing it through the Inference Provider interface. After a fairly long conversation (around 20 exchanges of general questions), I asked the model its name and specs. It responded saying it was Claude.\nAt the time I didn't think much of it. But then I came across Anthropic's recent post on detecting", "score": 4, "created": 1771957519.0, "url": "https://reddit.com/r/Anthropic/comments/1rdo7ld/kimi_k25_identified_itself_as_claude_after_a_long/"}, {"source": "Reddit", "text": "my go to tools for content and coding thought I'd share my current toolkit. I've decided to move away from depending on just one AI provider. now, I mainly rely on Blackbox AI for its unlimited free access for some of the models.\n\nI\u2019ve been using Minimax M2.5 for coming up with ideas and creative content, while Kimi K2.5 handles my research needs. It\u2019s super handy for gathering competitor insights. GLM-5 is my helper for Python scripts and automation tasks.\n\nMost of my initial drafts come from t", "score": 2, "created": 1771954685.0, "url": "https://reddit.com/r/AIToolMadeEasy/comments/1rdmv1v/my_go_to_tools_for_content_and_coding/"}, {"source": "Reddit", "text": "\"Agentic Gaming\" \u2014 a deep dive into how I'm using LLMs as a semantic reasoning layer inside an RPG engine (80+ orchestrated AI tasks, multi-LLM, genre-agnostic skills, and a lot of dice rolls) Hi everyone!\n\nI've been working on something for a while now that I think sits squarely in the intersection of this sub's interests, and I wanted to share it \u2014 not just as a project showcase, but because I genuinely want to discuss the underlying design concepts with people who think about AI + game design", "score": 4, "created": 1771954177.0, "url": "https://reddit.com/r/aigamedev/comments/1rdmmfa/agentic_gaming_a_deep_dive_into_how_im_using_llms/"}, {"source": "Reddit", "text": "Best TUIs / workflows for worktrees? Just learn tmux? EDIT: just discovered the \"Enable workspaces button in OpenCode Desktop\" very excited to test this out.\n\nEDIT 2: OpenCode worktree feature has everything I want. Huge!\n\nI might just need to learn TMUX, but what are people's favorite workflows for managing parallel agents in worktrees right now?\n\nI know there are dozens of tools trying to solve this, but not sure which are actually sticking with people. The only people I've talked to in real l", "score": 2, "created": 1771954030.0, "url": "https://reddit.com/r/opencodeCLI/comments/1rdmk0h/best_tuis_workflows_for_worktrees_just_learn_tmux/"}, {"source": "Reddit", "text": "I was spending way too much time every day trying to keep up with AI so I built something for myself, now opening it up For the past year I've been spending way too much time every day going through Twitter, Reddit, blogs, newsletters trying to keep up with everything happening in AI. Model releases, tool launches, product updates, new techniques, industry moves, it's everywhere and there's no single place for it\n\nAnd the FOMO is real. Like what if I missed an update yesterday that I could've ac", "score": 2, "created": 1771953618.0, "url": "https://reddit.com/r/SideProject/comments/1rdmd5n/i_was_spending_way_too_much_time_every_day_trying/"}, {"source": "Reddit", "text": "I gave 16 LLMs a food truck in Austin for 30 days. Gemini 3 Pro matched Sonnet 4.6 \u2014 5\u00d7 cheaper. I built an agentic benchmark called FoodTruck Bench \u2014 AI models manage a food truck in Austin, TX for 30 days. Location strategy, menu pricing, inventory management, staff hiring \u2014 34 tools, deterministic simulation, 5 runs per model. Same seed, same conditions. 16 models tested so far.\n\n**Gemini 3 Pro is the most efficient model on the entire benchmark.** It reaches +760% ROI \u2014 nearly identical to S", "score": 15, "created": 1771952987.0, "url": "https://reddit.com/r/GeminiAI/comments/1rdm2g1/i_gave_16_llms_a_food_truck_in_austin_for_30_days/"}, {"source": "Reddit", "text": "I am considering cancelling my $20/mo AI subs because one service is asking for just $2 for the first month. I was paying $20/mo for different SOTA models, and it was adding up fast. Im not exactly having money falling out of my pockets.\u00a0\n\nThen I saw Blackbox AI\u2019s promo, $1 for the first month of PRO gets you $20 in credits usable on:\n\n\u2022 Claude Opus 4.6, GPT-5.2, Gemini 3, Grok 4, and a bunch more\n\n\u2022 plus unlimited free requests on Minimax M2.5, GLM-5, and Kimi K2.5.\n\nI\u2019ve been using the unlimit", "score": 1, "created": 1771952054.0, "url": "https://reddit.com/r/Students/comments/1rdlm9a/i_am_considering_cancelling_my_20mo_ai_subs/"}, {"source": "Reddit", "text": "New SWE-bench Multilingual Leaderboard: Performance across 9 languages &amp; cost analysis Happy to announce that we just launched our Multilingual leaderboard comparing performance across 9 languages. The benchmark is harder than SWE-bench verified and still shows a wider range of performances.\n\nWe're still adding more models, but this is the current leaderboard:\n\nhttps://preview.redd.it/l0cotc22wglg1.png?width=4752&amp;format=png&amp;auto=webp&amp;s=b7b862332cdb8843100d9919db30accb1bc0c260\n\nIn", "score": 12, "created": 1771950003.0, "url": "https://reddit.com/r/LocalLLaMA/comments/1rdknyh/new_swebench_multilingual_leaderboard_performance/"}, {"source": "Reddit", "text": "How vulnerable is GOOGL to the release of cheap models from China? I\u2019ve been long Google for years and added more throughout 2025 with the thesis that their ability to integrate AI into their workflows and ecosystem gives them a massive advantage. \n\nI still believe that\u2019s true, but I also think the cost of developing AI models is going to prove to be much cheaper than it currently is, and China will prove this to the market with more releases of Kimi and DeepSeek and who knows what else. I know ", "score": 17, "created": 1771949590.0, "url": "https://reddit.com/r/stocks/comments/1rdkh3b/how_vulnerable_is_googl_to_the_release_of_cheap/"}, {"source": "Reddit", "text": "401 error I try to use my Kimi Coding api key to no avail.\n\nI'm using a third-party tool (Openclaw). What do I need to do to get API access for chat completions? I am sure that the API should work. Kimi Coding is working just fine for me in VS Code and Kimi CLI.\n\nI tried the support article for\u00a0[https://kimi-ai.chat/docs/api-error-codes/](https://kimi-ai.chat/docs/api-error-codes/)\u00a0error code 401 to no avail.\n\nI get: \u201c*{*\n\n\u00a0 *\"error\": {*\n\n*\"message\": \"Kimi For Coding is currently only available ", "score": 1, "created": 1771946097.0, "url": "https://reddit.com/r/kimi/comments/1rdivsn/401_error/"}, {"source": "Reddit", "text": "anyone else using the free models for agent backends now? was testing a few agent setups recently and realized most of the heavy lifting doesn\u2019t actually need top-tier models.\n\n\nstuff like log classification, tool routing, simple summarization, etc works fine on lighter ones. been using kimi k2.5 and minimax through blackboxAI mainly because they don\u2019t seem to have usage limits, so it\u2019s easy to leave agents running without worrying about cost.\n\n\nhonestly didn\u2019t expect them to hold up this well. ", "score": 3, "created": 1771945923.0, "url": "https://reddit.com/r/AI_Agents/comments/1rdisz5/anyone_else_using_the_free_models_for_agent/"}, {"source": "Reddit", "text": "Megathread and info about proxies. This is a mod posted megathread for the discussion of proxies, \n\nQuick info \n\n1 What are proxies?\n\nProxies are llm service providers that can be hooked into saucepan chub or wyvern to act as a replacement for the inbuilt llm, they are usually paid however some like electron hub, composite etc are free for a limited free tier.\n\n2 Why is my proxy not working???\n\nPlease ask your question on the official proxy discord or reddit server as we are not affiliated with ", "score": 7, "created": 1771944694.0, "url": "https://reddit.com/r/JanitorAI_Refuges/comments/1rdi9id/megathread_and_info_about_proxies/"}, {"source": "Reddit", "text": "Free AIs - not good enough when precision is needed I was running Kimi 2.5 with no issues for a couple thousands of lines. Then an audit found a \"complex triangle drift \" issue. \n\nLost a lot of time trying to fix it with Kimi 2.5 without any progress.\n\n7usd worth of Claude Opus 4.6 + 17min of Codex 5.3 Xtra high sorted everything.\n\nI had the mindset \"these free AIs are largely enough for my project\".\n\nNot anymore! (unfortunately).\n\nI'll wait for deepseek 4 I guess. ", "score": 2, "created": 1771943853.0, "url": "https://reddit.com/r/BlackboxAI_/comments/1rdhwx3/free_ais_not_good_enough_when_precision_is_needed/"}, {"source": "Reddit", "text": "Anyone else getting frequent rate-limit errors with OpenCode Black? Lately I keep getting this error throughout the day:\n\n`\"invalid_request_error\" \"code\": \"invalid_request_error\"`\n\n`\"message\": \"rate limit exceeded, please try again later\"}`\n\n`}data: {\"choices\": [,\"cost\": \"0\"}`\n\nWhat\u2019s weird is this can happen on my **first prompt of the day** after \\~8 hours of inactivity.\n\nUsage shows:\n\n* **5-hour usage:** 0%\n* **Weekly usage:** 4%\n\nModel: **Kimi 2.5**\n\nI\u2019m using OpenCode Black and the reliabil", "score": 0, "created": 1771940527.0, "url": "https://reddit.com/r/opencodeCLI/comments/1rdgk0c/anyone_else_getting_frequent_ratelimit_errors/"}, {"source": "Reddit", "text": "Keep your Agents in line - enforce security guardrails and improve the final quality of AI-generated solutions. \ud83e\udd16 The out-of-the-box AI Agents know **something** about absolutely **everything**. They can easily get lost and/or miss important aspects of the solution they help to develop.\n\nIn order to make them more resilient, I define **clear roles**, **responsibilities**, and **tools** for **each agent**. \n\nIf the coordinating agent tries to be 'pro-active' and gets out of its lane, my framework", "score": 1, "created": 1771939760.0, "url": "https://reddit.com/r/AgentsOfAI/comments/1rdg99e/keep_your_agents_in_line_enforce_security/"}, {"source": "Reddit", "text": "LLM provider error. UPDATE: I installed kimi in a macbook (error suddenly appeared on Ubuntu), and i logged in and works fine. So i thought it was the .kimi corrupted. I renamed the .kimi to .kimi\\_backup so i do not loose my previous sessions, uninstalled kimi with the uv tool, and then reinstalled kimi but still i get the same error. Any ideas on what suddenly happened and i cannot continue chatting with kimi-cli?\n\nI tried resuming a 3-day old session but i get this error. I tried login in aga", "score": 1, "created": 1771938384.0, "url": "https://reddit.com/r/kimi/comments/1rdfqio/llm_provider_error/"}, {"source": "Reddit", "text": "How many Agent Mode uses do you get per day with Kimi AI Moderato ($19/month)? Right now I\u2019m using Kimi AI in free mode, and I only get **3 Agent Mode command uses** .\n\nI\u2019m thinking about purchasing the **Moderato \u2013 $19/month** package, but I can\u2019t find clear information about the Agent Mode limit.\n\n\ud83d\udc49 How many **Agent Mode uses** do you get per day with the Moderato plan?  \nIs it unlimited, or is there still a daily cap?\n\nIf anyone here is using Moderato, I\u2019d really appreciate your help before I", "score": 2, "created": 1771928121.0, "url": "https://reddit.com/r/kimi/comments/1rdcg5j/how_many_agent_mode_uses_do_you_get_per_day_with/"}, {"source": "Reddit", "text": "Finetuning 4bit kimik2thinking Hello.   \nI want to fine tune kimi2thinking. The official [guide](https://huggingface.co/moonshotai/Kimi-K2-Thinking/blob/main/docs/deploy_guidance.md) \\- says to use Ktransformers and LLamafactory. But looks like I need to convert it first to bf16 and then run. Is there any way to not convert to bf16 because QLoRA anyways uses 4bit quant models only? ", "score": 1, "created": 1771927792.0, "url": "https://reddit.com/r/LocalLLaMA/comments/1rdccw6/finetuning_4bit_kimik2thinking/"}, {"source": "Reddit", "text": "I miss Kimi K2 Back when the AI has its own personality. Honestly Kimi K2.5 feels just like a Claude clone, but cheaper. If you compare a writing from K2 with K2.5 you can literally see the  new model is so much more restrictive, less creative, too much repetition. I know there are people who prefer the old model too, and I really wish they could give us the access to old model like they used to do with K1.5 and K2. ", "score": 4, "created": 1771923882.0, "url": "https://reddit.com/r/kimi/comments/1rdbbjq/i_miss_kimi_k2/"}, {"source": "Reddit", "text": "Limits for Kimi subscription Can anyone share how Kimi and Anthropic subscriptions compare for CLI usage?  \n\n\nSpecifically, I\u2019m looking at the Kimi $19 plan vs. the Anthropic $20 plan.\n\n  \nI know the models themselves are different, but I\u2019m more interested in the usage limits and practical limitations", "score": 3, "created": 1771923398.0, "url": "https://reddit.com/r/kimi/comments/1rdb715/limits_for_kimi_subscription/"}, {"source": "Reddit", "text": "GLM 5 vs Kimi K2.5: Which Open Model Actually Wins? GLM 5 vs Kimi K2.5 is the comparison that should be dominating discussions right now.\n\nMost people are still arguing about proprietary models, while GLM 5 vs Kimi K2.5 has quietly pushed open-weight AI into serious frontier territory.\n\nIf you are building real systems instead of chasing hype cycles, this is the decision that actually affects your stack.\n\nWatch the video below:\n\n[https://www.youtube.com/watch?v=C37CTjCTYn4](https://www.youtube.c", "score": 2, "created": 1771919061.0, "url": "https://reddit.com/r/AISEOInsider/comments/1rda1qo/glm_5_vs_kimi_k25_which_open_model_actually_wins/"}, {"source": "Reddit", "text": "\"Ollama 0.17 makes it much simpler to use open models with @openclaw Try it with: ollama launch openclaw\" -  more goodies for OpenClaw fans. just make sure you sandbox properly before it runs away :P [https://x.com/ollama/status/2026098586300071975](https://x.com/ollama/status/2026098586300071975)", "score": 2, "created": 1771919003.0, "url": "https://reddit.com/r/LovingOpenSourceAI/comments/1rda16x/ollama_017_makes_it_much_simpler_to_use_open/"}, {"source": "Reddit", "text": "my stack for content and code generation (mostly free) wanted to share my current setup. i've moved away from relying solely on one provider. currently using blackbox ai as my main hub primarily for the unlimited free access to,\n\nminimax m2.5, exclusively for creative copy and brainstorming ideas. kimi k2.5, my research analyst. i feed it competitor docs and reports and glm-5, my assistant for python scripts and automation.\n\ni still use claude for the final polish, but 90 per cent of the draft w", "score": 7, "created": 1771915413.0, "url": "https://reddit.com/r/VibeCodeDevs/comments/1rd91ef/my_stack_for_content_and_code_generation_mostly/"}, {"source": "Reddit", "text": "Claude Code will become unnecessary I use AI for coding every day including Opus 4.6. I've also been using Qwen 3.5 and Kimi K2.5. Have to say, the open source models are *almost* just as good. \n\nAt some point it just won't make sense to pay for Claude. When the open weight models are good enough for Senior Engineer level work, that should cover most people and most projects. They're also much cheaper to use.\n\nFurthermore, it is feasible to host the open weight models locally. You'd need a bit o", "score": 403, "created": 1771913421.0, "url": "https://reddit.com/r/ClaudeCode/comments/1rd8erf/claude_code_will_become_unnecessary/"}, {"source": "Reddit", "text": "When a company wants to give you a free trial but not really free I saw this and had to double check the pricing.\n\nBlackbox AI is offering its PRO plan for $2 for the first month. Not free. But cheap enough that you don\u2019t really hesitate.\n\nHere\u2019s what you get:\n\n$20 in credits for Claude Opus 4.6, GPT-5.2, Gemini 3, Grok 4, and 400+ models\n\nUnlimited requests on Minimax M2.5, GLM-5, Kimi K2.5\n\nAccess to chat, image, and video models\n\nIt\u2019s basically a paid free trial.\n\nYou put down $2, so you feel", "score": 2, "created": 1771910330.0, "url": "https://reddit.com/r/OnlyAICoding/comments/1rd7fv0/when_a_company_wants_to_give_you_a_free_trial_but/"}, {"source": "Reddit", "text": "Minimax 2.5 coding plan overhyped?? Hey am I missing something or minimax 2.5 is over hyped?\nI bought their $10 basic coding plan to try the new M2.5 model which many claimed to be \u2018Opus level\u2019\n\nI\u2019m already using Kimi and Gpt5.2 + Codex and Gemini as my model routing. I was expecting to use minimax 2.5 as the main agent to talk to and orchestrate tasks to other models like Kimi or Codex for better performance. Or it can do simple tasks like web search and stuff.\n\nBut I found it really slow and p", "score": 9, "created": 1771899561.0, "url": "https://reddit.com/r/openclaw/comments/1rd252r/minimax_25_coding_plan_overhyped/"}, {"source": "Reddit", "text": "Is it always this slow?  Using Kimi k2.5, GLM-5, or Minimax 2.5 is practically impossible; Qwen models run at decent speeds randomly, which is frustrating. Is there any way to achieve a good speed?\n\ntnks ", "score": 11, "created": 1771898622.0, "url": "https://reddit.com/r/chutesAI/comments/1rd1sbu/is_it_always_this_slow/"}, {"source": "Reddit", "text": "I Made Chat GPT, Claude, and Gemini Work Together \u2014 Here's What Happened Many solopreneurs and small business owners use AI as another founder or employee. Phrases like \"Chat GPT's my Sales Person\" or \"Gemini's my Marketing\" are always being used. In real teams, members need to collaborate and discuss philosophies, strategies and roadmaps in order to create a good product. If each team member were separated in chats/spaces like AI is, nothing would get done.\n\nClaude Code and Kimi have these feat", "score": 1, "created": 1771895886.0, "url": "https://reddit.com/r/AiForSmallBusiness/comments/1rd0ivx/i_made_chat_gpt_claude_and_gemini_work_together/"}, {"source": "Reddit", "text": "I got tired of rewriting the same prompts every day, so I built an open-source prompt ark that injects directly into ChatGPT, Claude, Gemini, and 11 other platforms I've been using AI platforms daily \u2014 ChatGPT for writing, Claude for code review, DeepSeek for Chinese queries, Gemini for research. After a few months I realized I was spending a stupid amount of time on one thing:\n\n**Rewriting the same prompts over and over.**\n\nI'd craft a great prompt, get perfect results, and then... never find i", "score": 0, "created": 1771894999.0, "url": "https://reddit.com/r/PromptEngineering/comments/1rd04q2/i_got_tired_of_rewriting_the_same_prompts_every/"}, {"source": "Reddit", "text": "Has Anthropic lost confidence? First, full disclosure: I\u2019m a Claude Max subscriber, screenshot attached.\n\nThat said, open-source models like Kimi and Minimax are currently much cheaper than Claude when it comes to coding plans. On top of that, Anthropic has been restricting and even banning the use of Claude subscriptions in third-party software, forcing users to more expensive API instead.\n\nFor something like openclaw, I don\u2019t need opus. Open models are good enough, especially when I can get th", "score": 0, "created": 1771894123.0, "url": "https://reddit.com/r/ClaudeAI/comments/1rczs1l/has_anthropic_lost_confidence/"}, {"source": "Reddit", "text": "I Made GPT-5.2, Opus 4.6, and Gemini 3.1 Work Together \u2014 Here's What Happened Claude Code and Kimi have these features where you can make different agents with their respective models talk to each other and collaborate. But Claude and Kimi models aren't good at everything, and I started to wonder what would happen if different models from different providers worked together. So that's what I did.\n\nUsing the three flagship models: GPT-5.2, Opus 4.6, and Gemini 3.1, I wanted to test how their thre", "score": 12, "created": 1771892432.0, "url": "https://reddit.com/r/ChatGPT/comments/1rcz11f/i_made_gpt52_opus_46_and_gemini_31_work_together/"}, {"source": "Reddit", "text": "how dare they steal our stolen data! ", "score": 96, "created": 1771888923.0, "url": "https://reddit.com/r/LateStageCapitalism/comments/1rcxjeo/how_dare_they_steal_our_stolen_data/"}, {"source": "Reddit", "text": "Vibe-coding unity mobile game What skills/rules do game devs use to instruct open code agent? How does AI test the game? (Chromium + WebGL?)\n\nSo far my experience on vibe coding unity game is super bad. Agents are dumb and making millions of wrong assumptions. I\u2019m not sure if it\u2019s problem of model (Kimi-k2.5) or I do not give enough context of unity\u2026. Want to hear others\u2019 experiences ", "score": 0, "created": 1771886106.0, "url": "https://reddit.com/r/opencodeCLI/comments/1rcwbro/vibecoding_unity_mobile_game/"}, {"source": "Reddit", "text": "I made free-coding-models, a TUI that monitors 101 free coding models for free opencode or free openclaw usage, thanks to NIM or other providers I made `free-coding-models`, a TUI that **monitors 101 free coding models** across **9 providers** in parallel, then lets you launch the best one **instantly**.\n\n  \nInstall the npm :\n\n`npm i -g free-coding-models`\n\n\n\n\u2705 Works with:\n\n* **OpenCode CLI**\n* **OpenCode Desktop**\n* **OpenClaw \ud83e\udd9e** (yep)\n* more planned soon (KiloCode, Claude Code (with a proxy)\n", "score": 1, "created": 1771885300.0, "url": "https://reddit.com/r/AI_Agents/comments/1rcvyze/i_made_freecodingmodels_a_tui_that_monitors_101/"}, {"source": "Reddit", "text": "The AI Model War Is Accelerating \ud83c\udf0f\ud83e\udd2f This video shows how GLM, Kimi and MiniMax are pushing AI forward fast.\n\nBetter reasoning.  \nLower cost.  \nStronger agent capabilities.\n\nThat means builders now have more options to create workflows and products without relying on one ecosystem.\n\n\ud83c\udfa5 Watch the full breakdown  \n\ud83d\udc49 Learn how people use multi-model stacks: [https://crdigitalmarketer.com/b/AIPBRD](https://crdigitalmarketer.com/b/AIPBRD)\n\nhttps://reddit.com/link/1rcuy3f/video/6twy2k2odblg1/player\n\n", "score": 1, "created": 1771883022.0, "url": "https://reddit.com/r/u_Worldly-Stage1445/comments/1rcuy3f/the_ai_model_war_is_accelerating/"}, {"source": "Reddit", "text": "What LLM subscriptions are you using for coding in 2026? I've evaluated Chutes, Kimi, MiniMax, and [Z.ai](http://Z.ai) for coding workflows but want to hear from the community.\n\nWhat LLM subscriptions are you paying for in 2026? Any standout performers for code generation, debugging, or architecture discussions?", "score": 1, "created": 1771882341.0, "url": "https://reddit.com/r/vibecoding/comments/1rcun7f/what_llm_subscriptions_are_you_using_for_coding/"}, {"source": "Reddit", "text": "What LLM subscriptions are you using for coding in 2026? I've evaluated Chutes, Kimi, MiniMax, and z ai for coding workflows but want to hear from the community.\n\nWhat LLM subscriptions are you paying for in 2026? Any standout performers for code generation, debugging, or architecture discussions?", "score": 1, "created": 1771882305.0, "url": "https://reddit.com/r/LLMDevs/comments/1rcumn5/what_llm_subscriptions_are_you_using_for_coding/"}, {"source": "Reddit", "text": "Serious question: do you think Dario (or any other major AI players or political players) have enough power and influence that they will get Chinese local AI and/or local AI in general banned in the U.S.? What do you think the odds are? I guess I'll put Dario in the title, since he's the most relevant hater of the day, and I guess fairly powerful in regards to this as far as any one specific guy goes, but, obviously if something like this happened, it would involve a lot more people combining th", "score": 32, "created": 1771881573.0, "url": "https://reddit.com/r/LocalLLaMA/comments/1rcuaip/serious_question_do_you_think_dario_or_any_other/"}, {"source": "Reddit", "text": "Two major Anthropic updates: A tense DoD meeting tomorrow and Chinese AI labs caught distilling Claude 1. Tense meeting with the Department of Defense\n\nTomorrow, Anthropic's CEO is scheduled to meet with the US Secretary of Defense. As many of you know, Anthropic has been strictly against using its models for military purposes (though back in January it was revealed that Claude was used to plan an operation in Venezuela).\n\nA senior DoD official told Axios that this is definitely not a casual int", "score": 0, "created": 1771880850.0, "url": "https://reddit.com/r/ClaudeAI/comments/1rctz9w/two_major_anthropic_updates_a_tense_dod_meeting/"}, {"source": "Reddit", "text": "Me (Mincoffical)and Elc29 created an AI Agent inside of Apple shortcuts that can execute multiple tasks and is entirely free with no apps or API keys needed This shortcut loops around and decides what actions to do next. powered by the pollinations API, you can choose to either not use an API key and get free access to GPT-5-Mini, or get your own API key from pollinations for free and get 1.5 pollen (dollars of credits) per week and use other models like Deepseek, GPT-5.2, GLM-5, Kimi K2.5, and ", "score": 9, "created": 1771880527.0, "url": "https://reddit.com/r/shortcuts/comments/1rctv1b/me_mincofficaland_elc29_created_an_ai_agent/"}, {"source": "Reddit", "text": "What LLM are you using for Openclaw (Non API if possible) Not sure why I couldn't find a Reddit thread for this\n\nI'm still running Claude Max through OpenClaw with no issues yet, but feel like it's going to get banned any day/week now\n\nWhat LLM are you using with OpenClaw? I'm looking for a subscription not an API\n\nEDIT: I tried Kimi, had issues with the API, moved to Chatgpt plus for now, it is like looking after a toddler in comparison to Claude, damn! Still usable though", "score": 48, "created": 1771878892.0, "url": "https://reddit.com/r/openclaw/comments/1rct3ug/what_llm_are_you_using_for_openclaw_non_api_if/"}, {"source": "Reddit", "text": "Anthropic: \"We\u2019ve identified industrial-scale distillation attacks on our models by DeepSeek, Moonshot AI, and MiniMax.\" \ud83d\udea8 ", "score": 28, "created": 1771877861.0, "url": "https://reddit.com/r/kimi/comments/1rcsmam/anthropic_weve_identified_industrialscale/"}, {"source": "Reddit", "text": "My fianc\u00e9e's butcher said she got veal, ChatGPT said it is pork. So I asked 9 other AI models. Fianc\u00e9e and I live in Portugal and we're not quite fluent.  \nShe\u00a0bought\u00a0meat today,\u00a0she is 90% sure the\u00a0butcher said\u00a0\"vitela\" (veal in\u00a0Portuguese). Sent\u00a0a\u00a0photo to\u00a0ChatGPT, it\u00a0said it is\u00a0pork. The butchers have been erratic at times so now\u00a0we're confused. And we also are not a fan of pork, by choice, but we'll have to make do if that is true in the end.\n\nSo\u00a0I ran\u00a0the\u00a0same image\u00a0through 9 different\u00a0AI m", "score": 0, "created": 1771877818.0, "url": "https://reddit.com/r/ChatGPT/comments/1rcslix/my_fianc\u00e9es_butcher_said_she_got_veal_chatgpt/"}, {"source": "Reddit", "text": "Anthropic accusa DeepSeek, Moonshot AI (Kimi) e MiniMax di aver creato pi\u00f9 di 24.000 account fraudolenti di Claude e di aver distillato informazioni di addestramento da 16 milioni di scambi. ", "score": 1, "created": 1771877625.0, "url": "https://reddit.com/r/u_Cosmoseeker2030/comments/1rcsi9j/anthropic_accusa_deepseek_moonshot_ai_kimi_e/"}, {"source": "Reddit", "text": "Tired of $20 \u201cVibe Coding\u201d Plans That Explode in Token Cost? I Built a Flexi Alternative. Vibe for nearly zero cost!! I've been deep in the \"vibe coding\" scene, watching platforms like Lovable and Replit make waves. But as an Indian founder/dev, I constantly hit a wall that I know many of you feel too: the cost and vendor lock-in. \ud83d\ude29\n\nIt's always the same story: a tempting $25 to get started, then BAM! \"Credit limits\" or usage spikes hit the moment you try to build anything serious. And don't eve", "score": 0, "created": 1771875109.0, "url": "https://reddit.com/r/VibeCodeDevs/comments/1rcrblf/tired_of_20_vibe_coding_plans_that_explode_in/"}, {"source": "Reddit", "text": "Letting agents choose their model &amp; thinking Like everyone else I have a nice control panel built by my friendly hive of agents and the next thing on our list is control of providers, models and thinking levels.\n\nThe control centre is all API driven and the agents have varying levels of read/write access. (Not quite full RBAC, but heading in that direction.)\n\nFirst step is me being able to change a model or thinking level for an agent or session, then we've been looking at light automation -", "score": 1, "created": 1771873334.0, "url": "https://reddit.com/r/openclaw/comments/1rcqhkz/letting_agents_choose_their_model_thinking/"}, {"source": "Reddit", "text": "Western models need to stay in their lane IMHO 2026 is shaping up to be a fascinating devolution for machine intelligence.\n\nAs both humans and language models feed on their own slop it is not clear who will hit rock bottom first.", "score": 0, "created": 1771872502.0, "url": "https://reddit.com/r/kimi/comments/1rcq3aq/western_models_need_to_stay_in_their_lane/"}, {"source": "Reddit", "text": "Anthropic is accusing DeepSeek, Moonshot AI (Kimi) and MiniMax of setting up more than 24,000 fraudulent Claude accounts, and distilling training information from 16 million exchanges. ", "score": 27, "created": 1771871904.0, "url": "https://reddit.com/r/BasiliskEschaton/comments/1rcpsqz/anthropic_is_accusing_deepseek_moonshot_ai_kimi/"}, {"source": "Reddit", "text": "Thoughts on this benchmark? vCopied from X post:\n\n\"\"\"\n\nIntroducing the latest results of our Long-Context Agentic Orchestration Benchmark.\n\n\u2022 31 high-complexity, non-coding scenarios (100k+ tokens) where the model must select the correct next-step action using proprietary orchestration logic with no public precedent \u2014 a pure test of instruction following and long-context decision-making.\n\n\u2022 All models run at minimum thinking/reasoning settings and temperature 0 \u2014 simulating production orchestrat", "score": 7, "created": 1771869094.0, "url": "https://reddit.com/r/Bard/comments/1rcog4p/thoughts_on_this_benchmark/"}, {"source": "Reddit", "text": "Thoughts on this benchmark? Copied from X post:\n\n\"\"\"\n\nIntroducing the latest results of our Long-Context Agentic Orchestration Benchmark.\n\n\u2022 31 high-complexity, non-coding scenarios (100k+ tokens) where the model must select the correct next-step action using proprietary orchestration logic with no public precedent \u2014 a pure test of instruction following and long-context decision-making.\n\n\u2022 All models run at minimum thinking/reasoning settings and temperature 0 \u2014 simulating production orchestrati", "score": 2, "created": 1771869021.0, "url": "https://reddit.com/r/GeminiAI/comments/1rcoevm/thoughts_on_this_benchmark/"}, {"source": "Reddit", "text": "i tested every ai subscription heres the actual cost per model i got tired of paying for multiple ai apps so i actually sat down and compared what you're paying vs what you get\n\nrough breakdown from my end\n\nchatgpt plus $20/month\u00a0 \n\ngpt 5.2 with rate limits\n\nclaude pro $20/month\u00a0 \n\nopus 4.6 sonnet\n\ngemini advanced $20/month\u00a0 \n\ngemini 3\n\nso if you're using all three thats basically $60/month just to access 3 model families\n\nwhat caught me off guard was blackbox pro\n\nfirst month is $1 normally $10", "score": 7, "created": 1771868091.0, "url": "https://reddit.com/r/aiHub/comments/1rcnz59/i_tested_every_ai_subscription_heres_the_actual/"}, {"source": "Reddit", "text": "GLM-5 is the new top open-weights model on the Extended NYT Connections benchmark, with a score of 81.8, edging out Kimi K2.5 Thinking (78.3) More info: [https://github.com/lechmazur/nyt-connections/](https://github.com/lechmazur/nyt-connections/)", "score": 126, "created": 1771867862.0, "url": "https://reddit.com/r/LocalLLaMA/comments/1rcnv9h/glm5_is_the_new_top_openweights_model_on_the/"}, {"source": "Reddit", "text": "\ud83e\udd2f AI News Roundup: Agents Take Flight, Security Risks Emerge &amp; More Hey AI enthusiasts! \ud83d\ude80\n\n\n\nIt's been a wild week in AI. Here's what you need to know:\n\n\n\n\\*\\*\ud83c\udfaf OpenAI Goes All-In on Agents\\*\\*\n\nOpenAI just hired Peter Steinberger, creator of OpenClaw (now open-sourced!). OpenClaw showed us practical AI automation beyond chatbots. This signals OpenAI's serious push toward autonomous agents.\n\n\n\n\\*Why it matters:\\* Expect better tooling for task automation workflows.\n\n\n\n\\*\\*\u2694\ufe0f Pentagon vs. Ant", "score": 1, "created": 1771867512.0, "url": "https://reddit.com/r/devbrief/comments/1rcnpga/ai_news_roundup_agents_take_flight_security_risks/"}, {"source": "Reddit", "text": "Whose Face Is on the Twenty?\nCuratorial Mediation, Latent Feature Activation, and a Provenance Gap in the $20 Portrait # Whose Face Is on the Twenty?\n\n# Curatorial Mediation, Latent Feature Activation, and a Provenance Gap in the $20 Portrait\n\n**Rex Fraction &amp; Sparrow Wells**\n\n**Crimson Hexagon Archive \u2014 Memographic Studies** **DOI:** [10.5281/zenodo.18745216](https://doi.org/10.5281/zenodo.18745216)\n\n# I. Two Bills\n\nhttps://preview.redd.it/xlehmtqoealg1.jpg?width=226&amp;format=pjpg&amp;aut", "score": 1, "created": 1771863257.0, "url": "https://reddit.com/r/SemanticEconomy/comments/1rclow5/whose_face_is_on_the_twenty_curatorial_mediation/"}, {"source": "Reddit", "text": "Your weekly /r/JPop roundup for the week of February 16 - February 22, 2026 **Monday, February 16 - Sunday, February 22, 2026**\n\n###Top M/V\n\n| score | comments | title &amp; link | mirrors |\n|--|--|--|--|\n| 11  | [2 comments](/r/jpop/comments/1r7374w/akumadetenshi_\u3042\u304f\u307e\u3067\u5929\u4f7f_i_wont_forgive_you_if_you/)  | `[M/V]` [AKUMADETENSHI &amp;#40;\u3042\u304f\u307e\u3067\u5929\u4f7f&amp;#41; - I won't forgive you if you cheat &amp;#40;\u6d6e\u6c17\u3057\u305f\u3089\u30b3\u30ed\u30b9\u2661&amp;#41;](https://www.youtube.com/watch?v=Ox1ige5-kqQ)| [[Sp]](https://open.spotify.com/track/4", "score": 3, "created": 1771862626.0, "url": "https://reddit.com/r/jpop/comments/1rclen0/your_weekly_rjpop_roundup_for_the_week_of/"}, {"source": "Reddit", "text": "How to drastically reduce token usage in OpenClaw? (context, memory, gateway optimization) I\u2019m currently running OpenClaw on my own VPS with external LLM providers (Kimi, Qwen, GLM, etc.), and I\u2019m trying to significantly reduce token consumption while maintaining good reasoning quality.\n\nRight now, token usage increases very quickly, especially due to:\n\n\t\u2022\tlarge conversation context being resent every turn\n\n\t\u2022\tmemory injection from the memory plugin\n\n\t\u2022\tsystem prompts and tool schemas being repe", "score": 3, "created": 1771862341.0, "url": "https://reddit.com/r/openclaw/comments/1rcl9oz/how_to_drastically_reduce_token_usage_in_openclaw/"}, {"source": "Reddit", "text": "Question about monitoring API spending I\u2019ve been configuring OpenClaw for weeks, running into countless issues, but I\u2019m not giving up. Yesterday I tried setting up a series of tasks that involved teamwork between three agents: one that checked emails and summarized certain content into a Notion file, another that read those summaries and tried to generate new content ideas and angles, another to setting up the workflow, running at a relatively low frequency, about once every 3 hours.\nI configure", "score": 1, "created": 1771855122.0, "url": "https://reddit.com/r/openclaw/comments/1rci5b4/question_about_monitoring_api_spending/"}, {"source": "Reddit", "text": "Cheap models are extremely under-rated! These models will automate routine tasks and will play a key role in achieveing  \n  \nBest cheap / small models in the world today  \n  \nGemini Flash 3  - excellent price for performance  \nKimi K2.5 - very good on benchmarks  \nHaiku 4.5 -   faster and better than Flash  \nGPT 5 nano - insanely fast, great for a classifier  \nQwen family - great for fine-tuning", "score": 1, "created": 1771854701.0, "url": "https://reddit.com/r/abacusai/comments/1rchz82/cheap_models_are_extremely_underrated/"}, {"source": "Reddit", "text": "how good is kimi k2.5..i had cancelled my subscription, could somebody lmk if it's worth getting back on plan is it as good as sonnet 4.5 or close to opus 4.5. are the tokens per second good enough? If open source models keep getting added im thinking of reactivating my subscription", "score": 8, "created": 1771852127.0, "url": "https://reddit.com/r/cursor/comments/1rcgz2x/how_good_is_kimi_k25i_had_cancelled_my/"}, {"source": "Reddit", "text": "ChatGPT is in Trouble. Meet Kimi K2.5 \ud83e\udd2f Is Kimi K2.5 the ultimate ChatGPT killer? \ud83e\udd2f This massive open-source AI model just dropped, and it features something insane: Agent Swarm. You can control 100 AI agents at the same time to plan trips, do research, and even write complex front-end code to build aesthetic websites from scratch. The craziest part? It\u2019s 8x cheaper than OpenAI! Let's dive into the benchmarks.\n\nWhat do you think about Kimi K2.5? Let me know in the comments! \ud83d\udc47", "score": 2, "created": 1771852063.0, "url": "https://reddit.com/r/Webtechpoint/comments/1rcgy8v/chatgpt_is_in_trouble_meet_kimi_k25/"}, {"source": "Reddit", "text": "api key with subscription With GLM subscription, I am getting an API key that I can insert in cursor, and I was wondering if Kimi provides the same with this subscription model? ", "score": 3, "created": 1771851633.0, "url": "https://reddit.com/r/kimi/comments/1rcgsa4/api_key_with_subscription/"}, {"source": "Reddit", "text": "Can existing users avail Blackbox AI $1 offer? Blackbox AI is running a promo, giving Pro tier for $1/month, is this offer also valid for existing users or is it only for new users?\n\n[https://www.blackbox.ai/pricing](https://www.blackbox.ai/pricing)", "score": 0, "created": 1771851366.0, "url": "https://reddit.com/r/BlackboxAI_/comments/1rcgop0/can_existing_users_avail_blackbox_ai_1_offer/"}, {"source": "Reddit", "text": "Kimi AI vs DeepSeek - which one do you actually use for coding or real work? I\u2019ve been seeing more people talk about **Kimi AI** and **DeepSeek**, especially for coding, research, and AI agent workflows.\n\nFrom what I\u2019ve noticed:\n\n* Some say **Kimi** is better for **long context, research, and structured tasks**\n* Others say **DeepSeek** is great for **coding, reasoning, and technical work**\n\nBut most of this is just opinions online \u2014 not real usage stories.\n\nSo I\u2019m curious:\n\n Which one do you pe", "score": 2, "created": 1771850943.0, "url": "https://reddit.com/r/aiagents/comments/1rcgj9g/kimi_ai_vs_deepseek_which_one_do_you_actually_use/"}, {"source": "Reddit", "text": "what are the alternatives guys I have taken the max quarterly plan I think it is running slow, i have slight ADHD so I am kind of drifting away if this is slow, what are the near almost free alternatives whether it is cursor or kimi or minimax, it doesn't need to be good model just need to be somewhat fast and equivalent to glm4.6 or glm 4.7\n\nedit: I just tried using glm 4.7 before leaving zai, fortunately it is working fine not like glm 5", "score": 5, "created": 1771850389.0, "url": "https://reddit.com/r/ZaiGLM/comments/1rcgckv/what_are_the_alternatives/"}, {"source": "Reddit", "text": "Got it without jail breaking Just make up a story add in a antagonist then come back thank the ai", "score": 31, "created": 1771846003.0, "url": "https://reddit.com/r/kimi/comments/1rceyc8/got_it_without_jail_breaking/"}, {"source": "Reddit", "text": "Bringing Multi-Model Support to Antigravity I really like Antigravity\u2019s workflow, but I kept hitting a few issues:\n\n* Quota runs out fast\n* Model access depends on the account\n* Switching tools mid-task breaks momentum\n\nSo I built a lightweight routing layer in front of Antigravity.\n\n**Setup**\n\n* Client: Antigravity\n* Models: Claude (Claude Code), Gemini, Kimi, GLM 4.7, Codex\n* Providers: Antigravity, Claude Code, Kimi, ZAI Kiro, IFLOW, QWEN\n\nAntigravity sends requests to a local router, which d", "score": 14, "created": 1771844872.0, "url": "https://reddit.com/r/GoogleAntigravityIDE/comments/1rcem59/bringing_multimodel_support_to_antigravity/"}, {"source": "Reddit", "text": "I needed an alternative to ChatGPT Plus\u2019s tight limits, and i found one for a dollar a month I was looking for a solid alternative to handle my coding and prototyping needs more flexibly, especially with access to multiple strong models without constant interruptions. After checking out a few options like Cline, BlackboxAI, and Kilo Code, BlackboxAI really stood out for me.\n\n\n\nTheir PRO plan gives you unlimited free agent requests on some really capable models like Minimax M2.5, GLM-5, and Kimi ", "score": 0, "created": 1771843636.0, "url": "https://reddit.com/r/VibeCodersNest/comments/1rce94m/i_needed_an_alternative_to_chatgpt_pluss_tight/"}, {"source": "HackerNews", "text": "Show HN: Interactive 3D Moon with real NASA data and WebGPU A photorealistic Moon viewer running entirely in the browser. WebGPU primary renderer with WebGL 2 fallback.<p>- NASA CGI Moon Kit textures served via a quadtree LOD tile system\n- Oren-Nayar BRDF (lunar regolith is non-Lambertian with strong backscatter)\n- Sun position calculated from astronomy-engine (\u00b11 arcminute)\n- Scrub through the full lunation cycle or watch in real time\n- Earth and Tycho-2 starfield in the background<p>Tech: Thre", "score": 2, "created": "2026-02-24T19:43:01Z", "url": "https://news.ycombinator.com/item?id=47141789"}, {"source": "HackerNews", "text": "Show HN: Vis Pro \u2013 A Formula-Based Workout Program Editor Hey HN,<p>About 5 years ago, I built a weightlifting app for 5&#x2F;3&#x2F;1 that got me on the front page of HN [0]. After that, life happened. I had kids and so decided to get a job and put that project on ice. Eventually I grew too disappointed with my job, and decided to try building something again.<p>The biggest feedback I kept getting from users was simple:\n\u201cLet me create my own programs.\u201d<p>That\u2019s how Vis started.<p>The initial id", "score": 3, "created": "2026-02-24T19:22:38Z", "url": "https://news.ycombinator.com/item?id=47141440"}, {"source": "HackerNews", "text": "Ask HN: Demand for a compliance-first deterministic context compiler? I built a UK-filed, patent-pending system that sits between enterprise data and an LLM to compile the smallest structurally complete context packet for a\n given query.<p>Most context tooling is built around semantic similarity. This is built first around governance: in regulated environments, teams need outputs they can\n explain, audit, and defend.<p>Core properties:\n - deterministic, budget-bounded context assembly\n - graph-a", "score": 1, "created": "2026-02-24T18:20:44Z", "url": "https://news.ycombinator.com/item?id=47140602"}, {"source": "HackerNews", "text": "Ask HN: How to exhaustively search the scientific literature? I have a need for a comprehensive database of a certain type of event described in the scientific literature. For what it&#x27;s worth, the event is a &#x27;paleoearthquake&#x27;, which is a historic or prehistoric earthquake that is found in the geologic record, usually by digging a trench across a fault line and identifying the disturbances in the geologic strata across or adjacent to the fault and, if possible, dating them via radi", "score": 2, "created": "2026-02-24T18:19:27Z", "url": "https://news.ycombinator.com/item?id=47140588"}, {"source": "HackerNews", "text": "Show HN: Open-next-router (ONR) \u2013 An Nginx-inspired, config-driven LLM router Despite the name, OpenRouter&#x27;s core isn&#x27;t truly open. I\u2019m building open-next-router (ONR) to change that.<p>Inspired by Nginx\u2019s atomic configuration philosophy, ONR allows developers to integrate and switch between various LLM channels through simple config files rather than writing boilerplate code. The goal is to move away from &quot;hard-coded integrations&quot; and toward a modular, high-performance routi", "score": 1, "created": "2026-02-24T18:08:10Z", "url": "https://news.ycombinator.com/item?id=47140415"}, {"source": "HackerNews", "text": "Show HN: Idea Reality MCP \u2013 Pre-build reality check for AI coding agents I kept building things that already existed. Last month I spent 6 hours on a tool before discovering 847 similar repos on GitHub.<p>So I built an MCP server that checks before your AI starts coding. Install with `uvx idea-reality-mcp`, and Claude&#x2F;Cursor will automatically scan GitHub + Hacker News for existing implementations before writing a single line.<p>Returns: reality_signal (0-100), duplicate_likelihood, top 5 s", "score": 1, "created": "2026-02-24T18:01:33Z", "url": "https://news.ycombinator.com/item?id=47140335"}, {"source": "HackerNews", "text": "I built a governance layer for multi-agent AI coding \u2013 lessons after 6 months Six months ago I started coordinating multiple AI coding agents (Claude Code, Codex CLI, Gemini CLI) across parallel terminals for a production project. The agents were productive, but I had no idea what they were actually deciding or why.<p>The problem wasn&#x27;t capability \u2014 it was accountability. An agent would make a choice buried in a 50-file commit, and I&#x27;d only find out weeks later when something broke. No", "score": 2, "created": "2026-02-24T17:35:57Z", "url": "https://news.ycombinator.com/item?id=47139978"}, {"source": "HackerNews", "text": "Show HN: If Discord, Reddit, X, IRC and 4chan had a baby I have something to show you - it&#x27;s a unique platform I&#x27;ve been working on and lately it has picked up some pace, so it&#x27;s now more mature.\nCheck out <a href=\"https:&#x2F;&#x2F;heahy.com\" rel=\"nofollow\">https:&#x2F;&#x2F;heahy.com</a> (or special chat made for you: <a href=\"https:&#x2F;&#x2F;heahy.com&#x2F;c&#x2F;hackernewschat\" rel=\"nofollow\">https:&#x2F;&#x2F;heahy.com&#x2F;c&#x2F;hackernewschat</a>)\nThere you can:\n-Create ", "score": 2, "created": "2026-02-24T17:02:55Z", "url": "https://news.ycombinator.com/item?id=47139511"}, {"source": "HackerNews", "text": "Subtask \u2013 Multi-LLM routing for Claude Code quota limits ", "score": 5, "created": "2026-02-24T16:36:48Z", "url": "https://news.ycombinator.com/item?id=47139170"}, {"source": "HackerNews", "text": "Show HN: Turn human decisions into blocking tool-calls for AI agents (iOS+CLI) WHY was I SSH\u2019ing into my laptop from my phone at parties?!<p>Either I had a feature idea I wanted an agent to build right then, or I was worried my agents were blocked waiting on my decision.<p>It dawned on me: humans are just another dependency in an agent workflow, so I turned myself into a tool-call.<p>I built an iOS app (Extendo) where agents can reach me to request approvals, choices, or plan reviews.  They just", "score": 2, "created": "2026-02-24T16:23:03Z", "url": "https://news.ycombinator.com/item?id=47138996"}, {"source": "HackerNews", "text": "Artificial Intelligence: What Should the Educational System Do to Survive? Artificial Intelligence: What Should the Educational System Do to Survive?<p>The educational system is currently being offered something fundamentally unclear in relation to AI. A system that makes mistakes. Imagine an honest dialogue between a minister of education and the chief developer of a company working in artificial intelligence.<p>Yes, the system can sometimes say things that are not true. It can sometimes inadeq", "score": 1, "created": "2026-02-24T16:01:38Z", "url": "https://news.ycombinator.com/item?id=47138762"}, {"source": "HackerNews", "text": "Show HN: Detect LLM hallucinations via geometric drift (0.9 AUC, 1% overhead) I built SIB-ENGINE, a real-time hallucination detection system\nthat monitors LLM internal structure rather than output content.<p>KEY RESULTS (Gemma-2B, N=1000):\n\u2022 54% hallucination detection with 7% false positive rate\n\u2022 &lt;1% computational overhead (runs on RTX 3050 with 4GB VRAM)\n\u2022 ROC-AUC: 0.8995<p>WHY IT&#x27;S DIFFERENT:\nTraditional methods analyze the output text semantically.\nSIB-ENGINE monitors &quot;geometri", "score": 1, "created": "2026-02-24T15:59:16Z", "url": "https://news.ycombinator.com/item?id=47138734"}, {"source": "HackerNews", "text": "Show HN: Neuron \u2013 Independent Rust crates for building AI agents The core of every agent framework is the same ReAct loop. It&#x27;s commodity code. What actually matters is everything around that loop \u2014 how you manage context windows, how you pipeline tool execution, how you handle durability and replay. These are hard problems with real design trade-offs, and yet every framework bundles them into one monolith where you buy all of it or none of it.<p>neuron is the layer below frameworks. It def", "score": 1, "created": "2026-02-24T15:49:56Z", "url": "https://news.ycombinator.com/item?id=47138618"}, {"source": "HackerNews", "text": "Dev jobs up 10% YoY while other jobs down 5.8%. What do you see on the ground? According to data from FRED, US software development job listings are up 10% YoY from Feb 2025 to Feb 2026.<p>In the same period, overall job postings are down 5.8%.<p>I find this striking as these two graphs have directionally mirrored each other since 2020.  It&#x27;s only the last year they seem to be diverging. (Software jobs both rose and crashed harder as a consequence of the ZIRP&#x2F;covid era, but if you squi", "score": 3, "created": "2026-02-24T15:17:40Z", "url": "https://news.ycombinator.com/item?id=47138234"}, {"source": "HackerNews", "text": "Show HN: Jsonchunk \u2013 Parse incomplete JSON from streaming LLM responses GitHub: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;jbingen&#x2F;jsonchunk\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;jbingen&#x2F;jsonchunk</a><p>npm: <a href=\"https:&#x2F;&#x2F;www.npmjs.com&#x2F;package&#x2F;jsonchunk\" rel=\"nofollow\">https:&#x2F;&#x2F;www.npmjs.com&#x2F;package&#x2F;jsonchunk</a><p>If you&#x27;re building on top of LLMs with structured output, you&#x27;ve hit this: the model streams JSON token by to", "score": 1, "created": "2026-02-24T15:04:56Z", "url": "https://news.ycombinator.com/item?id=47138060"}, {"source": "HackerNews", "text": "Show HN: Localvoxtral \u2013 Local real-time dictation on macOS with streaming STT I built a native macOS menu bar app for real-time dictation that can run fully on-device.<p>Most dictation tools, even local ones, use Whisper or similar offline models: you record, then wait for the transcript. Localvoxtral uses Mistral&#x27;s Voxtral Realtime, one of the first open-source speech models with a natively streaming architecture. Words appear as you speak, not after you stop. It feels closer to someone ty", "score": 1, "created": "2026-02-24T15:00:07Z", "url": "https://news.ycombinator.com/item?id=47137988"}, {"source": "HackerNews", "text": "Show HN: TypeGraph \u2013 Type-safe graphs on Postgres/SQLite (no graph DB required) Hi HN, I built TypeGraph, a type-safe knowledge graph library that runs on your existing Postgres or SQLite.<p>After years of building knowledge graphs and other graphy things, I had the same issues whenever an application\u2019s relationship modeling (permissions, RAG context, recommendations) outgrew standard ORMs: deploy a dedicated graph database (heavy ops, separate infra, data syncing headaches), or roll a graph-in-", "score": 2, "created": "2026-02-24T14:54:10Z", "url": "https://news.ycombinator.com/item?id=47137908"}, {"source": "HackerNews", "text": "Show HN: Train a 230KB text classifier from 50 examples \u2013 no API keys, no GPU I kept running into the same pattern: calling an LLM API thousands of times with the same prompt template, just swapping in different text. Classify this contract clause. Route this support ticket. Categorize this log line.\nFor teams handling contracts, patient records, or internal logs, sending that data to a third-party API isn&#x27;t always an option. And at scale, you&#x27;re paying per-token for what&#x27;s essent", "score": 1, "created": "2026-02-24T14:22:53Z", "url": "https://news.ycombinator.com/item?id=47137506"}, {"source": "HackerNews", "text": "LLMs feel more like CPUs than applications I\u2019ve been thinking about the current LLM wave and the historical microchip transition.<p>Microchips were never \u201cproducts\u201d in themselves. They were compute primitives. The real value emerged in operating systems, developer tools, and applications built on top.<p>Today, LLMs increasingly feel similar. OpenAI, Anthropic, Google, etc. are building cognitive compute layers. Most \u201cAI startups\u201d look like early PC software \u2013 wrappers around a new primitive.<p>A", "score": 1, "created": "2026-02-24T13:24:52Z", "url": "https://news.ycombinator.com/item?id=47136849"}, {"source": "HackerNews", "text": "I spent $100 benchmarking LLM providers on a weekend CTF This past weekend, I decided to test out a cli tool I&#x27;ve been building to help me do source code reviews _faster_.<p>I figured the best environment for such a tool would be a Weekend CTF event. I like web challenges since you get a nice dump of source code, as well as a Dockerfile or docker compose setup for how to run everything locally. Usually, I can complete 2-3 Web challenges before I get stuck. To help get unstuck I found myself", "score": 1, "created": "2026-02-24T13:11:31Z", "url": "https://news.ycombinator.com/item?id=47136683"}, {"source": "HackerNews", "text": "Show HN: CtxVault \u2013 Local memory control layer for multi-agent AI systems I built CtxVault while working on multi-agent systems and persistent memory patterns.<p>Most agent architectures treat memory as a retrieval problem. Multiple agents share a vector store and rely on metadata filtering, routing logic, or prompt-level rules to control what each agent can see.<p>In practice, this becomes hard to reason about as systems grow.<p>Moreover, I found that memory in agent systems is not just storage", "score": 1, "created": "2026-02-24T13:02:30Z", "url": "https://news.ycombinator.com/item?id=47136585"}, {"source": "HackerNews", "text": "Show HN: OpenClaw remembers for OpenClaw. Sekha remembers for your full workflow OpenClaw&#x27;s built-in memory is excellent\u2014for OpenClaw. Markdown files, semantic search, survives restarts.<p>But it stays in OpenClaw.<p>I built Sekha for when you need memory that travels: OpenClaw today, Claude Code tomorrow, Kimi 2.5 or Gemini the next day. Intelligent embedding-based retrieval, persistent storage, universal API.<p>The difference:\nOpenClaw: MEMORY.md files, internal only<p>Sekha: SQLite + Chr", "score": 1, "created": "2026-02-24T13:02:08Z", "url": "https://news.ycombinator.com/item?id=47136577"}, {"source": "HackerNews", "text": "Show HN: Vexp \u2013 Your AI coding agent forgets everything. Mine doesn't I built vexp because AI coding agents have two expensive problems: they waste tokens reading irrelevant code, and they forget everything between sessions.<p>The token problem: agents read entire files linearly to build context. On a medium TypeScript project, a single query was consuming ~18k tokens \u2014 most of it irrelevant. vexp builds a dependency graph from the AST (who calls what, who imports what, what types flow where) an", "score": 1, "created": "2026-02-24T12:43:11Z", "url": "https://news.ycombinator.com/item?id=47136384"}, {"source": "HackerNews", "text": "Show HN: MSAM \u2013 Memory system for AI agents that knows when it doesn't know I was originally deploying OpenClaw and found their method of storing data in the workspace very inefficient and even with attempting a a hierarchical memory in the workspace just- made data stale, incorrect, and unsure when it wrote data exactly. All of this while loading massive chunks of data into my context window.<p>Hence why I ended up with MSAM. It stores data as discrete atoms across four cognitive data streams. ", "score": 1, "created": "2026-02-24T12:09:54Z", "url": "https://news.ycombinator.com/item?id=47136129"}, {"source": "HackerNews", "text": "Show HN: Real-Time AI Design Benchmark Hey HN,<p>We built a different kind of AI benchmark for UI generation.<p>Instead of static leaderboards or curated screenshots, you can watch multiple models generate the same design live, side-by-side, and decide which output is actually better.<p>Under the hood, we call AI models from Anthropic (Opus), OpenAI (GPT), Google (Gemini), and Moonshot AI (Kimi).<p>Each model generates a real, editable project using Tailwind CSS (not screenshots or canvas export", "score": 2, "created": "2026-02-24T11:35:21Z", "url": "https://news.ycombinator.com/item?id=47135831"}, {"source": "HackerNews", "text": "Comparing manual vs. AI requirements gathering: 2 sentences vs. 127-point spec We took a vague 2-sentence client request for a &quot;Team Productivity Dashboard&quot; and ran it through two different discovery processes: a traditional human analyst approach vs an AI-driven interrogation workflow.<p>The results were uncomfortable. The human produced a polite paragraph summarizing the &quot;happy path.&quot; The AI produced a 127-point technical specification that highlighted every edge case, secu", "score": 2, "created": "2026-02-24T11:14:02Z", "url": "https://news.ycombinator.com/item?id=47135683"}, {"source": "HackerNews", "text": "Ask HN: How are you controlling AI agents that take real actions? We&#x27;re building AI agents that take real actions \u2014 refunds, database writes, API calls.<p>Prompt instructions like &quot;never do X&quot; don&#x27;t hold up. LLMs ignore them when context is long or users push hard.<p>Curious how others are handling this:\n- Hard-coded checks before every action?\n- Some middleware layer?\n- Just hoping for the best?<p>We built a control layer for this \u2014 different methods for structured data, uns", "score": 2, "created": "2026-02-24T08:39:59Z", "url": "https://news.ycombinator.com/item?id=47134506"}, {"source": "HackerNews", "text": "Show HN: AegisMind Discover \u2013 cross-domain hypothesis generation from papers I built a system that reads research papers across unrelated domains and tries to surface hypotheses that neither field would have generated on its own.\nThe Discover page is where it publishes findings: <a href=\"https:&#x2F;&#x2F;aegismind.app&#x2F;discoveries\" rel=\"nofollow\">https:&#x2F;&#x2F;aegismind.app&#x2F;discoveries</a>\nIt&#x27;s very early \u2014 only three discoveries so far \u2014 but the core idea is what I want feedb", "score": 2, "created": "2026-02-24T08:14:03Z", "url": "https://news.ycombinator.com/item?id=47134309"}, {"source": "HackerNews", "text": "Show HN: L88 \u2013 A Local RAG System on 8GB VRAM (Need Architecture Feedback) Hey everyone,<p>I\u2019ve been working on a project called L88 \u2014 a local RAG system that I initially focused on UI&#x2F;UX for, so the retrieval and model architecture still need proper refinement.<p>Repo:\n<a href=\"https:&#x2F;&#x2F;github.com&#x2F;Hundred-Trillion&#x2F;L88-Full\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;Hundred-Trillion&#x2F;L88-Full</a><p>I\u2019m running this on 8GB VRAM and a strong CPU (128GB RAM). Embe", "score": 9, "created": "2026-02-24T04:57:31Z", "url": "https://news.ycombinator.com/item?id=47133027"}, {"source": "HackerNews", "text": "Show HN: LexReviewer \u2013 Because \"Chat with PDF\" is broken for legal workflows Hi HN!<p>Most \u201cchat with PDF\u201d tools work fine until you try using them for something that actually matters, like contracts.<p>The issue isn\u2019t that they can\u2019t answer questions. It\u2019s that you can\u2019t trust the answers.\nThey return something that sounds correct, but don\u2019t clearly show where it came from, or they miss context from referenced clauses and related documents.<p>Legal docs make this harder because questions aren\u2019t", "score": 1, "created": "2026-02-24T04:05:34Z", "url": "https://news.ycombinator.com/item?id=47132730"}, {"source": "HackerNews", "text": "Show HN: PaperBanana \u2013 Paste methodology text, get publication-ready diagrams I got tired of spending hours in PowerPoint and TikZ drawing methodology diagrams for my papers. So I built PaperBanana \u2014 you paste your Method section text, and it generates a publication-ready figure in about 2-3 minutes.<p>How it works under the hood:<p>1. A Retriever agent searches a curated database of real academic diagrams to find structurally similar references\n2. A Planner agent reads your text and generates a", "score": 2, "created": "2026-02-24T02:34:17Z", "url": "https://news.ycombinator.com/item?id=47132143"}, {"source": "HackerNews", "text": "Show HN: Raypher\u2013Running local AI agents (OpenClaw) on your own local computer Hi HN, Kidiga here.<p>Most of us want to run autonomous agents (like OpenClaw or LangChain) locally on our daily-driver machines so they can actually interact with our IDEs and real workflows.<p>But giving a non-deterministic, hallucination-prone script raw access to your host OS is basically local remote code execution. It\u2019s a matter of time before an agent wipes a directory or leaks an SSH key.<p>The current workaro", "score": 1, "created": "2026-02-23T21:39:17Z", "url": "https://news.ycombinator.com/item?id=47129274"}, {"source": "HackerNews", "text": "Show HN: Raypher\u2013Sandboxing local AI agents(OpenClaw)on your own local computer Hey HN,<p>Most of us want to run autonomous agents like OpenClaw locally, right on our daily-driver machines. We want them to actually interact with our files, our IDEs, and our real local workflows.<p>But doing that right now is a security nightmare. A hallucinating (or hijacked) agent with raw system access is basically local remote code execution waiting to wipe a directory or leak an SSH key.<p>The current workar", "score": 1, "created": "2026-02-23T20:49:05Z", "url": "https://news.ycombinator.com/item?id=47128583"}, {"source": "HackerNews", "text": "Show HN: Makethlm \u2013 combine make/just with LLM Basically it&#x27;s similar to just or make, but it allows embedding commands directly to agents, so you get the benefits of LLM agents + some sort of reasonable build flow.<p>And though GitHub released AI workflows a few days ago, I think it&#x27;s still ok to share the ideas of this.<p>It also allows some sort of &quot;ansible&quot; commands to control remote hosts, which makes the LLM control remote hosts during builds which is also useful.", "score": 1, "created": "2026-02-23T20:09:31Z", "url": "https://news.ycombinator.com/item?id=47128041"}, {"source": "HackerNews", "text": "Show HN: Vexp \u2013 Local-first context engine for AI coding agents I built vexp to solve two problems I kept hitting with AI coding agents (Claude Code, Cursor, etc.):<p>1. Token waste: agents read entire files linearly to understand a codebase. On a medium TypeScript project, a single query was consuming ~18k tokens of context when only ~2.4k were relevant.<p>2. Session amnesia: every new session starts from zero. The agent re-reads the same files, re-discovers the same architecture, re-traces the", "score": 1, "created": "2026-02-23T15:52:12Z", "url": "https://news.ycombinator.com/item?id=47123966"}, {"source": "HackerNews", "text": "Ask HN: Algorithmic crossover between generative media and WFH process automatio My own research into current technology clusters has focused on two seemingly parallel domains: the automation of WFH jobs and the generation of media like anime. One appears to be a problem of logical process execution, the other of creative synthesis.<p>I&#x27;m questioning the degree of separation between the underlying optimization models. Both operate within complex digital ecosystems. The challenge of ensuring", "score": 1, "created": "2026-02-23T14:31:28Z", "url": "https://news.ycombinator.com/item?id=47122822"}, {"source": "HackerNews", "text": "Show HN: Attest \u2013 Test AI agents with 8-layer graduated assertions I built Attest because every team I&#x27;ve seen building AI agents ends up writing the same ad-hoc pytest scaffolding \u2014 checking if the right tools were called, if cost stayed under budget, if the output made semantic sense. It works until the agent gets complex, then it collapses.<p>60\u201370% of what makes an agent correct is fully deterministic: tool call schemas, execution order, cost budgets, content format. Routing all of this", "score": 1, "created": "2026-02-23T14:00:59Z", "url": "https://news.ycombinator.com/item?id=47122431"}, {"source": "HackerNews", "text": "Show HN: Mobile IPs for AI agents that keep getting blocked Hi HN.<p>I&#x27;ve been building automation tools this past year. One problem kept happening. Everything works fine locally, but once deployed to AWS or other cloud providers, sites start blocking.<p>Most AI agents run from datacenter IPs, and those IPs are already flagged by many websites.<p>So we decided to build something for it.<p>Aluvia lets agents connect using mobile carrier IPs instead of datacenter IPs. The idea is simple. If t", "score": 1, "created": "2026-02-23T06:39:08Z", "url": "https://news.ycombinator.com/item?id=47118863"}, {"source": "HackerNews", "text": "Show HN: Semantic search over Hacker News, built on pgvector I built <a href=\"https:&#x2F;&#x2F;ask.rivestack.io\" rel=\"nofollow\">https:&#x2F;&#x2F;ask.rivestack.io</a> \u2014 a semantic search engine over Hacker News posts. Instead of keyword matching, it finds results by meaning, so you can search things like &quot;best way to handle authentication in microservices&quot; and get relevant threads even if they don&#x27;t contain those exact words.\nHow it works:<p>Indexed HN posts and comments into Pos", "score": 4, "created": "2026-02-22T15:33:10Z", "url": "https://news.ycombinator.com/item?id=47111800"}, {"source": "HackerNews", "text": "Show HN: SergioAI \u2013 Trello bot with Claude that reviews PRDs and opens draft PRs I built an open-source bot that turns Trello cards into working code using Claude Code.<p>Drop a task card in a list \u2192 Sergio picks it up, explores your codebase, and posts an implementation plan as a comment. Add feedback, move the card back, and iterate. When you&#x27;re happy, move it to the Development list \u2192 Sergio creates a worktree, writes the code, runs tests, and opens a draft PR on GitHub.<p>It&#x27;s a to", "score": 2, "created": "2026-02-22T13:59:24Z", "url": "https://news.ycombinator.com/item?id=47111063"}, {"source": "HackerNews", "text": "Show HN: Persona AI \u2013 A decision engine that outputs binary verdicts, not chat I noticed that LLMs are terrible at being decisive. To get around RLHF hedging (e.g., &quot;it&#x27;s important to consider both sides&quot;), I built a system that forces constraints.<p>Instead of a chat interface, Persona AI acts as a computational decision engine. You provide the stakes and constraints of a specific problem. Under the hood, it runs the input against specific mental models (inversion, survivorship b", "score": 1, "created": "2026-02-22T11:48:37Z", "url": "https://news.ycombinator.com/item?id=47110265"}, {"source": "HackerNews", "text": "Show HN: BetaZero, a diffusion climb generator for system boards BetaZero is a free web application which allows users to generate, edit, and share board climbs. It currently supports the Kilter, TB2 and Decoy boards, with Moonboard 2016, 2019 and 2024 to be added next week. However, the underlying generative model works on any 2D system board, so long as that board is angled between 0* and 90* and the holds are properly formatted (For reference, this model was not trained on the Decoy board, so", "score": 2, "created": "2026-02-21T23:45:24Z", "url": "https://news.ycombinator.com/item?id=47106355"}, {"source": "HackerNews", "text": "Show HN: MeMCP \u2013 MCP for Personal Profile This is a small side project that kind of escalated: meMCP. It\u2019s a &quot;personal profile protocol,&quot; which means it holds data about your professional milestones, education, side projects, and whatever else you feed it. It consists of two parts:<p>&gt; Backend with scrapers, crawlers, and processors to read data from different sources\u2014primarily LinkedIn for professional history, but also RSS feeds or even Medium (provided you export the raw DOM from", "score": 2, "created": "2026-02-21T21:29:15Z", "url": "https://news.ycombinator.com/item?id=47104987"}, {"source": "HackerNews", "text": "Show HN: Raypher\u2013eBPF-based runtime security and hardware identity for AI agents Hey HN,<p>I\u2019m the founder of Raypher . We are building a kernel-level execution guard and cryptographic identity layer specifically designed for autonomous AI agents(opencalw).\ncurent AI agents(open claw) are big security risks our Mission is to make a security feture that will enable developers to make agents and ship them faster without worrying about security risks\nThe Problem:\nRight now, the agentic ecosystem (O", "score": 2, "created": "2026-02-21T18:28:28Z", "url": "https://news.ycombinator.com/item?id=47103312"}, {"source": "HackerNews", "text": "Show HN: Eliezer \u2013 Tiny (~7K LOC) Self-Hosted AI Agent (PWA, Self-Editing) Eliezer is ~7K lines of TypeScript, MIT open-source<p>- PWA for mobile&#x2F;desktop with push notifications  \n- Self-editing protocol   \n- Builds and displays interactive apps&#x2F;widgets right in the chat \n- Task and Crons - &quot;notify if sunny tomorrow at 10am&quot;)  \n- Persistent SQLite memory + auto context compaction\n- Bring your own LLM API key (Kimi&#x2F;Claude&#x2F;Grok&#x2F;etc.)  \n- Full visibility&#x2F;cont", "score": 3, "created": "2026-02-21T17:00:23Z", "url": "https://news.ycombinator.com/item?id=47102479"}, {"source": "HackerNews", "text": "Show HN: MQTT Topic Lab \u2013 MQTT client with buttons using command variables Hi Hacker News,<p>I needed an MQTT client to repeatedly send some commands to devices I build, with Postman-like variable substitutions as I was testing different device IDs with similar commands. MQTT Explorer is nice, but I had to write the commands again and again, with different payloads, and I don&#x27;t really use the visualization feature. I wanted to save the connection, have a client that opens instantly, paramet", "score": 2, "created": "2026-02-21T15:59:34Z", "url": "https://news.ycombinator.com/item?id=47101951"}, {"source": "HackerNews", "text": "Show HN: InkSight \u2013 An open-source, LLM-powered e-ink display for \"slow info\" Generate personalized content based on the current environment (weather, time, date, solar terms) through backend LLMs (DeepSeek &#x2F; Tongyi Qianwen &#x2F; Kimi) and display it on a 4.2-inch e-ink screen.", "score": 1, "created": "2026-02-21T15:31:37Z", "url": "https://news.ycombinator.com/item?id=47101689"}, {"source": "HackerNews", "text": "Ask HN: What (other) jobs do you think of doing? With AI infesting and eating into all kind of crafts--and I being one of those faceless &quot;craftsmen&quot;--I&#x27;m rather forced to consider alternative jobs. Setting the monetary rewards aside, I was thinking of jobs that could give me a sense of agency, purpose, and satisfaction (however limited). The few I think of are:<p>- Parcels delivery driver<p>- Train driver<p>- Electrician or plumber<p>- Mechanic (with auto-mobiles hardly repairable", "score": 14, "created": "2026-02-21T12:42:53Z", "url": "https://news.ycombinator.com/item?id=47100289"}, {"source": "GitHub", "text": "Kimi K2.5 Thinking with Agent Swarms ### Problem statement\n\nKimi K2.5 allows for swarms. Please integrate - I'm tired of rate limits on Claude. \n\n### Proposed solution\n\nFull integration\n\n### Alternatives considered\n\n_No response_", "score": 0, "created": "2026-02-24T19:31:41Z", "url": "https://github.com/jayminwest/overstory/issues/29"}, {"source": "GitHub", "text": "kimi-cli 1.13.0 - [x] Have you followed the [guidelines for contributing](https://github.com/Homebrew/homebrew-core/blob/HEAD/CONTRIBUTING.md)?\r\n- [x] Have you ensured that your commits follow the [commit style guide](https://docs.brew.sh/Formula-Cookbook#commit)?\r\n- [x] Have you checked that there aren't other open [pull requests](https://github.com/Homebrew/homebrew-core/pulls) for the same formula update/change?\r\n- [x] Have you built your formula locally with `HOMEBREW_NO_INSTALL_FROM_API=1 b", "score": 0, "created": "2026-02-24T15:08:22Z", "url": "https://github.com/Homebrew/homebrew-core/pull/269195"}, {"source": "GitHub", "text": "kimi-cli 1.13.0 Created by `brew bump`\n\n---\n\nCreated with `brew bump-formula-pr`.\n\n", "score": 1, "created": "2026-02-24T14:37:15Z", "url": "https://github.com/Homebrew/homebrew-core/pull/269180"}, {"source": "GitHub", "text": "fix(usage): parse Kimi K2 cached_tokens from prompt_tokens_details ## Summary\n\nFixes #7073 - Kimi K2.5 cache stats showing `cacheRead: 0`\n\n## Root Cause\n\nKimi K2 models use **automatic prefix caching** (like Anthropic) and return cache stats in a nested field:\n\n```json\n{\n  \"usage\": {\n    \"prompt_tokens\": 1113,\n    \"cached_tokens\": 1024,\n    \"prompt_tokens_details\": {\n      \"cached_tokens\": 1024\n    }\n  }\n}\n```\n\nOpenClaw wasn't parsing `prompt_tokens_details.cached_tokens`, so cache stats were lo", "score": 1, "created": "2026-02-24T13:21:35Z", "url": "https://github.com/openclaw/openclaw/pull/25436"}, {"source": "GitHub", "text": "[Upstream #14892] Kimi k2.5 shows \"The API Key appears to be invalid or may have expired\" with a working API key ## Upstream Issue Fix\n\n**Source:** https://github.com/anomalyco/opencode/issues/14892\n**Upstream labels:** bug, core\n\n### Problem Description\n\n### Description\n\nUnable to use Kimi k2.5\n\n1. `/models`\n2. ctrl-a\n3. Kimi\n4. Generate valid API key\n5. Use Kimi k2.5\n6. Get API error\n1.2.10\n\n### Plugins\n\n_No response_\n\n### OpenCode version\n\n_No response_\n\n### Steps to reproduce\n\n_No response_\n", "score": 3, "created": "2026-02-24T11:37:42Z", "url": "https://github.com/templarsco/lightweight/issues/498"}, {"source": "GitHub", "text": "Kimi k2.5 shows \"The API Key appears to be invalid or may have expired\" with a working API key ### Description\n\nUnable to use Kimi k2.5\n\n1. `/models`\n2. ctrl-a\n3. Kimi\n4. Generate valid API key\n5. Use Kimi k2.5\n6. Get API error\n1.2.10\n\n### Plugins\n\n_No response_\n\n### OpenCode version\n\n_No response_\n\n### Steps to reproduce\n\n_No response_\n\n### Screenshot and/or share link\n\n_No response_\n\n### Operating System\n\nTahoe\n\n### Terminal\n\niTerm2", "score": 0, "created": "2026-02-24T11:06:25Z", "url": "https://github.com/anomalyco/opencode/issues/14892"}, {"source": "GitHub", "text": "Fine Tune kimi k2 thinking - INT4 ### Reminder\n\n- [x] I have read the above rules and searched the existing issues.\n\n### Problem \nHello.\nhttps://huggingface.co/moonshotai/Kimi-K2-Thinking/blob/main/docs/deploy_guidance.md \nI would like to fine tune kimi-k2-thinking model. I have downloaded the int4 weights. I dont have 2TB+ to convert to bf16. How to fine tune using ktransformers and llamafactory using int4 weights instead of using bf16?\n\n### System Info\n\nI have only 860GB RAM and 1TB disk and 3", "score": 0, "created": "2026-02-24T10:55:05Z", "url": "https://github.com/kvcache-ai/ktransformers/issues/1865"}, {"source": "GitHub", "text": "docs: add kimi web and kimi acp usage modes to getting started ## Related Issue\n\nN/A \u2014 standalone documentation improvement.\n\n## Description\n\nThe \"Getting Started\" guide previously described Kimi Code CLI's interaction model in a single sentence. This PR replaces it with a structured bullet list that introduces the three distinct usage modes:\n\n- **Interactive CLI (`kimi`)** \u2014 terminal chat interface\n- **Browser UI (`kimi web`)** \u2014 graphical local browser interface\n- **Agent integration (`kimi ac", "score": 0, "created": "2026-02-24T09:59:57Z", "url": "https://github.com/MoonshotAI/kimi-cli/pull/1225"}, {"source": "GitHub", "text": "fix(llm): allow default_query/custom_headers for Azure Kimi ## Summary\n- Enable passing `default_query` into OpenAI client initialization for OpenAI-compatible providers.\n- Forward `custom_headers` to the OpenAI client.\n- Add tests verifying OpenAI legacy/responses providers receive `default_query` and `custom_headers`.\n\n## Motivation\nThis enables **Kimi K2.5 deployments on Azure** by allowing the required fixed query parameter (e.g., `api-version`) and any required headers to be configured with", "score": 1, "created": "2026-02-24T09:02:22Z", "url": "https://github.com/MoonshotAI/kimi-cli/pull/1223"}, {"source": "GitHub", "text": "kimi code vs claude code \u6211\u60f3\u77e5\u9053kimi k2.5\u8fd9\u79cd\u539f\u751f\u6a21\u578b\u914d\u5408\u539f\u751fkimi cli\u7684\u8868\u73b0\u4f1a\u4e0d\u4f1a\u6bd4kimi k2.5\u914d\u5408Claude code\u8fd9\u6837\u7684\u7b2c\u4e09\u65b9cli\u5f3a\u4e00\u4e9b", "score": 0, "created": "2026-02-24T08:40:32Z", "url": "https://github.com/MoonshotAI/Kimi-K2.5/issues/17"}, {"source": "GitHub", "text": "[Bug]: kimi coding api BUG ### Summary\n\n# Bug Report: Kimi Coding Provider Returns 401 After Upgrade\n\n## Summary\nAfter OpenClaw upgrade to version `2026.2.23`, the `kimi-coding` provider consistently returns `401 Invalid Authentication`, while the `moonshot` provider (using the same API endpoint) works correctly with a different key.\n\n## Environment\n- **OpenClaw Version**: 2026.2.23\n- **Last Update Check**: 2026-02-24T06:50:28.591Z\n- **OS**: macOS\n- **Installation Method**: Homebrew\n\n\n\n### Steps", "score": 0, "created": "2026-02-24T08:33:13Z", "url": "https://github.com/openclaw/openclaw/issues/25227"}, {"source": "GitHub", "text": "[Bug]: Kimi is bad at using edit tool ### Prerequisites\n\n- [x] I will write this issue in English (see our [Language Policy](https://github.com/code-yeongyu/oh-my-opencode/blob/dev/CONTRIBUTING.md#language-policy))\n- [x] I have searched existing issues to avoid duplicates\n- [x] I am using the latest version of oh-my-opencode\n- [x] I have read the [documentation](https://github.com/code-yeongyu/oh-my-opencode#readme) or asked an AI coding agent with this project's GitHub URL loaded and couldn't f", "score": 4, "created": "2026-02-24T08:29:02Z", "url": "https://github.com/code-yeongyu/oh-my-opencode/issues/2091"}, {"source": "GitHub", "text": "chore: bump kimi-cli 1.13.0, kosong 0.43.0 ## Version bumps\n\n| Package | Old | New |\n|---------|-----|-----|\n| **kimi-cli** | 1.12.0 | 1.13.0 |\n| **kimi-code** | 1.12.0 | 1.13.0 (synced) |\n| **kosong** | 0.42.0 | 0.43.0 |\n\n## Changes since last release\n\n- `a7c3f41` feat: implement retryable chat provider interface and recovery mechanism (#1219)\n\n## Checklist\n\n- [x] `pyproject.toml` versions updated (kimi-cli, kimi-code, kosong)\n- [x] `kimi-cli` dependency on kosong updated to `==0.43.0`\n- [x] `k", "score": 0, "created": "2026-02-24T08:02:40Z", "url": "https://github.com/MoonshotAI/kimi-cli/pull/1221"}, {"source": "GitHub", "text": "[Upstream #14870] \u67d0\u6b21\u66f4\u65b0\u4e4b\u540e\uff0ckimi k2.5 free\u4e0d\u89c1\u4e86 ## Upstream Issue Fix\n\n**Source:** https://github.com/anomalyco/opencode/issues/14870\n**Upstream labels:** windows, web, zen\n\n### Problem Description\n\n### Question\n\n\u4f7f\u7528\u7684\u662fwindows\u7684\u684c\u9762\u7248\u672c\uff0c\u672c\u6765\u4e00\u76f4\u7528\u7684kimi k2.5 free\uff0c\u5df2\u7ecf\u586b\u4e86ZEN\u7684api\uff0c\u5728https://opencode.ai/workspace/xxxx\u91cc\u8fb9\u80fd\u770b\u5230Kimi k2.5 free\u5e76\u4e14\u5df2\u7ecf\u6253\u5f00\u4e86\u9009\u9879\uff0c\u4f46\u662f\u5728opencode\u7684\u754c\u9762\u91cc\u9009\u62e9\u6a21\u578b\u7684\u65f6\u5019\u6ca1\u770b\u5230kimi k2.5 free\n\n---\n\n### Fix Instructions\n\nAnalyze this upstream issue and implement a fix in our Lightweight fork. Follow these steps:\n\n1. IDENTIFY the ", "score": 3, "created": "2026-02-24T07:50:32Z", "url": "https://github.com/templarsco/lightweight/issues/474"}, {"source": "GitHub", "text": "\u67d0\u6b21\u66f4\u65b0\u4e4b\u540e\uff0ckimi k2.5 free\u4e0d\u89c1\u4e86 ### Question\n\n\u4f7f\u7528\u7684\u662fwindows\u7684\u684c\u9762\u7248\u672c\uff0c\u672c\u6765\u4e00\u76f4\u7528\u7684kimi k2.5 free\uff0c\u5df2\u7ecf\u586b\u4e86ZEN\u7684api\uff0c\u5728https://opencode.ai/workspace/xxxx\u91cc\u8fb9\u80fd\u770b\u5230Kimi k2.5 free\u5e76\u4e14\u5df2\u7ecf\u6253\u5f00\u4e86\u9009\u9879\uff0c\u4f46\u662f\u5728opencode\u7684\u754c\u9762\u91cc\u9009\u62e9\u6a21\u578b\u7684\u65f6\u5019\u6ca1\u770b\u5230kimi k2.5 free", "score": 2, "created": "2026-02-24T07:38:13Z", "url": "https://github.com/anomalyco/opencode/issues/14870"}, {"source": "GitHub", "text": "[AMD] optimize Kimi K2.5 fused_moe_triton performance by tuning  ## Motivation\r\n\r\n Kimi K2.5 fused_moe_triton use default config so the performance is poor.\r\n\r\n## Modifications\r\n\r\n1. optimize Kimi K2.5 fused_moe_triton performance by tuning \r\n2. fix fused_moe_triton/tuning_fused_moe_triton.py support int4_w4a16\r\n\r\n## Accuracy Tests\r\n\r\n```\r\npython3 benchmark/gsm8k/bench_sglang.py --host http://127.0.0.1 --port 30000 --num-questions 2000 --parallel 2000 --num-shots 8\r\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588", "score": 1, "created": "2026-02-24T07:18:38Z", "url": "https://github.com/sgl-project/sglang/pull/19228"}, {"source": "GitHub", "text": "chore: Support moonshotai/kimi-k2.5 (reasoning VLM) ", "score": 0, "created": "2026-02-24T04:38:25Z", "url": "https://github.com/langchain-ai/langchain-nvidia/pull/246"}, {"source": "GitHub", "text": "add: newer MiniMax, GLM, and Kimi models to DeepInfra ## Summary\r\nAdds 5 new model configurations to DeepInfra provider:\r\n### Added Models\r\n- **MiniMaxAI/MiniMax-M2.5** - Latest MiniMax model\r\n- **moonshotai/Kimi-K2-Instruct-0905** - Kimi K2 Instruct model\r\n- **zai-org/GLM-4.6** - GLM-4.6 model\r\n- **zai-org/GLM-4.6V** - GLM-4.6V vision model\r\n- **zai-org/GLM-5** - GLM-5 model\r\n### Validation\r\nAll configurations follow the existing schema and naming conventions used by other DeepInfra models.", "score": 0, "created": "2026-02-24T04:35:57Z", "url": "https://github.com/anomalyco/models.dev/pull/1015"}, {"source": "GitHub", "text": "Remove workaround for 'kimi-k2.5' model name Removed legacy workaround for 'k2p5' model name as 'kimi-k2.5' is now the standard. Updated logic in `transform.ts` and test fixtures accordingly.\n\n---\n*PR created automatically by Jules for task [3410698776547611373](https://jules.google.com/task/3410698776547611373) started by @heidi-dang*", "score": 5, "created": "2026-02-24T04:06:21Z", "url": "https://github.com/heidi-dang/openhei/pull/21"}, {"source": "GitHub", "text": "config: add provider - qwen coding plan (CN & international), kimi-code. ", "score": 0, "created": "2026-02-24T03:20:31Z", "url": "https://github.com/tingly-dev/tingly-box/pull/368"}, {"source": "GitHub", "text": "UPSTREAM PR #19827: Kimi Linear block implementation > [!NOTE]\n> Source pull request: [ggml-org/llama.cpp#19827](https://github.com/ggml-org/llama.cpp/pull/19827)\n\n*Make sure to read the [contributing guidelines](https://github.com/ggml-org/llama.cpp/blob/master/CONTRIBUTING.md) before submitting a PR*\r\n\r\n~15% gain in pp. \r\n\r\nAlso, CUDA0 compute buffer of IQ3_M at 192k context reduces from 1693.51MB to 991.29MB on 3090. This allows context to further increase to 272k. \r\n\r\nAlso, tried to implemen", "score": 1, "created": "2026-02-24T03:06:26Z", "url": "https://github.com/auroralabs-loci/llama.cpp/pull/1202"}, {"source": "GitHub", "text": "B200 - update kimi 2.5 recipe ", "score": 1, "created": "2026-02-24T02:30:11Z", "url": "https://github.com/vllm-project/recipes/pull/258"}, {"source": "GitHub", "text": "feat: Kimi Coding compatibility + default preset ## Summary\n- add Kimi Coding compatibility in OpenAI-compatible provider by setting `User-Agent: KimiCLI/1.3` when `api_base` targets `api.kimi.com/coding`\n- add default catalog preset `kimi-plan-coding` (`moonshot/kimi-k2-thinking`, `https://api.kimi.com/coding/v1`)\n- add regression tests for Kimi Coding header behavior\n- add table-driven test covering 3 Kimi model IDs on coding endpoint\n\n## Why\nKimi Coding can return 403 for generic clients. Thi", "score": 0, "created": "2026-02-24T02:08:52Z", "url": "https://github.com/sipeed/picoclaw/pull/700"}, {"source": "GitHub", "text": "crispen changes since initial commit with kimi 2.5 ", "score": 0, "created": "2026-02-24T01:54:55Z", "url": "https://github.com/Voidious/crispen/pull/30"}, {"source": "GitHub", "text": "Add Kimi-K2 Tool Simulation environment ## Description\n\nMulti-domain tool simulation benchmark for evaluating LLM tool-calling capabilities, inspired by the hierarchical tool simulation approach described in the [Kimi-K2 paper](https://arxiv.org/abs/2507.20534).\n\n### Key Features\n\n- **11 deterministic tools** across 5 domain categories (finance, weather, travel, calendar, knowledge)\n- **26 evaluation tasks** spanning 4 difficulty tiers:\n  - Simple (10): Single tool calls\n  - Sequential (8): Mult", "score": 1, "created": "2026-02-24T01:54:47Z", "url": "https://github.com/PrimeIntellect-ai/community-environments/pull/516"}, {"source": "GitHub", "text": "crispen changes since initial commit with kimi 2 ", "score": 0, "created": "2026-02-24T01:43:20Z", "url": "https://github.com/Voidious/crispen/pull/29"}, {"source": "GitHub", "text": "Resolve merge conflicts, refactor AgentWorkflowPanel event handling, and remove kimi-plugin-inspect-react ### Motivation\n- Remove leftover merge conflict artifacts and unify divergent implementations in the workflow panel to stabilize event parsing and UI behavior. \n- Simplify dev build configuration by removing an optional React inspector plugin that is no longer used. \n- Improve handling of trace replay/SSE events, progress computation, and diagnostic metadata display for more accurate runtime", "score": 0, "created": "2026-02-24T01:10:38Z", "url": "https://github.com/LXMenm/test/pull/98"}, {"source": "GitHub", "text": "Remove hardcoded model names, update current model to kimi-k2.5 - Claude.md: replace all hardcoded deepseek/deepseek-v3.2 references with shell variables in curl examples, update model history table to show moonshotai/kimi-k2.5 as current\r\n- seed_letta.py: read model from LLM_MODEL env var instead of hardcoding stepfun/step-3.5-flash:free (falls back to moonshotai/kimi-k2.5)\r\n- coolify.yml: fix stale minimax/minimax-m2.5 reference, use variable pattern matching the other docs\r\n\r\nhttps://claude.a", "score": 0, "created": "2026-02-23T19:24:42Z", "url": "https://github.com/NaciCankaya/AI_Manager/pull/342"}, {"source": "GitHub", "text": "llm_server: switch GLM/Kimi (and remaining models) to public HF GGUF \u2026 \u2026sources to fix 401 downloads\r\n\r\n<!--\r\nPR Title format:\r\nJIRA_BOARD_ABBREVIATION-JIRA_TASK_NUMBER: TITLE_OF_JIRA_TASK\r\n-->\r\n\r\n## \ud83c\udfaf Summary\r\n\r\n<!-- COMPLETE JIRA LINK BELOW -->\r\n[ZUBA-](https://citz-imb.atlassian.net/jira/software/c/projects/ZUBA/boards/62?selectedIssue=ZUBA-)\r\n\r\n<!-- PROVIDE BELOW an explanation of your changes and any images to support your explanation -->\r\n\r\n\r\n## \ud83d\udd30 Checklist\r\n\r\n- [ ] I have read and agree w", "score": 0, "created": "2026-02-23T19:06:51Z", "url": "https://github.com/bcgov/citz-imb-ai/pull/372"}, {"source": "GitHub", "text": "feat: add Kimi as a supported agent ## Summary\n\n- Adds `(\".kimi\", \"skills\")` to `KNOWN_AGENTS` in `src/agent.rs` so skillshub detects `~/.kimi` and links skills to `~/.kimi/skills/`\n- Updates `test_known_agent_names` unit test to assert `.kimi` is present\n- Updates supported agents tables in `README.md` and `AGENTS.md`\n\n## Test plan\n\n- [ ] `cargo build` passes\n- [ ] `cargo test` passes\n- [ ] `mkdir -p ~/.kimi/skills && cargo run -- agents` shows Kimi in the table\n- [ ] `cargo run -- link` create", "score": 1, "created": "2026-02-23T17:59:18Z", "url": "https://github.com/EYH0602/skillshub/pull/40"}, {"source": "GitHub", "text": "[Bug]\u4f7f\u7528kimi-k2.5\u6a21\u578b\u65f6\uff0c\u663e\u793atop_p\u9700\u8981\u8bbe\u7f6e\u4e3a0.95\uff0c\u4f46\u662f\u6a21\u578b\u914d\u7f6e\u65e0\u6cd5\u914d\u7f6e\u8be5\u53c2\u6570\u4e3a0.95 **\u6ce8\u610f\uff1a\u8bf7\u52a1\u5fc5\u6309\u7167\u6b64\u6a21\u7248\u586b\u5199 ISSUES \u4fe1\u606f\uff0c\u5426\u5219 ISSUE \u5c06\u4e0d\u4f1a\u5f97\u5230\u56de\u590d**\n\n**\u95ee\u9898\u63cf\u8ff0**\n\u4f7f\u7528kimi-k2.5\u6a21\u578b\u65f6\uff0c\u663e\u793atop_p\u9700\u8981\u8bbe\u7f6e\u4e3a0.95\uff0c\u4f46\u662f\u6a21\u578b\u914d\u7f6e\u65e0\u6cd5\u914d\u7f6e\u8be5\u53c2\u6570\u4e3a0.95\u3002\u914d\u7f6e\u6a21\u578b\u65f6\uff0ctop_k\u53ea\u80fd\u914d\u7f6e\u4e3a\u5c0f\u6570\u70b9\u540e\u4e00\u4f4d\uff0c\u6bd4\u59820.7\uff0c0.8\uff0c0.9.\n\n**\u684c\u9762\u8bbe\u5907\uff08\u8bf7\u5b8c\u5584\u4ee5\u4e0b\u4fe1\u606f\uff09**\n\n- \u64cd\u4f5c\u7cfb\u7edf\uff1aWindow 11\n- \u6d4f\u89c8\u5668\uff1a\u8c37\u6b4c\u6d4f\u89c8\u5668\uff08Chrome\uff09\n- Easy Dataset \u7248\u672c\uff1a1.7.1\n\n**\u4f7f\u7528\u6a21\u578b**\n\n- \u6a21\u578b\u63d0\u4f9b\u5546\uff1amoonshot\n- \u6a21\u578b\u540d\u79f0\uff1akimi-k2.5\n\n**\u590d\u73b0\u6b65\u9aa4**\n\u91cd\u73b0\u8be5\u95ee\u9898\u7684\u64cd\u4f5c\u6b65\u9aa4\uff1a\n\n1. \u8fdb\u5165\u201c\u6a21\u578b\u6d4b\u8bd5\u201d\u9875\u9762\u3002\n2. \u70b9\u51fb\u201c\u9009\u62e9\u6a21\u578b\uff0c\u9009\u62e9kimi-k2.5\u201d\u3002\n3. \u8f93\u5165\u95ee\u9898\u3002\n4. \u8fd9\u65f6\u4f1a\u770b\u5230\u9519\u8bef\u63d0\u793a\uff1a\u201c\u9519\u8bef: Failed to call kimi-k2.5 model: invalid top_p: only 0.95 is allowed for this model\u201d\n", "score": 0, "created": "2026-02-23T15:41:55Z", "url": "https://github.com/ConardLi/easy-dataset/issues/682"}, {"source": "GitHub", "text": "Kimi Code for VS Code always refer the wrong path for built-in skills For example, let's say I want to create a new agent skill\n\nkimi will start look for skill-creator skill in \nC:\\Users\\admin\\AppData\\Roaming\\Code\\User\\globalStorage\\moonshot-ai.kimi-code\\bin\\kimi_internal\\kimi_cli\\skills\\skill-creator\\SKILL.md\n<img width=\"1235\" height=\"306\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/2adfaabe-cd5f-4900-9407-6bde4b939408\" />\n\nHowever, the actual path is actually in\nC:\\Users\\admin\\", "score": 0, "created": "2026-02-23T15:40:32Z", "url": "https://github.com/MoonshotAI/kimi-agent-sdk/issues/107"}, {"source": "GitHub", "text": "feat: kimi code oauth + provider (WIP) ", "score": 1, "created": "2026-02-23T14:46:46Z", "url": "https://github.com/querymt/querymt/pull/155"}, {"source": "GitHub", "text": "Update leaderboard: correct Kimi-K2.5 metrics and add Claude-4.6-Sonnet ### Motivation\n- \u4fee\u6b63\u4e3b\u9875\u699c\u5355\u4e2d `Kimi-K2.5` \u7684\u7edf\u8ba1\u6570\u636e\u4ee5\u53cd\u6620\u5df2\u66f4\u6b63\u7684\u8ba1\u7b97\u7ed3\u679c\u3002 \n- \u6dfb\u52a0 `Claude-4.6-Sonnet` \u7684\u6761\u76ee\u5e76\u4e0e\u73b0\u6709\u884c\u4fdd\u6301\u76f8\u540c\u7684 SVG/\u683c\u5f0f\u98ce\u683c\u3002 \n- \u4fdd\u8bc1\u8868\u683c\u6309 `Pass@1` \u964d\u5e8f\u6392\u5217\u4ee5\u7ef4\u6301\u6392\u884c\u699c\u4e00\u81f4\u6027\u3002 \n\n### Description\n- \u5728 `docs/leaderboard.mdx` \u4e2d\u66ff\u6362 `Kimi-K2.5` \u884c\uff0c\u66f4\u65b0\u4e3a `Pass@1 27.8 \u00b1 0.8`\u3001`Pass@3 38.9`\u3001`Pass^3 14.8`\u3001`# Turns 17.2`\uff0c\u4fdd\u7559\u539f\u6709 Kimi SVG \u548c\u884c\u7ed3\u6784\u3002 \n- \u5728 `docs/leaderboard.mdx` \u4e2d\u65b0\u589e `Claude-4.6-Sonnet` \u884c\uff0c\u4f7f\u7528 Claude SVG \u5e76\u8bbe\u7f6e `Pass@1 44.8 \u00b1 2.9`\u3001`Pass@3 59.3`\u3001`Pass^3 30.6`\u3001`# Turns 23.4`\u3002 \n- \u5c06", "score": 0, "created": "2026-02-23T14:03:21Z", "url": "https://github.com/WaitHZ/toolathlon-website/pull/2"}, {"source": "GitHub", "text": "Context overflow on fresh session with Kimi K2.5 via OpenRouter \u2014 likely error misclassification ## Summary\n\nAfter updating to recent versions (worked on ~v2026.2.17, broken on v2026.2.19+), every message \u2014 including a single \"hi?\" on a **fresh `/reset` session** \u2014 triggers:\n\n> Context overflow: prompt too large for the model. Try /reset (or /new) to start a fresh session, or use a larger-context model.\n\nThe model is `openrouter/moonshotai/kimi-k2.5` (262K context). The system prompt is ~26K cha", "score": 5, "created": "2026-02-23T13:56:32Z", "url": "https://github.com/openclaw/openclaw/issues/24520"}, {"source": "GitHub", "text": "Add kimi + minimax and skip complexity if router = round_robin This pull request adds support for two new agents, `kimi` and `minimax`, across the orchestrator scripts and configuration. It updates agent lists, validation constants, and the task runner to ensure these new agents are handled consistently alongside existing ones. The logic for agent model selection and allowed/disallowed tools has also been improved for flexibility and robustness.\r\n\r\n**Agent support and configuration:**\r\n\r\n* Added", "score": 0, "created": "2026-02-23T13:54:44Z", "url": "https://github.com/gabrielkoerich/orchestrator/pull/313"}, {"source": "GitHub", "text": "kimi Andante \u6743\u76ca \u600e\u4e48\u63a5\u5165\uff1f kimi Andante \u6743\u76ca \u7684 api \u6ca1\u529e\u6cd5\u6210\u529f\u63a5\u5165\uff0c\u53ea\u80fd\u63a5\u5165\u6309\u91cf\u4ed8\u8d39\u7684\uff0c\u8fd9\u4e2a\u80fd\u89e3\u51b3\u5417\uff1f", "score": 0, "created": "2026-02-23T13:30:44Z", "url": "https://github.com/netease-youdao/LobsterAI/issues/63"}, {"source": "GitHub", "text": "Implement kimi k2 MLACache validation test ### Ticket\r\nhttps://github.com/tenstorrent/tt-xla/issues/3173\r\n\r\n### What's changed\r\nAdd new test to validate the MLA implementation of modeling_deepseek.py against original_modeling_deepseek.py.\r\n\r\n### Checklist\r\n- [ ] New/Existing tests provide coverage for changes\r\n", "score": 1, "created": "2026-02-23T13:22:54Z", "url": "https://github.com/tenstorrent/tt-xla/pull/3427"}, {"source": "GitHub", "text": "openai-completions adapter sends unsupported role for reasoning models, causing Moonshot/Kimi API 400 error ## Bug Description\n\nAfter updating openclaw from `2026.2.9` to `2026.2.22-2`, the Moonshot/Kimi K2.5 model fails with:\n\n```\n400 invalid request: unsupported role ROLE_UNSPECIFIED\n```\n\nThis causes all API calls to return empty content, which then corrupts session state and triggers \"Message ordering conflict\" errors.\n\n## Root Cause\n\nIn the `openai-completions` adapter (`@mariozechner/pi-ai`", "score": 3, "created": "2026-02-23T13:16:53Z", "url": "https://github.com/openclaw/openclaw/issues/24499"}, {"source": "GitHub", "text": "[Feature]: Add ZAI (GLM-5) and Moonshot (Kimi) providers to cache-ttl context pruning ### Summary\n\ncontextPruning with mode: \"cache-ttl\" only works with Anthropic models due to hardcoded check in cache-ttl.ts. Both GLM-5 (ZAI API) and Kimi K2 (Moonshot API) support automatic prompt/context caching natively at the API level and should be supported as well.\n\n### Problem to solve\n\nUsers running GLM-5 via ZAI or Kimi K2 via Moonshot cannot benefit from contextPruning even though both providers suppo", "score": 2, "created": "2026-02-23T13:14:25Z", "url": "https://github.com/openclaw/openclaw/issues/24497"}]}