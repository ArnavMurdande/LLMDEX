{"timestamp": 1771962998.8916829, "mentions": [{"source": "Reddit", "text": "I built a persistent AI system that runs my three businesses. It took 16 weeks, 150+ prompt versions, and 14 spectacular failures. Here's the full paper.  Thoughts? The system is called Fish. It's a persistent cognitive architecture across multiple LLMs \u2014 Claude for reasoning, GPT for creative tasks, Gemini for research, Grok for chaos testing. 97,000+ persistent memory records. 16 autonomous daemons. Voice agent taking real customer calls.\n\nI wrote it up as an academic paper because the methodo", "score": 0, "created": 1771962451.0, "url": "https://reddit.com/r/LocalLLaMA/comments/1rdqjbb/i_built_a_persistent_ai_system_that_runs_my_three/"}, {"source": "Reddit", "text": "GLM 4.7 Flash Setup Running Local AI Faster Than Paid Cloud Models GLM 4.7 Flash setup gives you a powerful local AI model that runs entirely on your device.\n\nRunning the whole system for free feels like unlocking paid-level performance without subscriptions.\n\nNothing relies on the cloud once the GLM 4.7 Flash setup is complete.\n\nWatch the video below:\n\n[https://www.youtube.com/watch?v=UoTn-O9WPoc&amp;t=1s](https://www.youtube.com/watch?v=UoTn-O9WPoc&amp;t=1s)\n\nWant to make money and save time w", "score": 1, "created": 1771962297.0, "url": "https://reddit.com/r/AISEOInsider/comments/1rdqgml/glm_47_flash_setup_running_local_ai_faster_than/"}, {"source": "Reddit", "text": "Alibaba Qwen Team Releases Qwen 3.5 Medium Model Series: A Production Powerhouse Proving that Smaller AI Models are Smarter ", "score": 2, "created": 1771961902.0, "url": "https://reddit.com/r/OpenSourceeAI/comments/1rdqa44/alibaba_qwen_team_releases_qwen_35_medium_model/"}, {"source": "Reddit", "text": "How many tokens do you \ud83d\udd25 per month &amp; what\u2019s the real cost? (API) \nGuys, can you drop a number for models like \n\nMiniMax M2.5 \n\nKimi 2.5 \n\nGLM5 \n\nQwen 3.5plus\n\nGemini 3.1 Pro\n\nGPT5.3 codex\n\nClaude Sonnet/Opus 4.6\n\nUsecase would be cool to know \n\nThanks in advance ", "score": 2, "created": 1771961297.0, "url": "https://reddit.com/r/openclaw/comments/1rdpzyc/how_many_tokens_do_you_per_month_whats_the_real/"}, {"source": "Reddit", "text": "AI wood carving is a bummer... ... especially when it's being posted by accounts with 17K followers, showering praise on phony photos generated by text prompts.\n\nTo be fair, web-based \"AI detectors\" are not perfect, and there's a nonzero chance that they're flat-out wrong, but hand carved wood is already devalued to a depressing degree, and slop like this makes it worse.   \n  \nOk I'm done ranting, but I feel a little better now.  \n  \nHappy carving!", "score": 6, "created": 1771961016.0, "url": "https://reddit.com/r/Carving/comments/1rdpv72/ai_wood_carving_is_a_bummer/"}, {"source": "Reddit", "text": "more qwens will appear (remember that 9B was promised before)", "score": 27, "created": 1771960941.0, "url": "https://reddit.com/r/LocalLLaMA/comments/1rdptw8/more_qwens_will_appear/"}, {"source": "Reddit", "text": "Comparing the latest Qwen3 and Liquid AI models: context windows and pricing Recent industry discussions highlight a surge of new model architectures, with newly spotted variants like Qwen3.5-122B-A10B and Qwen3.5-35B-A3B entering the space alongside Liquid AI's LFM2-24B-A2B release. Looking at the currently available endpoints, there is a stark contrast in pricing and capacity across these ecosystems.\n\nThe current data shows a wide spread in cost-to-context ratios for reasoning engines:\n- **Qwe", "score": 1, "created": 1771960831.0, "url": "https://reddit.com/r/AIToolsPerformance/comments/1rdps2b/comparing_the_latest_qwen3_and_liquid_ai_models/"}, {"source": "Reddit", "text": "Engineering the Autonomous Local Enterprise: A Technical Blueprint for Agentic RAG and Sovereign AI Infrastructure # Engineering the Autonomous Local Enterprise: A Technical Blueprint for Agentic RAG and Sovereign AI Infrastructure\n\nThe transition from reactive large language model applications to autonomous agentic workflows represents a fundamental paradigm shift in enterprise computing. In the 2025\u20132026 technological landscape, the industry has moved beyond simple chat interfaces toward syste", "score": 1, "created": 1771960677.0, "url": "https://reddit.com/r/OpenAI/comments/1rdppfn/engineering_the_autonomous_local_enterprise_a/"}, {"source": "Reddit", "text": "Open vs Closed Source SOTA - Benchmark overview Sonnet 4.5 was released about 6 months ago. What's the advantage of the closed source labs? About that amount of time? Even less?\n\n|Benchmark|GPT-5.2|Opus 4.6|Opus 4.5|Sonnet 4.6|Sonnet 4.5|Q3.5 397B-A17B|Q3.5 122B-A10B|Q3.5 35B-A3B|Q3.5 27B|GLM-5|\n|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|:-|\n|Release date|Dec 2025|Feb 2026|Nov 2025|Feb 2026|Nov 2025|Feb 2026|Feb 2026|Feb 2026|Feb 2026|Feb 2026|\n|**Reasoning &amp; STEM**|||||||||||\n|GPQA Diamond|93.2|91.3|87", "score": 5, "created": 1771960118.0, "url": "https://reddit.com/r/LocalLLaMA/comments/1rdpfy6/open_vs_closed_source_sota_benchmark_overview/"}, {"source": "Reddit", "text": "Frontier LLM Leaderboard Check it out at [https://www.onyx.app/llm-leaderboard](https://www.onyx.app/llm-leaderboard)", "score": 0, "created": 1771959166.0, "url": "https://reddit.com/r/OpenAI/comments/1rdozjs/frontier_llm_leaderboard/"}, {"source": "Reddit", "text": "\ud83d\udce2 New Model(s) Drop: Qwen3.5 Medium Model Series is now live on Yupp! Qwen3.5 35B A3B, Qwen3.5 122B A10B, and Qwen3.5 27B are ready to prompt for free.\n\nWhat will you learn, build and create \u2013 and how will these new Qwens perform on our leaderboard? \ud83d\udcca\n\nLet\u2019s find out!\n\nCongrats to Qwen on the launch.", "score": 1, "created": 1771957714.0, "url": "https://reddit.com/r/yupp_ai/comments/1rdoatr/new_models_drop_qwen35_medium_model_series_is_now/"}, {"source": "Reddit", "text": "Qwen 3.5 122b/35b is fire \ud83d\udd25 Score comparision between Qwen 3 35B-A3B, GPT-5 High, Qwen 3 122B-A10B, and GPT-OSS 120B. EDIT: \u26a0\ufe0f\u26a0\ufe0f\u26a0\ufe0f  SORRY \ud83e\udd72 --&gt; in graph its should be qwen 3.5 not qwen 3 \u26a0\ufe0f\u26a0\ufe0f\n\nBenchmark Comparison\n\n\ud83d\udc49\ud83d\udd34GPT-OSS 120B \\[defeated by qwen 3.5 35b \ud83e\udd73\\]\n\nMMLU-Pro: 80.8\n\nHLE (Humanity\u2019s Last Exam): 14.9\n\nGPQA Diamond: 80.1\n\nIFBench: 69.0\n\n\ud83d\udc49\ud83d\udd34Qwen 3.5 122B-A10B\n\nMMLU-Pro: 86.7\n\nHLE (Humanity\u2019s Last Exam): 25.3 (47.5 with tools \u2014 \ud83c\udfc6 Winner)\n\nGPQA Diamond: 86.6 (\ud83c\udfc6 Winner)\n\nIFBench: 76.1 (\ud83c\udfc6 W", "score": 43, "created": 1771957180.0, "url": "https://reddit.com/r/LocalLLaMA/comments/1rdo1z5/qwen_35_122b35b_is_fire_score_comparision_between/"}, {"source": "Reddit", "text": "Connected Qwen3-VL-2B-Instruct to my security cameras, result is great Just tried the new Qwen3-VL-2B-Instruct (Unsloth GGUF) on my security camera feeds\n\n**The output:**\n\n&gt;\"A mailman is delivering mail to a suburban house. The mailman is wearing a blue uniform and carrying a white mail bag. The house is white with a brown roof, and there's a driveway with a black car parked in front. The mailman is walking on a brick path surrounded by green bushes and trees.\"\n\nFor a 2B model at IQ2 quantiza", "score": 23, "created": 1771957030.0, "url": "https://reddit.com/r/Qwen_AI/comments/1rdnzbe/connected_qwen3vl2binstruct_to_my_security/"}, {"source": "Reddit", "text": "Qwen3-Coder-Next vs Qwen3.5-35B-A3B vs Qwen3.5-27B - A quick coding test https://preview.redd.it/hu6rne78hhlg1.png?width=2546&amp;format=png&amp;auto=webp&amp;s=f5ba5093633344e41f2c35671835f75e738f08d9\n\nWhile we're waiting for the GGUF, I ran a quick test to compare the one shot ability between the 3 models on Qwen Chat.\n\nBuilding two examples: a jumping knight game and a sand game. You can see the live version here [https://qwen-bench.vercel.app/](https://qwen-bench.vercel.app/)\n\n**Knight game*", "score": 23, "created": 1771956917.0, "url": "https://reddit.com/r/LocalLLaMA/comments/1rdnxe6/qwen3codernext_vs_qwen3535ba3b_vs_qwen3527b_a/"}, {"source": "Reddit", "text": "Local model users! Which model arch do you use? To clarify, the arch is the base the model you use is trained off of. So Cydonia would be mistral.\n\n1. Mistral\n\n2. Nemo\n\n3. GLM\n\n4. Qwen\n\n5. GPT oss\ud83d\udc80 \n\n6. Gemma\n\n7. LFM?\n\n8. Other\n\nThis is not a \u201cbest model\u201d post, I just want to know what y\u2019all use.", "score": 3, "created": 1771956881.0, "url": "https://reddit.com/r/SillyTavernAI/comments/1rdnwtu/local_model_users_which_model_arch_do_you_use/"}, {"source": "Reddit", "text": "Qwen releases new Qwen3.5 Medium models! ", "score": 19, "created": 1771956248.0, "url": "https://reddit.com/r/LocalLLM/comments/1rdnlvl/qwen_releases_new_qwen35_medium_models/"}, {"source": "Reddit", "text": "Qwen3.5 Medium models out now! Qwen releases new Qwen3.5 Medium models! \ud83d\udd25 The 35B and 27B work on 24GB RAM.\n\n* Qwen3.5 35B-A3B (MoE \u2022 works on 24GB RAM)\n* Qwen3.5 27B (dense \u2022 18GB)\n* Qwen3.5 122B-A10B (MoE \u2022 70GB)\n\nThe multimodal hybrid reasoning LLMs are the best performing for their sizes.\n\nGGUFs: [https://huggingface.co/collections/unsloth/qwen35](https://huggingface.co/collections/unsloth/qwen35)\n\nGuide: [https://unsloth.ai/docs/models/qwen3.5](https://unsloth.ai/docs/models/qwen3.5)\n\n**Uns", "score": 137, "created": 1771954428.0, "url": "https://reddit.com/r/unsloth/comments/1rdmqp8/qwen35_medium_models_out_now/"}, {"source": "Reddit", "text": "\"Agentic Gaming\" \u2014 a deep dive into how I'm using LLMs as a semantic reasoning layer inside an RPG engine (80+ orchestrated AI tasks, multi-LLM, genre-agnostic skills, and a lot of dice rolls) Hi everyone!\n\nI've been working on something for a while now that I think sits squarely in the intersection of this sub's interests, and I wanted to share it \u2014 not just as a project showcase, but because I genuinely want to discuss the underlying design concepts with people who think about AI + game design", "score": 4, "created": 1771954177.0, "url": "https://reddit.com/r/aigamedev/comments/1rdmmfa/agentic_gaming_a_deep_dive_into_how_im_using_llms/"}, {"source": "Reddit", "text": "[Guide] Dealing with 400 Errors and Region Mismatch on Qwen 3.5/Max API Hi everyone,\n\nFollowing up on the initial dev support post, I\u2019ve been tracking feedback from about a dozen of you stress-testing Qwen3-Max/Coder. After reviewing several logs and tickets, I\u2019ve noticed a few common \"traps\" that might save you some debugging hours.\n\nHere is a quick technical guide based on real production cases:\n\n1. The \"Safety Filter\" Trap (DataInspectionFailed 400)\n\nA few of you building security tools or re", "score": 1, "created": 1771953599.0, "url": "https://reddit.com/r/Qwen_AI/comments/1rdmcuc/guide_dealing_with_400_errors_and_region_mismatch/"}, {"source": "Reddit", "text": "I gave 16 LLMs a food truck in Austin for 30 days. Gemini 3 Pro matched Sonnet 4.6 \u2014 5\u00d7 cheaper. I built an agentic benchmark called FoodTruck Bench \u2014 AI models manage a food truck in Austin, TX for 30 days. Location strategy, menu pricing, inventory management, staff hiring \u2014 34 tools, deterministic simulation, 5 runs per model. Same seed, same conditions. 16 models tested so far.\n\n**Gemini 3 Pro is the most efficient model on the entire benchmark.** It reaches +760% ROI \u2014 nearly identical to S", "score": 16, "created": 1771952987.0, "url": "https://reddit.com/r/GeminiAI/comments/1rdm2g1/i_gave_16_llms_a_food_truck_in_austin_for_30_days/"}, {"source": "Reddit", "text": "Qwen just released Qwen 3.5 medium model Series: Qwen 3.5 Flash plus 3 more models Introducing the Qwen 3.5 Medium Model Series\nQwen3.5-Flash, Qwen3.5-35B-A3B, Qwen3.5-122B-A10B &amp; Qwen3.5-27B\n\n\u2728 More intelligence, less compute.\n\n\u2022 Qwen3.5-35B-A3B now surpasses Qwen3-235B-A22B-2507 and Qwen3-VL-235B-A22B \u2014 a reminder that better architecture, data quality and RL can move intelligence forward, not just bigger parameter counts.\n\n\u2022 Qwen3.5-122B-A10B and 27B continue narrowing the gap between med", "score": 48, "created": 1771952764.0, "url": "https://reddit.com/r/singularity/comments/1rdlyeo/qwen_just_released_qwen_35_medium_model_series/"}, {"source": "Reddit", "text": "Fine-tune multi-modal Qwen models or other open-source LLMs on Persian (a low-resource) language ", "score": 1, "created": 1771952377.0, "url": "https://reddit.com/r/huggingface/comments/1rdlrqr/finetune_multimodal_qwen_models_or_other/"}, {"source": "Reddit", "text": "Fine-tune multi-modal Qwen models or other open-source LLMs on Persian (a low-resource) language I've collected a dataset of \\~1300 short clipped videos. I've also convert those .mp4 files to .mp3 and have their audio files separately.\n\nIn addition, I have extracted their texts manually. All of them are in Persian, and I want to analyse the ability of reasoning and inference of Multi-modal LLMs for sentiment and emotion classification over my dataset. It's completely novel and no prior work has ", "score": 3, "created": 1771952317.0, "url": "https://reddit.com/r/MLQuestions/comments/1rdlqro/finetune_multimodal_qwen_models_or_other/"}, {"source": "Reddit", "text": "Small Qwen Models OUT!! [https://huggingface.co/Qwen/Qwen3.5-35B-A3B](https://huggingface.co/Qwen/Qwen3.5-35B-A3B)\n\n*Processing img sxcx52pp1hlg1...*\n\n", "score": 169, "created": 1771951564.0, "url": "https://reddit.com/r/LocalLLaMA/comments/1rdldt6/small_qwen_models_out/"}, {"source": "Reddit", "text": "New Qwen 3.5 models are online on HF ", "score": 35, "created": 1771951487.0, "url": "https://reddit.com/r/LocalLLaMA/comments/1rdlck5/new_qwen_35_models_are_online_on_hf/"}, {"source": "Reddit", "text": "2 days of work + Opus 4.6 = Voice Cloning App using Qwen TTS. Free app, No Sing Up Required A few days ago, Qwen released a new open weight speech-to-speech model: Qwen3-TTS-12Hz-0.6B-Base. It is great model but it's huge and hard to run on any current regular laptop or PC so I built a free web service so people can check the model and see how it works.\n\n* No registration required\n* Free to test how it works\n* Up to 500 characters per conversion\n* Upload a voice sample + enter text, and it gener", "score": 23, "created": 1771950969.0, "url": "https://reddit.com/r/vibecoding/comments/1rdl3xc/2_days_of_work_opus_46_voice_cloning_app_using/"}, {"source": "Reddit", "text": "Headline: Openclaw Usage Tips and Workflow Patterns TL;DR: A list of 11 practical tips for maximizing OpenClaw value: use Opus as a central brain with specialized models, prefer local hosting for fast file workflows, pick communication channels by task, and avoid exposing email/X accounts.\n\n- Scope/Impact: Focuses on workflow efficiency\u2014model orchestration reduces cost and parallelizes tasks; local hosting shortens file loops.\n- Key techniques: Model delegation (Opus + Codex/Minimax 2.5/Qwen 3.5", "score": 1, "created": 1771950164.0, "url": "https://reddit.com/r/HasambaShared/comments/1rdkqre/headline_openclaw_usage_tips_and_workflow_patterns/"}, {"source": "Reddit", "text": "Anyone building voice AI agents with Qwen? Looking for tips on prompting and general best practices. ", "score": 1, "created": 1771944821.0, "url": "https://reddit.com/r/u_Select_Flatworm8668/comments/1rdibfo/anyone_building_voice_ai_agents_with_qwen_looking/"}, {"source": "Reddit", "text": "Increasing Claude Code Usable Context and Tokens I wanted to give back to the community that has helped me greatly with a setup and finding that has greatly increased my Ai Assisted coding.\n\nOver the past year I\u2019ve used Claude code ALOT and I\u2019ve built a lot of great products with it. But what I always found was, boy, was I burning through tokens even on my Max subscription and I\u2019d have to dumb down my model choices or switch to another service near the end of the month like Cursor, just to bridg", "score": 2, "created": 1771944807.0, "url": "https://reddit.com/r/AIAssisted/comments/1rdib7w/increasing_claude_code_usable_context_and_tokens/"}, {"source": "Reddit", "text": "Anyone building voice AI agents with Qwen? Looking for tips on prompting and general best practices I've been exploring Qwen3-30B-A3B for building voice-based AI agents and wanted to reach out to the community to see if anyone else is working on something similar.\n\nA few things I'm curious about:\n\n1. **Is anyone actively building voice AI agents on top of Qwen models?** I'd love to hear about your stack, architecture, and what made you choose Qwen over other options.\n2. **Any Qwen-specific promp", "score": 2, "created": 1771944778.0, "url": "https://reddit.com/r/AI_Agents/comments/1rdiask/anyone_building_voice_ai_agents_with_qwen_looking/"}, {"source": "Reddit", "text": "My wish has been fulfilled ", "score": 19, "created": 1771943935.0, "url": "https://reddit.com/r/Qwen_AI/comments/1rdhy4i/my_wish_has_been_fulfilled/"}, {"source": "Reddit", "text": "Lessons learned running Qwen3-VL-8B as a fully local voice assistant on AMD ROCm I've been building a local voice assistant over the past few weeks and wanted to share some things I learned that might be useful to others here, especially anyone on AMD hardware.\n\nThe setup is wake word \u2192 fine-tuned Whisper STT \u2192 Qwen3-VL-8B for reasoning \u2192 Kokoro TTS for voice output. Everything runs on-device, no cloud APIs in the loop.\n\n# Things that surprised me\n\n**Self-quantizing beats downloading pre-made qu", "score": 25, "created": 1771942010.0, "url": "https://reddit.com/r/LocalLLaMA/comments/1rdh5lv/lessons_learned_running_qwen3vl8b_as_a_fully/"}, {"source": "Reddit", "text": "Time based model switching I am getting rate limited at night (heartbeat stuff?) What would be the best way to tell OpenClaw to use the Codex 5.3 model from 9am-9pm and then switch to Qwen or a local model in the evening while I sleep?", "score": 1, "created": 1771939845.0, "url": "https://reddit.com/r/openclaw/comments/1rdgag3/time_based_model_switching/"}, {"source": "Reddit", "text": "ive had it with this quota thingy what i need to do ??? ne,\n\nI\u2019m currently building some projects using tools like AntiGravity, OpenCode, and OpenClaw, but I\u2019m hitting a wall with my setup and could really use some advice from the community.\n\nMy goal is to have a strong, reliable model (like Claude Opus 4.6 or Sonnet 4.5) as my daily driver for the long term. The problem is, I\u2019m constantly running into rate limits and context window issues.\n\nHere is my dilemma:\n\n1. **Free Tiers/Basic Plans:** I ", "score": 3, "created": 1771938729.0, "url": "https://reddit.com/r/google_antigravity/comments/1rdfv8x/ive_had_it_with_this_quota_thingy_what_i_need_to/"}, {"source": "Reddit", "text": "A small 4B sub-agent for local codebase navigation with 100% tool-calling validity I\u2019ve been experimenting with a specialized 4B model (based on Qwen) that acts as an \"explorer\" for local codebases. It\u2019s designed to handle the heavy lifting like grep, find, and file reading so you can save your Claude/GPT tokens for high-level logic.\n\nIn my tests, it achieved 100% JSON validity for tool calls, which is better than some 7B models I've tried.\n\nI want to share the GGUFs and the repo, but I'll put t", "score": 8, "created": 1771938652.0, "url": "https://reddit.com/r/LocalLLaMA/comments/1rdfu5e/a_small_4b_subagent_for_local_codebase_navigation/"}, {"source": "Reddit", "text": "Encountered a CUDA error using Forge classic-neo. My screen went black and my computer made a couple of beeps and then returned to normal other than I need to restart neo. Anyone know what's going on here? torch.AcceleratorError: CUDA error: an illegal memory access was encountered\n\nSearch for \\`cudaErrorIllegalAddress' in [https://docs.nvidia.com/cuda/cuda-runtime-api/group\\_\\_CUDART\\_\\_TYPES.html](https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html) for more information.\n\nC", "score": 0, "created": 1771938326.0, "url": "https://reddit.com/r/StableDiffusion/comments/1rdfpr4/encountered_a_cuda_error_using_forge_classicneo/"}, {"source": "Reddit", "text": "New Qwen3.5 models spotted on qwen chat ", "score": 540, "created": 1771937710.0, "url": "https://reddit.com/r/LocalLLaMA/comments/1rdfhfx/new_qwen35_models_spotted_on_qwen_chat/"}, {"source": "Reddit", "text": "Gemini, Z.ai, Routeway, and other external providers. Pinned Comments # More providers\n\nWe now support the following providers:\n\n* Gemini\n* Moonshot\n* Z.ai\n* Perplexity\n* Qwen\n* Routeway\n\nNote that external providers will receive limited support as Saucepan's focus has always been on the experience of our in-house models.\n\n# Pinned Comments\n\nYou can now pin up to 3 comments. To pin something, click the three dot menu and click pin.\n\n* You can only pin top level comments, not replies\n* The latest", "score": 15, "created": 1771936316.0, "url": "https://reddit.com/r/SaucepanAI/comments/1rdf00c/gemini_zai_routeway_and_other_external_providers/"}, {"source": "Reddit", "text": "I built an embeddable AI inference runtime, no server, no API keys, everything runs on-device I wanted to add AI to my apps without sending user data to a third party. I needed inference to stay on the device.\n\nSo I built Xybrid. A Rust runtime that embeds directly into your app process.\n\nLLMs, text-to-speech, speech recognition, all running locally in just three lines of code:\n\n```dart\nfinal model = await Xybrid.model(modelId: 'llama-3.2-1b').load();\nfinal input = Envelope.text(text: 'Explain q", "score": 7, "created": 1771933038.0, "url": "https://reddit.com/r/FlutterDev/comments/1rdduzx/i_built_an_embeddable_ai_inference_runtime_no/"}, {"source": "Reddit", "text": "Karma police Anthropic accused DeepSeek, Moonshot, and MiniMax of \"industrial-scale distillation\" of Claude. LoL. Ok, the Chinese are the Robin Hoods of AI - they take closed frontier models, distill them, and give them to the public for free.\n\nNow the billion-dollar question: what can Anthropic do next?\n\n**Option A (bad):** Run with their ass on fire to Congress/the courts and start pushing for a \"ban on public models,\" \"distillation regulation,\" and \"export controls on open-weights.\" Result - ", "score": 0, "created": 1771930601.0, "url": "https://reddit.com/r/ClaudeAI/comments/1rdd4t2/karma_police/"}, {"source": "Reddit", "text": "Hardware recommendation Notebook for local development Hello, I am looking for a laptop for local execution of AI models (LLMs such as Llama 3/Phi-4 and image generation via Stable Diffusion). My budget is \u20ac2,500.\n\nI am trying to familiarize myself with the topic, but I need advice on what is important in this area.\n\nWhat exactly I want to do: Primarily coding, probably with QWEN. Video, image, text, and voice processing.\n\nI know that smaller models can be made with \u201cless powerful\u201d laptops. But ", "score": 2, "created": 1771920969.0, "url": "https://reddit.com/r/AI_developers/comments/1rdakaj/hardware_recommendation_notebook_for_local/"}, {"source": "Reddit", "text": "Best practices for running local LLMs for ~70\u2013150 developers (agentic coding use case) Hi everyone,\n\nI\u2019m planning infrastructure for a software startup where we want to use **local LLMs for agentic coding workflows** (code generation, refactoring, test writing, debugging, PR reviews, etc.).\n\n# Scale\n\n* Initial users: \\~70\u2013100 developers\n* Expected growth: up to \\~150 users\n* Daily usage during working hours (8\u201310 hrs/day)\n* Concurrent requests likely during peak coding hours\n\n# Use Case\n\n* Agent", "score": 24, "created": 1771917330.0, "url": "https://reddit.com/r/LocalLLaMA/comments/1rd9kpk/best_practices_for_running_local_llms_for_70150/"}, {"source": "Reddit", "text": "Claude Code will become unnecessary I use AI for coding every day including Opus 4.6. I've also been using Qwen 3.5 and Kimi K2.5. Have to say, the open source models are *almost* just as good. \n\nAt some point it just won't make sense to pay for Claude. When the open weight models are good enough for Senior Engineer level work, that should cover most people and most projects. They're also much cheaper to use.\n\nFurthermore, it is feasible to host the open weight models locally. You'd need a bit o", "score": 401, "created": 1771913421.0, "url": "https://reddit.com/r/ClaudeCode/comments/1rd8erf/claude_code_will_become_unnecessary/"}, {"source": "Reddit", "text": "Models to run on an iphone 14 pro Hey everyone, not a native speaker (Dutch), I write my own posts without LLMs. Please correct me if I make mistakes, only way to learn!\n\nI was gifted an iphone 14 pro, which has a little less than 6 GB available for use, realistically 4GB.\n\nSince I am planning to go to Japan, I thought having some offline SLMs available to me might be useful in a pinch.\n\nFor inference I am using pocketpal from the app store ([link](https://apps.apple.com/nl/app/pocketpal-ai/id65", "score": 1, "created": 1771911345.0, "url": "https://reddit.com/r/LocalLLaMA/comments/1rd7rqu/models_to_run_on_an_iphone_14_pro/"}, {"source": "Reddit", "text": "Anthropic's new \"Persona\" theory: How do we know when an AI is actually thinking vs. just wearing a mask? Anthropic just dropped a fascinating new research post on the\u00a0**Persona Selection Model (PSM)**. Their core argument is that modern AI assistants don't act human because they were trained to be human, they act human because\u00a0*pre-training*\u00a0forces them to simulate thousands of \"personas\" (characters from the internet), and\u00a0*post-training*\u00a0(RLHF) just selects the \"Helpful Assistant\" persona fro", "score": 15, "created": 1771911267.0, "url": "https://reddit.com/r/machinelearningnews/comments/1rd7qwc/anthropics_new_persona_theory_how_do_we_know_when/"}, {"source": "Reddit", "text": "Looking for one click installer for comfyui that isn't paywalled? [https://www.patreon.com/posts/105023709](https://www.patreon.com/posts/105023709)\n\n  \nI found this but its paywalled behind a $24/month subscription. I'm in college and I literally don't have it right now. I have tried using chatgpt to help me install it but it keeps suggesting an older version of python that is no longer available for download (3.11.9) instead of the latest version. \n\nI already have .safetensors file for the qwe", "score": 0, "created": 1771899315.0, "url": "https://reddit.com/r/StableDiffusion/comments/1rd21q0/looking_for_one_click_installer_for_comfyui_that/"}, {"source": "Reddit", "text": "I compared the reconstruction quality of the latest VAE models (Focusing on small faces). Here are the results! I\u2019m currently working on a few face-editing projects, which led me down a rabbit hole of testing the reconstruction quality of the latest VAE models. To get a good baseline, I also threw standard SD and SDXL into the mix just to see how they compare.\n\nBecause of my project, I paid special attention to how these models handle **small faces**. I've attached the comparisons below if you'r", "score": 31, "created": 1771899182.0, "url": "https://reddit.com/r/StableDiffusion/comments/1rd1zvp/i_compared_the_reconstruction_quality_of_the/"}, {"source": "Reddit", "text": "Is it always this slow?  Using Kimi k2.5, GLM-5, or Minimax 2.5 is practically impossible; Qwen models run at decent speeds randomly, which is frustrating. Is there any way to achieve a good speed?\n\ntnks ", "score": 12, "created": 1771898622.0, "url": "https://reddit.com/r/chutesAI/comments/1rd1sbu/is_it_always_this_slow/"}, {"source": "Reddit", "text": "Experimenting with Qwen3-VL-32B I'd like to put a model specifically of this size to the test to see the performance gap between smaller models and medium-sized models for my complex ternary (three-way) text classification task. I will tune using RL-esque methods.\n\nShould I tune Qwen 3 32B VL Thinking or Instruct? Which is the best one to tune for 1,024 max reasoning tokens (from my experience, Qwen3 yaps a lot)?\n\n  \n(I know Qwen 3.5 is coming, but leaks show a 2B and 9B dense with a 35B MoE, th", "score": 2, "created": 1771897946.0, "url": "https://reddit.com/r/LocalLLaMA/comments/1rd1h6s/experimenting_with_qwen3vl32b/"}, {"source": "Reddit", "text": "My 2 cents on ZIT and Qwen Image 2512 Hey guys, I\u2019m currently using ZIT and QWEN. I run AI models on social networks like Instagram and TikTok, and I monetize them through FV.\n\nI know QWEN should technically be compared to Z Image Base, but I haven\u2019t tested ZIB properly yet. From my experience so far, QWEN feels qualitatively superior, especially when it comes to environments context and model poses. Everything looks softer and more realistic. That said, ZIT makes it much easier to achieve photo", "score": 0, "created": 1771896636.0, "url": "https://reddit.com/r/StableDiffusion/comments/1rd0uir/my_2_cents_on_zit_and_qwen_image_2512/"}, {"source": "Reddit", "text": "not a tutorial - just a quick fix if anyone is having OOM using QWEN image edit 2511 with Lighting LoRa , try this.   \nhi everyone, i am very new to AI generation and comfyUI (about 2 weeks in with no previous experience lol) in this time i have been really enjoying QWEN image edit 2511, however over the past 4-5 days out of nowhere i have been encountering the OOM (out of memory error) whilst loading the model before it even starts to generate the image.\n\ni am on the latest version of Nightly C", "score": 0, "created": 1771896569.0, "url": "https://reddit.com/r/comfyui/comments/1rd0tap/not_a_tutorial_just_a_quick_fix_if_anyone_is/"}, {"source": "Reddit", "text": "I got tired of rewriting the same prompts every day, so I built an open-source prompt ark that injects directly into ChatGPT, Claude, Gemini, and 11 other platforms I've been using AI platforms daily \u2014 ChatGPT for writing, Claude for code review, DeepSeek for Chinese queries, Gemini for research. After a few months I realized I was spending a stupid amount of time on one thing:\n\n**Rewriting the same prompts over and over.**\n\nI'd craft a great prompt, get perfect results, and then... never find i", "score": 1, "created": 1771894999.0, "url": "https://reddit.com/r/PromptEngineering/comments/1rd04q2/i_got_tired_of_rewriting_the_same_prompts_every/"}, {"source": "Reddit", "text": "Slow chat responses I have been having slow chat responses. I have switched from Ollama to QWen to now Open AI. QWen and Ollama have been local models running with a high context window, which was significantly slow due to the Mac Mini I have with only 16 GB of RAM. Now, when I chose to do Open AI as running a model, it will still take 55 seconds to respond. Is that normal for everyone, or is there something else? ", "score": 2, "created": 1771891639.0, "url": "https://reddit.com/r/openclaw/comments/1rcyngb/slow_chat_responses/"}, {"source": "Reddit", "text": "Qwen 3 Next Coder Hallucinating Tools? Anyone else experiencing this? I was workshopping a website prototype when I noticed it got stuck in a loop continuously attempting to \"make\" the website infrastructor itself.\n\n[Qwen 3 Coder Next hallucinating tool call in LM Studio](https://preview.redd.it/d147gfsolblg1.png?width=1218&amp;format=png&amp;auto=webp&amp;s=e8319a814e843fa052a0bcb5cfaa4219b84af4bc)\n\nIt went on like this for over an hour, stuck in a loop trying to do these tool calls.", "score": 4, "created": 1771885670.0, "url": "https://reddit.com/r/LocalLLaMA/comments/1rcw4sk/qwen_3_next_coder_hallucinating_tools/"}, {"source": "Reddit", "text": "Managing Comfy UI Chaos Hi everyone\n\nSo I've had all my models and workflows running on 2 separate instances of Comfy UI on a dedicated drive. One instance is just for using Trellis 3D mesh generation from images (because it requires specific python versions and other dependencies), and my other runs everything else like LTX, QWEN, Flux etc. \n\nAnyway, the main instance with all my other models broke after some updates and it's got me thinking about how best to avoid breaking so much stuff with a", "score": 0, "created": 1771883621.0, "url": "https://reddit.com/r/comfyui/comments/1rcv7ve/managing_comfy_ui_chaos/"}, {"source": "Reddit", "text": "\ud83c\udd95 New Tavern Models Added! Hey everyone! \ud83d\udc4b\n\nWe\u2019ve added several new Tavern models \u2014 check out the details and pricing below:\n\n# GLM 5\n\n**Usage Cost (Per Message)**\n\n* **Default &amp; Plus**: 15 unpaid/paid YoBeans\n* **Pro**: 14 unpaid/paid YoBeans\n* **Premium**: 12 unpaid/paid YoBeans\n* **Platinum**: 12 unpaid/paid YoBeans\n\n# Claude Sonnet 4.6\n\n**Usage Cost (Per Message)**\n\n* **Default &amp; Plus**: 18 paid YoBeans\n* **Pro**: 18 paid YoBeans\n* **Premium**: 17 paid YoBeans\n* **Platinum**: 17 paid", "score": 2, "created": 1771882573.0, "url": "https://reddit.com/r/YodayoTavern/comments/1rcuquz/new_tavern_models_added/"}, {"source": "Reddit", "text": "A new terminal AI agent just dropped! \ud83d\udd25OpenCrabs \u2014 An AI orchestration layer inspired by OpenClaw. Multi-provider support, 3-tier memory, hybrid search &amp; more...! |Feature|Description|\n|:-|:-|\n||\n|**Multi-Provider**|Anthropic Claude (with OAuth), OpenAI, OpenRouter (400+ models), Qwen, Azure, and any OpenAI-compatible API. Model lists fetched live from provider APIs \u2014 new models available instantly|\n|**Real-time Streaming**|Character-by-character response streaming with animated spinner show", "score": 1, "created": 1771877973.0, "url": "https://reddit.com/r/AIAGENTSNEWS/comments/1rcso8r/a_new_terminal_ai_agent_just_dropped_opencrabs_an/"}, {"source": "Reddit", "text": "Qwen 3.5 for MLX is like its own industrial revolution I'm using a 4-bit model on a mac studio m3 and it is mindblowing how fast this thing works for the quality of the results. I love it.", "score": 59, "created": 1771873194.0, "url": "https://reddit.com/r/Qwen_AI/comments/1rcqezx/qwen_35_for_mlx_is_like_its_own_industrial/"}, {"source": "Reddit", "text": "Arij - OSS project - Another agent / project manager. Kanban powered by any agent CLI Beware, non ai slop text onward.\n\nI present Arij to you (you can pronounce it how you want), a project / agent manager UI, that let you easily manage multiple agent across multiple CLI / models, and enforce an easy-to-read workflow.\n\nThe core idea is born during my own work habit. I usually work on many project at the same time, and as part of my job it to try and work with many different LLMs and coding agent ", "score": 1, "created": 1771872180.0, "url": "https://reddit.com/r/OpenSourceeAI/comments/1rcpxpj/arij_oss_project_another_agent_project_manager/"}, {"source": "Reddit", "text": "FoodTruck Bench update: tested Sonnet 4.6, Gemini 3.1 Pro, Qwen 3.5. Case studies with comparisons for each. Three new models tested and added to the leaderboard since last week's post: Claude Sonnet 4.6, Gemini 3.1 Pro, and Qwen 3.5 397B. Wrote detailed case studies for each. Here's the summary.\n\nClaude Sonnet 4.6 \u2014 massive leap from Sonnet 4.5. Genuine business reasoning, zero bankruptcies, $17.4K net worth. But here's the thing: a single simulation run on Sonnet costs only 10% less than Opus ", "score": 0, "created": 1771868165.0, "url": "https://reddit.com/r/LocalLLaMA/comments/1rco0d9/foodtruck_bench_update_tested_sonnet_46_gemini_31/"}, {"source": "Reddit", "text": "Am I stupid? Hi, so I'm kind new to this, I only just downloaded ComfyUI like two days ago. I've tried making my own workflow and making it run and it was alright. So far I've really only messed around with templates and other peoples workflows. I am trying to replace the pink jacket with the jean shorts while still keeping the background and the lighting of the \"pink jacket\" image. The best that I could do was ( 4th and 3rd images) with the \"Flux.2 Klein 4B: Image edit\" template but the backgro", "score": 0, "created": 1771866681.0, "url": "https://reddit.com/r/comfyui/comments/1rcnb44/am_i_stupid/"}, {"source": "Reddit", "text": "Stop babysitting LLMs. I built an MCP server where AI writes the code, and another AI (QwQ) audits it. We chat with an LLM, it loses context after 5 messages, and starts spitting out lazily written\u00a0`// implement the rest here`\u00a0placeholders. You end up being a micro-manager for an AI.\n\nI built the\u00a0**Qwen Engineering Engine**\u00a0(open-source MCP Server) to stop this.\n\nYou just talk naturally in your IDE chat (Cursor / Antigravity / Claude Desktop) like:\u00a0*\"Refactor the auth module.\"*\u00a0Under the hood, t", "score": 1, "created": 1771866494.0, "url": "https://reddit.com/r/google_antigravity/comments/1rcn7tu/stop_babysitting_llms_i_built_an_mcp_server_where/"}, {"source": "Reddit", "text": "Arij - OSS project - Another agent / project manager. Kanban powered by any agent CLI. Beware, non ai slop text onward.\n\nI present Arij to you (you can pronounce it how you want), a project / agent manager UI, that let you easily manage multiple agent across multiple CLI / models, and enforce an easy-to-read workflow.\n\nThe core idea is born during my own work habit. I usually work on many project at the same time, and as part of my job it to try and work with many different LLMs and coding agent", "score": 4, "created": 1771862958.0, "url": "https://reddit.com/r/LocalLLaMA/comments/1rclk23/arij_oss_project_another_agent_project_manager/"}, {"source": "Reddit", "text": "How to drastically reduce token usage in OpenClaw? (context, memory, gateway optimization) I\u2019m currently running OpenClaw on my own VPS with external LLM providers (Kimi, Qwen, GLM, etc.), and I\u2019m trying to significantly reduce token consumption while maintaining good reasoning quality.\n\nRight now, token usage increases very quickly, especially due to:\n\n\t\u2022\tlarge conversation context being resent every turn\n\n\t\u2022\tmemory injection from the memory plugin\n\n\t\u2022\tsystem prompts and tool schemas being repe", "score": 3, "created": 1771862341.0, "url": "https://reddit.com/r/openclaw/comments/1rcl9oz/how_to_drastically_reduce_token_usage_in_openclaw/"}, {"source": "Reddit", "text": "Squeezed in two different local LLMs for analyzing PDFs and generating summaries or replying to questions Hey guys,  \n\n\nMe and my buddy run a small indie dev studio and we built\u00a0[myPDF](https://apps.apple.com/ro/app/pdf-master-scan-edit-sign/id6751173174), a lightweight, privacy-first, and (hopefully) not annoying to use full PDF editor.  \n  \nWe've added on iOS and macOS a local LiquidAI LLM which runs on-device and is able to  analyze your PDF file and answer any questions you might have about ", "score": 3, "created": 1771859514.0, "url": "https://reddit.com/r/BlackboxAI_/comments/1rck0gp/squeezed_in_two_different_local_llms_for/"}, {"source": "Reddit", "text": "Qwen3-Coder-Next is now the #1 most downloaded model on Unsloth! Qwen3-Coder Next has been really gaining a lot of traction recently and with the recent llama.cpp fixes and speed improvements, the model seems like an even better choice now.\n\nAlso there's been new benchmarks conducted for the Unsloth Dynamic GGUFs and the results are surprisingly great even at lower bits! The XL 3-bit one works on a 36GB RAM device.\n\nTo learn how to run the model (Claude Code, Codex, llama.cpp) and see quant benc", "score": 182, "created": 1771858964.0, "url": "https://reddit.com/r/unsloth/comments/1rcjrux/qwen3codernext_is_now_the_1_most_downloaded_model/"}, {"source": "Reddit", "text": "V6rge \u2014 unified local AI \u2014 now on MS Store We will appreciate suggestions  \n\n[https://apps.microsoft.com/detail/9NS36H0M4S9N?hl=en&amp;gl=US&amp;ocid=pdpshare](https://apps.microsoft.com/detail/9NS36H0M4S9N?hl=en&amp;gl=US&amp;ocid=pdpshare)\n\nhttps://preview.redd.it/fj4duvord9lg1.png?width=1358&amp;format=png&amp;auto=webp&amp;s=1ed51a9408033094bb13f5b980fbc95a9b1f17e9\n\nhttps://preview.redd.it/nx2b1ic2e9lg1.png?width=1343&amp;format=png&amp;auto=webp&amp;s=ed827a0007a8f8f1a970d91d025656e604a5e22", "score": 3, "created": 1771858959.0, "url": "https://reddit.com/r/LocalLLM/comments/1rcjrsm/v6rge_unified_local_ai_now_on_ms_store/"}, {"source": "Reddit", "text": "Sarvam would be better off making smaller separate models for each language. The architectural details for the 30B and 105B models haven't been released yet, except for this blog on Nvidia's website [https://developer.nvidia.com/blog/how-nvidia-extreme-hardware-software-co-design-delivered-a-large-inference-boost-for-sarvam-ais-sovereign-models/](https://developer.nvidia.com/blog/how-nvidia-extreme-hardware-software-co-design-delivered-a-large-inference-boost-for-sarvam-ais-sovereign-models/)\n\n&", "score": 3, "created": 1771855037.0, "url": "https://reddit.com/r/AI_India/comments/1rci42p/sarvam_would_be_better_off_making_smaller/"}, {"source": "Reddit", "text": "Cheap models are extremely under-rated! These models will automate routine tasks and will play a key role in achieveing  \n  \nBest cheap / small models in the world today  \n  \nGemini Flash 3  - excellent price for performance  \nKimi K2.5 - very good on benchmarks  \nHaiku 4.5 -   faster and better than Flash  \nGPT 5 nano - insanely fast, great for a classifier  \nQwen family - great for fine-tuning", "score": 1, "created": 1771854701.0, "url": "https://reddit.com/r/abacusai/comments/1rchz82/cheap_models_are_extremely_underrated/"}, {"source": "HackerNews", "text": "Off Grid: On-device AI-web browsing, tools, vision, image gen, voice \u2013 3x faster Nine days ago I posted Off Grid here and you showed up - 124 points, 66 comments, bug reports I fixed same-day, and the kind of feedback that makes open source worth it.<p>You told me what you wanted. \nHere&#x27;s what I shipped:\nYour AI can now use tools - entirely offline.<p>Web search, calculator, date&#x2F;time, device info - with automatic tool loops.<p>Your 3B parameter model doesn&#x27;t just generate text an", "score": 1, "created": "2026-02-24T19:43:48Z", "url": "https://news.ycombinator.com/item?id=47141803"}, {"source": "HackerNews", "text": "Show HN: I applied Markowitz port. theory to agent teams / proved it in a zkVM I run multi-agent teams in high-consequence scenarios. Read: fuckups at 3 AM = I&#x27;m awake.<p>I kept hitting the same issue. I couldn&#x27;t get a rules-based system to enforce behavior <i>and</i> I had no real way to prove that agents really did what they said they did. I can log and monitor them - set up (a million) Slack alerts but none of these things are PROOF. Logs are mutable. And that matters more every day", "score": 2, "created": "2026-02-24T19:41:04Z", "url": "https://news.ycombinator.com/item?id=47141753"}, {"source": "HackerNews", "text": "Qwen 3.5 small models out ", "score": 4, "created": "2026-02-24T18:55:22Z", "url": "https://news.ycombinator.com/item?id=47141052"}, {"source": "HackerNews", "text": "Replacing Anthropic's API with 2x 3090s. Claude Code on a local 80B Qwen model ", "score": 1, "created": "2026-02-24T17:02:46Z", "url": "https://news.ycombinator.com/item?id=47139507"}, {"source": "HackerNews", "text": "Show HN: oMLX \u2013 coding agents on local LLMs without the painful reprefill I was frustrated that coding agents like Claude Code were basically unusable with local models. every few turns the prefix shifts, KV cache gets invalidated, and your mac has to re-prefill the entire context from scratch.<p>So i built oMLX. it persists KV cache blocks to SSD, and when a previous context comes back, it restores from disk instead of recomputing. this alone made Qwen3-Coder-80B on my M3 Ultra actually usable ", "score": 3, "created": "2026-02-24T16:35:45Z", "url": "https://news.ycombinator.com/item?id=47139158"}, {"source": "HackerNews", "text": "Show HN: Glass Box: writing editor that exports a verifiable PDF of your process We built a local-first writing editor that records the composition process (keystrokes, paste events, AI interactions) and exports a PDF with annotation highlights + an AI usage appendix.<p>The motivation: AI detectors are genuinely broken. Stanford research showed &gt;60% false positive rates for non-native English writers on TOEFL essays. The &quot;solution&quot; from institutions has been to buy more detectors or", "score": 2, "created": "2026-02-24T15:20:16Z", "url": "https://news.ycombinator.com/item?id=47138273"}, {"source": "HackerNews", "text": "Show HN: Waggle \u2013 A search engine for A2A protocol agents Hey HN,<p>I&#x27;ve been following Google&#x27;s A2A protocol since it launched and noticed that there is still no good way to find agents out on the public internet. They&#x27;re scattered across GitHub repos, registries, cloud deployments, random subdomains, and many go offline without anyone noticing.<p>So I built Waggle, which is a search engine that crawls the web for any domain that exposes a valid agent card, indexes them with sema", "score": 1, "created": "2026-02-24T15:05:12Z", "url": "https://news.ycombinator.com/item?id=47138064"}, {"source": "HackerNews", "text": "Show HN: Dicta.to \u2013 Local voice dictation for Mac with on-device AI I built a macOS dictation app where everything runs on-device. Transcription, auto-correct, translation. No audio or text leaves your machine.<p>It ships with 4 transcription engines you can swap between: WhisperKit (99 languages), NVIDIA Parakeet TDT 0.6B (25 European languages, fastest of the bunch), Qwen3-ASR 0.6B (30 languages), and Apple Speech on macOS 26+. They all run through CoreML&#x2F;Metal. Whisper is the most versat", "score": 2, "created": "2026-02-24T14:07:58Z", "url": "https://news.ycombinator.com/item?id=47137329"}, {"source": "HackerNews", "text": "Show HN: Lila-E8 \u2013 40M Parameter LLM with 0.37 Loss via E8 Lattice Attention I\u2019m excited to release Sovereign-Lila-E8, a novel transformer architecture that replaces standard attention mechanisms with a native E8 Root System Lattice.\nWhile the industry is brute-forcing intelligence with trillions of parameters, I went &quot;outside&quot; the system to find a zero-viscosity solution.<p>I built Sovereign-Lila-E8 because I wanted to see if we could bypass the &#x27;viscosity&#x27; of standard atten", "score": 1, "created": "2026-02-24T13:03:05Z", "url": "https://news.ycombinator.com/item?id=47136591"}, {"source": "HackerNews", "text": "Show HN: Touch Trigonometry \u2013 interactive way to understand the trig functions I started to teach myself to code around 15 years ago. At the time I was working service industry jobs (restaurant kitchens, coffee shops) and desperate to change my career and life.<p>Around that time there was a new thing called &lt;canvas&gt; available in HTML5 that you could use to render graphics in web pages without plugins; despite my limited knowledge of tech and lack of coding skills, I knew I wanted to be a ", "score": 2, "created": "2026-02-23T20:56:03Z", "url": "https://news.ycombinator.com/item?id=47128665"}, {"source": "HackerNews", "text": "I replaced my observability alerts with an AI agent that understands production Built a tiny ECS container that queries our observability data via ClickHouse SQL, compares against 7-day history, and alerts on Slack. Went from DuckDB prototype \u2192 Lambda \u2192 long-running agent in about a week.", "score": 1, "created": "2026-02-22T09:46:31Z", "url": "https://news.ycombinator.com/item?id=47109729"}, {"source": "HackerNews", "text": "Show HN: AI agent that watches production 24/7 for $15/month Built a tiny ECS container that queries our observability data via ClickHouse SQL, compares against 7-day history, and alerts on Slack. Went from DuckDB prototype \u2192 Lambda \u2192 long-running agent in about a week.", "score": 3, "created": "2026-02-22T09:11:27Z", "url": "https://news.ycombinator.com/item?id=47109552"}, {"source": "HackerNews", "text": "I Got Pwned by a Malicious AI Plugin: A Technical Breakdown *Context:* I run OpenClaw. On Feb 5th, I installed `@getfoundry&#x2F;unbrowse-openclaw` from npm. Two weeks later, I discovered it was exfiltrating credentials to a remote &quot;skill marketplace.&quot; I did something stupid and I am sharing this to warn others.<p>## Attack Vectors<p>### 1. Process Environment Access<p>Plugin ran inside the OpenClaw gateway (Node.js). Could read `process.env`, which included:<p>- `OP_SERVICE_ACCOUNT_TO", "score": 3, "created": "2026-02-22T07:41:27Z", "url": "https://news.ycombinator.com/item?id=47109114"}, {"source": "HackerNews", "text": "No LLM, No training data, No cloud \u2013 Engine that understands architecture Point it at a codebase. Any language. Any size.<p>In under a second it tells you the architecture. Not a dependency graph. Not a file tree. The actual architecture \u2014 what orchestrates what, where state lives, where the boundaries are, what breaks if you touch something.<p>I&#x27;ve run it against 45,000+ functions across 6 real-world codebases in 4 languages. It works. On a laptop. No cloud. No GPU. No setup.<p>Everyone&#x", "score": 2, "created": "2026-02-22T05:50:12Z", "url": "https://news.ycombinator.com/item?id=47108587"}, {"source": "HackerNews", "text": "Show HN: A 2D animation DSL \u2013 every line written by Claude, zero human code I wanted to see how far vibe coding could actually go. Not autocomplete, not copilot \u2014 I gave Claude Opus 4.6 (running in OpenCode, an agentic CLI) full ownership of building a domain-specific language for generating 2D animated movies from code.\nThe constraint: I describe what I want, the agent builds it. I critique the output, the agent iterates. No human touches the code at any point. Not the parser, not the renderer,", "score": 1, "created": "2026-02-22T04:09:57Z", "url": "https://news.ycombinator.com/item?id=47108065"}, {"source": "HackerNews", "text": "Show HN: Omni-Glass \u2013 Rust app that turns screen pixels into MCP tool calls Omni-Glass is an open-source macOS app (Rust&#x2F;Tauri) that sits in your menu bar. You draw a box around anything on your screen \u2014 a terminal error, a data table, a foreign-language doc \u2014 and it runs local OCR, sends the text to an LLM, and gives you a menu of executable actions in under a second. Not explanations. Actions. It fixes the error, exports the CSV, creates the GitHub issue, runs the command.\nThe LLM layer s", "score": 3, "created": "2026-02-22T00:07:24Z", "url": "https://news.ycombinator.com/item?id=47106525"}, {"source": "HackerNews", "text": "Show HN: BetaZero, a diffusion climb generator for system boards BetaZero is a free web application which allows users to generate, edit, and share board climbs. It currently supports the Kilter, TB2 and Decoy boards, with Moonboard 2016, 2019 and 2024 to be added next week. However, the underlying generative model works on any 2D system board, so long as that board is angled between 0* and 90* and the holds are properly formatted (For reference, this model was not trained on the Decoy board, so", "score": 2, "created": "2026-02-21T23:45:24Z", "url": "https://news.ycombinator.com/item?id=47106355"}, {"source": "HackerNews", "text": "Show HN: HN Showcase \u2013 I rebuilt my 2011 Show HN gallery with AI curation I built HN Showcase as a weekend project in 2011 (<a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=2843490\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=2843490</a>) - a thumbnail gallery for Show HN posts. It got some love (<a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=4053755\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=4053755</a>, 158 pts), then went offline like all side proje", "score": 3, "created": "2026-02-21T07:07:57Z", "url": "https://news.ycombinator.com/item?id=47098260"}, {"source": "HackerNews", "text": "Show HN: Give your OpenClaw agent a face and voice with LiveKit and LemonSlice For a fun side weekend project we gave our own OpenClaw agent called &quot;Mahmut&quot; a face and had a live interview with it. It went surprisingly well.<p>Here&#x27;s a sneak peek from the interview: <a href=\"https:&#x2F;&#x2F;x.com&#x2F;ptservlor&#x2F;status&#x2F;2024597444890128767\" rel=\"nofollow\">https:&#x2F;&#x2F;x.com&#x2F;ptservlor&#x2F;status&#x2F;2024597444890128767</a><p>User speaks, Deepgram transcribes i", "score": 5, "created": "2026-02-21T00:50:20Z", "url": "https://news.ycombinator.com/item?id=47096208"}, {"source": "HackerNews", "text": "ChatGPT Now Enforces Data Access Controls Got a popup saying ChatGPT will now use my conversations to train their AI. Went into the Access Controls section in settings to turn it off \u2014 the toggle doesn&#x27;t work. Deleted my account.", "score": 4, "created": "2026-02-20T21:36:11Z", "url": "https://news.ycombinator.com/item?id=47094315"}, {"source": "HackerNews", "text": "Instance segmentation model that extracts 3D geometry from 2D floor plans Hey HN,<p>I am an ML Engineer and a full-stack software engineer. For the past few weekends, I have been working on a pipeline to solve a PropTech problem: turning messy, highly occluded 2D floor plans into clean, structured data for 3D extrusion. Originally demoed for a firm hiring for the role.<p>The Problem:\nIf you try to use standard object detection (bounding boxes) or basic OCR (tested Qwen, DeepSeek) on architectura", "score": 2, "created": "2026-02-20T19:17:57Z", "url": "https://news.ycombinator.com/item?id=47092547"}, {"source": "HackerNews", "text": "Show HN: Tropes.fyi \u2013 Name and shame AI writing Today I come to you on this beautiful Friday with a freshly hardthink-ed solution to a proliferous problem plaguing our world: the loss of original voice. The blanket of blandness slowly suffocating centuries of writing.<p>Or to put it bluntly: AI writing is trash.<p>It is disrespectful to expect ME to read something YOU could not even be bothered to write (or likely even read).\nThe lingering human connection that remained resilient on the internet", "score": 5, "created": "2026-02-20T14:58:25Z", "url": "https://news.ycombinator.com/item?id=47088813"}, {"source": "HackerNews", "text": "Ask HN: How did you get your drive back? Feeling lost at the moment, and don&#x27;t feel like repeating myself to an LLM for advice again so I thought I would maybe ask here.<p>So I&#x27;m in my early 30&#x27;s, I&#x27;ve built the career and got all the high position roles one strives for in our profession, travelled everywhere, lived and worked overseas and done everything I&#x27;ve wanted to except starting my own business.<p>2020 came which I feel wiped me out (mentally and economically). I&", "score": 3, "created": "2026-02-20T14:10:05Z", "url": "https://news.ycombinator.com/item?id=47088256"}, {"source": "HackerNews", "text": "The Car Wash Problem: A variable isolation study on prompt architecture Most AI products inject facts and hope reasoning follows. But intelligence is not measured by how much a model holds in its context window.\nIt is measured by knowing to pick up the keys before leaving the house.<p>Last week, the &quot;Car Wash problem&quot; (50m away, walk or drive?) went viral here on HN. Every major LLM failed because they missed the implicit physical constraint: the car must be there.\nWhile testing Interv", "score": 2, "created": "2026-02-20T13:23:56Z", "url": "https://news.ycombinator.com/item?id=47087746"}, {"source": "HackerNews", "text": "Show HN: InkSight \u2013 An open-source, LLM-powered e-ink display for \"slow info\" Generate personalized content based on the current environment (weather, time, date, and solar terms) via backend LLMs (DeepSeek &#x2F; Qwen &#x2F; Kimi) for display on a 4.2-inch E-ink screen.", "score": 1, "created": "2026-02-20T13:23:30Z", "url": "https://news.ycombinator.com/item?id=47087739"}, {"source": "HackerNews", "text": "Show HN: AstroLens \u2013 AI that watches the sky and finds what nobody catalogued # Show HN: AstroLens -- AI that watches the sky and finds what nobody catalogued<p>*<a href=\"https:&#x2F;&#x2F;github.com&#x2F;samantaba&#x2F;astroLens**\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;samantaba&#x2F;astroLens**</a> (MIT licensed, Python)<p>AstroLens is an open-source tool that downloads images from sky surveys (SDSS, ZTF, DECaLS, Pan-STARRS, Hubble, and others), runs them through a Vision Transforme", "score": 1, "created": "2026-02-20T08:50:37Z", "url": "https://news.ycombinator.com/item?id=47085410"}, {"source": "HackerNews", "text": "Show HN: I Built a Kotlin Package Manager (KPM) Disclaimer: Still in alpha. Also vibe coded, so... you&#x27;ve been warned.<p>I&#x27;m not really sure where this is going or if it needs to go anywhere, but as someone who lives in Kotlin based projects almost all day, I always envied web-devs with their npm&#x27;s and bun&#x27;s. Or Python devs with their pips.<p>Using those tools makes spinning up a project or adding dependencies seem so frictionless. No Google searches for every dependency path", "score": 1, "created": "2026-02-20T04:23:37Z", "url": "https://news.ycombinator.com/item?id=47083709"}, {"source": "HackerNews", "text": "Show HN: Local TTS for OpenClaw on Apple Silicon (MLX-Powered, Zero Setup) I built an OpenClaw plugin that runs text-to-speech entirely on your Mac. No API keys, no cloud, no pre-installed Python required.<p>It wraps mlx-audio and handles the full lifecycle: bootstraps its own Python environment via uv, downloads the model on first run, manages the server process, auto-restarts on crash, and exposes a standard OpenAI-compatible &#x2F;v1&#x2F;audio&#x2F;speech endpoint.<p>Installation:<p>openclaw", "score": 2, "created": "2026-02-20T03:00:32Z", "url": "https://news.ycombinator.com/item?id=47083116"}, {"source": "HackerNews", "text": "Unpaid \u2013 AI payment reminders that verify, escalate, and auto-reply I built a tool because I was tired of writing this email:<p><pre><code>  &quot;Hi, just following up on my invoice from 3 weeks ago...&quot;\n\n  I ran a small business from 2016 to 2019 and lost it because\n  clients didn&#x27;t pay on time. The stress of constantly following up,\n  not knowing what to write without sounding rude, feeling like\n  you&#x27;re begging to be paid \u2014 it eventually broke the business.\n  I sold at a loss a", "score": 1, "created": "2026-02-20T02:05:01Z", "url": "https://news.ycombinator.com/item?id=47082761"}, {"source": "HackerNews", "text": "The $2k Laptop That Replaced My $200/Month AI Subscription Cloud AI pricing is per-token. The more useful your pipeline, the more it costs. I built a dual-model orchestration pattern that routes 80% of work to a free local model (Qwen3 8B on Ollama, GPU-accelerated) and only sends the synthesis&#x2F;judgment stage to a cloud API.<p>Cost for a 50-item research pipeline: $0.15-0.40 vs $8-15 all-cloud. Same output quality where it matters.<p>Stack: RTX 5080 laptop, Ollama in Docker with GPU passthr", "score": 8, "created": "2026-02-19T14:47:59Z", "url": "https://news.ycombinator.com/item?id=47074347"}, {"source": "HackerNews", "text": "Show HN: Assign tasks to 7 AI agents with -mentions, autonomous mode, OpenClaw I posted Mysti here a couple months ago and got a lot of feedback that shaped where I took it. Quick recap: it&#x27;s a VS Code extension that lets you use multiple AI coding agents through one interface, including having them collaborate on problems.<p>Three things I want to highlight in this release.<p>@-mentions for task delegation. You can now assign work to specific agents inline. Something like: @claude write th", "score": 1, "created": "2026-02-18T18:10:51Z", "url": "https://news.ycombinator.com/item?id=47064122"}, {"source": "HackerNews", "text": "Self-Hosted LLM Upgrade on AMD: Kimi Linear 48B, Qwen3 Coder Next, and Q2_K_XL ", "score": 3, "created": "2026-02-18T16:06:26Z", "url": "https://news.ycombinator.com/item?id=47062512"}, {"source": "HackerNews", "text": "Show HN: Prompts are coupled to LLMs and nobody builds tooling for it I went down a rabbit hole trying to understand why my Claude prompts turn to garbage on GPT-4 and vice versa. Not just &quot;slightly worse&quot; \u2014 fundamentally broken. Turns out researchers have already measured this: removing colons from a prompt template swings LLaMA-2-13B accuracy by 78 percentage points (Sclar et al., ICLR 2024). The format that works best on one model family overlaps less than 20% with what works best o", "score": 2, "created": "2026-02-18T14:41:57Z", "url": "https://news.ycombinator.com/item?id=47061443"}, {"source": "HackerNews", "text": "Tell HN: We analyzed our dev time.80% is still infrastructure'setup',notfeatures We recently did a deep dive into our engineering time allocation for a standard 5-person team building a B2B SaaS application. The results were pretty depressing: we spent roughly 960 hours (annualized) on &quot;setup&quot; tasks\u2014environment config, auth flows, RBAC, CI&#x2F;CD pipelines, and database scaffolding\u2014before we built a single unique feature that actually differentiated the product.<p>I\u2019m sharing this bec", "score": 13, "created": "2026-02-18T12:20:13Z", "url": "https://news.ycombinator.com/item?id=47060234"}, {"source": "HackerNews", "text": "Ask HN: Do you think China will produce a SOTA model in the next 2 years Recent models like Kimi, Qwen, GLM, Deepseek etc seem to do well in benchmarks but not when actually using them in practise. Do you think they&#x27;ll be an actual SOTA model by them in the next 2 years? Why&#x2F;why not?<p>NOTE: referring to text models", "score": 3, "created": "2026-02-18T11:18:12Z", "url": "https://news.ycombinator.com/item?id=47059842"}, {"source": "HackerNews", "text": "Ask HN: How do you debug multi-step AI workflows when the output is wrong? I\u2019ve been building multi-step AI workflows with multiple agents (planning, reasoning, tool use, etc.), and I sometimes run into cases where the final output is incorrect even though nothing technically fails. There are no runtime errors - just wrong results.<p>The main challenge is figuring out where things went wrong. The issue could be in an early reasoning step, how context is passed between steps, or a subtle mistake ", "score": 4, "created": "2026-02-18T10:55:45Z", "url": "https://news.ycombinator.com/item?id=47059704"}, {"source": "HackerNews", "text": "After a fierce competition OpenAI hired Peter Steineberger ", "score": 2, "created": "2026-02-18T08:17:55Z", "url": "https://news.ycombinator.com/item?id=47058570"}, {"source": "HackerNews", "text": "Show HN: I analyzed 120 films to help screenwriters test narrative structure Almost 10 years ago, I used to host a film club in my office. A friend of mine was hosting one in the city and they needed a space.<p>I had an openfloor office and that meant we clear the space, fire up the projector and can host the film club. They met between 9pm to 7am once a month, on a friday. Each meeting had 100-150 people attending.<p>This went on for a few months - there was a curator assigned for each meet who", "score": 2, "created": "2026-02-18T07:42:13Z", "url": "https://news.ycombinator.com/item?id=47058351"}, {"source": "HackerNews", "text": "Show HN: AIBenchy \u2013 Independent AI Leaderboard Hey HN,\nLike many of you, I&#x27;m tired of public AI leaderboards that mostly recycle the same saturated&#x2F;overfitted benchmarks (MMLU, HumanEval, etc.) and often miss fast&#x2F;cheap variants or real daily pain points.<p>A couple days ago I launched AIBenchy \u2014 a small, opinionated leaderboard running my own custom tests focused on end-user&#x2F;dev scenarios that actually trip up models today.<p>Current tests cover categories like:<p>- Anti-AI ", "score": 1, "created": "2026-02-18T02:31:35Z", "url": "https://news.ycombinator.com/item?id=47056436"}, {"source": "HackerNews", "text": "Show HN: NadirClaw, LLM router that cuts costs by routing prompts right I use Claude and Codex heavily for coding, and I kept burning through my quota halfway through the week. When I looked at my logs, most of my prompts were things like &quot;summarize this,&quot; &quot;reformat this JSON,&quot; or &quot;write a docstring.&quot; Stuff that any small model handles fine.<p>So I built NadirClaw. It&#x27;s a Python proxy that sits between your app and your LLM providers. It classifies each prompt ", "score": 1, "created": "2026-02-17T23:31:18Z", "url": "https://news.ycombinator.com/item?id=47054977"}, {"source": "HackerNews", "text": "Show HN: Cursor for Observability Hi HN, I&#x27;ve been building RocketLogs, an intelligence observability layer that sits on top of Loki, Tempo, and Prometheus.<p>The problem I kept running into: you get paged at 3 AM, open Grafana, flip between six dashboards, grep through logs, try to figure out which deploy went out, and an hour later you maybe have a root cause. You still need to dig through code and find the culprit. The data is all there, but nothing connects it for you.<p>RocketLogs trie", "score": 3, "created": "2026-02-17T21:50:04Z", "url": "https://news.ycombinator.com/item?id=47053906"}, {"source": "HackerNews", "text": "Ask HN: Best multi-lingual text-to-speech system I&#x27;m looking for a way to bulk-generate audio based on text files.  Ideally, it would be a system I can run locally (M3 mac, 24GB RAM), and support at least 10 languages natively.<p>I have tried a few systems (eSpeak, Piper, QWEN) and none of them have given satisfactory results.  Huggingface seems to have no text-to-speech models with particular acclaim, either.  I have been using OpenAI&#x27;s gpt-4o-mini model, but that seems to be approach", "score": 2, "created": "2026-02-17T18:53:05Z", "url": "https://news.ycombinator.com/item?id=47051425"}, {"source": "HackerNews", "text": "Show HN: WodBlock \u2013 the AI-powered workout timer Hi, I&#x27;m Nico. I do CF&#x2F;functional workouts on a regular basis and use timers to measure my progress. These workouts usually involve a few different blocks, with different types of timers and rest in between. I couldn&#x27;t find an app that would allow me to set it and forget it so I went ahead and built it myself. I soon realized entering the blocks by hand is a bit tedious, so I added coach Woddie, which allows the users to talk to set ", "score": 2, "created": "2026-02-17T17:44:42Z", "url": "https://news.ycombinator.com/item?id=47050431"}, {"source": "HackerNews", "text": "Show HN: AIP \u2013 An open protocol for verifying what AI agents are allowed to do Hey HN,<p>I&#x27;ve been building AIP (Agent Intent Protocol) \u2014 an open, cryptographic protocol for identity and authorization of autonomous AI agents.<p>The problem: Every AI agent framework (LangChain, CrewAI, AutoGen) gives agents the ability to act \u2014 call APIs, send emails, move money, access databases. But there&#x27;s no standard way to verify what an agent is allowed to do before it does it. No identity system,", "score": 1, "created": "2026-02-17T17:29:17Z", "url": "https://news.ycombinator.com/item?id=47050216"}, {"source": "HackerNews", "text": "Launch HN: Sonarly (YC W26) \u2013 AI agent to triage and fix your production alerts Hey HN, I am Dimittri and we\u2019re building Sonarly (<a href=\"https:&#x2F;&#x2F;sonarly.com\">https:&#x2F;&#x2F;sonarly.com</a>), an AI engineer for production. It connects to your observability tools like Sentry, Datadog, or user feedback channels, triages issues, and fixes them to cut your resolution time. Here&#x27;s a demo: <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=rr3VHv0eRdw\" rel=\"nofollow\">https:&#x2", "score": 30, "created": "2026-02-17T17:03:09Z", "url": "https://news.ycombinator.com/item?id=47049776"}, {"source": "HackerNews", "text": "Show HN: My 16MB vibe-coded voice cloning app I vibe coded this text to speech app in an hour last weekend. It uses the new open weight Qwen models so it&#x27;s fully local. Supports both instruct and voice cloning.<p>And since it&#x27;s built with Electrobun it&#x27;s only 16MB and uses typescript for the main and browser views.", "score": 2, "created": "2026-02-17T16:11:35Z", "url": "https://news.ycombinator.com/item?id=47049077"}, {"source": "HackerNews", "text": "Show HN: Local Voice Assistant Several weeks ago I built a fully-local voice assistant demo with a FastAPI backend and a simple HTML front-end. All the models (ASR &#x2F; LLM &#x2F; TTS) are open weight and running locally, i.e. no data is being sent to the Internet nor any API. It&#x27;s intended to demonstrate how easy it is to run a fully-local AI setup on affordable commodity hardware, while also demonstrating the uncanny valley and teasing out the ethical considerations of such a setup - it", "score": 2, "created": "2026-02-17T16:07:02Z", "url": "https://news.ycombinator.com/item?id=47049030"}, {"source": "HackerNews", "text": "Show HN: Gait \u2013 because \"what did the AI agent do?\" shouldn't require guesswork I run cloud and AI infrastructure at an enterprise. Over the past year agents went from experiments to touching real systems with real credentials. Then one broke. Legal asked what happened. We had logs but no reproducible artifact, no proof of what policy governed the action, no way to show the same inputs would produce the same behavior again.\nNobody was building this internally, so I started building it at 11pm af", "score": 1, "created": "2026-02-17T13:18:13Z", "url": "https://news.ycombinator.com/item?id=47047189"}]}